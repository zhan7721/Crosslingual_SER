Loading python/3.10.8-gpu
  Loading requirement: nvidia/nvhpc-nompi/22.2 gcc/10.2.0
    openmpi/4.1.6-cuda-11.6
Loading pytorch/1.13.1-gpu
  Loading requirement: nvidia/cudnn/8.6.0-cuda-11.6 nvidia/tensorrt/8.4.3.1-u2
    libsndfile/1.0.28
------------------NEXT SCRIPT: RUNNER_DE----------------------
/work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Matplotlib created a temporary cache directory at /dev/shm/zhan7721_5912051/matplotlib-v1g6ozdj because the default path (/home/tc062/tc062/zhan7721/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Some weights of the model checkpoint at /work/tc062/tc062/zhan7721/saved_models/de were not used when initializing Wav2Vec2Model: ['encoder.layers.10.attention.k_proj.bias', 'encoder.layers.10.attention.k_proj.weight', 'encoder.layers.10.attention.out_proj.bias', 'encoder.layers.10.attention.out_proj.weight', 'encoder.layers.10.attention.q_proj.bias', 'encoder.layers.10.attention.q_proj.weight', 'encoder.layers.10.attention.v_proj.bias', 'encoder.layers.10.attention.v_proj.weight', 'encoder.layers.10.feed_forward.intermediate_dense.bias', 'encoder.layers.10.feed_forward.intermediate_dense.weight', 'encoder.layers.10.feed_forward.output_dense.bias', 'encoder.layers.10.feed_forward.output_dense.weight', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.10.layer_norm.bias', 'encoder.layers.10.layer_norm.weight', 'encoder.layers.11.attention.k_proj.bias', 'encoder.layers.11.attention.k_proj.weight', 'encoder.layers.11.attention.out_proj.bias', 'encoder.layers.11.attention.out_proj.weight', 'encoder.layers.11.attention.q_proj.bias', 'encoder.layers.11.attention.q_proj.weight', 'encoder.layers.11.attention.v_proj.bias', 'encoder.layers.11.attention.v_proj.weight', 'encoder.layers.11.feed_forward.intermediate_dense.bias', 'encoder.layers.11.feed_forward.intermediate_dense.weight', 'encoder.layers.11.feed_forward.output_dense.bias', 'encoder.layers.11.feed_forward.output_dense.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.11.layer_norm.bias', 'encoder.layers.11.layer_norm.weight', 'encoder.layers.5.attention.k_proj.bias', 'encoder.layers.5.attention.k_proj.weight', 'encoder.layers.5.attention.out_proj.bias', 'encoder.layers.5.attention.out_proj.weight', 'encoder.layers.5.attention.q_proj.bias', 'encoder.layers.5.attention.q_proj.weight', 'encoder.layers.5.attention.v_proj.bias', 'encoder.layers.5.attention.v_proj.weight', 'encoder.layers.5.feed_forward.intermediate_dense.bias', 'encoder.layers.5.feed_forward.intermediate_dense.weight', 'encoder.layers.5.feed_forward.output_dense.bias', 'encoder.layers.5.feed_forward.output_dense.weight', 'encoder.layers.5.final_layer_norm.bias', 'encoder.layers.5.final_layer_norm.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.6.attention.k_proj.bias', 'encoder.layers.6.attention.k_proj.weight', 'encoder.layers.6.attention.out_proj.bias', 'encoder.layers.6.attention.out_proj.weight', 'encoder.layers.6.attention.q_proj.bias', 'encoder.layers.6.attention.q_proj.weight', 'encoder.layers.6.attention.v_proj.bias', 'encoder.layers.6.attention.v_proj.weight', 'encoder.layers.6.feed_forward.intermediate_dense.bias', 'encoder.layers.6.feed_forward.intermediate_dense.weight', 'encoder.layers.6.feed_forward.output_dense.bias', 'encoder.layers.6.feed_forward.output_dense.weight', 'encoder.layers.6.final_layer_norm.bias', 'encoder.layers.6.final_layer_norm.weight', 'encoder.layers.6.layer_norm.bias', 'encoder.layers.6.layer_norm.weight', 'encoder.layers.7.attention.k_proj.bias', 'encoder.layers.7.attention.k_proj.weight', 'encoder.layers.7.attention.out_proj.bias', 'encoder.layers.7.attention.out_proj.weight', 'encoder.layers.7.attention.q_proj.bias', 'encoder.layers.7.attention.q_proj.weight', 'encoder.layers.7.attention.v_proj.bias', 'encoder.layers.7.attention.v_proj.weight', 'encoder.layers.7.feed_forward.intermediate_dense.bias', 'encoder.layers.7.feed_forward.intermediate_dense.weight', 'encoder.layers.7.feed_forward.output_dense.bias', 'encoder.layers.7.feed_forward.output_dense.weight', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.7.layer_norm.bias', 'encoder.layers.7.layer_norm.weight', 'encoder.layers.8.attention.k_proj.bias', 'encoder.layers.8.attention.k_proj.weight', 'encoder.layers.8.attention.out_proj.bias', 'encoder.layers.8.attention.out_proj.weight', 'encoder.layers.8.attention.q_proj.bias', 'encoder.layers.8.attention.q_proj.weight', 'encoder.layers.8.attention.v_proj.bias', 'encoder.layers.8.attention.v_proj.weight', 'encoder.layers.8.feed_forward.intermediate_dense.bias', 'encoder.layers.8.feed_forward.intermediate_dense.weight', 'encoder.layers.8.feed_forward.output_dense.bias', 'encoder.layers.8.feed_forward.output_dense.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.8.layer_norm.bias', 'encoder.layers.8.layer_norm.weight', 'encoder.layers.9.attention.k_proj.bias', 'encoder.layers.9.attention.k_proj.weight', 'encoder.layers.9.attention.out_proj.bias', 'encoder.layers.9.attention.out_proj.weight', 'encoder.layers.9.attention.q_proj.bias', 'encoder.layers.9.attention.q_proj.weight', 'encoder.layers.9.attention.v_proj.bias', 'encoder.layers.9.attention.v_proj.weight', 'encoder.layers.9.feed_forward.intermediate_dense.bias', 'encoder.layers.9.feed_forward.intermediate_dense.weight', 'encoder.layers.9.feed_forward.output_dense.bias', 'encoder.layers.9.feed_forward.output_dense.weight', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.layer_norm.bias', 'encoder.layers.9.layer_norm.weight']
- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).

======================= This is fold_0 on de =======================

Load dataset: 
Loading de train data: fold_0...
Preprocess de fold_0 data for de model
Loading de eval data: fold_0...
Preprocess de fold_0 data for de model
Loading de test data: fold_0...
Preprocess de fold_0 data for de model
Use de model to add lora
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training loss: 1363.4093, Training accuracy: 0.6125
Macro F1-score: 0.6112
Model performance on Angry speech (in training): 
	Precision: 0.9275, Recall: 0.3200, F1_score: 0.4758
Model performance on Happy speech (in training): 
	Precision: 0.3887, Recall: 0.8075, F1_score: 0.5248
Model performance on Neutral speech (in training): 
	Precision: 0.7056, Recall: 0.4375, F1_score: 0.5401
Model performance on Sad speech (in training): 
	Precision: 0.9243, Recall: 0.8850, F1_score: 0.9042

Eval Phase: 
Validation loss: 168.8412, Validation accuracy: 0.6450
Macro F1-score: 0.6172
Model performance on Angry speech (in validation): 
	Precision: 0.5155, Recall: 1.0000, F1_score: 0.6803
Model performance on Happy speech (in validation): 
	Precision: 0.2000, Recall: 0.1200, F1_score: 0.1500
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.4800, F1_score: 0.6486
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
New best accuracy for layer 4 on epoch 1: 0.6450. Model saved.
Epoch 2/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:   0%|          | 1/1600 [00:14<6:19:09, 14.23s/it]Training:   9%|▊         | 139/1600 [00:24<03:30,  6.94it/s]Training:  19%|█▉        | 307/1600 [00:34<01:57, 11.04it/s]Training:  31%|███       | 490/1600 [00:44<01:20, 13.74it/s]Training:  42%|████▏     | 679/1600 [00:54<00:59, 15.51it/s]Training:  55%|█████▍    | 874/1600 [01:04<00:43, 16.80it/s]Training:  67%|██████▋   | 1077/1600 [01:14<00:29, 17.90it/s]Training:  80%|████████  | 1280/1600 [01:24<00:17, 18.55it/s]Training:  93%|█████████▎| 1482/1600 [01:34<00:06, 19.05it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 225/1600 [00:10<01:01, 22.42it/s]Training:  28%|██▊       | 450/1600 [00:20<00:Training loss: 310.1669, Training accuracy: 0.9444
Macro F1-score: 0.9444
Model performance on Angry speech (in training): 
	Precision: 0.9593, Recall: 0.9425, F1_score: 0.9508
Model performance on Happy speech (in training): 
	Precision: 0.9007, Recall: 0.9300, F1_score: 0.9151
Model performance on Neutral speech (in training): 
	Precision: 0.9532, Recall: 0.9175, F1_score: 0.9350
Model performance on Sad speech (in training): 
	Precision: 0.9658, Recall: 0.9875, F1_score: 0.9765

Eval Phase: 
Validation loss: 35.9007, Validation accuracy: 0.9350
Macro F1-score: 0.9349
Model performance on Angry speech (in validation): 
	Precision: 0.9796, Recall: 0.9600, F1_score: 0.9697
Model performance on Happy speech (in validation): 
	Precision: 0.9556, Recall: 0.8600, F1_score: 0.9053
Model performance on Neutral speech (in validation): 
	Precision: 0.8704, Recall: 0.9400, F1_score: 0.9038
Model performance on Sad speech (in validation): 
	Precision: 0.9423, Recall: 0.9800, F1_score: 0.9608
New best accuracy for layer 4 on epoch 2: 0.9350. Model saved.
Epoch 3/100

Training Phase:
51, 22.13it/s]Training:  42%|████▏     | 670/1600 [00:30<00:42, 21.94it/s]Training:  56%|█████▌    | 888/1600 [00:40<00:32, 21.74it/s]Training:  69%|██████▉   | 1104/1600 [00:50<00:22, 21.68it/s]Training:  82%|████████▎ | 1320/1600 [01:00<00:12, 21.63it/s]Training:  96%|█████████▌| 1536/1600 [01:10<00:02, 21.45it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 215/1600 [00:10<01:04, 21.39it/s]Training:  27%|██▋       | 437/1600 [00:20<00:53, 21.86it/s]Training:  41%|████      | 659/1600 [00:30<00:42, 21.91it/s]Training:  55%|█████▌    | 882/1600 [00:40<00:32, 22.06it/s]Training:  69%|██████▉   | 1105/1600 [00:50<00:22, 21.84it/s]Training:  83%|████████▎ | 1324/1600 [01Training loss: 171.8967, Training accuracy: 0.9700
Macro F1-score: 0.9700
Model performance on Angry speech (in training): 
	Precision: 0.9823, Recall: 0.9700, F1_score: 0.9761
Model performance on Happy speech (in training): 
	Precision: 0.9407, Recall: 0.9525, F1_score: 0.9466
Model performance on Neutral speech (in training): 
	Precision: 0.9649, Recall: 0.9625, F1_score: 0.9637
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938

Eval Phase: 
Validation loss: 25.2670, Validation accuracy: 0.9650
Macro F1-score: 0.9651
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Happy speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Neutral speech (in validation): 
	Precision: 0.9245, Recall: 0.9800, F1_score: 0.9515
Model performance on Sad speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
New best accuracy for layer 4 on epoch 3: 0.9650. Model saved.
Epoch 4/100

Training Phase:
Training loss: 123.8862, Training accuracy: 0.9800
Macro F1-score: 0.9800
Model performance on Angry speech (in training): 
	Precision: 0.9776, Recall: 0.9800, F1_score: 0.9788
Model performance on Happy speech (in training): 
	Precision: 0.9627, Recall: 0.9675, F1_score: 0.9651
Model performance on Neutral speech (in training): 
	Precision: 0.9873, Recall: 0.9725, F1_score: 0.9798
Model performance on Sad speech (in training): 
	Precision: 0.9926, Recall: 1.0000, F1_score: 0.9963

Eval Phase: 
Validation loss: 15.6886, Validation accuracy: 0.9750
Macro F1-score: 0.9750
Model performance on Angry speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in validation): 
	Precision: 0.9792, Recall: 0.9400, F1_score: 0.9592
Model performance on Neutral speech (in validation): 
	Precision: 0.9434, Recall: 1.0000, F1_score: 0.9709
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
New best accuracy for layer 4 on epoch 4: 0.9750. Model saved.
Epoch 5/100

Training Phase:
:00<00:12, 21.86it/s]Training:  96%|█████████▋| 1543/1600 [01:10<00:02, 21.85it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 225/1600 [00:10<01:01, 22.49it/s]Training:  28%|██▊       | 450/1600 [00:20<00:51, 22.28it/s]Training:  42%|████▏     | 672/1600 [00:30<00:41, 22.18it/s]Training:  56%|█████▌    | 897/1600 [00:40<00:31, 22.29it/s]Training:  70%|███████   | 1122/1600 [00:50<00:21, 22.31it/s]Training:  84%|████████▍ | 1346/1600 [01:00<00:11, 22.17it/s]Training:  98%|█████████▊| 1565/1600 [01:10<00:01, 22.02it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|    Training loss: 114.0908, Training accuracy: 0.9800
Macro F1-score: 0.9800
Model performance on Angry speech (in training): 
	Precision: 0.9727, Recall: 0.9800, F1_score: 0.9763
Model performance on Happy speech (in training): 
	Precision: 0.9822, Recall: 0.9650, F1_score: 0.9735
Model performance on Neutral speech (in training): 
	Precision: 0.9801, Recall: 0.9850, F1_score: 0.9825
Model performance on Sad speech (in training): 
	Precision: 0.9851, Recall: 0.9900, F1_score: 0.9875

Eval Phase: 
Validation loss: 23.5975, Validation accuracy: 0.9750
Macro F1-score: 0.9751
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Happy speech (in validation): 
	Precision: 0.9423, Recall: 0.9800, F1_score: 0.9608
Model performance on Neutral speech (in validation): 
	Precision: 0.9600, Recall: 0.9600, F1_score: 0.9600
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Epoch 6/100

Training Phase:
      | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 219/1600 [00:10<01:03, 21.85it/s]Training:  28%|██▊       | 440/1600 [00:20<00:52, 21.99it/s]Training:  41%|████▏     | 661/1600 [00:30<00:42, 21.90it/s]Training:  55%|█████▌    | 886/1600 [00:40<00:32, 22.14it/s]Training:  69%|██████▉   | 1111/1600 [00:50<00:22, 22.12it/s]Training:  83%|████████▎ | 1332/1600 [01:00<00:12, 22.06it/s]Training:  97%|█████████▋| 1552/1600 [01:10<00:02, 21.70it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 218/1600 [00:10<01:03, 21.76it/s]Training:  28%|██▊       | 440/1600 [00:20<00:52, 21.97it/s]Training:  41%|████▏     | 663/1600 [00:30<00:42, 22.12it/s]Training:  55%|█████▌    | 886/1600 [00:40<0Training loss: 91.7356, Training accuracy: 0.9812
Macro F1-score: 0.9813
Model performance on Angry speech (in training): 
	Precision: 0.9825, Recall: 0.9800, F1_score: 0.9812
Model performance on Happy speech (in training): 
	Precision: 0.9627, Recall: 0.9675, F1_score: 0.9651
Model performance on Neutral speech (in training): 
	Precision: 0.9825, Recall: 0.9800, F1_score: 0.9812
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Validation loss: 19.4145, Validation accuracy: 0.9750
Macro F1-score: 0.9750
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Happy speech (in validation): 
	Precision: 0.9600, Recall: 0.9600, F1_score: 0.9600
Model performance on Neutral speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 7/100

Training Phase:
0:32, 21.92it/s]Training:  69%|██████▉   | 1105/1600 [00:50<00:22, 21.89it/s]Training:  83%|████████▎ | 1324/1600 [01:00<00:12, 21.70it/s]Training:  97%|█████████▋| 1549/1600 [01:10<00:02, 21.94it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 220/1600 [00:10<01:02, 21.92it/s]Training:  28%|██▊       | 440/1600 [00:20<00:53, 21.78it/s]Training:  41%|████      | 657/1600 [00:30<00:43, 21.65it/s]Training:  55%|█████▍    | 872/1600 [00:40<00:33, 21.52it/s]Training:  68%|██████▊   | 1086/1600 [00:50<00:24, 21.39it/s]Training:  81%|████████▏ | 1301/1600 [01:00<00:13, 21.40it/s]Training:  95%|█████████▍| 1516/1600 [01:10<00:03, 21.43it/s]                                      Training loss: 75.7732, Training accuracy: 0.9869
Macro F1-score: 0.9869
Model performance on Angry speech (in training): 
	Precision: 0.9924, Recall: 0.9850, F1_score: 0.9887
Model performance on Happy speech (in training): 
	Precision: 0.9777, Recall: 0.9875, F1_score: 0.9826
Model performance on Neutral speech (in training): 
	Precision: 0.9899, Recall: 0.9800, F1_score: 0.9849
Model performance on Sad speech (in training): 
	Precision: 0.9876, Recall: 0.9950, F1_score: 0.9913

Eval Phase: 
Validation loss: 17.5915, Validation accuracy: 0.9750
Macro F1-score: 0.9751
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Happy speech (in validation): 
	Precision: 0.9796, Recall: 0.9600, F1_score: 0.9697
Model performance on Neutral speech (in validation): 
	Precision: 0.9423, Recall: 0.9800, F1_score: 0.9608
Model performance on Sad speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Epoch 8/100

Training Phase:
Training loss: 74.7711, Training accuracy: 0.9856
Macro F1-score: 0.9856
Model performance on Angry speech (in training): 
	Precision: 0.9875, Recall: 0.9850, F1_score: 0.9862
Model performance on Happy speech (in training): 
	Precision: 0.9751, Recall: 0.9800, F1_score: 0.9776
Model performance on Neutral speech (in training): 
	Precision: 0.9874, Recall: 0.9825, F1_score: 0.9850
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938

Eval Phase: 
Validation loss: 15.6421, Validation accuracy: 0.9800
Macro F1-score: 0.9800
Model performance on Angry speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9400, F1_score: 0.9691
Model performance on Neutral speech (in validation): 
	Precision: 0.9434, Recall: 1.0000, F1_score: 0.9709
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
New best accuracy for layer 4 on epoch 8: 0.9800. Model saved.
Epoch 9/100

Training Phase:
                       Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 213/1600 [00:10<01:05, 21.27it/s]Training:  27%|██▋       | 426/1600 [00:20<00:55, 21.27it/s]Training:  40%|███▉      | 639/1600 [00:30<00:45, 21.25it/s]Training:  53%|█████▎    | 852/1600 [00:40<00:35, 21.26it/s]Training:  67%|██████▋   | 1065/1600 [00:50<00:25, 21.25it/s]Training:  80%|████████  | 1283/1600 [01:00<00:14, 21.40it/s]Training:  94%|█████████▍| 1500/1600 [01:10<00:04, 21.37it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 214/1600 [00:10<01:04, 21.36it/s]Training:  27%|██▋       | 430/1600 [00:20<Training loss: 78.9773, Training accuracy: 0.9856
Macro F1-score: 0.9856
Model performance on Angry speech (in training): 
	Precision: 0.9801, Recall: 0.9850, F1_score: 0.9825
Model performance on Happy speech (in training): 
	Precision: 0.9799, Recall: 0.9750, F1_score: 0.9774
Model performance on Neutral speech (in training): 
	Precision: 0.9875, Recall: 0.9900, F1_score: 0.9888
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937

Eval Phase: 
Validation loss: 21.7803, Validation accuracy: 0.9750
Macro F1-score: 0.9750
Model performance on Angry speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9400, F1_score: 0.9691
Model performance on Neutral speech (in validation): 
	Precision: 0.9423, Recall: 0.9800, F1_score: 0.9608
Model performance on Sad speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Epoch 10/100

Training Phase:
00:54, 21.43it/s]Training:  40%|████      | 647/1600 [00:30<00:44, 21.53it/s]Training:  54%|█████▍    | 864/1600 [00:40<00:34, 21.51it/s]Training:  67%|██████▋   | 1079/1600 [00:50<00:24, 21.48it/s]Training:  81%|████████  | 1295/1600 [01:00<00:14, 21.52it/s]Training:  95%|█████████▍| 1516/1600 [01:10<00:03, 21.68it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 216/1600 [00:10<01:04, 21.59it/s]Training:  27%|██▋       | 434/1600 [00:20<00:53, 21.70it/s]Training:  41%|████      | 652/1600 [00:30<00:44, 21.52it/s]Training:  54%|█████▍    | 867/1600 [00:40<00:34, 21.51it/s]Training:  68%|██████▊   | 1087/1600 [00:50<00:23, 21.68it/s]Training:  82%|████████▏ | 1307/1600 [01:Training loss: 45.6809, Training accuracy: 0.9912
Macro F1-score: 0.9912
Model performance on Angry speech (in training): 
	Precision: 0.9850, Recall: 0.9850, F1_score: 0.9850
Model performance on Happy speech (in training): 
	Precision: 0.9825, Recall: 0.9825, F1_score: 0.9825
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 40.8331, Validation accuracy: 0.9350
Macro F1-score: 0.9350
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.8600, F1_score: 0.9247
Model performance on Happy speech (in validation): 
	Precision: 0.8704, Recall: 0.9400, F1_score: 0.9038
Model performance on Neutral speech (in validation): 
	Precision: 0.9231, Recall: 0.9600, F1_score: 0.9412
Model performance on Sad speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Epoch 11/100

Training Phase:
Training loss: 49.7516, Training accuracy: 0.9912
Macro F1-score: 0.9913
Model performance on Angry speech (in training): 
	Precision: 0.9924, Recall: 0.9850, F1_score: 0.9887
Model performance on Happy speech (in training): 
	Precision: 0.9826, Recall: 0.9875, F1_score: 0.9850
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Validation loss: 13.7311, Validation accuracy: 0.9850
Macro F1-score: 0.9851
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Neutral speech (in validation): 
	Precision: 0.9434, Recall: 1.0000, F1_score: 0.9709
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
New best accuracy for layer 4 on epoch 11: 0.9850. Model saved.
Epoch 12/100

Training Phase:
00<00:13, 21.47it/s]Training:  95%|█████████▌| 1523/1600 [01:10<00:03, 21.51it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 215/1600 [00:10<01:04, 21.40it/s]Training:  27%|██▋       | 430/1600 [00:20<00:55, 21.22it/s]Training:  40%|████      | 647/1600 [00:30<00:44, 21.43it/s]Training:  54%|█████▍    | 865/1600 [00:40<00:34, 21.56it/s]Training:  68%|██████▊   | 1083/1600 [00:50<00:24, 21.52it/s]Training:  81%|████████  | 1298/1600 [01:00<00:14, 21.49it/s]Training:  95%|█████████▌| 1523/1600 [01:10<00:03, 21.79it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|         Training loss: 44.5282, Training accuracy: 0.9912
Macro F1-score: 0.9913
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9875, F1_score: 0.9900
Model performance on Happy speech (in training): 
	Precision: 0.9851, Recall: 0.9900, F1_score: 0.9875
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950

Eval Phase: 
Validation loss: 22.8156, Validation accuracy: 0.9700
Macro F1-score: 0.9701
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9400, F1_score: 0.9691
Model performance on Neutral speech (in validation): 
	Precision: 0.9231, Recall: 0.9600, F1_score: 0.9412
Model performance on Sad speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Epoch 13/100

Training Phase:
 | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 221/1600 [00:10<01:02, 22.08it/s]Training:  28%|██▊       | 442/1600 [00:20<00:53, 21.67it/s]Training:  41%|████      | 659/1600 [00:30<00:43, 21.67it/s]Training:  55%|█████▍    | 879/1600 [00:40<00:33, 21.79it/s]Training:  69%|██████▉   | 1102/1600 [00:50<00:22, 21.95it/s]Training:  83%|████████▎ | 1325/1600 [01:00<00:12, 21.88it/s]Training:  97%|█████████▋| 1546/1600 [01:10<00:02, 21.94it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 220/1600 [00:10<01:02, 21.99it/s]Training:  28%|██▊       | 442/1600 [00:20<00:52, 22.06it/s]Training:  42%|████▏     | 664/1600 [00:30<00:42, 22.00it/s]Training:  42%|████▏     | 664/1600 [00:40<00:42, 22.Training loss: 43.8027, Training accuracy: 0.9912
Macro F1-score: 0.9913
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9900, F1_score: 0.9925
Model performance on Happy speech (in training): 
	Precision: 0.9850, Recall: 0.9875, F1_score: 0.9863
Model performance on Neutral speech (in training): 
	Precision: 0.9876, Recall: 0.9925, F1_score: 0.9900
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962

Eval Phase: 
Validation loss: 14.7081, Validation accuracy: 0.9850
Macro F1-score: 0.9850
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Neutral speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 14/100

Training Phase:
00it/s]Training:  55%|█████▌    | 884/1600 [00:40<00:32, 21.92it/s]Training:  69%|██████▉   | 1104/1600 [00:50<00:22, 21.93it/s]Training:  83%|████████▎ | 1324/1600 [01:00<00:12, 21.95it/s]Training:  97%|█████████▋| 1549/1600 [01:10<00:02, 22.10it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 218/1600 [00:10<01:03, 21.73it/s]Training:  27%|██▋       | 438/1600 [00:20<00:53, 21.84it/s]Training:  41%|████      | 659/1600 [00:30<00:42, 21.93it/s]Training:  55%|█████▌    | 880/1600 [00:40<00:33, 21.82it/s]Training:  69%|██████▊   | 1098/1600 [00:50<00:23, 21.79it/s]Training:  82%|████████▏ | 1319/1600 [01:00<00:12, 21.89it/s]Training:  96%|█████████▋| 1540/1600Training loss: 10.8929, Training accuracy: 0.9981
Macro F1-score: 0.9981
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963
Model performance on Happy speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 15.7856, Validation accuracy: 0.9800
Macro F1-score: 0.9799
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in validation): 
	Precision: 0.9796, Recall: 0.9600, F1_score: 0.9697
Model performance on Neutral speech (in validation): 
	Precision: 0.9600, Recall: 0.9600, F1_score: 0.9600
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 15/100

Training Phase:
Training loss: 72.9165, Training accuracy: 0.9881
Macro F1-score: 0.9881
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9925, F1_score: 0.9950
Model performance on Happy speech (in training): 
	Precision: 0.9751, Recall: 0.9800, F1_score: 0.9776
Model performance on Neutral speech (in training): 
	Precision: 0.9800, Recall: 0.9825, F1_score: 0.9813
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987

Eval Phase: 
Validation loss: 30.9138, Validation accuracy: 0.9600
Macro F1-score: 0.9598
Model performance on Angry speech (in validation): 
	Precision: 0.9434, Recall: 1.0000, F1_score: 0.9709
Model performance on Happy speech (in validation): 
	Precision: 0.9787, Recall: 0.9200, F1_score: 0.9485
Model performance on Neutral speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Sad speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Epoch 16/100

Training Phase:
 [01:10<00:02, 21.96it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 225/1600 [00:10<01:01, 22.39it/s]Training:  28%|██▊       | 449/1600 [00:20<00:52, 22.12it/s]Training:  42%|████▏     | 673/1600 [00:30<00:41, 22.22it/s]Training:  42%|████▏     | 673/1600 [00:40<00:41, 22.22it/s]Training:  56%|█████▌    | 897/1600 [00:40<00:31, 22.11it/s]Training:  70%|██████▉   | 1117/1600 [00:50<00:22, 21.89it/s]Training:  83%|████████▎ | 1332/1600 [01:00<00:12, 21.71it/s]Training:  97%|█████████▋| 1551/1600 [01:10<00:02, 21.75it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          |Training loss: 27.7394, Training accuracy: 0.9956
Macro F1-score: 0.9956
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912
Model performance on Neutral speech (in training): 
	Precision: 0.9900, Recall: 0.9950, F1_score: 0.9925
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 23.3088, Validation accuracy: 0.9850
Macro F1-score: 0.9850
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Neutral speech (in validation): 
	Precision: 0.9796, Recall: 0.9600, F1_score: 0.9697
Model performance on Sad speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Epoch 17/100

Training Phase:
 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 218/1600 [00:10<01:03, 21.79it/s]Training:  27%|██▋       | 438/1600 [00:20<00:53, 21.88it/s]Training:  41%|████      | 658/1600 [00:30<00:42, 21.92it/s]Training:  55%|█████▍    | 878/1600 [00:40<00:33, 21.87it/s]Training:  69%|██████▊   | 1097/1600 [00:50<00:23, 21.80it/s]Training:  82%|████████▏ | 1315/1600 [01:00<00:13, 21.80it/s]Training:  96%|█████████▌| 1536/1600 [01:10<00:02, 21.86it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 217/1600 [00:10<01:04, 21.59it/s]Training:  27%|██▋       | 434/1600 [00:20<00:53, 21.64it/s]Training:  41%|████      | 659/1600 [00:30<00:42, 21.98it/s]Training:  55%|█████▌    | 884/1600 [00:40<00:32, 22.17Training loss: 40.7761, Training accuracy: 0.9956
Macro F1-score: 0.9956
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Validation loss: 12.8776, Validation accuracy: 0.9850
Macro F1-score: 0.9849
Model performance on Angry speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Neutral speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 18/100

Training Phase:
it/s]Training:  55%|█████▌    | 884/1600 [00:50<00:32, 22.17it/s]Training:  69%|██████▉   | 1108/1600 [00:50<00:22, 22.19it/s]Training:  83%|████████▎ | 1333/1600 [01:00<00:11, 22.28it/s]Training:  97%|█████████▋| 1558/1600 [01:10<00:01, 22.06it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 226/1600 [00:10<01:01, 22.51it/s]Training:  28%|██▊       | 452/1600 [00:20<00:50, 22.56it/s]Training:  42%|████▎     | 680/1600 [00:30<00:40, 22.66it/s]Training:  57%|█████▋    | 908/1600 [00:40<00:30, 22.69it/s]Training:  71%|███████   | 1136/1600 [00:50<00:20, 22.64it/s]Training:  85%|████████▌ | 1362/1600 [01:00<00:10, 22.23it/s]Training:  99%|█████████▉| 1585/1600Training loss: 34.1619, Training accuracy: 0.9938
Macro F1-score: 0.9937
Model performance on Angry speech (in training): 
	Precision: 0.9924, Recall: 0.9825, F1_score: 0.9874
Model performance on Happy speech (in training): 
	Precision: 0.9827, Recall: 0.9925, F1_score: 0.9876
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 34.3177, Validation accuracy: 0.9700
Macro F1-score: 0.9697
Model performance on Angry speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9000, F1_score: 0.9474
Model performance on Neutral speech (in validation): 
	Precision: 0.9423, Recall: 0.9800, F1_score: 0.9608
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 19/100

Training Phase:
Training loss: 28.9099, Training accuracy: 0.9956
Macro F1-score: 0.9956
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Happy speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 16.0023, Validation accuracy: 0.9800
Macro F1-score: 0.9800
Model performance on Angry speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Neutral speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Sad speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Epoch 20/100

Training Phase:
 [01:10<00:00, 22.22it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 221/1600 [00:10<01:02, 22.06it/s]Training:  28%|██▊       | 447/1600 [00:20<00:51, 22.35it/s]Training:  42%|████▏     | 675/1600 [00:30<00:41, 22.55it/s]Training:  56%|█████▋    | 903/1600 [00:40<00:31, 22.34it/s]Training:  70%|███████   | 1124/1600 [00:50<00:21, 22.13it/s]Training:  84%|████████▍ | 1342/1600 [01:00<00:11, 21.88it/s]Training:  97%|█████████▋| 1559/1600 [01:10<00:01, 21.82it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 215/1600 [00:10Training loss: 21.2280, Training accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in training): 
	Precision: 0.9900, Recall: 0.9950, F1_score: 0.9925
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9875, F1_score: 0.9900
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Validation loss: 9.0106, Validation accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Neutral speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
New best accuracy for layer 4 on epoch 20: 0.9900. Model saved.
Epoch 21/100

Training Phase:
<01:04, 21.48it/s]Training:  27%|██▋       | 432/1600 [00:20<00:54, 21.58it/s]Training:  41%|████      | 649/1600 [00:30<00:44, 21.58it/s]Training:  54%|█████▍    | 871/1600 [00:40<00:33, 21.81it/s]Training:  68%|██████▊   | 1093/1600 [00:50<00:23, 21.91it/s]Training:  82%|████████▏ | 1316/1600 [01:00<00:12, 22.03it/s]Training:  96%|█████████▋| 1541/1600 [01:10<00:02, 22.16it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 227/1600 [00:10<01:00, 22.64it/s]Training:  28%|██▊       | 454/1600 [00:20<00:51, 22.24it/s]Training:  42%|████▏     | 679/1600 [00:30<00:41, 22.35it/s]Training:  56%|█████▋    | 904/1600 [00:40<00:31, 22.41it/s]Training:  71%|███████   | 1129/1600 [00:50<00:21Training loss: 33.7520, Training accuracy: 0.9912
Macro F1-score: 0.9913
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9900, F1_score: 0.9925
Model performance on Neutral speech (in training): 
	Precision: 0.9826, Recall: 0.9900, F1_score: 0.9863
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912

Eval Phase: 
Validation loss: 15.3806, Validation accuracy: 0.9800
Macro F1-score: 0.9800
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Neutral speech (in validation): 
	Precision: 0.9792, Recall: 0.9400, F1_score: 0.9592
Model performance on Sad speech (in validation): 
	Precision: 0.9434, Recall: 1.0000, F1_score: 0.9709
Epoch 22/100

Training Phase:
Training loss: 10.4905, Training accuracy: 0.9975
Macro F1-score: 0.9975
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
, 22.11it/s]Training:  84%|████████▍ | 1347/1600 [01:00<00:11, 21.99it/s]Training:  98%|█████████▊| 1565/1600 [01:10<00:01, 21.88it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 214/1600 [00:10<01:04, 21.37it/s]Training:  27%|██▋       | 433/1600 [00:20<00:53, 21.64it/s]Training:  41%|████      | 659/1600 [00:30<00:42, 22.07it/s]Training:  55%|█████▌    | 885/1600 [00:40<00:32, 22.12it/s]Training:  69%|██████▉   | 1108/1600 [00:50<00:22, 22.18it/s]Training:  83%|████████▎ | 1331/1600 [01:00<00:12, 22.17it/s]Training:  98%|█████████▊| 1561/1600 [01:10<00:01, 22.42it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]   Validation loss: 21.9433, Validation accuracy: 0.9750
Macro F1-score: 0.9750
Model performance on Angry speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Happy speech (in validation): 
	Precision: 0.9792, Recall: 0.9400, F1_score: 0.9592
Model performance on Neutral speech (in validation): 
	Precision: 0.9423, Recall: 0.9800, F1_score: 0.9608
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Epoch 23/100

Training Phase:
Training loss: 43.6987, Training accuracy: 0.9931
Macro F1-score: 0.9931
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Happy speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962

Eval Phase: 
Validation loss: 25.3571, Validation accuracy: 0.9800
Macro F1-score: 0.9800
Model performance on Angry speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Happy speech (in validation): 
	Precision: 0.9796, Recall: 0.9600, F1_score: 0.9697
Model performance on Neutral speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Epoch 24/100

Training Phase:
                                                Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 219/1600 [00:10<01:03, 21.82it/s]Training:  27%|██▋       | 438/1600 [00:20<00:53, 21.73it/s]Training:  41%|████      | 656/1600 [00:30<00:43, 21.72it/s]Training:  55%|█████▍    | 874/1600 [00:40<00:33, 21.67it/s]Training:  68%|██████▊   | 1096/1600 [00:50<00:23, 21.85it/s]Training:  82%|████████▏ | 1319/1600 [01:00<00:12, 21.98it/s]Training:  96%|█████████▋| 1542/1600 [01:10<00:02, 21.80it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 218/1600 [00:10<01:03, 21.78it/s]Training:  28%|██▊       | 444/1600 [00:20<00:52, 22.21it/s]Training:  42%|████▏     | 670/1600 [00:30<00:41, Training loss: 7.2577, Training accuracy: 0.9988
Macro F1-score: 0.9988
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Happy speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 24.6864, Validation accuracy: 0.9800
Macro F1-score: 0.9800
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Neutral speech (in validation): 
	Precision: 0.9600, Recall: 0.9600, F1_score: 0.9600
Model performance on Sad speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Epoch 25/100

Training Phase:
22.15it/s]Training:  56%|█████▌    | 895/1600 [00:40<00:31, 22.27it/s]Training:  70%|███████   | 1120/1600 [00:50<00:21, 22.07it/s]Training:  84%|████████▎ | 1338/1600 [01:00<00:11, 21.91it/s]Training:  97%|█████████▋| 1554/1600 [01:10<00:02, 21.69it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 216/1600 [00:10<01:04, 21.52it/s]Training:  27%|██▋       | 432/1600 [00:20<00:54, 21.48it/s]Training:  40%|████      | 647/1600 [00:30<00:44, 21.36it/s]Training:  54%|█████▍    | 870/1600 [00:40<00:33, 21.69it/s]Training:  68%|██████▊   | 1096/1600 [00:50<00:22, 21.99it/s]Training:  83%|████████▎ | 1322/1600 [01:00<00:12, 22.00it/s]Training:  97%|█████████▋| 1547/1Training loss: 32.1236, Training accuracy: 0.9944
Macro F1-score: 0.9944
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9925, F1_score: 0.9950
Model performance on Happy speech (in training): 
	Precision: 0.9900, Recall: 0.9950, F1_score: 0.9925
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962

Eval Phase: 
Validation loss: 21.6106, Validation accuracy: 0.9800
Macro F1-score: 0.9800
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Neutral speech (in validation): 
	Precision: 0.9600, Recall: 0.9600, F1_score: 0.9600
Model performance on Sad speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Epoch 26/100

Training Phase:
Training loss: 7.8384, Training accuracy: 0.9988
Macro F1-score: 0.9987
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988

Eval Phase: 
Validation loss: 6.3139, Validation accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Neutral speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Epoch 27/100

Training Phase:
600 [01:10<00:02, 22.16it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 220/1600 [00:10<01:02, 21.95it/s]Training:  28%|██▊       | 442/1600 [00:20<00:52, 22.07it/s]Training:  42%|████▏     | 664/1600 [00:30<00:42, 22.01it/s]Training:  55%|█████▌    | 886/1600 [00:40<00:32, 22.08it/s]Training:  69%|██████▉   | 1108/1600 [00:50<00:22, 22.06it/s]Training:  83%|████████▎ | 1332/1600 [01:00<00:12, 22.17it/s]Training:  97%|█████████▋| 1556/1600 [01:10<00:01, 22.16it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 218/1600 [00Training loss: 5.3208, Training accuracy: 0.9988
Macro F1-score: 0.9988
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 14.9563, Validation accuracy: 0.9800
Macro F1-score: 0.9799
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Neutral speech (in validation): 
	Precision: 0.9792, Recall: 0.9400, F1_score: 0.9592
Model performance on Sad speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Epoch 28/100

Training Phase:
:10<01:03, 21.74it/s]Training:  27%|██▋       | 439/1600 [00:20<00:52, 21.94it/s]Training:  41%|████▏     | 662/1600 [00:30<00:42, 22.08it/s]Training:  55%|█████▌    | 885/1600 [00:40<00:32, 22.12it/s]Training:  69%|██████▉   | 1107/1600 [00:50<00:22, 22.04it/s]Training:  83%|████████▎ | 1329/1600 [01:00<00:12, 22.06it/s]Training:  97%|█████████▋| 1553/1600 [01:10<00:02, 22.16it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 217/1600 [00:10<01:03, 21.67it/s]Training:  27%|██▋       | 434/1600 [00:20<00:53, 21.62it/s]Training:  27%|██▋       | 434/1600 [00:30<00:53, 21.62it/s]Training:  38%|███▊      | 609/1600 [00:30<00:50, 19.64it/s]Training:  49%|████▉     | 782/1600 [00:41<00:45, 17.98iTraining loss: 18.4046, Training accuracy: 0.9969
Macro F1-score: 0.9969
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Validation loss: 23.4795, Validation accuracy: 0.9800
Macro F1-score: 0.9800
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Neutral speech (in validation): 
	Precision: 0.9600, Recall: 0.9600, F1_score: 0.9600
Model performance on Sad speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Epoch 29/100

Training Phase:
t/s]Training:  60%|██████    | 965/1600 [00:51<00:35, 18.09it/s]Training:  72%|███████▏  | 1148/1600 [01:01<00:24, 18.10it/s]Training:  84%|████████▍ | 1346/1600 [01:11<00:13, 18.65it/s]Training:  97%|█████████▋| 1550/1600 [01:21<00:02, 19.17it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 211/1600 [00:10<01:06, 20.97it/s]Training:  26%|██▋       | 421/1600 [00:20<00:56, 20.86it/s]Training:  40%|███▉      | 634/1600 [00:30<00:45, 21.05it/s]Training:  53%|█████▎    | 847/1600 [00:40<00:36, 20.83it/s]Training:  66%|██████▌   | 1052/1600 [00:50<00:26, 20.61it/s]Training:  79%|███████▉  | 1262/1600 [01:00<00:16, 20.72it/s]Training:  92%|█████████▏| 1473/1600 [0Training loss: 9.7827, Training accuracy: 0.9988
Macro F1-score: 0.9988
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Validation loss: 15.1652, Validation accuracy: 0.9800
Macro F1-score: 0.9801
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in validation): 
	Precision: 0.9796, Recall: 0.9600, F1_score: 0.9697
Model performance on Neutral speech (in validation): 
	Precision: 0.9423, Recall: 0.9800, F1_score: 0.9608
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Epoch 30/100

Training Phase:
Training loss: 9.8123, Training accuracy: 0.9988
Macro F1-score: 0.9988
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 21.1038, Validation accuracy: 0.9850
Macro F1-score: 0.9850
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in validation): 
	Precision: 0.9796, Recall: 0.9600, F1_score: 0.9697
Model performance on Neutral speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 31/100

Training Phase:
1:10<00:06, 20.83it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 223/1600 [00:10<01:01, 22.28it/s]Training:  28%|██▊       | 446/1600 [00:20<00:52, 21.84it/s]Training:  42%|████▏     | 670/1600 [00:30<00:42, 22.08it/s]Training:  56%|█████▌    | 894/1600 [00:40<00:32, 22.06it/s]Training:  70%|██████▉   | 1118/1600 [00:50<00:21, 22.15it/s]Training:  84%|████████▍ | 1344/1600 [01:00<00:11, 22.28it/s]Training:  98%|█████████▊| 1570/1600 [01:11<00:01, 21.99it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 222/1600 [00:10<01Training loss: 38.8367, Training accuracy: 0.9944
Macro F1-score: 0.9944
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937
Model performance on Happy speech (in training): 
	Precision: 0.9851, Recall: 0.9925, F1_score: 0.9888
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9925, F1_score: 0.9950
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 34.1911, Validation accuracy: 0.9750
Macro F1-score: 0.9748
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Neutral speech (in validation): 
	Precision: 0.9787, Recall: 0.9200, F1_score: 0.9485
Model performance on Sad speech (in validation): 
	Precision: 0.9434, Recall: 1.0000, F1_score: 0.9709
Epoch 32/100

Training Phase:
:02, 22.19it/s]Training:  28%|██▊       | 450/1600 [00:20<00:51, 22.50it/s]Training:  42%|████▏     | 678/1600 [00:30<00:41, 22.48it/s]Training:  57%|█████▋    | 907/1600 [00:40<00:30, 22.63it/s]Training:  71%|███████   | 1136/1600 [00:50<00:20, 22.30it/s]Training:  71%|███████   | 1136/1600 [01:00<00:20, 22.30it/s]Training:  84%|████████▍ | 1350/1600 [01:00<00:11, 21.95it/s]Training:  98%|█████████▊| 1565/1600 [01:10<00:01, 21.79it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 224/1600 [00:10<01:01, 22.31it/s]Training:  28%|██▊       | 448/1600 [00:20<00:52, 21.79it/s]Training:  42%|████▏     | 667/1600 [00:30<00:42, 21.81it/s]Training:  55%|█████▌    | 886/1600 [00:40<00:32,Training loss: 5.0736, Training accuracy: 0.9994
Macro F1-score: 0.9994
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 46.1691, Validation accuracy: 0.9750
Macro F1-score: 0.9749
Model performance on Angry speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Happy speech (in validation): 
	Precision: 0.9792, Recall: 0.9400, F1_score: 0.9592
Model performance on Neutral speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Epoch 33/100

Training Phase:
 21.66it/s]Training:  69%|██████▉   | 1101/1600 [00:50<00:23, 21.55it/s]Training:  82%|████████▏ | 1315/1600 [01:00<00:13, 21.39it/s]Training:  96%|█████████▌| 1530/1600 [01:10<00:03, 21.41it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 214/1600 [00:10<01:04, 21.36it/s]Training:  13%|█▎        | 214/1600 [00:20<01:04, 21.36it/s]Training:  27%|██▋       | 428/1600 [00:20<00:55, 21.27it/s]Training:  40%|████      | 646/1600 [00:30<00:44, 21.50it/s]Training:  54%|█████▍    | 865/1600 [00:40<00:33, 21.65it/s]Training:  68%|██████▊   | 1094/1600 [00:50<00:22, 22.09it/s]Training:  83%|████████▎ | 1323/1600 [01:00<00:12, 22.02it/s]Training:  97%|█████████▋| 1553/1600 [01Training loss: 28.2521, Training accuracy: 0.9944
Macro F1-score: 0.9944
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Neutral speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962

Eval Phase: 
Validation loss: 9.6474, Validation accuracy: 0.9850
Macro F1-score: 0.9850
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Neutral speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Epoch 34/100

Training Phase:
Training loss: 29.6641, Training accuracy: 0.9962
Macro F1-score: 0.9963
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 27.3840, Validation accuracy: 0.9750
Macro F1-score: 0.9749
Model performance on Angry speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Happy speech (in validation): 
	Precision: 0.9796, Recall: 0.9600, F1_score: 0.9697
Model performance on Neutral speech (in validation): 
	Precision: 0.9600, Recall: 0.9600, F1_score: 0.9600
Model performance on Sad speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Epoch 35/100

Training Phase:
:10<00:02, 22.31it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 217/1600 [00:10<01:03, 21.61it/s]Training:  27%|██▋       | 435/1600 [00:20<00:53, 21.67it/s]Training:  41%|████      | 653/1600 [00:30<00:43, 21.71it/s]Training:  55%|█████▍    | 875/1600 [00:40<00:33, 21.89it/s]Training:  69%|██████▉   | 1104/1600 [00:50<00:22, 22.24it/s]Training:  83%|████████▎ | 1333/1600 [01:00<00:11, 22.38it/s]Training:  98%|█████████▊| 1561/1600 [01:10<00:01, 22.50it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 228/1600 [00:10<01:00Training loss: 16.7875, Training accuracy: 0.9981
Macro F1-score: 0.9981
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 14.6761, Validation accuracy: 0.9850
Macro F1-score: 0.9851
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Neutral speech (in validation): 
	Precision: 0.9434, Recall: 1.0000, F1_score: 0.9709
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Epoch 36/100

Training Phase:
, 22.74it/s]Training:  28%|██▊       | 456/1600 [00:20<00:50, 22.71it/s]Training:  43%|████▎     | 683/1600 [00:30<00:40, 22.41it/s]Training:  43%|████▎     | 683/1600 [00:40<00:40, 22.41it/s]Training:  56%|█████▋    | 902/1600 [00:40<00:31, 22.03it/s]Training:  70%|███████   | 1122/1600 [00:50<00:21, 22.01it/s]Training:  84%|████████▍ | 1342/1600 [01:00<00:11, 21.96it/s]Training:  98%|█████████▊| 1561/1600 [01:10<00:01, 21.93it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 216/1600 [00:10<01:04, 21.54it/s]Training:  28%|██▊       | 443/1600 [00:20<00:52, 22.21it/s]Training:  42%|████▏     | 670/1600 [00:30<00:41, 22.29it/s]Training:  56%|█████▌    | 894/1600 [00:40<00:32, 22.06itTraining loss: 0.6335, Training accuracy: 1.0000
Macro F1-score: 1.0000
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 21.3686, Validation accuracy: 0.9800
Macro F1-score: 0.9800
Model performance on Angry speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9400, F1_score: 0.9691
Model performance on Neutral speech (in validation): 
	Precision: 0.9434, Recall: 1.0000, F1_score: 0.9709
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Validation loss does not decrease for 10 epochs. End training.
Model best accuracy on validation set: 0.9900

Test Phase: 
/s]Training:  70%|██████▉   | 1112/1600 [00:50<00:22, 21.88it/s]Training:  83%|████████▎ | 1329/1600 [01:00<00:12, 21.80it/s]Training:  97%|█████████▋| 1548/1600 [01:10<00:02, 21.81it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]                                                Some weights of the model checkpoint at /work/tc062/tc062/zhan7721/saved_models/de were not used when initializing Wav2Vec2Model: ['encoder.layers.10.attention.k_proj.bias', 'encoder.layers.10.attention.k_proj.weight', 'encoder.layers.10.attention.out_proj.bias', 'encoder.layers.10.attention.out_proj.weight', 'encoder.layers.10.attention.q_proj.bias', 'encoder.layers.10.attention.q_proj.weight', 'encoder.layers.10.attention.v_proj.bias', 'encoder.layers.10.attention.v_proj.weight', 'encoder.layers.10.feed_forward.intermediate_dense.bias', 'encoder.layers.10.feed_forward.intermediate_dense.weight', 'encoder.layers.10.feed_forward.output_dense.bias', 'encoder.layers.10.feed_forward.output_dense.weight', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.10.layer_norm.bias', 'encoder.layers.10.layer_norm.weight', 'encoder.layers.11.attention.k_proj.bias', 'encoder.layers.11.attention.k_proj.weight', 'encoder.layers.11.attention.out_proj.bias', 'encoder.layers.11.attention.out_proj.weight', 'encoder.layers.11.attention.q_proj.bias', 'encoder.layers.11.attention.q_proj.weight', 'encoder.layers.11.attention.v_proj.bias', 'encoder.layers.11.attention.v_proj.weight', 'encoder.layers.11.feed_forward.intermediate_dense.bias', 'encoder.layers.11.feed_forward.intermediate_dense.weight', 'encoder.layers.11.feed_forward.output_dense.bias', 'encoder.layers.11.feed_forward.output_dense.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.11.layer_norm.bias', 'encoder.layers.11.layer_norm.weight', 'encoder.layers.5.attention.k_proj.bias', 'encoder.layers.5.attention.k_proj.weight', 'encoder.layers.5.attention.out_proj.bias', 'encoder.layers.5.attention.out_proj.weight', 'encoder.layers.5.attention.q_proj.bias', 'encoder.layers.5.attention.q_proj.weight', 'encoder.layers.5.attention.v_proj.bias', 'encoder.layers.5.attention.v_proj.weight', 'encoder.layers.5.feed_forward.intermediate_dense.bias', 'encoder.layers.5.feed_forward.intermediate_dense.weight', 'encoder.layers.5.feed_forward.output_dense.bias', 'encoder.layers.5.feed_forward.output_dense.weight', 'encoder.layers.5.final_layer_norm.bias', 'encoder.layers.5.final_layer_norm.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.6.attention.k_proj.bias', 'encoder.layers.6.attention.k_proj.weight', 'encoder.layers.6.attention.out_proj.bias', 'encoder.layers.6.attention.out_proj.weight', 'encoder.layers.6.attention.q_proj.bias', 'encoder.layers.6.attention.q_proj.weight', 'encoder.layers.6.attention.v_proj.bias', 'encoder.layers.6.attention.v_proj.weight', 'encoder.layers.6.feed_forward.intermediate_dense.bias', 'encoder.layers.6.feed_forward.intermediate_dense.weight', 'encoder.layers.6.feed_forward.output_dense.bias', 'encoder.layers.6.feed_forward.output_dense.weight', 'encoder.layers.6.final_layer_norm.bias', 'encoder.layers.6.final_layer_norm.weight', 'encoder.layers.6.layer_norm.bias', 'encoder.layers.6.layer_norm.weight', 'encoder.layers.7.attention.k_proj.bias', 'encoder.layers.7.attention.k_proj.weight', 'encoder.layers.7.attention.out_proj.bias', 'encoder.layers.7.attention.out_proj.weight', 'encoder.layers.7.attention.q_proj.bias', 'encoder.layers.7.attention.q_proj.weight', 'encoder.layers.7.attention.v_proj.bias', 'encoder.layers.7.attention.v_proj.weight', 'encoder.layers.7.feed_forward.intermediate_dense.bias', 'encoder.layers.7.feed_forward.intermediate_dense.weight', 'encoder.layers.7.feed_forward.output_dense.bias', 'encoder.layers.7.feed_forward.output_dense.weight', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.7.layer_norm.bias', 'encoder.layers.7.layer_norm.weight', 'encoder.layers.8.attention.k_proj.bias', 'encoder.layers.8.attention.k_proj.weight', 'encoder.layers.8.attention.out_proj.bias', 'encoder.layers.8.attention.out_proj.weight', 'encoder.layers.8.attention.q_proj.bias', 'encoder.layers.8.attention.q_proj.weight', 'encoder.layers.8.attention.v_proj.bias', 'encoder.layers.8.attention.v_proj.weight', 'encoder.layers.8.feed_forward.intermediate_dense.bias', 'encoder.layers.8.feed_forward.intermediate_dense.weight', 'encoder.layers.8.feed_forward.output_dense.bias', 'encoder.layers.8.feed_forward.output_dense.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.8.layer_norm.bias', 'encoder.layers.8.layer_norm.weight', 'encoder.layers.9.attention.k_proj.bias', 'encoder.layers.9.attention.k_proj.weight', 'encoder.layers.9.attention.out_proj.bias', 'encoder.layers.9.attention.out_proj.weight', 'encoder.layers.9.attention.q_proj.bias', 'encoder.layers.9.attention.q_proj.weight', 'encoder.layers.9.attention.v_proj.bias', 'encoder.layers.9.attention.v_proj.weight', 'encoder.layers.9.feed_forward.intermediate_dense.bias', 'encoder.layers.9.feed_forward.intermediate_dense.weight', 'encoder.layers.9.feed_forward.output_dense.bias', 'encoder.layers.9.feed_forward.output_dense.weight', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.layer_norm.bias', 'encoder.layers.9.layer_norm.weight']
- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Test loss: 33.7687, Test accuracy: 0.9700
Macro F1-score: 0.9699
Model performance on Angry speech (in test): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in test): 
	Precision: 0.9792, Recall: 0.9400, F1_score: 0.9592
Model performance on Neutral speech (in test): 
	Precision: 0.9600, Recall: 0.9600, F1_score: 0.9600
Model performance on Sad speech (in test): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804

======================= This is fold_1 on de =======================

Load dataset: 
Loading de train data: fold_1...
Preprocess de fold_1 data for de model
Loading de eval data: fold_1...
Preprocess de fold_1 data for de model
Loading de test data: fold_1...
Preprocess de fold_1 data for de model
Use de model to add lora
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training loss: 557.3391, Training accuracy: 0.8750
Macro F1-score: 0.8752
Model performance on Angry speech (in training): 
	Precision: 0.9143, Recall: 0.8800, F1_score: 0.8968
Model performance on Happy speech (in training): 
	Precision: 0.8184, Recall: 0.7775, F1_score: 0.7974
Model performance on Neutral speech (in training): 
	Precision: 0.8094, Recall: 0.9025, F1_score: 0.8534
Model performance on Sad speech (in training): 
	Precision: 0.9666, Recall: 0.9400, F1_score: 0.9531

Eval Phase: 
Validation loss: 34.2350, Validation accuracy: 0.9300
Macro F1-score: 0.9291
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9400, F1_score: 0.9691
Model performance on Happy speech (in validation): 
	Precision: 0.9074, Recall: 0.9800, F1_score: 0.9423
Model performance on Neutral speech (in validation): 
	Precision: 0.9756, Recall: 0.8000, F1_score: 0.8791
Model performance on Sad speech (in validation): 
	Precision: 0.8621, Recall: 1.0000, F1_score: 0.9259
New best accuracy for layer 4 on epoch 1: 0.9300. Model saved.
Epoch 2/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 217/1600 [00:10<01:03, 21.64it/s]Training:  27%|██▋       | 434/1600 [00:20<00:54, 21.52it/s]Training:  41%|████      | 653/1600 [00:30<00:43, 21.66it/s]Training:  55%|█████▍    | 872/1600 [00:40<00:33, 21.47it/s]Training:  68%|██████▊   | 1084/1600 [00:50<00:24, 21.35it/s]Training:  82%|████████▏ | 1307/1600 [01:00<00:13, 21.67it/s]Training:  96%|█████████▌| 1534/1600 [01:10<00:03, 21.98it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 213/1600 [00:10<01:05, 21.24it/s]Training:  27%|██▋       | 429/1600 [00:20<00:54, 21.43it/s]Training:  41%|████      | 656/1600 [00:30<00:42, 22.00it/s]Training:  55%|█████▌    | 8Training loss: 135.4605, Training accuracy: 0.9719
Macro F1-score: 0.9719
Model performance on Angry speech (in training): 
	Precision: 0.9748, Recall: 0.9675, F1_score: 0.9711
Model performance on Happy speech (in training): 
	Precision: 0.9479, Recall: 0.9550, F1_score: 0.9514
Model performance on Neutral speech (in training): 
	Precision: 0.9701, Recall: 0.9750, F1_score: 0.9726
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9900, F1_score: 0.9925

Eval Phase: 
Validation loss: 12.3326, Validation accuracy: 0.9800
Macro F1-score: 0.9800
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Happy speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Neutral speech (in validation): 
	Precision: 0.9600, Recall: 0.9600, F1_score: 0.9600
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
New best accuracy for layer 4 on epoch 2: 0.9800. Model saved.
Epoch 3/100

Training Phase:
83/1600 [00:40<00:32, 22.05it/s]Training:  69%|██████▉   | 1111/1600 [00:50<00:21, 22.29it/s]Training:  84%|████████▍ | 1340/1600 [01:00<00:11, 22.49it/s]Training:  98%|█████████▊| 1569/1600 [01:10<00:01, 22.40it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 230/1600 [00:10<00:59, 22.90it/s]Training:  29%|██▊       | 459/1600 [00:20<00:51, 22.34it/s]Training:  42%|████▏     | 679/1600 [00:30<00:41, 22.04it/s]Training:  56%|█████▌    | 896/1600 [00:40<00:32, 21.79it/s]Training:  69%|██████▉   | 1110/1600 [00:50<00:22, 21.62it/s]Training:  83%|████████▎ | 1324/1600 [01:00<00:12, 21.54it/s]Training:  96%|█████████▌| 1538/1600 [01:10<00:02, 21.44it/s]                    Training loss: 118.1144, Training accuracy: 0.9750
Macro F1-score: 0.9750
Model performance on Angry speech (in training): 
	Precision: 0.9824, Recall: 0.9775, F1_score: 0.9799
Model performance on Happy speech (in training): 
	Precision: 0.9622, Recall: 0.9550, F1_score: 0.9586
Model performance on Neutral speech (in training): 
	Precision: 0.9631, Recall: 0.9775, F1_score: 0.9702
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912

Eval Phase: 
Validation loss: 14.3241, Validation accuracy: 0.9850
Macro F1-score: 0.9850
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Neutral speech (in validation): 
	Precision: 0.9796, Recall: 0.9600, F1_score: 0.9697
Model performance on Sad speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
New best accuracy for layer 4 on epoch 3: 0.9850. Model saved.
Epoch 4/100

Training Phase:
Training loss: 59.4291, Training accuracy: 0.9869
Macro F1-score: 0.9869
Model performance on Angry speech (in training): 
	Precision: 0.9798, Recall: 0.9725, F1_score: 0.9762
Model performance on Happy speech (in training): 
	Precision: 0.9726, Recall: 0.9750, F1_score: 0.9738
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 1.0000, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 29.4777, Validation accuracy: 0.9600
Macro F1-score: 0.9597
Model performance on Angry speech (in validation): 
	Precision: 0.9423, Recall: 0.9800, F1_score: 0.9608
Model performance on Happy speech (in validation): 
	Precision: 0.9783, Recall: 0.9000, F1_score: 0.9375
Model performance on Neutral speech (in validation): 
	Precision: 0.9412, Recall: 0.9600, F1_score: 0.9505
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 5/100

Training Phase:
                                         Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 215/1600 [00:10<01:04, 21.44it/s]Training:  27%|██▋       | 430/1600 [00:20<00:54, 21.44it/s]Training:  40%|████      | 648/1600 [00:30<00:44, 21.58it/s]Training:  55%|█████▍    | 872/1600 [00:40<00:33, 21.87it/s]Training:  69%|██████▊   | 1098/1600 [00:50<00:22, 22.13it/s]Training:  83%|████████▎ | 1324/1600 [01:00<00:12, 22.10it/s]Training:  97%|█████████▋| 1550/1600 [01:10<00:02, 22.21it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 226/1600 [00:10<01:01, 22.50it/s]Training:  28%|██▊     Training loss: 59.0290, Training accuracy: 0.9850
Macro F1-score: 0.9850
Model performance on Angry speech (in training): 
	Precision: 0.9900, Recall: 0.9875, F1_score: 0.9887
Model performance on Happy speech (in training): 
	Precision: 0.9752, Recall: 0.9825, F1_score: 0.9788
Model performance on Neutral speech (in training): 
	Precision: 0.9849, Recall: 0.9775, F1_score: 0.9812
Model performance on Sad speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913

Eval Phase: 
Validation loss: 16.9844, Validation accuracy: 0.9850
Macro F1-score: 0.9850
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Neutral speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 6/100

Training Phase:
  | 452/1600 [00:20<00:51, 22.39it/s]Training:  42%|████▏     | 676/1600 [00:30<00:41, 22.17it/s]Training:  56%|█████▋    | 903/1600 [00:40<00:31, 22.37it/s]Training:  71%|███████   | 1130/1600 [00:50<00:21, 22.33it/s]Training:  85%|████████▍ | 1353/1600 [01:00<00:11, 22.20it/s]Training:  99%|█████████▊| 1578/1600 [01:10<00:00, 22.27it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 229/1600 [00:10<01:00, 22.84it/s]Training:  29%|██▊       | 458/1600 [00:20<00:50, 22.72it/s]Training:  43%|████▎     | 685/1600 [00:30<00:40, 22.58it/s]Training:  43%|████▎     | 685/1600 [00:40<00:40, 22.58it/s]Training:  57%|█████▋    | 908/1600 [00:40<00:30, 22.44it/s]Training:  71%|███████  Training loss: 48.3361, Training accuracy: 0.9906
Macro F1-score: 0.9906
Model performance on Angry speech (in training): 
	Precision: 0.9850, Recall: 0.9875, F1_score: 0.9863
Model performance on Happy speech (in training): 
	Precision: 0.9825, Recall: 0.9800, F1_score: 0.9812
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 48.6207, Validation accuracy: 0.9500
Macro F1-score: 0.9495
Model performance on Angry speech (in validation): 
	Precision: 0.9074, Recall: 0.9800, F1_score: 0.9423
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.8600, F1_score: 0.9247
Model performance on Neutral speech (in validation): 
	Precision: 0.9412, Recall: 0.9600, F1_score: 0.9505
Model performance on Sad speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Epoch 7/100

Training Phase:
Training loss: 53.2418, Training accuracy: 0.9881
Macro F1-score: 0.9881
Model performance on Angry speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900
Model performance on Happy speech (in training): 
	Precision: 0.9849, Recall: 0.9800, F1_score: 0.9825
Model performance on Neutral speech (in training): 
	Precision: 0.9826, Recall: 0.9900, F1_score: 0.9863
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937

Eval Phase: 
 | 1133/1600 [00:50<00:20, 22.43it/s]Training:  85%|████████▌ | 1362/1600 [01:00<00:10, 22.57it/s]Training:  99%|█████████▉| 1591/1600 [01:10<00:00, 22.55it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 224/1600 [00:10<01:01, 22.33it/s]Training:  28%|██▊       | 448/1600 [00:20<00:51, 22.20it/s]Training:  42%|████▏     | 670/1600 [00:30<00:42, 21.82it/s]Training:  55%|█████▌    | 884/1600 [00:40<00:33, 21.55it/s]Training:  69%|██████▉   | 1102/1600 [00:50<00:23, 21.62it/s]Training:  82%|████████▎ | 1320/1600 [01:00<00:12, 21.67it/s]Training:  96%|█████████▌| 1538/1600 [01:10<00:02, 21.65it/s]                                                             Evaluating:   0%|          |Validation loss: 10.4477, Validation accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Neutral speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
New best accuracy for layer 4 on epoch 7: 0.9900. Model saved.
Epoch 8/100

Training Phase:
Training loss: 42.6446, Training accuracy: 0.9931
Macro F1-score: 0.9931
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9875, F1_score: 0.9900
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963

Eval Phase: 
Validation loss: 17.3291, Validation accuracy: 0.9750
Macro F1-score: 0.9750
Model performance on Angry speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9400, F1_score: 0.9691
Model performance on Neutral speech (in validation): 
	Precision: 0.9423, Recall: 0.9800, F1_score: 0.9608
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 9/100

Training Phase:
 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 216/1600 [00:10<01:04, 21.55it/s]Training:  28%|██▊       | 446/1600 [00:20<00:51, 22.36it/s]Training:  42%|████▏     | 676/1600 [00:30<00:41, 22.42it/s]Training:  42%|████▏     | 676/1600 [00:40<00:41, 22.42it/s]Training:  56%|█████▌    | 897/1600 [00:40<00:31, 22.00it/s]Training:  69%|██████▉   | 1111/1600 [00:50<00:22, 21.76it/s]Training:  83%|████████▎ | 1327/1600 [01:00<00:12, 21.69it/s]Training:  97%|█████████▋| 1545/1600 [01:10<00:02, 21.70it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 215/1600 [00:10<01:04, 21.47it/s]Training:  27%|██▋   Training loss: 19.4598, Training accuracy: 0.9969
Macro F1-score: 0.9969
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 23.4367, Validation accuracy: 0.9700
Macro F1-score: 0.9698
Model performance on Angry speech (in validation): 
	Precision: 0.9434, Recall: 1.0000, F1_score: 0.9709
Model performance on Happy speech (in validation): 
	Precision: 0.9787, Recall: 0.9200, F1_score: 0.9485
Model performance on Neutral speech (in validation): 
	Precision: 0.9796, Recall: 0.9600, F1_score: 0.9697
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 10/100

Training Phase:
    | 436/1600 [00:20<00:53, 21.83it/s]Training:  41%|████      | 657/1600 [00:30<00:43, 21.60it/s]Training:  55%|█████▍    | 872/1600 [00:40<00:33, 21.55it/s]Training:  68%|██████▊   | 1087/1600 [00:50<00:23, 21.53it/s]Training:  82%|████████▏ | 1313/1600 [01:00<00:13, 21.89it/s]Training:  96%|█████████▌| 1539/1600 [01:10<00:02, 21.97it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 226/1600 [00:10<01:00, 22.57it/s]Training:  28%|██▊       | 452/1600 [00:20<00:51, 22.49it/s]Training:  42%|████▏     | 677/1600 [00:30<00:41, 22.42it/s]Training:  56%|█████▋    | 901/1600 [00:40<00:31, 22.14it/s]Training:  70%|██████▉   | 1119/1600 [00:50<00:21, 21.94it/s]Training:  83%|██████Training loss: 39.9634, Training accuracy: 0.9912
Macro F1-score: 0.9912
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937
Model performance on Happy speech (in training): 
	Precision: 0.9851, Recall: 0.9925, F1_score: 0.9888
Model performance on Neutral speech (in training): 
	Precision: 0.9924, Recall: 0.9850, F1_score: 0.9887
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938

Eval Phase: 
Validation loss: 18.3340, Validation accuracy: 0.9750
Macro F1-score: 0.9752
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Happy speech (in validation): 
	Precision: 0.9796, Recall: 0.9600, F1_score: 0.9697
Model performance on Neutral speech (in validation): 
	Precision: 0.9259, Recall: 1.0000, F1_score: 0.9615
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Epoch 11/100

Training Phase:
Training loss: 8.8777, Training accuracy: 0.9988
Macro F1-score: 0.9988
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Happy speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
██▎ | 1335/1600 [01:00<00:12, 21.75it/s]Training:  97%|█████████▋| 1556/1600 [01:10<00:02, 21.84it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 221/1600 [00:10<01:02, 22.06it/s]Training:  28%|██▊       | 442/1600 [00:20<00:52, 22.05it/s]Training:  41%|████▏     | 663/1600 [00:30<00:42, 22.06it/s]Training:  56%|█████▌    | 888/1600 [00:40<00:32, 22.22it/s]Training:  70%|██████▉   | 1113/1600 [00:50<00:21, 22.21it/s]Training:  84%|████████▎ | 1337/1600 [01:00<00:11, 22.27it/s]Training:  98%|█████████▊| 1561/1600 [01:10<00:01, 22.15it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                               Validation loss: 36.6425, Validation accuracy: 0.9700
Macro F1-score: 0.9697
Model performance on Angry speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9000, F1_score: 0.9474
Model performance on Neutral speech (in validation): 
	Precision: 0.9423, Recall: 0.9800, F1_score: 0.9608
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 12/100

Training Phase:
Training loss: 35.8762, Training accuracy: 0.9938
Macro F1-score: 0.9938
Model performance on Angry speech (in training): 
	Precision: 0.9875, Recall: 0.9875, F1_score: 0.9875
Model performance on Happy speech (in training): 
	Precision: 0.9875, Recall: 0.9875, F1_score: 0.9875
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 39.0794, Validation accuracy: 0.9750
Macro F1-score: 0.9751
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9400, F1_score: 0.9691
Model performance on Neutral speech (in validation): 
	Precision: 0.9245, Recall: 0.9800, F1_score: 0.9515
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 13/100

Training Phase:
    Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 220/1600 [00:10<01:02, 21.94it/s]Training:  28%|██▊       | 440/1600 [00:20<00:53, 21.86it/s]Training:  41%|████      | 659/1600 [00:30<00:43, 21.66it/s]Training:  55%|█████▌    | 881/1600 [00:40<00:32, 21.83it/s]Training:  69%|██████▉   | 1103/1600 [00:50<00:22, 21.96it/s]Training:  83%|████████▎ | 1325/1600 [01:00<00:12, 21.95it/s]Training:  97%|█████████▋| 1545/1600 [01:10<00:02, 21.92it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 226/1600 [00:10<01:01, 22.51it/s]Training:  28%|██▊       | 452/1600 [00:20<00:51, 22.28it/s]Training:  42%|████▏     | 674/1600 [00:30<00:41, 22.11it/s]Training:  56%|█████▌Training loss: 16.6730, Training accuracy: 0.9975
Macro F1-score: 0.9975
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Validation loss: 22.2540, Validation accuracy: 0.9750
Macro F1-score: 0.9751
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Neutral speech (in validation): 
	Precision: 0.9412, Recall: 0.9600, F1_score: 0.9505
Model performance on Sad speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Epoch 14/100

Training Phase:
    | 894/1600 [00:40<00:32, 22.05it/s]Training:  70%|██████▉   | 1114/1600 [00:50<00:22, 22.03it/s]Training:  83%|████████▎ | 1334/1600 [01:00<00:12, 21.91it/s]Training:  97%|█████████▋| 1555/1600 [01:10<00:02, 21.96it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 216/1600 [00:10<01:04, 21.59it/s]Training:  27%|██▋       | 438/1600 [00:20<00:53, 21.92it/s]Training:  41%|████▏     | 660/1600 [00:30<00:42, 21.96it/s]Training:  55%|█████▌    | 881/1600 [00:40<00:32, 21.87it/s]Training:  69%|██████▉   | 1104/1600 [00:50<00:22, 22.01it/s]Training:  83%|████████▎ | 1327/1600 [01:00<00:12, 21.96it/s]Training:  97%|█████████▋| 1548/1600 [01:10<00:02, 21.99it/s]             Training loss: 32.1787, Training accuracy: 0.9925
Macro F1-score: 0.9925
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Neutral speech (in training): 
	Precision: 0.9875, Recall: 0.9900, F1_score: 0.9888
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925

Eval Phase: 
Validation loss: 41.2776, Validation accuracy: 0.9600
Macro F1-score: 0.9600
Model performance on Angry speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9200, F1_score: 0.9583
Model performance on Neutral speech (in validation): 
	Precision: 0.9216, Recall: 0.9400, F1_score: 0.9307
Model performance on Sad speech (in validation): 
	Precision: 0.9434, Recall: 1.0000, F1_score: 0.9709
Epoch 15/100

Training Phase:
Training loss: 12.0718, Training accuracy: 0.9975
Macro F1-score: 0.9975
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963
Model performance on Happy speech (in training): 
	Precision: 0.9975, Recall: 0.9925, F1_score: 0.9950
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 39.6076, Validation accuracy: 0.9750
Macro F1-score: 0.9751
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9400, F1_score: 0.9691
Model performance on Neutral speech (in validation): 
	Precision: 0.9245, Recall: 0.9800, F1_score: 0.9515
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 16/100

Training Phase:
                                                Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 219/1600 [00:10<01:03, 21.81it/s]Training:  28%|██▊       | 442/1600 [00:20<00:52, 22.06it/s]Training:  42%|████▏     | 665/1600 [00:30<00:42, 21.76it/s]Training:  55%|█████▌    | 883/1600 [00:40<00:32, 21.76it/s]Training:  69%|██████▉   | 1101/1600 [00:50<00:23, 21.57it/s]Training:  83%|████████▎ | 1324/1600 [01:00<00:12, 21.80it/s]Training:  97%|█████████▋| 1548/1600 [01:10<00:02, 21.98it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 222/1600 [00:10<01:02, 22.12it/s]Training:  28%|█Training loss: 24.1972, Training accuracy: 0.9962
Macro F1-score: 0.9963
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 35.3080, Validation accuracy: 0.9750
Macro F1-score: 0.9750
Model performance on Angry speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9400, F1_score: 0.9691
Model performance on Neutral speech (in validation): 
	Precision: 0.9423, Recall: 0.9800, F1_score: 0.9608
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 17/100

Training Phase:
▊       | 444/1600 [00:20<00:53, 21.61it/s]Training:  41%|████▏     | 661/1600 [00:30<00:43, 21.65it/s]Training:  41%|████▏     | 661/1600 [00:41<00:43, 21.65it/s]Training:  54%|█████▍    | 861/1600 [00:41<00:36, 20.48it/s]Training:  66%|██████▋   | 1063/1600 [00:51<00:26, 20.26it/s]Training:  80%|████████  | 1283/1600 [01:01<00:15, 20.82it/s]Training:  94%|█████████▍| 1508/1600 [01:11<00:04, 21.35it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 225/1600 [00:10<01:01, 22.45it/s]Training:  28%|██▊       | 450/1600 [00:20<00:51, 22.26it/s]Training:  42%|████▏     | 672/1600 [00:30<00:41, 22.14it/s]Training:  56%|█████▌    | 896/1600 [00:40<00:31, 22.24it/s]Training:  70%|█████Training loss: 18.4477, Training accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Happy speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 31.2085, Validation accuracy: 0.9650
Macro F1-score: 0.9649
Model performance on Angry speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Neutral speech (in validation): 
	Precision: 0.9400, Recall: 0.9400, F1_score: 0.9400
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Validation loss does not decrease for 10 epochs. End training.
Model best accuracy on validation set: 0.9900

Test Phase: 
█   | 1120/1600 [00:51<00:22, 21.56it/s]Training:  84%|████████▍ | 1343/1600 [01:01<00:11, 21.80it/s]Training:  98%|█████████▊| 1566/1600 [01:11<00:01, 21.88it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]                                                Some weights of the model checkpoint at /work/tc062/tc062/zhan7721/saved_models/de were not used when initializing Wav2Vec2Model: ['encoder.layers.10.attention.k_proj.bias', 'encoder.layers.10.attention.k_proj.weight', 'encoder.layers.10.attention.out_proj.bias', 'encoder.layers.10.attention.out_proj.weight', 'encoder.layers.10.attention.q_proj.bias', 'encoder.layers.10.attention.q_proj.weight', 'encoder.layers.10.attention.v_proj.bias', 'encoder.layers.10.attention.v_proj.weight', 'encoder.layers.10.feed_forward.intermediate_dense.bias', 'encoder.layers.10.feed_forward.intermediate_dense.weight', 'encoder.layers.10.feed_forward.output_dense.bias', 'encoder.layers.10.feed_forward.output_dense.weight', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.10.layer_norm.bias', 'encoder.layers.10.layer_norm.weight', 'encoder.layers.11.attention.k_proj.bias', 'encoder.layers.11.attention.k_proj.weight', 'encoder.layers.11.attention.out_proj.bias', 'encoder.layers.11.attention.out_proj.weight', 'encoder.layers.11.attention.q_proj.bias', 'encoder.layers.11.attention.q_proj.weight', 'encoder.layers.11.attention.v_proj.bias', 'encoder.layers.11.attention.v_proj.weight', 'encoder.layers.11.feed_forward.intermediate_dense.bias', 'encoder.layers.11.feed_forward.intermediate_dense.weight', 'encoder.layers.11.feed_forward.output_dense.bias', 'encoder.layers.11.feed_forward.output_dense.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.11.layer_norm.bias', 'encoder.layers.11.layer_norm.weight', 'encoder.layers.5.attention.k_proj.bias', 'encoder.layers.5.attention.k_proj.weight', 'encoder.layers.5.attention.out_proj.bias', 'encoder.layers.5.attention.out_proj.weight', 'encoder.layers.5.attention.q_proj.bias', 'encoder.layers.5.attention.q_proj.weight', 'encoder.layers.5.attention.v_proj.bias', 'encoder.layers.5.attention.v_proj.weight', 'encoder.layers.5.feed_forward.intermediate_dense.bias', 'encoder.layers.5.feed_forward.intermediate_dense.weight', 'encoder.layers.5.feed_forward.output_dense.bias', 'encoder.layers.5.feed_forward.output_dense.weight', 'encoder.layers.5.final_layer_norm.bias', 'encoder.layers.5.final_layer_norm.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.6.attention.k_proj.bias', 'encoder.layers.6.attention.k_proj.weight', 'encoder.layers.6.attention.out_proj.bias', 'encoder.layers.6.attention.out_proj.weight', 'encoder.layers.6.attention.q_proj.bias', 'encoder.layers.6.attention.q_proj.weight', 'encoder.layers.6.attention.v_proj.bias', 'encoder.layers.6.attention.v_proj.weight', 'encoder.layers.6.feed_forward.intermediate_dense.bias', 'encoder.layers.6.feed_forward.intermediate_dense.weight', 'encoder.layers.6.feed_forward.output_dense.bias', 'encoder.layers.6.feed_forward.output_dense.weight', 'encoder.layers.6.final_layer_norm.bias', 'encoder.layers.6.final_layer_norm.weight', 'encoder.layers.6.layer_norm.bias', 'encoder.layers.6.layer_norm.weight', 'encoder.layers.7.attention.k_proj.bias', 'encoder.layers.7.attention.k_proj.weight', 'encoder.layers.7.attention.out_proj.bias', 'encoder.layers.7.attention.out_proj.weight', 'encoder.layers.7.attention.q_proj.bias', 'encoder.layers.7.attention.q_proj.weight', 'encoder.layers.7.attention.v_proj.bias', 'encoder.layers.7.attention.v_proj.weight', 'encoder.layers.7.feed_forward.intermediate_dense.bias', 'encoder.layers.7.feed_forward.intermediate_dense.weight', 'encoder.layers.7.feed_forward.output_dense.bias', 'encoder.layers.7.feed_forward.output_dense.weight', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.7.layer_norm.bias', 'encoder.layers.7.layer_norm.weight', 'encoder.layers.8.attention.k_proj.bias', 'encoder.layers.8.attention.k_proj.weight', 'encoder.layers.8.attention.out_proj.bias', 'encoder.layers.8.attention.out_proj.weight', 'encoder.layers.8.attention.q_proj.bias', 'encoder.layers.8.attention.q_proj.weight', 'encoder.layers.8.attention.v_proj.bias', 'encoder.layers.8.attention.v_proj.weight', 'encoder.layers.8.feed_forward.intermediate_dense.bias', 'encoder.layers.8.feed_forward.intermediate_dense.weight', 'encoder.layers.8.feed_forward.output_dense.bias', 'encoder.layers.8.feed_forward.output_dense.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.8.layer_norm.bias', 'encoder.layers.8.layer_norm.weight', 'encoder.layers.9.attention.k_proj.bias', 'encoder.layers.9.attention.k_proj.weight', 'encoder.layers.9.attention.out_proj.bias', 'encoder.layers.9.attention.out_proj.weight', 'encoder.layers.9.attention.q_proj.bias', 'encoder.layers.9.attention.q_proj.weight', 'encoder.layers.9.attention.v_proj.bias', 'encoder.layers.9.attention.v_proj.weight', 'encoder.layers.9.feed_forward.intermediate_dense.bias', 'encoder.layers.9.feed_forward.intermediate_dense.weight', 'encoder.layers.9.feed_forward.output_dense.bias', 'encoder.layers.9.feed_forward.output_dense.weight', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.layer_norm.bias', 'encoder.layers.9.layer_norm.weight']
- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Test loss: 5.1231, Test accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in test): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in test): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Neutral speech (in test): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Sad speech (in test): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804

======================= This is fold_2 on de =======================

Load dataset: 
Loading de train data: fold_2...
Preprocess de fold_2 data for de model
Loading de eval data: fold_2...
Preprocess de fold_2 data for de model
Loading de test data: fold_2...
Preprocess de fold_2 data for de model
Use de model to add lora
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training loss: 447.2686, Training accuracy: 0.9075
Macro F1-score: 0.9077
Model performance on Angry speech (in training): 
	Precision: 0.9217, Recall: 0.9125, F1_score: 0.9171
Model performance on Happy speech (in training): 
	Precision: 0.8686, Recall: 0.8425, F1_score: 0.8553
Model performance on Neutral speech (in training): 
	Precision: 0.8601, Recall: 0.9225, F1_score: 0.8902
Model performance on Sad speech (in training): 
	Precision: 0.9845, Recall: 0.9525, F1_score: 0.9682

Eval Phase: 
Validation loss: 43.0543, Validation accuracy: 0.9500
Macro F1-score: 0.9502
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9200, F1_score: 0.9583
Model performance on Happy speech (in validation): 
	Precision: 0.9565, Recall: 0.8800, F1_score: 0.9167
Model performance on Neutral speech (in validation): 
	Precision: 0.8621, Recall: 1.0000, F1_score: 0.9259
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
New best accuracy for layer 4 on epoch 1: 0.9500. Model saved.
Epoch 2/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 212/1600 [00:10<01:05, 21.11it/s]Training:  27%|██▋       | 427/1600 [00:20<00:54, 21.33it/s]Training:  40%|████      | 644/1600 [00:30<00:44, 21.49it/s]Training:  54%|█████▍    | 861/1600 [00:40<00:34, 21.55it/s]Training:  68%|██████▊   | 1084/1600 [00:50<00:23, 21.79it/s]Training:  68%|██████▊   | 1084/1600 [01:00<00:23, 21.79it/s]Training:  81%|████████▏ | 1303/1600 [01:00<00:13, 21.64it/s]Training:  95%|█████████▌| 1527/1600 [01:10<00:03, 21.85it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 222/1600 [00:10<01:02, 22.16it/s]Training:  28%|██▊       | 444/1600 [00:20<00:53, 21.78it/s]Training:  41%|████▏   Training loss: 119.8914, Training accuracy: 0.9744
Macro F1-score: 0.9744
Model performance on Angry speech (in training): 
	Precision: 0.9678, Recall: 0.9775, F1_score: 0.9726
Model performance on Happy speech (in training): 
	Precision: 0.9719, Recall: 0.9525, F1_score: 0.9621
Model performance on Neutral speech (in training): 
	Precision: 0.9655, Recall: 0.9800, F1_score: 0.9727
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9875, F1_score: 0.9900

Eval Phase: 
Validation loss: 88.4770, Validation accuracy: 0.8850
Macro F1-score: 0.8850
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.8200, F1_score: 0.9011
Model performance on Happy speech (in validation): 
	Precision: 0.8667, Recall: 0.7800, F1_score: 0.8211
Model performance on Neutral speech (in validation): 
	Precision: 0.7705, Recall: 0.9400, F1_score: 0.8468
Model performance on Sad speech (in validation): 
	Precision: 0.9434, Recall: 1.0000, F1_score: 0.9709
Epoch 3/100

Training Phase:
  | 663/1600 [00:30<00:42, 21.79it/s]Training:  55%|█████▌    | 882/1600 [00:40<00:33, 21.58it/s]Training:  69%|██████▉   | 1101/1600 [00:50<00:23, 21.68it/s]Training:  83%|████████▎ | 1322/1600 [01:00<00:12, 21.80it/s]Training:  97%|█████████▋| 1547/1600 [01:10<00:02, 22.00it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 228/1600 [00:10<01:00, 22.77it/s]Training:  28%|██▊       | 456/1600 [00:20<00:51, 22.38it/s]Training:  42%|████▏     | 678/1600 [00:30<00:41, 22.13it/s]Training:  56%|█████▌    | 897/1600 [00:40<00:32, 21.89it/s]Training:  70%|██████▉   | 1113/1600 [00:50<00:22, 21.77it/s]Training:  83%|████████▎ | 1329/1600 [01:00<00:12, 21.55it/s]Training:  97%|███Training loss: 77.3501, Training accuracy: 0.9831
Macro F1-score: 0.9831
Model performance on Angry speech (in training): 
	Precision: 0.9874, Recall: 0.9825, F1_score: 0.9850
Model performance on Happy speech (in training): 
	Precision: 0.9749, Recall: 0.9700, F1_score: 0.9724
Model performance on Neutral speech (in training): 
	Precision: 0.9728, Recall: 0.9850, F1_score: 0.9789
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962

Eval Phase: 
Validation loss: 37.9177, Validation accuracy: 0.9550
Macro F1-score: 0.9548
Model performance on Angry speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.8600, F1_score: 0.9247
Model performance on Neutral speech (in validation): 
	Precision: 0.8750, Recall: 0.9800, F1_score: 0.9245
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
New best accuracy for layer 4 on epoch 3: 0.9550. Model saved.
Epoch 4/100

Training Phase:
Training loss: 62.1110, Training accuracy: 0.9888
Macro F1-score: 0.9888
Model performance on Angry speech (in training): 
	Precision: 0.9850, Recall: 0.9825, F1_score: 0.9837
Model performance on Happy speech (in training): 
	Precision: 0.9751, Recall: 0.9800, F1_score: 0.9776
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 46.8150, Validation accuracy: 0.9400
Macro F1-score: 0.9396
Model performance on Angry speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.8600, F1_score: 0.9247
Model performance on Neutral speech (in validation): 
	Precision: 0.9020, Recall: 0.9200, F1_score: 0.9109
Model performance on Sad speech (in validation): 
	Precision: 0.9091, Recall: 1.0000, F1_score: 0.9524
Epoch 5/100

Training Phase:
██████▋| 1550/1600 [01:10<00:02, 21.70it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 214/1600 [00:10<01:04, 21.38it/s]Training:  27%|██▋       | 428/1600 [00:20<00:54, 21.36it/s]Training:  40%|████      | 642/1600 [00:30<00:44, 21.36it/s]Training:  54%|█████▎    | 858/1600 [00:40<00:34, 21.41it/s]Training:  67%|██████▋   | 1073/1600 [00:50<00:24, 21.44it/s]Training:  81%|████████  | 1298/1600 [01:00<00:13, 21.79it/s]Training:  95%|█████████▌| 1523/1600 [01:10<00:03, 21.83it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█Training loss: 48.6099, Training accuracy: 0.9906
Macro F1-score: 0.9906
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9900, F1_score: 0.9925
Model performance on Happy speech (in training): 
	Precision: 0.9826, Recall: 0.9875, F1_score: 0.9850
Model performance on Neutral speech (in training): 
	Precision: 0.9875, Recall: 0.9900, F1_score: 0.9888
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962

Eval Phase: 
Validation loss: 33.7223, Validation accuracy: 0.9600
Macro F1-score: 0.9596
Model performance on Angry speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.8600, F1_score: 0.9247
Model performance on Neutral speech (in validation): 
	Precision: 0.8929, Recall: 1.0000, F1_score: 0.9434
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
New best accuracy for layer 4 on epoch 5: 0.9600. Model saved.
Epoch 6/100

Training Phase:
▍        | 222/1600 [00:10<01:02, 22.13it/s]Training:  28%|██▊       | 447/1600 [00:20<00:51, 22.30it/s]Training:  42%|████▏     | 672/1600 [00:30<00:41, 22.16it/s]Training:  56%|█████▌    | 897/1600 [00:40<00:31, 22.25it/s]Training:  70%|███████   | 1122/1600 [00:50<00:21, 22.31it/s]Training:  84%|████████▍ | 1347/1600 [01:00<00:11, 22.30it/s]Training:  98%|█████████▊| 1570/1600 [01:10<00:01, 22.22it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 222/1600 [00:10<01:02, 22.17it/s]Training:  28%|██▊       | 444/1600 [00:20<00:53, 21.61it/s]Training:  41%|████      | 659/1600 [00:30<00:43, 21.53it/s]Training:  55%|█████▍    | 876/1600 [00:40<00:33, 21.58it/s]Training:  68%|██████Training loss: 31.2277, Training accuracy: 0.9944
Macro F1-score: 0.9944
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Happy speech (in training): 
	Precision: 0.9924, Recall: 0.9850, F1_score: 0.9887
Model performance on Neutral speech (in training): 
	Precision: 0.9926, Recall: 1.0000, F1_score: 0.9963
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 19.9480, Validation accuracy: 0.9750
Macro F1-score: 0.9749
Model performance on Angry speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9200, F1_score: 0.9583
Model performance on Neutral speech (in validation): 
	Precision: 0.9434, Recall: 1.0000, F1_score: 0.9709
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
New best accuracy for layer 4 on epoch 6: 0.9750. Model saved.
Epoch 7/100

Training Phase:
Training loss: 53.1933, Training accuracy: 0.9888
Macro F1-score: 0.9887
Model performance on Angry speech (in training): 
	Precision: 0.9876, Recall: 0.9925, F1_score: 0.9900
Model performance on Happy speech (in training): 
	Precision: 0.9825, Recall: 0.9800, F1_score: 0.9812
Model performance on Neutral speech (in training): 
	Precision: 0.9875, Recall: 0.9875, F1_score: 0.9875
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962

Eval Phase: 
   | 1093/1600 [00:50<00:23, 21.59it/s]Training:  82%|████████▏ | 1310/1600 [01:00<00:13, 21.59it/s]Training:  96%|█████████▌| 1528/1600 [01:10<00:03, 21.62it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 215/1600 [00:10<01:04, 21.50it/s]Training:  27%|██▋       | 435/1600 [00:20<00:53, 21.74it/s]Training:  41%|████      | 655/1600 [00:30<00:43, 21.73it/s]Training:  55%|█████▍    | 878/1600 [00:40<00:32, 21.94it/s]Training:  69%|██████▉   | 1101/1600 [00:50<00:22, 21.76it/s]Training:  83%|████████▎ | 1323/1600 [01:00<00:12, 21.88it/s]Training:  97%|█████████▋| 1545/1600 [01:11<00:02, 21.45it/s]                                                             Evaluating:   0%|          Validation loss: 34.6841, Validation accuracy: 0.9650
Macro F1-score: 0.9649
Model performance on Angry speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.8800, F1_score: 0.9362
Model performance on Neutral speech (in validation): 
	Precision: 0.8929, Recall: 1.0000, F1_score: 0.9434
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 8/100

Training Phase:
Training loss: 22.8917, Training accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912
Model performance on Happy speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988

Eval Phase: 
Validation loss: 31.3980, Validation accuracy: 0.9700
Macro F1-score: 0.9698
Model performance on Angry speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9000, F1_score: 0.9474
Model performance on Neutral speech (in validation): 
	Precision: 0.9259, Recall: 1.0000, F1_score: 0.9615
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 9/100

Training Phase:
| 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 222/1600 [00:10<01:02, 22.18it/s]Training:  28%|██▊       | 444/1600 [00:20<00:52, 21.93it/s]Training:  42%|████▏     | 666/1600 [00:30<00:42, 22.05it/s]Training:  56%|█████▌    | 888/1600 [00:40<00:32, 21.98it/s]Training:  69%|██████▉   | 1108/1600 [00:50<00:22, 21.96it/s]Training:  83%|████████▎ | 1328/1600 [01:00<00:12, 21.90it/s]Training:  97%|█████████▋| 1550/1600 [01:10<00:02, 21.96it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 223/1600 [00:10<01:01, 22.30it/s]Training:  28%|██▊       | 446/1600 [00:20<00:52, 21.99it/s]Training:  42%|████▏Training loss: 22.1953, Training accuracy: 0.9956
Macro F1-score: 0.9956
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9975, F1_score: 0.9950
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9900, F1_score: 0.9937
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963

Eval Phase: 
Validation loss: 41.7183, Validation accuracy: 0.9650
Macro F1-score: 0.9649
Model performance on Angry speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.8800, F1_score: 0.9362
Model performance on Neutral speech (in validation): 
	Precision: 0.8929, Recall: 1.0000, F1_score: 0.9434
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 10/100

Training Phase:
     | 664/1600 [00:30<00:42, 21.78it/s]Training:  55%|█████▌    | 881/1600 [00:40<00:33, 21.73it/s]Training:  69%|██████▉   | 1103/1600 [00:50<00:22, 21.88it/s]Training:  83%|████████▎ | 1326/1600 [01:00<00:12, 22.02it/s]Training:  97%|█████████▋| 1549/1600 [01:10<00:02, 22.07it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 223/1600 [00:10<01:01, 22.26it/s]Training:  28%|██▊       | 446/1600 [00:20<00:53, 21.67it/s]Training:  42%|████▏     | 668/1600 [00:30<00:42, 21.89it/s]Training:  56%|█████▌    | 890/1600 [00:47<00:40, 17.53it/s]Training:  67%|██████▋   | 1070/1600 [00:57<00:30, 17.65it/s]Training:  79%|███████▊  | 1259/1600 [01:07<00:18, 18.02it/s]Training:  90%|██Training loss: 19.6103, Training accuracy: 0.9956
Macro F1-score: 0.9956
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 31.4474, Validation accuracy: 0.9750
Macro F1-score: 0.9750
Model performance on Angry speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9200, F1_score: 0.9583
Model performance on Neutral speech (in validation): 
	Precision: 0.9259, Recall: 1.0000, F1_score: 0.9615
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 11/100

Training Phase:
Training loss: 31.8611, Training accuracy: 0.9975
Macro F1-score: 0.9975
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Happy speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 0.9950, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 1.0000, F1_score: 0.9975

Eval Phase: 
Validation loss: 27.7944, Validation accuracy: 0.9650
Macro F1-score: 0.9647
Model performance on Angry speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.8800, F1_score: 0.9362
Model performance on Neutral speech (in validation): 
	Precision: 0.9091, Recall: 1.0000, F1_score: 0.9524
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 12/100

Training Phase:
██████ | 1448/1600 [01:17<00:08, 18.13it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 211/1600 [00:10<01:05, 21.09it/s]Training:  26%|██▋       | 422/1600 [00:20<00:56, 20.88it/s]Training:  39%|███▉      | 630/1600 [00:30<00:47, 20.50it/s]Training:  52%|█████▏    | 833/1600 [00:40<00:37, 20.41it/s]Training:  65%|██████▌   | 1040/1600 [00:50<00:27, 20.50it/s]Training:  78%|███████▊  | 1247/1600 [01:00<00:17, 20.53it/s]Training:  91%|█████████ | 1453/1600 [01:10<00:07, 20.51it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎Training loss: 12.0979, Training accuracy: 0.9969
Macro F1-score: 0.9969
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 0.9950, F1_score: 0.9975
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9975, F1_score: 0.9950
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987

Eval Phase: 
Validation loss: 88.1850, Validation accuracy: 0.9300
Macro F1-score: 0.9297
Model performance on Angry speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9200, F1_score: 0.9583
Model performance on Neutral speech (in validation): 
	Precision: 0.9756, Recall: 0.8000, F1_score: 0.8791
Model performance on Sad speech (in validation): 
	Precision: 0.8197, Recall: 1.0000, F1_score: 0.9009
Epoch 13/100

Training Phase:
        | 214/1600 [00:10<01:04, 21.34it/s]Training:  27%|██▋       | 428/1600 [00:20<00:55, 21.05it/s]Training:  40%|███▉      | 638/1600 [00:30<00:45, 20.97it/s]Training:  53%|█████▎    | 847/1600 [00:40<00:36, 20.70it/s]Training:  66%|██████▋   | 1062/1600 [00:50<00:25, 20.98it/s]Training:  80%|███████▉  | 1277/1600 [01:00<00:15, 21.11it/s]Training:  93%|█████████▎| 1494/1600 [01:10<00:04, 21.30it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 215/1600 [00:10<01:04, 21.49it/s]Training:  27%|██▋       | 431/1600 [00:20<00:54, 21.54it/s]Training:  40%|████      | 647/1600 [00:30<00:44, 21.44it/s]Training:  54%|█████▍    | 861/1600 [00:40<00:34, 21.35it/s]Training:  67%|██████▋   | 1Training loss: 45.7494, Training accuracy: 0.9931
Macro F1-score: 0.9931
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Neutral speech (in training): 
	Precision: 0.9875, Recall: 0.9900, F1_score: 0.9888
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912

Eval Phase: 
Validation loss: 15.6602, Validation accuracy: 0.9800
Macro F1-score: 0.9800
Model performance on Angry speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9400, F1_score: 0.9691
Model performance on Neutral speech (in validation): 
	Precision: 0.9434, Recall: 1.0000, F1_score: 0.9709
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
New best accuracy for layer 4 on epoch 13: 0.9800. Model saved.
Epoch 14/100

Training Phase:
Training loss: 14.1997, Training accuracy: 0.9975
Macro F1-score: 0.9975
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Happy speech (in training): 
	Precision: 0.9975, Recall: 0.9925, F1_score: 0.9950
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 1.0000, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
076/1600 [00:50<00:24, 21.40it/s]Training:  81%|████████  | 1295/1600 [01:00<00:14, 21.57it/s]Training:  95%|█████████▍| 1514/1600 [01:10<00:04, 21.48it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 217/1600 [00:10<01:03, 21.67it/s]Training:  27%|██▋       | 434/1600 [00:20<00:54, 21.55it/s]Training:  41%|████      | 652/1600 [00:30<00:43, 21.65it/s]Training:  55%|█████▍    | 875/1600 [00:40<00:33, 21.87it/s]Training:  69%|██████▊   | 1099/1600 [00:50<00:22, 22.05it/s]Training:  83%|████████▎ | 1323/1600 [01:00<00:12, 21.83it/s]Training:  96%|█████████▌| 1538/1600 [01:10<00:02, 21.68it/s]                                                             Evaluating:   0%|          | 0/200 [Validation loss: 40.7872, Validation accuracy: 0.9700
Macro F1-score: 0.9699
Model performance on Angry speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9000, F1_score: 0.9474
Model performance on Neutral speech (in validation): 
	Precision: 0.9091, Recall: 1.0000, F1_score: 0.9524
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 15/100

Training Phase:
Training loss: 20.1388, Training accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 1.0000, F1_score: 0.9975
Model performance on Happy speech (in training): 
	Precision: 0.9975, Recall: 0.9875, F1_score: 0.9925
Model performance on Neutral speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988

Eval Phase: 
Validation loss: 9.3370, Validation accuracy: 0.9850
Macro F1-score: 0.9850
Model performance on Angry speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Happy speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Neutral speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
New best accuracy for layer 4 on epoch 15: 0.9850. Model saved.
Epoch 16/100

Training Phase:
00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 217/1600 [00:10<01:03, 21.62it/s]Training:  27%|██▋       | 434/1600 [00:20<00:54, 21.49it/s]Training:  41%|████      | 652/1600 [00:30<00:43, 21.59it/s]Training:  54%|█████▍    | 870/1600 [00:40<00:33, 21.55it/s]Training:  68%|██████▊   | 1085/1600 [00:50<00:24, 21.43it/s]Training:  81%|████████▏ | 1301/1600 [01:00<00:13, 21.49it/s]Training:  95%|█████████▍| 1517/1600 [01:10<00:03, 21.41it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 219/1600 [00:10<01:03, 21.87it/s]Training:  28%|██▊       | 445/1600 [00:20<00:51, 22.26it/s]Training:  42%|████▏     | 671/Training loss: 17.4357, Training accuracy: 0.9962
Macro F1-score: 0.9963
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Happy speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Validation loss: 9.9723, Validation accuracy: 0.9850
Macro F1-score: 0.9850
Model performance on Angry speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Neutral speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 17/100

Training Phase:
1600 [00:30<00:41, 22.40it/s]Training:  56%|█████▌    | 898/1600 [00:40<00:31, 22.50it/s]Training:  70%|███████   | 1125/1600 [00:50<00:21, 22.52it/s]Training:  84%|████████▍ | 1351/1600 [01:00<00:11, 21.97it/s]Training:  98%|█████████▊| 1567/1600 [01:10<00:01, 21.82it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 221/1600 [00:10<01:02, 22.03it/s]Training:  14%|█▍        | 221/1600 [00:20<01:02, 22.03it/s]Training:  28%|██▊       | 442/1600 [00:20<00:53, 21.75it/s]Training:  41%|████▏     | 660/1600 [00:30<00:43, 21.77it/s]Training:  55%|█████▍    | 878/1600 [00:40<00:33, 21.67it/s]Training:  68%|██████▊   | 1096/1600 [00:50<00:23, 21.70it/s]Training:  82%|████████▏ | 13Training loss: 18.6959, Training accuracy: 0.9962
Macro F1-score: 0.9962
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9975, F1_score: 0.9950
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9900, F1_score: 0.9925
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Validation loss: 18.7184, Validation accuracy: 0.9750
Macro F1-score: 0.9749
Model performance on Angry speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9200, F1_score: 0.9583
Model performance on Neutral speech (in validation): 
	Precision: 0.9434, Recall: 1.0000, F1_score: 0.9709
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 18/100

Training Phase:
Training loss: 19.9833, Training accuracy: 0.9975
Macro F1-score: 0.9975
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 39.1380, Validation accuracy: 0.9700
Macro F1-score: 0.9699
Model performance on Angry speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9000, F1_score: 0.9474
Model performance on Neutral speech (in validation): 
	Precision: 0.9091, Recall: 1.0000, F1_score: 0.9524
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 19/100

Training Phase:
14/1600 [01:00<00:13, 21.65it/s]Training:  96%|█████████▌| 1532/1600 [01:10<00:03, 21.68it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 213/1600 [00:10<01:05, 21.21it/s]Training:  27%|██▋       | 433/1600 [00:20<00:53, 21.65it/s]Training:  42%|████▏     | 664/1600 [00:30<00:41, 22.29it/s]Training:  56%|█████▌    | 895/1600 [00:40<00:31, 22.52it/s]Training:  70%|███████   | 1124/1600 [00:50<00:21, 22.55it/s]Training:  84%|████████▍ | 1350/1600 [01:00<00:11, 22.48it/s]Training:  98%|█████████▊| 1574/1600 [01:10<00:01, 22.40it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   TrainingTraining loss: 2.6726, Training accuracy: 0.9994
Macro F1-score: 0.9994
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 24.4632, Validation accuracy: 0.9800
Macro F1-score: 0.9800
Model performance on Angry speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9400, F1_score: 0.9691
Model performance on Neutral speech (in validation): 
	Precision: 0.9434, Recall: 1.0000, F1_score: 0.9709
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 20/100

Training Phase:
:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 226/1600 [00:10<01:00, 22.55it/s]Training:  28%|██▊       | 453/1600 [00:20<00:50, 22.58it/s]Training:  42%|████▎     | 680/1600 [00:30<00:41, 22.24it/s]Training:  56%|█████▌    | 899/1600 [00:40<00:31, 21.98it/s]Training:  70%|██████▉   | 1115/1600 [00:50<00:22, 21.76it/s]Training:  83%|████████▎ | 1330/1600 [01:00<00:12, 21.67it/s]Training:  97%|█████████▋| 1553/1600 [01:10<00:02, 21.84it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 224/1600 [00:10<01:01, 22.34it/s]Training:  28%|██▊       | 451/1600 [00:20<00:50, 22.55it/s]Training:  42%|████▏     | 678/1600 [00:30<00:40, 22.52it/s]Training:  56%|█████▋    | 904/16Training loss: 0.8983, Training accuracy: 1.0000
Macro F1-score: 1.0000
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 35.6512, Validation accuracy: 0.9750
Macro F1-score: 0.9750
Model performance on Angry speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9200, F1_score: 0.9583
Model performance on Neutral speech (in validation): 
	Precision: 0.9259, Recall: 1.0000, F1_score: 0.9615
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 21/100

Training Phase:
00 [00:40<00:30, 22.55it/s]Training:  71%|███████   | 1130/1600 [00:50<00:20, 22.55it/s]Training:  85%|████████▍ | 1356/1600 [01:00<00:10, 22.51it/s]Training:  99%|█████████▉| 1581/1600 [01:10<00:00, 22.50it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 229/1600 [00:10<01:00, 22.81it/s]Training:  29%|██▊       | 458/1600 [00:20<00:50, 22.83it/s]Training:  43%|████▎     | 687/1600 [00:30<00:40, 22.40it/s]Training:  57%|█████▋    | 907/1600 [00:40<00:31, 22.14it/s]Training:  70%|███████   | 1125/1600 [00:50<00:21, 21.93it/s]Training:  84%|████████▍ | 1346/1600 [01:00<00:11, 21.96it/s]Training:  98%|█████████▊| 1568/1600 [01:10<00:01, 22.03it/s]                         Training loss: 17.7021, Training accuracy: 0.9969
Macro F1-score: 0.9969
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988

Eval Phase: 
Validation loss: 15.3988, Validation accuracy: 0.9700
Macro F1-score: 0.9700
Model performance on Angry speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9200, F1_score: 0.9583
Model performance on Neutral speech (in validation): 
	Precision: 0.9259, Recall: 1.0000, F1_score: 0.9615
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Epoch 22/100

Training Phase:
Training loss: 15.3334, Training accuracy: 0.9981
Macro F1-score: 0.9981
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 31.0882, Validation accuracy: 0.9650
Macro F1-score: 0.9647
Model performance on Angry speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.8800, F1_score: 0.9362
Model performance on Neutral speech (in validation): 
	Precision: 0.9091, Recall: 1.0000, F1_score: 0.9524
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 23/100

Training Phase:
                                    Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 221/1600 [00:10<01:02, 22.08it/s]Training:  28%|██▊       | 442/1600 [00:20<00:52, 22.08it/s]Training:  42%|████▏     | 668/1600 [00:30<00:41, 22.29it/s]Training:  56%|█████▌    | 894/1600 [00:40<00:31, 22.18it/s]Training:  70%|██████▉   | 1115/1600 [00:50<00:22, 21.84it/s]Training:  83%|████████▎ | 1330/1600 [01:00<00:12, 21.72it/s]Training:  97%|█████████▋| 1545/1600 [01:10<00:02, 21.49it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 224/1600 [00:10<01:01, 22.31it/s]Training:  28%|██▊       |Training loss: 18.4585, Training accuracy: 0.9975
Macro F1-score: 0.9975
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 23.8170, Validation accuracy: 0.9700
Macro F1-score: 0.9698
Model performance on Angry speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9000, F1_score: 0.9474
Model performance on Neutral speech (in validation): 
	Precision: 0.9259, Recall: 1.0000, F1_score: 0.9615
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 24/100

Training Phase:
 450/1600 [00:20<00:51, 22.45it/s]Training:  42%|████▏     | 676/1600 [00:30<00:41, 22.33it/s]Training:  56%|█████▋    | 901/1600 [00:40<00:31, 22.38it/s]Training:  70%|███████   | 1126/1600 [00:50<00:21, 22.33it/s]Training:  84%|████████▍ | 1350/1600 [01:00<00:11, 22.35it/s]Training:  98%|█████████▊| 1574/1600 [01:10<00:01, 22.07it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 208/1600 [00:10<01:07, 20.74it/s]Training:  26%|██▌       | 416/1600 [00:20<00:57, 20.68it/s]Training:  40%|████      | 640/1600 [00:30<00:44, 21.44it/s]Training:  54%|█████▍    | 870/1600 [00:40<00:33, 22.05it/s]Training:  69%|██████▉   | 1100/1600 [00:50<00:22, 22.06it/s]Training:  83%|███████Training loss: 12.0019, Training accuracy: 0.9962
Macro F1-score: 0.9962
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9975, F1_score: 0.9950
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9900, F1_score: 0.9925
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 19.0624, Validation accuracy: 0.9800
Macro F1-score: 0.9799
Model performance on Angry speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9400, F1_score: 0.9691
Model performance on Neutral speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 25/100

Training Phase:
Training loss: 4.1947, Training accuracy: 0.9994
Macro F1-score: 0.9994
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 28.3941, Validation accuracy: 0.9800
Macro F1-score: 0.9798
Model performance on Angry speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9200, F1_score: 0.9583
Model performance on Neutral speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Validation loss does not decrease for 10 epochs. End training.
Model best accuracy on validation set: 0.9850

Test Phase: 
▎ | 1326/1600 [01:00<00:12, 22.23it/s]Training:  97%|█████████▋| 1554/1600 [01:10<00:02, 22.39it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 212/1600 [00:10<01:05, 21.17it/s]Training:  27%|██▋       | 427/1600 [00:20<00:54, 21.34it/s]Training:  40%|████      | 643/1600 [00:30<00:44, 21.43it/s]Training:  54%|█████▎    | 859/1600 [00:40<00:34, 21.44it/s]Training:  67%|██████▋   | 1074/1600 [00:50<00:24, 21.40it/s]Training:  81%|████████  | 1289/1600 [01:00<00:14, 21.41it/s]Training:  94%|█████████▍| 1504/1600 [01:10<00:04, 21.43it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]                                                Some weights of the model checkpoint at /work/tc062/tc062/zhan7721/saved_models/de were not used when initializing Wav2Vec2Model: ['encoder.layers.10.attention.k_proj.bias', 'encoder.layers.10.attention.k_proj.weight', 'encoder.layers.10.attention.out_proj.bias', 'encoder.layers.10.attention.out_proj.weight', 'encoder.layers.10.attention.q_proj.bias', 'encoder.layers.10.attention.q_proj.weight', 'encoder.layers.10.attention.v_proj.bias', 'encoder.layers.10.attention.v_proj.weight', 'encoder.layers.10.feed_forward.intermediate_dense.bias', 'encoder.layers.10.feed_forward.intermediate_dense.weight', 'encoder.layers.10.feed_forward.output_dense.bias', 'encoder.layers.10.feed_forward.output_dense.weight', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.10.layer_norm.bias', 'encoder.layers.10.layer_norm.weight', 'encoder.layers.11.attention.k_proj.bias', 'encoder.layers.11.attention.k_proj.weight', 'encoder.layers.11.attention.out_proj.bias', 'encoder.layers.11.attention.out_proj.weight', 'encoder.layers.11.attention.q_proj.bias', 'encoder.layers.11.attention.q_proj.weight', 'encoder.layers.11.attention.v_proj.bias', 'encoder.layers.11.attention.v_proj.weight', 'encoder.layers.11.feed_forward.intermediate_dense.bias', 'encoder.layers.11.feed_forward.intermediate_dense.weight', 'encoder.layers.11.feed_forward.output_dense.bias', 'encoder.layers.11.feed_forward.output_dense.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.11.layer_norm.bias', 'encoder.layers.11.layer_norm.weight', 'encoder.layers.5.attention.k_proj.bias', 'encoder.layers.5.attention.k_proj.weight', 'encoder.layers.5.attention.out_proj.bias', 'encoder.layers.5.attention.out_proj.weight', 'encoder.layers.5.attention.q_proj.bias', 'encoder.layers.5.attention.q_proj.weight', 'encoder.layers.5.attention.v_proj.bias', 'encoder.layers.5.attention.v_proj.weight', 'encoder.layers.5.feed_forward.intermediate_dense.bias', 'encoder.layers.5.feed_forward.intermediate_dense.weight', 'encoder.layers.5.feed_forward.output_dense.bias', 'encoder.layers.5.feed_forward.output_dense.weight', 'encoder.layers.5.final_layer_norm.bias', 'encoder.layers.5.final_layer_norm.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.6.attention.k_proj.bias', 'encoder.layers.6.attention.k_proj.weight', 'encoder.layers.6.attention.out_proj.bias', 'encoder.layers.6.attention.out_proj.weight', 'encoder.layers.6.attention.q_proj.bias', 'encoder.layers.6.attention.q_proj.weight', 'encoder.layers.6.attention.v_proj.bias', 'encoder.layers.6.attention.v_proj.weight', 'encoder.layers.6.feed_forward.intermediate_dense.bias', 'encoder.layers.6.feed_forward.intermediate_dense.weight', 'encoder.layers.6.feed_forward.output_dense.bias', 'encoder.layers.6.feed_forward.output_dense.weight', 'encoder.layers.6.final_layer_norm.bias', 'encoder.layers.6.final_layer_norm.weight', 'encoder.layers.6.layer_norm.bias', 'encoder.layers.6.layer_norm.weight', 'encoder.layers.7.attention.k_proj.bias', 'encoder.layers.7.attention.k_proj.weight', 'encoder.layers.7.attention.out_proj.bias', 'encoder.layers.7.attention.out_proj.weight', 'encoder.layers.7.attention.q_proj.bias', 'encoder.layers.7.attention.q_proj.weight', 'encoder.layers.7.attention.v_proj.bias', 'encoder.layers.7.attention.v_proj.weight', 'encoder.layers.7.feed_forward.intermediate_dense.bias', 'encoder.layers.7.feed_forward.intermediate_dense.weight', 'encoder.layers.7.feed_forward.output_dense.bias', 'encoder.layers.7.feed_forward.output_dense.weight', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.7.layer_norm.bias', 'encoder.layers.7.layer_norm.weight', 'encoder.layers.8.attention.k_proj.bias', 'encoder.layers.8.attention.k_proj.weight', 'encoder.layers.8.attention.out_proj.bias', 'encoder.layers.8.attention.out_proj.weight', 'encoder.layers.8.attention.q_proj.bias', 'encoder.layers.8.attention.q_proj.weight', 'encoder.layers.8.attention.v_proj.bias', 'encoder.layers.8.attention.v_proj.weight', 'encoder.layers.8.feed_forward.intermediate_dense.bias', 'encoder.layers.8.feed_forward.intermediate_dense.weight', 'encoder.layers.8.feed_forward.output_dense.bias', 'encoder.layers.8.feed_forward.output_dense.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.8.layer_norm.bias', 'encoder.layers.8.layer_norm.weight', 'encoder.layers.9.attention.k_proj.bias', 'encoder.layers.9.attention.k_proj.weight', 'encoder.layers.9.attention.out_proj.bias', 'encoder.layers.9.attention.out_proj.weight', 'encoder.layers.9.attention.q_proj.bias', 'encoder.layers.9.attention.q_proj.weight', 'encoder.layers.9.attention.v_proj.bias', 'encoder.layers.9.attention.v_proj.weight', 'encoder.layers.9.feed_forward.intermediate_dense.bias', 'encoder.layers.9.feed_forward.intermediate_dense.weight', 'encoder.layers.9.feed_forward.output_dense.bias', 'encoder.layers.9.feed_forward.output_dense.weight', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.layer_norm.bias', 'encoder.layers.9.layer_norm.weight']
- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Test loss: 21.9721, Test accuracy: 0.9700
Macro F1-score: 0.9700
Model performance on Angry speech (in test): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Happy speech (in test): 
	Precision: 0.9231, Recall: 0.9600, F1_score: 0.9412
Model performance on Neutral speech (in test): 
	Precision: 1.0000, Recall: 0.9200, F1_score: 0.9583
Model performance on Sad speech (in test): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

======================= This is fold_3 on de =======================

Load dataset: 
Loading de train data: fold_3...
Preprocess de fold_3 data for de model
Loading de eval data: fold_3...
Preprocess de fold_3 data for de model
Loading de test data: fold_3...
Preprocess de fold_3 data for de model
Use de model to add lora
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training loss: 346.1039, Training accuracy: 0.9244
Macro F1-score: 0.9247
Model performance on Angry speech (in training): 
	Precision: 0.9359, Recall: 0.9125, F1_score: 0.9241
Model performance on Happy speech (in training): 
	Precision: 0.8837, Recall: 0.8925, F1_score: 0.8881
Model performance on Neutral speech (in training): 
	Precision: 0.8926, Recall: 0.9350, F1_score: 0.9133
Model performance on Sad speech (in training): 
	Precision: 0.9897, Recall: 0.9575, F1_score: 0.9733

Eval Phase: 
Validation loss: 29.4358, Validation accuracy: 0.9250
Macro F1-score: 0.9239
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Happy speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Neutral speech (in validation): 
	Precision: 0.9737, Recall: 0.7400, F1_score: 0.8409
Model performance on Sad speech (in validation): 
	Precision: 0.7937, Recall: 1.0000, F1_score: 0.8850
New best accuracy for layer 4 on epoch 1: 0.9250. Model saved.
Epoch 2/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 213/1600 [00:10<01:05, 21.26it/s]Training:  27%|██▋       | 429/1600 [00:20<00:54, 21.45it/s]Training:  40%|████      | 645/1600 [00:30<00:44, 21.51it/s]Training:  54%|█████▍    | 861/1600 [00:40<00:34, 21.45it/s]Training:  67%|██████▋   | 1075/1600 [00:50<00:24, 21.41it/s]Training:  81%|████████  | 1296/1600 [01:00<00:14, 21.63it/s]Training:  95%|█████████▌| 1520/1600 [01:10<00:03, 21.86it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 221/1600 [00:10<01:02, 22.08it/s]Training:  28%|██▊       | 445/1600 [00:20<00:51, 22.25it/s]Training:  42%|████▏     | 670/1600 [00:30<00:41, 22.36it/s]Training:  56%|█████▌    | 8Training loss: 106.3178, Training accuracy: 0.9781
Macro F1-score: 0.9781
Model performance on Angry speech (in training): 
	Precision: 0.9848, Recall: 0.9700, F1_score: 0.9773
Model performance on Happy speech (in training): 
	Precision: 0.9601, Recall: 0.9625, F1_score: 0.9613
Model performance on Neutral speech (in training): 
	Precision: 0.9704, Recall: 0.9825, F1_score: 0.9764
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Validation loss: 11.5649, Validation accuracy: 0.9700
Macro F1-score: 0.9700
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Happy speech (in validation): 
	Precision: 0.9792, Recall: 0.9400, F1_score: 0.9592
Model performance on Neutral speech (in validation): 
	Precision: 0.9412, Recall: 0.9600, F1_score: 0.9505
Model performance on Sad speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
New best accuracy for layer 4 on epoch 2: 0.9700. Model saved.
Epoch 3/100

Training Phase:
95/1600 [00:40<00:31, 22.36it/s]Training:  70%|███████   | 1121/1600 [00:50<00:21, 22.42it/s]Training:  84%|████████▍ | 1347/1600 [01:00<00:11, 22.33it/s]Training:  98%|█████████▊| 1569/1600 [01:10<00:01, 22.16it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 215/1600 [00:10<01:04, 21.43it/s]Training:  27%|██▋       | 430/1600 [00:20<00:54, 21.36it/s]Training:  27%|██▋       | 430/1600 [00:30<00:54, 21.36it/s]Training:  40%|████      | 647/1600 [00:30<00:44, 21.48it/s]Training:  54%|█████▍    | 864/1600 [00:40<00:34, 21.44it/s]Training:  67%|██████▋   | 1078/1600 [00:50<00:24, 21.35it/s]Training:  81%|████████  | 1297/1600 [01:00<00:14, 21.50it/s]Training:  95%|████████Training loss: 62.3547, Training accuracy: 0.9862
Macro F1-score: 0.9863
Model performance on Angry speech (in training): 
	Precision: 0.9949, Recall: 0.9825, F1_score: 0.9887
Model performance on Happy speech (in training): 
	Precision: 0.9776, Recall: 0.9800, F1_score: 0.9788
Model performance on Neutral speech (in training): 
	Precision: 0.9753, Recall: 0.9875, F1_score: 0.9814
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962

Eval Phase: 
Validation loss: 3.3515, Validation accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
New best accuracy for layer 4 on epoch 3: 0.9900. Model saved.
Epoch 4/100

Training Phase:
Training loss: 65.0775, Training accuracy: 0.9875
Macro F1-score: 0.9875
Model performance on Angry speech (in training): 
	Precision: 0.9825, Recall: 0.9800, F1_score: 0.9812
Model performance on Happy speech (in training): 
	Precision: 0.9752, Recall: 0.9825, F1_score: 0.9788
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987

Eval Phase: 
Validation loss: 8.1442, Validation accuracy: 0.9800
Macro F1-score: 0.9799
Model performance on Angry speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in validation): 
	Precision: 0.9796, Recall: 0.9600, F1_score: 0.9697
Model performance on Neutral speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 5/100

Training Phase:
█▍| 1515/1600 [01:10<00:03, 21.49it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 215/1600 [00:10<01:04, 21.45it/s]Training:  27%|██▋       | 433/1600 [00:20<00:53, 21.62it/s]Training:  41%|████      | 651/1600 [00:30<00:44, 21.42it/s]Training:  55%|█████▍    | 878/1600 [00:40<00:32, 21.89it/s]Training:  69%|██████▉   | 1105/1600 [00:50<00:22, 21.80it/s]Training:  83%|████████▎ | 1322/1600 [01:01<00:12, 21.60it/s]Training:  96%|█████████▌| 1536/1600 [01:11<00:02, 21.53it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | Training loss: 28.3937, Training accuracy: 0.9944
Macro F1-score: 0.9944
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Happy speech (in training): 
	Precision: 0.9924, Recall: 0.9850, F1_score: 0.9887
Model performance on Neutral speech (in training): 
	Precision: 0.9876, Recall: 0.9950, F1_score: 0.9913
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 5.5280, Validation accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Happy speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
New best accuracy for layer 4 on epoch 5: 0.9950. Model saved.
Epoch 6/100

Training Phase:
215/1600 [00:10<01:04, 21.47it/s]Training:  27%|██▋       | 430/1600 [00:20<00:54, 21.46it/s]Training:  41%|████      | 656/1600 [00:30<00:42, 21.97it/s]Training:  55%|█████▌    | 882/1600 [00:40<00:32, 22.11it/s]Training:  69%|██████▉   | 1107/1600 [00:50<00:22, 22.23it/s]Training:  83%|████████▎ | 1332/1600 [01:00<00:12, 22.20it/s]Training:  97%|█████████▋| 1554/1600 [01:10<00:02, 21.93it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 211/1600 [00:10<01:05, 21.08it/s]Training:  27%|██▋       | 429/1600 [00:20<00:54, 21.44it/s]Training:  40%|████      | 647/1600 [00:30<00:44, 21.56it/s]Training:  54%|█████▍    | 864/1600 [00:40<00:34, 21.43it/s]Training:  68%|██████▊   | 1081/1600Training loss: 58.5999, Training accuracy: 0.9888
Macro F1-score: 0.9888
Model performance on Angry speech (in training): 
	Precision: 0.9899, Recall: 0.9850, F1_score: 0.9875
Model performance on Happy speech (in training): 
	Precision: 0.9801, Recall: 0.9850, F1_score: 0.9825
Model performance on Neutral speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950

Eval Phase: 
Validation loss: 7.2710, Validation accuracy: 0.9850
Macro F1-score: 0.9850
Model performance on Angry speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 7/100

Training Phase:
Training loss: 19.1114, Training accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9875, F1_score: 0.9900
Model performance on Happy speech (in training): 
	Precision: 0.9876, Recall: 0.9925, F1_score: 0.9900
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
 [00:50<00:24, 21.50it/s]Training:  81%|████████  | 1298/1600 [01:00<00:14, 21.48it/s]Training:  95%|█████████▍| 1514/1600 [01:10<00:03, 21.52it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 218/1600 [00:10<01:03, 21.79it/s]Training:  27%|██▋       | 436/1600 [00:20<00:54, 21.34it/s]Training:  41%|████      | 653/1600 [00:30<00:44, 21.47it/s]Training:  54%|█████▍    | 870/1600 [00:40<00:33, 21.49it/s]Training:  68%|██████▊   | 1091/1600 [00:50<00:23, 21.68it/s]Training:  82%|████████▏ | 1311/1600 [01:00<00:13, 21.48it/s]Training:  95%|█████████▌| 1527/1600 [01:10<00:03, 21.50it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?,Validation loss: 13.2985, Validation accuracy: 0.9800
Macro F1-score: 0.9799
Model performance on Angry speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in validation): 
	Precision: 0.9796, Recall: 0.9600, F1_score: 0.9697
Model performance on Neutral speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 8/100

Training Phase:
Training loss: 42.5746, Training accuracy: 0.9894
Macro F1-score: 0.9894
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9875, F1_score: 0.9900
Model performance on Neutral speech (in training): 
	Precision: 0.9752, Recall: 0.9825, F1_score: 0.9788
Model performance on Sad speech (in training): 
	Precision: 0.9900, Recall: 0.9875, F1_score: 0.9887

Eval Phase: 
Validation loss: 6.0483, Validation accuracy: 0.9800
Macro F1-score: 0.9799
Model performance on Angry speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in validation): 
	Precision: 0.9796, Recall: 0.9600, F1_score: 0.9697
Model performance on Neutral speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 9/100

Training Phase:
 ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 215/1600 [00:10<01:04, 21.46it/s]Training:  27%|██▋       | 433/1600 [00:20<00:53, 21.63it/s]Training:  41%|████      | 651/1600 [00:30<00:43, 21.64it/s]Training:  54%|█████▍    | 868/1600 [00:40<00:33, 21.66it/s]Training:  68%|██████▊   | 1085/1600 [00:50<00:23, 21.47it/s]Training:  81%|████████  | 1299/1600 [01:00<00:14, 21.43it/s]Training:  95%|█████████▍| 1513/1600 [01:10<00:04, 21.39it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 214/1600 [00:10<01:04, 21.38it/s]Training:  27%|██▋       | 434/1600 [00:20<00:53, 21.71it/s]Training:  41%|████      | 655/1600 [00:30<Training loss: 23.7839, Training accuracy: 0.9956
Macro F1-score: 0.9956
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 4.5333, Validation accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 10/100

Training Phase:
00:43, 21.84it/s]Training:  55%|█████▍    | 875/1600 [00:40<00:33, 21.65it/s]Training:  68%|██████▊   | 1089/1600 [00:50<00:23, 21.43it/s]Training:  82%|████████▏ | 1304/1600 [01:00<00:13, 21.43it/s]Training:  95%|█████████▌| 1522/1600 [01:10<00:03, 21.53it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 219/1600 [00:10<01:03, 21.84it/s]Training:  27%|██▋       | 438/1600 [00:20<00:53, 21.59it/s]Training:  41%|████      | 653/1600 [00:30<00:45, 20.87it/s]Training:  53%|█████▎    | 854/1600 [00:41<00:37, 19.91it/s]Training:  65%|██████▌   | 1047/1600 [00:51<00:28, 19.67it/s]Training:  78%|███████▊  | 1246/1600 [01:01<00:17, 19.74it/s]Training:  91%|█████████ | 145Training loss: 6.1105, Training accuracy: 0.9994
Macro F1-score: 0.9994
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987
Model performance on Happy speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 14.2471, Validation accuracy: 0.9850
Macro F1-score: 0.9849
Model performance on Angry speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in validation): 
	Precision: 0.9796, Recall: 0.9600, F1_score: 0.9697
Model performance on Neutral speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 11/100

Training Phase:
Training loss: 39.8669, Training accuracy: 0.9931
Macro F1-score: 0.9931
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9925, F1_score: 0.9950
Model performance on Happy speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913
Model performance on Neutral speech (in training): 
	Precision: 0.9876, Recall: 0.9925, F1_score: 0.9900
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962

Eval Phase: 
Validation loss: 9.0506, Validation accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Happy speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Neutral speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 12/100

Training Phase:
1/1600 [01:11<00:07, 19.97it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 217/1600 [00:10<01:03, 21.67it/s]Training:  28%|██▊       | 443/1600 [00:20<00:52, 22.18it/s]Training:  42%|████▏     | 669/1600 [00:30<00:42, 22.05it/s]Training:  56%|█████▌    | 888/1600 [00:40<00:32, 21.86it/s]Training:  69%|██████▉   | 1104/1600 [00:50<00:23, 21.50it/s]Training:  82%|████████▏ | 1313/1600 [01:01<00:13, 21.17it/s]Training:  95%|█████████▌| 1525/1600 [01:11<00:03, 21.17it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 216/1600 Training loss: 27.9177, Training accuracy: 0.9931
Macro F1-score: 0.9931
Model performance on Angry speech (in training): 
	Precision: 0.9875, Recall: 0.9900, F1_score: 0.9888
Model performance on Happy speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 8.2585, Validation accuracy: 0.9850
Macro F1-score: 0.9850
Model performance on Angry speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 13/100

Training Phase:
[00:10<01:04, 21.59it/s]Training:  27%|██▋       | 432/1600 [00:20<00:54, 21.45it/s]Training:  40%|████      | 646/1600 [00:30<00:44, 21.42it/s]Training:  54%|█████▍    | 868/1600 [00:40<00:33, 21.71it/s]Training:  68%|██████▊   | 1095/1600 [00:50<00:22, 22.04it/s]Training:  83%|████████▎ | 1322/1600 [01:00<00:12, 22.06it/s]Training:  96%|█████████▋| 1544/1600 [01:10<00:02, 22.02it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 221/1600 [00:10<01:02, 22.07it/s]Training:  28%|██▊       | 442/1600 [00:20<00:52, 22.08it/s]Training:  41%|████▏     | 663/1600 [00:30<00:43, 21.58it/s]Training:  55%|█████▌    | 884/1600 [00:40<00:32, 21.75it/s]Training:  69%|██████▉   | 1105/1600 [00:50Training loss: 9.3250, Training accuracy: 0.9975
Macro F1-score: 0.9975
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9925, F1_score: 0.9950
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9975, F1_score: 0.9950
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 9.1815, Validation accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Validation loss does not decrease for 10 epochs. End training.
Model best accuracy on validation set: 0.9950

Test Phase: 
<00:22, 21.76it/s]Training:  83%|████████▎ | 1323/1600 [01:00<00:12, 21.77it/s]Training:  96%|█████████▋| 1541/1600 [01:10<00:02, 21.67it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]                                                Some weights of the model checkpoint at /work/tc062/tc062/zhan7721/saved_models/de were not used when initializing Wav2Vec2Model: ['encoder.layers.10.attention.k_proj.bias', 'encoder.layers.10.attention.k_proj.weight', 'encoder.layers.10.attention.out_proj.bias', 'encoder.layers.10.attention.out_proj.weight', 'encoder.layers.10.attention.q_proj.bias', 'encoder.layers.10.attention.q_proj.weight', 'encoder.layers.10.attention.v_proj.bias', 'encoder.layers.10.attention.v_proj.weight', 'encoder.layers.10.feed_forward.intermediate_dense.bias', 'encoder.layers.10.feed_forward.intermediate_dense.weight', 'encoder.layers.10.feed_forward.output_dense.bias', 'encoder.layers.10.feed_forward.output_dense.weight', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.10.layer_norm.bias', 'encoder.layers.10.layer_norm.weight', 'encoder.layers.11.attention.k_proj.bias', 'encoder.layers.11.attention.k_proj.weight', 'encoder.layers.11.attention.out_proj.bias', 'encoder.layers.11.attention.out_proj.weight', 'encoder.layers.11.attention.q_proj.bias', 'encoder.layers.11.attention.q_proj.weight', 'encoder.layers.11.attention.v_proj.bias', 'encoder.layers.11.attention.v_proj.weight', 'encoder.layers.11.feed_forward.intermediate_dense.bias', 'encoder.layers.11.feed_forward.intermediate_dense.weight', 'encoder.layers.11.feed_forward.output_dense.bias', 'encoder.layers.11.feed_forward.output_dense.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.11.layer_norm.bias', 'encoder.layers.11.layer_norm.weight', 'encoder.layers.5.attention.k_proj.bias', 'encoder.layers.5.attention.k_proj.weight', 'encoder.layers.5.attention.out_proj.bias', 'encoder.layers.5.attention.out_proj.weight', 'encoder.layers.5.attention.q_proj.bias', 'encoder.layers.5.attention.q_proj.weight', 'encoder.layers.5.attention.v_proj.bias', 'encoder.layers.5.attention.v_proj.weight', 'encoder.layers.5.feed_forward.intermediate_dense.bias', 'encoder.layers.5.feed_forward.intermediate_dense.weight', 'encoder.layers.5.feed_forward.output_dense.bias', 'encoder.layers.5.feed_forward.output_dense.weight', 'encoder.layers.5.final_layer_norm.bias', 'encoder.layers.5.final_layer_norm.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.6.attention.k_proj.bias', 'encoder.layers.6.attention.k_proj.weight', 'encoder.layers.6.attention.out_proj.bias', 'encoder.layers.6.attention.out_proj.weight', 'encoder.layers.6.attention.q_proj.bias', 'encoder.layers.6.attention.q_proj.weight', 'encoder.layers.6.attention.v_proj.bias', 'encoder.layers.6.attention.v_proj.weight', 'encoder.layers.6.feed_forward.intermediate_dense.bias', 'encoder.layers.6.feed_forward.intermediate_dense.weight', 'encoder.layers.6.feed_forward.output_dense.bias', 'encoder.layers.6.feed_forward.output_dense.weight', 'encoder.layers.6.final_layer_norm.bias', 'encoder.layers.6.final_layer_norm.weight', 'encoder.layers.6.layer_norm.bias', 'encoder.layers.6.layer_norm.weight', 'encoder.layers.7.attention.k_proj.bias', 'encoder.layers.7.attention.k_proj.weight', 'encoder.layers.7.attention.out_proj.bias', 'encoder.layers.7.attention.out_proj.weight', 'encoder.layers.7.attention.q_proj.bias', 'encoder.layers.7.attention.q_proj.weight', 'encoder.layers.7.attention.v_proj.bias', 'encoder.layers.7.attention.v_proj.weight', 'encoder.layers.7.feed_forward.intermediate_dense.bias', 'encoder.layers.7.feed_forward.intermediate_dense.weight', 'encoder.layers.7.feed_forward.output_dense.bias', 'encoder.layers.7.feed_forward.output_dense.weight', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.7.layer_norm.bias', 'encoder.layers.7.layer_norm.weight', 'encoder.layers.8.attention.k_proj.bias', 'encoder.layers.8.attention.k_proj.weight', 'encoder.layers.8.attention.out_proj.bias', 'encoder.layers.8.attention.out_proj.weight', 'encoder.layers.8.attention.q_proj.bias', 'encoder.layers.8.attention.q_proj.weight', 'encoder.layers.8.attention.v_proj.bias', 'encoder.layers.8.attention.v_proj.weight', 'encoder.layers.8.feed_forward.intermediate_dense.bias', 'encoder.layers.8.feed_forward.intermediate_dense.weight', 'encoder.layers.8.feed_forward.output_dense.bias', 'encoder.layers.8.feed_forward.output_dense.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.8.layer_norm.bias', 'encoder.layers.8.layer_norm.weight', 'encoder.layers.9.attention.k_proj.bias', 'encoder.layers.9.attention.k_proj.weight', 'encoder.layers.9.attention.out_proj.bias', 'encoder.layers.9.attention.out_proj.weight', 'encoder.layers.9.attention.q_proj.bias', 'encoder.layers.9.attention.q_proj.weight', 'encoder.layers.9.attention.v_proj.bias', 'encoder.layers.9.attention.v_proj.weight', 'encoder.layers.9.feed_forward.intermediate_dense.bias', 'encoder.layers.9.feed_forward.intermediate_dense.weight', 'encoder.layers.9.feed_forward.output_dense.bias', 'encoder.layers.9.feed_forward.output_dense.weight', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.layer_norm.bias', 'encoder.layers.9.layer_norm.weight']
- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Test loss: 14.9770, Test accuracy: 0.9800
Macro F1-score: 0.9800
Model performance on Angry speech (in test): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Happy speech (in test): 
	Precision: 0.9796, Recall: 0.9600, F1_score: 0.9697
Model performance on Neutral speech (in test): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Sad speech (in test): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901

======================= This is fold_4 on de =======================

Load dataset: 
Loading de train data: fold_4...
Preprocess de fold_4 data for de model
Loading de eval data: fold_4...
Preprocess de fold_4 data for de model
Loading de test data: fold_4...
Preprocess de fold_4 data for de model
Use de model to add lora
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training loss: 292.8909, Training accuracy: 0.9413
Macro F1-score: 0.9414
Model performance on Angry speech (in training): 
	Precision: 0.9467, Recall: 0.9325, F1_score: 0.9395
Model performance on Happy speech (in training): 
	Precision: 0.9039, Recall: 0.9175, F1_score: 0.9107
Model performance on Neutral speech (in training): 
	Precision: 0.9293, Recall: 0.9525, F1_score: 0.9407
Model performance on Sad speech (in training): 
	Precision: 0.9872, Recall: 0.9625, F1_score: 0.9747

Eval Phase: 
Validation loss: 8.7763, Validation accuracy: 0.9850
Macro F1-score: 0.9850
Model performance on Angry speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Sad speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
New best accuracy for layer 4 on epoch 1: 0.9850. Model saved.
Epoch 2/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 216/1600 [00:10<01:04, 21.60it/s]Training:  28%|██▊       | 443/1600 [00:20<00:52, 22.20it/s]Training:  42%|████▏     | 670/1600 [00:30<00:41, 22.21it/s]Training:  56%|█████▌    | 896/1600 [00:40<00:31, 22.35it/s]Training:  70%|███████   | 1122/1600 [00:50<00:21, 22.30it/s]Training:  84%|████████▍ | 1345/1600 [01:01<00:11, 21.82it/s]Training:  98%|█████████▊| 1565/1600 [01:11<00:01, 21.85it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 224/1600 [00:10<01:01, 22.40it/s]Training:  28%|██▊       | 453/1600 [00:20<00:50, 22.67it/s]Training:  43%|████▎     | 682/1600 [00:30<00:40, 22.51it/s]Training:  57%|█████▋   Training loss: 87.6397, Training accuracy: 0.9800
Macro F1-score: 0.9800
Model performance on Angry speech (in training): 
	Precision: 0.9728, Recall: 0.9825, F1_score: 0.9776
Model performance on Happy speech (in training): 
	Precision: 0.9672, Recall: 0.9575, F1_score: 0.9623
Model performance on Neutral speech (in training): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 9.0101, Validation accuracy: 0.9800
Macro F1-score: 0.9800
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Happy speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Neutral speech (in validation): 
	Precision: 0.9796, Recall: 0.9600, F1_score: 0.9697
Model performance on Sad speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Epoch 3/100

Training Phase:
 | 906/1600 [00:40<00:31, 22.07it/s]Training:  70%|███████   | 1122/1600 [00:50<00:21, 21.89it/s]Training:  84%|████████▎ | 1338/1600 [01:00<00:12, 21.76it/s]Training:  98%|█████████▊| 1563/1600 [01:10<00:01, 21.98it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 223/1600 [00:10<01:01, 22.22it/s]Training:  28%|██▊       | 446/1600 [00:20<00:52, 21.79it/s]Training:  41%|████▏     | 661/1600 [00:30<00:43, 21.63it/s]Training:  55%|█████▍    | 876/1600 [00:40<00:33, 21.54it/s]Training:  68%|██████▊   | 1094/1600 [00:50<00:23, 21.61it/s]Training:  82%|████████▎ | 1320/1600 [01:00<00:12, 21.94it/s]Training:  97%|█████████▋| 1549/1600 [01:10<00:02, 22.23it/s]                Training loss: 63.5492, Training accuracy: 0.9838
Macro F1-score: 0.9837
Model performance on Angry speech (in training): 
	Precision: 0.9825, Recall: 0.9850, F1_score: 0.9838
Model performance on Happy speech (in training): 
	Precision: 0.9724, Recall: 0.9675, F1_score: 0.9699
Model performance on Neutral speech (in training): 
	Precision: 0.9825, Recall: 0.9850, F1_score: 0.9838
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Validation loss: 17.6884, Validation accuracy: 0.9700
Macro F1-score: 0.9699
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9000, F1_score: 0.9474
Model performance on Happy speech (in validation): 
	Precision: 0.9091, Recall: 1.0000, F1_score: 0.9524
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 4/100

Training Phase:
Training loss: 60.8664, Training accuracy: 0.9881
Macro F1-score: 0.9881
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9875, F1_score: 0.9900
Model performance on Happy speech (in training): 
	Precision: 0.9850, Recall: 0.9850, F1_score: 0.9850
Model performance on Neutral speech (in training): 
	Precision: 0.9826, Recall: 0.9900, F1_score: 0.9863
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912

Eval Phase: 
Validation loss: 4.1625, Validation accuracy: 0.9900
Macro F1-score: 0.9899
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
New best accuracy for layer 4 on epoch 4: 0.9900. Model saved.
Epoch 5/100

Training Phase:
                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 227/1600 [00:10<01:00, 22.61it/s]Training:  28%|██▊       | 454/1600 [00:20<00:52, 21.84it/s]Training:  42%|████▏     | 668/1600 [00:30<00:43, 21.63it/s]Training:  55%|█████▌    | 885/1600 [00:40<00:33, 21.63it/s]Training:  69%|██████▉   | 1104/1600 [00:50<00:22, 21.73it/s]Training:  83%|████████▎ | 1323/1600 [01:00<00:12, 21.70it/s]Training:  96%|█████████▋| 1543/1600 [01:10<00:02, 21.79it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 224/1600 [00:10<01:01, 22.37it/s]Training:  28%|██Training loss: 44.0621, Training accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in training): 
	Precision: 0.9850, Recall: 0.9825, F1_score: 0.9837
Model performance on Happy speech (in training): 
	Precision: 0.9825, Recall: 0.9850, F1_score: 0.9838
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Validation loss: 7.5215, Validation accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 6/100

Training Phase:
       | 448/1600 [00:20<00:51, 22.25it/s]Training:  42%|████▏     | 675/1600 [00:30<00:41, 22.44it/s]Training:  56%|█████▋    | 902/1600 [00:40<00:31, 22.37it/s]Training:  70%|███████   | 1125/1600 [00:50<00:21, 22.14it/s]Training:  84%|████████▍ | 1347/1600 [01:00<00:11, 22.15it/s]Training:  98%|█████████▊| 1570/1600 [01:10<00:01, 22.19it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 218/1600 [00:10<01:03, 21.69it/s]Training:  27%|██▋       | 435/1600 [00:20<00:53, 21.68it/s]Training:  41%|████      | 655/1600 [00:30<00:43, 21.79it/s]Training:  55%|█████▌    | 881/1600 [00:40<00:32, 22.07it/s]Training:  69%|██████▉   | 1107/1600 [00:50<00:22, 22.20it/s]Training:  83%|████Training loss: 24.8077, Training accuracy: 0.9956
Macro F1-score: 0.9956
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Happy speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 13.4087, Validation accuracy: 0.9850
Macro F1-score: 0.9850
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.9796, Recall: 0.9600, F1_score: 0.9697
Model performance on Sad speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Epoch 7/100

Training Phase:
Training loss: 43.3235, Training accuracy: 0.9912
Macro F1-score: 0.9912
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963
Model performance on Happy speech (in training): 
	Precision: 0.9874, Recall: 0.9825, F1_score: 0.9850
Model performance on Neutral speech (in training): 
	Precision: 0.9850, Recall: 0.9875, F1_score: 0.9863
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
███▎ | 1335/1600 [01:00<00:11, 22.38it/s]Training:  98%|█████████▊| 1563/1600 [01:10<00:01, 22.27it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 220/1600 [00:10<01:02, 21.95it/s]Training:  28%|██▊       | 449/1600 [00:20<00:51, 22.48it/s]Training:  42%|████▏     | 678/1600 [00:30<00:41, 22.30it/s]Training:  56%|█████▋    | 902/1600 [00:40<00:31, 22.32it/s]Training:  70%|███████   | 1126/1600 [00:50<00:21, 22.27it/s]Training:  84%|████████▍ | 1348/1600 [01:00<00:11, 22.02it/s]Training:  98%|█████████▊| 1564/1600 [01:11<00:01, 21.73it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                           Validation loss: 5.7772, Validation accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Neutral speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
New best accuracy for layer 4 on epoch 7: 0.9950. Model saved.
Epoch 8/100

Training Phase:
Training loss: 24.4071, Training accuracy: 0.9938
Macro F1-score: 0.9937
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912
Model performance on Happy speech (in training): 
	Precision: 0.9900, Recall: 0.9875, F1_score: 0.9887
Model performance on Neutral speech (in training): 
	Precision: 0.9926, Recall: 1.0000, F1_score: 0.9963
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987

Eval Phase: 
Validation loss: 10.6882, Validation accuracy: 0.9850
Macro F1-score: 0.9850
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Happy speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Neutral speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 9/100

Training Phase:
        Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 216/1600 [00:10<01:04, 21.51it/s]Training:  28%|██▊       | 442/1600 [00:20<00:52, 22.11it/s]Training:  42%|████▏     | 668/1600 [00:30<00:42, 22.16it/s]Training:  56%|█████▌    | 893/1600 [00:40<00:31, 22.26it/s]Training:  70%|███████   | 1120/1600 [00:50<00:21, 22.40it/s]Training:  84%|████████▍ | 1347/1600 [01:00<00:11, 22.32it/s]Training:  98%|█████████▊| 1569/1600 [01:10<00:01, 22.17it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 227/1600 [00:10<01:00, 22.68it/s]Training:  28%|██▊       | 454/1600 [00:20<00:50, 22.48it/s]Training:  42%|████▏     | 679/1600 [00:30<00:40, 22.48it/s]Training:  56%|████Training loss: 9.2131, Training accuracy: 0.9988
Macro F1-score: 0.9988
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Happy speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 10.7033, Validation accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 10/100

Training Phase:
█▋    | 904/1600 [00:40<00:31, 21.93it/s]Training:  70%|██████▉   | 1118/1600 [00:50<00:22, 21.73it/s]Training:  83%|████████▎ | 1335/1600 [01:00<00:12, 21.72it/s]Training:  97%|█████████▋| 1552/1600 [01:10<00:02, 21.71it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 222/1600 [00:10<01:02, 22.14it/s]Training:  28%|██▊       | 444/1600 [00:20<00:52, 22.16it/s]Training:  42%|████▏     | 666/1600 [00:30<00:43, 21.70it/s]Training:  55%|█████▌    | 881/1600 [00:40<00:33, 21.61it/s]Training:  69%|██████▉   | 1101/1600 [00:50<00:22, 21.74it/s]Training:  83%|████████▎ | 1328/1600 [01:00<00:12, 22.04it/s]Training:  97%|█████████▋| 1555/1600 [01:11<00:02, 21.95it/s]       Training loss: 37.6827, Training accuracy: 0.9925
Macro F1-score: 0.9925
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Neutral speech (in training): 
	Precision: 0.9851, Recall: 0.9900, F1_score: 0.9875
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9900, F1_score: 0.9925

Eval Phase: 
Validation loss: 5.8333, Validation accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 11/100

Training Phase:
Training loss: 5.4382, Training accuracy: 0.9988
Macro F1-score: 0.9988
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Happy speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 7.5112, Validation accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Happy speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 12/100

Training Phase:
                                                      Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 215/1600 [00:10<01:04, 21.46it/s]Training:  27%|██▋       | 433/1600 [00:20<00:54, 21.61it/s]Training:  41%|████      | 658/1600 [00:30<00:42, 21.99it/s]Training:  56%|█████▌    | 891/1600 [00:40<00:31, 22.50it/s]Training:  70%|███████   | 1124/1600 [00:50<00:21, 22.64it/s]Training:  85%|████████▍ | 1353/1600 [01:00<00:10, 22.53it/s]Training:  99%|█████████▊| 1577/1600 [01:10<00:01, 22.43it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 228/1600 [00:10<01:00, 22.77it/s]Training:  14%|Training loss: 26.7577, Training accuracy: 0.9944
Macro F1-score: 0.9944
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963
Model performance on Neutral speech (in training): 
	Precision: 0.9900, Recall: 0.9950, F1_score: 0.9925
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9900, F1_score: 0.9925

Eval Phase: 
Validation loss: 8.8813, Validation accuracy: 0.9850
Macro F1-score: 0.9850
Model performance on Angry speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Sad speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Epoch 13/100

Training Phase:
▍        | 228/1600 [00:20<01:00, 22.77it/s]Training:  28%|██▊       | 451/1600 [00:20<00:52, 22.07it/s]Training:  42%|████▏     | 668/1600 [00:30<00:42, 21.77it/s]Training:  55%|█████▌    | 887/1600 [00:40<00:32, 21.76it/s]Training:  69%|██████▉   | 1107/1600 [00:50<00:22, 21.83it/s]Training:  83%|████████▎ | 1327/1600 [01:00<00:12, 21.69it/s]Training:  96%|█████████▋| 1543/1600 [01:10<00:02, 21.63it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 212/1600 [00:10<01:05, 21.15it/s]Training:  27%|██▋       | 431/1600 [00:20<00:54, 21.53it/s]Training:  41%|████      | 649/1600 [00:30<00:44, 21.61it/s]Training:  54%|█████▍    | 867/1600 [00:40<00:33, 21.60it/s]Training:  68%|██████Training loss: 2.3121, Training accuracy: 1.0000
Macro F1-score: 1.0000
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 5.2377, Validation accuracy: 0.9850
Macro F1-score: 0.9850
Model performance on Angry speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 14/100

Training Phase:
Training loss: 28.4199, Training accuracy: 0.9938
Macro F1-score: 0.9938
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 0.9950, F1_score: 0.9975
Model performance on Happy speech (in training): 
	Precision: 0.9875, Recall: 0.9875, F1_score: 0.9875
Model performance on Neutral speech (in training): 
	Precision: 0.9876, Recall: 0.9925, F1_score: 0.9900
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
▊   | 1090/1600 [00:50<00:23, 21.85it/s]Training:  82%|████████▏ | 1313/1600 [01:00<00:13, 21.98it/s]Training:  96%|█████████▋| 1541/1600 [01:10<00:02, 22.21it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 229/1600 [00:10<01:00, 22.85it/s]Training:  29%|██▊       | 458/1600 [00:20<00:50, 22.62it/s]Training:  43%|████▎     | 683/1600 [00:30<00:40, 22.56it/s]Training:  57%|█████▋    | 911/1600 [00:40<00:30, 22.65it/s]Training:  71%|███████   | 1139/1600 [00:50<00:20, 22.20it/s]Training:  85%|████████▍ | 1354/1600 [01:00<00:11, 21.87it/s]Training:  98%|█████████▊| 1568/1600 [01:11<00:01, 21.68it/s]                                                             Evaluating:   0%|      Validation loss: 5.4155, Validation accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Validation loss does not decrease for 10 epochs. End training.
Model best accuracy on validation set: 0.9950

Test Phase: 
Test loss: 18.4400, Test accuracy: 0.9800
Macro F1-score: 0.9799
Model performance on Angry speech (in test): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Happy speech (in test): 
	Precision: 0.9792, Recall: 0.9400, F1_score: 0.9592
Model performance on Neutral speech (in test): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Sad speech (in test): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

de, all folds accuracy: ['0.9700', '0.9900', '0.9700', '0.9800', '0.9800']
de, all folds emo precision: {'Angry': ['0.9800', '1.0000', '0.9615', '0.9608', '0.9608'], 'Happy': ['0.9792', '1.0000', '0.9231', '0.9796', '0.9792'], 'Neutral': ['0.9600', '1.0000', '1.0000', '1.0000', '0.9804'], 'Sad': ['0.9615', '0.9615', '1.0000', '0.9804', '1.0000']}
de, all folds emo recall: {'Angry': ['0.9800', '1.0000', '1.0000', '0.9800', '0.9800'], 'Happy': ['0.9400', '1.0000', '0.9600', '0.9600', '0.9400'], 'Neutral': ['0.9600', '0.9600', '0.9200', '0.9800', '1.0000'], 'Sad': ['1.0000', '1.0000', '1.0000', '1.0000', '1.0000']}
de, all folds emo f1score: {'Angry': ['0.9800', '1.0000', '0.9804', '0.9703', '0.9703'], 'Happy': ['0.9592', '1.0000', '0.9412', '0.9697', '0.9592'], 'Neutral': ['0.9600', '0.9796', '0.9583', '0.9899', '0.9901'], 'Sad': ['0.9804', '0.9804', '1.0000', '0.9901', '1.0000']}
    | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]                                                ------------------NEXT SCRIPT: RUNNER_CN----------------------
/work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Matplotlib created a temporary cache directory at /dev/shm/zhan7721_5912051/matplotlib-_pq1eeiq because the default path (/home/tc062/tc062/zhan7721/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Some weights of the model checkpoint at /work/tc062/tc062/zhan7721/saved_models/de were not used when initializing Wav2Vec2Model: ['encoder.layers.10.attention.k_proj.bias', 'encoder.layers.10.attention.k_proj.weight', 'encoder.layers.10.attention.out_proj.bias', 'encoder.layers.10.attention.out_proj.weight', 'encoder.layers.10.attention.q_proj.bias', 'encoder.layers.10.attention.q_proj.weight', 'encoder.layers.10.attention.v_proj.bias', 'encoder.layers.10.attention.v_proj.weight', 'encoder.layers.10.feed_forward.intermediate_dense.bias', 'encoder.layers.10.feed_forward.intermediate_dense.weight', 'encoder.layers.10.feed_forward.output_dense.bias', 'encoder.layers.10.feed_forward.output_dense.weight', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.10.layer_norm.bias', 'encoder.layers.10.layer_norm.weight', 'encoder.layers.11.attention.k_proj.bias', 'encoder.layers.11.attention.k_proj.weight', 'encoder.layers.11.attention.out_proj.bias', 'encoder.layers.11.attention.out_proj.weight', 'encoder.layers.11.attention.q_proj.bias', 'encoder.layers.11.attention.q_proj.weight', 'encoder.layers.11.attention.v_proj.bias', 'encoder.layers.11.attention.v_proj.weight', 'encoder.layers.11.feed_forward.intermediate_dense.bias', 'encoder.layers.11.feed_forward.intermediate_dense.weight', 'encoder.layers.11.feed_forward.output_dense.bias', 'encoder.layers.11.feed_forward.output_dense.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.11.layer_norm.bias', 'encoder.layers.11.layer_norm.weight', 'encoder.layers.7.attention.k_proj.bias', 'encoder.layers.7.attention.k_proj.weight', 'encoder.layers.7.attention.out_proj.bias', 'encoder.layers.7.attention.out_proj.weight', 'encoder.layers.7.attention.q_proj.bias', 'encoder.layers.7.attention.q_proj.weight', 'encoder.layers.7.attention.v_proj.bias', 'encoder.layers.7.attention.v_proj.weight', 'encoder.layers.7.feed_forward.intermediate_dense.bias', 'encoder.layers.7.feed_forward.intermediate_dense.weight', 'encoder.layers.7.feed_forward.output_dense.bias', 'encoder.layers.7.feed_forward.output_dense.weight', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.7.layer_norm.bias', 'encoder.layers.7.layer_norm.weight', 'encoder.layers.8.attention.k_proj.bias', 'encoder.layers.8.attention.k_proj.weight', 'encoder.layers.8.attention.out_proj.bias', 'encoder.layers.8.attention.out_proj.weight', 'encoder.layers.8.attention.q_proj.bias', 'encoder.layers.8.attention.q_proj.weight', 'encoder.layers.8.attention.v_proj.bias', 'encoder.layers.8.attention.v_proj.weight', 'encoder.layers.8.feed_forward.intermediate_dense.bias', 'encoder.layers.8.feed_forward.intermediate_dense.weight', 'encoder.layers.8.feed_forward.output_dense.bias', 'encoder.layers.8.feed_forward.output_dense.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.8.layer_norm.bias', 'encoder.layers.8.layer_norm.weight', 'encoder.layers.9.attention.k_proj.bias', 'encoder.layers.9.attention.k_proj.weight', 'encoder.layers.9.attention.out_proj.bias', 'encoder.layers.9.attention.out_proj.weight', 'encoder.layers.9.attention.q_proj.bias', 'encoder.layers.9.attention.q_proj.weight', 'encoder.layers.9.attention.v_proj.bias', 'encoder.layers.9.attention.v_proj.weight', 'encoder.layers.9.feed_forward.intermediate_dense.bias', 'encoder.layers.9.feed_forward.intermediate_dense.weight', 'encoder.layers.9.feed_forward.output_dense.bias', 'encoder.layers.9.feed_forward.output_dense.weight', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.layer_norm.bias', 'encoder.layers.9.layer_norm.weight']
- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).

======================= This is fold_0 on cn =======================

Load dataset: 
Loading cn train data: fold_0...
Preprocess cn fold_0 data for cn model
Loading cn eval data: fold_0...
Preprocess cn fold_0 data for cn model
Loading cn test data: fold_0...
Preprocess cn fold_0 data for cn model
Use cn model to add lora
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:   0%|          | 1/1600 [00:42<18:56:12, 42.63s/it]Training:  16%|█▌        | 249/1600 [00:52<03:36,  6.24it/s] Training:  31%|███▏      | 500/1600 [01:02<01:38, 11.21it/s]Training:  47%|████▋     | 751/1600 [01:12<00:56, 14.99it/s]Training:  63%|██████▎   | 1001/1600 [01:22<00:33, 17.79it/s]Training:  78%|███████▊  | 1251/1600 [01:33<00:17, 19.40it/s]Training:  94%|█████████▍| 1500/1600 [01:43<00:04, 20.97it/s]                                                             /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Training loss: 1735.9049, Training accuracy: 0.5044
Macro F1-score: 0.4400
Model performance on Angry speech (in training): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Happy speech (in training): 
	Precision: 0.3632, Recall: 0.8925, F1_score: 0.5163
Model performance on Neutral speech (in training): 
	Precision: 0.6709, Recall: 0.3925, F1_score: 0.4953
Model performance on Sad speech (in training): 
	Precision: 0.7650, Recall: 0.7325, F1_score: 0.7484

Eval Phase: 
Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 139.4204, Validation accuracy: 0.7350
Macro F1-score: 0.6517
Model performance on Angry speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Happy speech (in validation): 
	Precision: 0.5000, Recall: 1.0000, F1_score: 0.6667
Model performance on Neutral speech (in validation): 
	Precision: 0.9600, Recall: 0.9600, F1_score: 0.9600
Model performance on Sad speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
New best accuracy for layer 6 on epoch 1: 0.7350. Model saved.
Epoch 2/100

Training Phase:
Training loss: 1000.7389, Training accuracy: 0.7144
Macro F1-score: 0.6872
Model performance on Angry speech (in training): 
	Precision: 0.7168, Recall: 0.2025, F1_score: 0.3158
Model performance on Happy speech (in training): 
	Precision: 0.4957, Recall: 0.8675, F1_score: 0.6309
Model performance on Neutral speech (in training): 
	Precision: 0.8734, Recall: 0.8625, F1_score: 0.8679
Model performance on Sad speech (in training): 
	Precision: 0.9439, Recall: 0.9250, F1_score: 0.9343

Eval Phase: 
Validation loss: 143.8480, Validation accuracy: 0.6800
Macro F1-score: 0.6652
Model performance on Angry speech (in validation): 
	Precision: 0.6667, Recall: 0.3600, F1_score: 0.4675
Model performance on Happy speech (in validation): 
	Precision: 0.5417, Recall: 0.7800, F1_score: 0.6393
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.5800, F1_score: 0.7342
Model performance on Sad speech (in validation): 
	Precision: 0.6944, Recall: 1.0000, F1_score: 0.8197
Epoch 3/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 235/1600 [00:10<00:58, 23.48it/s]Training:  29%|██▉       | 470/1600 [00:20<00:48, 23.43it/s]Training:  44%|████▍     | 705/1600 [00:30<00:38, 23.43it/s]Training:  59%|█████▉    | 940/1600 [00:40<00:28, 23.41it/s]Training:  73%|███████▎  | 1174/1600 [00:50<00:18, 23.38it/s]Training:  88%|████████▊ | 1409/1600 [01:00<00:08, 23.42it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 234/1600 [00:10<00:58, 23.31it/s]Training:  29%|██▉       | 471/1600 [00:20<00:48, 23.51it/s]Training:  44%|████▍     | 708/1600 [00:30<00:38, 23.36it/s]Training:  59%|█████▉    | 947/1600 [00:40<00:27, 23.55it/s]Training:  74%|███████▍  | Training loss: 710.7054, Training accuracy: 0.8256
Macro F1-score: 0.8256
Model performance on Angry speech (in training): 
	Precision: 0.7431, Recall: 0.7450, F1_score: 0.7441
Model performance on Happy speech (in training): 
	Precision: 0.7035, Recall: 0.7000, F1_score: 0.7018
Model performance on Neutral speech (in training): 
	Precision: 0.9035, Recall: 0.9125, F1_score: 0.9080
Model performance on Sad speech (in training): 
	Precision: 0.9521, Recall: 0.9450, F1_score: 0.9486

Eval Phase: 
Validation loss: 110.3441, Validation accuracy: 0.7450
Macro F1-score: 0.7434
Model performance on Angry speech (in validation): 
	Precision: 0.5538, Recall: 0.7200, F1_score: 0.6261
Model performance on Happy speech (in validation): 
	Precision: 0.5385, Recall: 0.4200, F1_score: 0.4719
Model performance on Neutral speech (in validation): 
	Precision: 0.9773, Recall: 0.8600, F1_score: 0.9149
Model performance on Sad speech (in validation): 
	Precision: 0.9423, Recall: 0.9800, F1_score: 0.9608
New best accuracy for layer 6 on epoch 3: 0.7450. Model saved.
Epoch 4/100

Training Phase:
Training loss: 509.8365, Training accuracy: 0.8906
Macro F1-score: 0.8903
Model performance on Angry speech (in training): 
	Precision: 0.8280, Recall: 0.8425, F1_score: 0.8352
Model performance on Happy speech (in training): 
	Precision: 0.8217, Recall: 0.7950, F1_score: 0.8081
Model performance on Neutral speech (in training): 
	Precision: 0.9451, Recall: 0.9475, F1_score: 0.9463
Model performance on Sad speech (in training): 
	Precision: 0.9654, Recall: 0.9775, F1_score: 0.9714

Eval Phase: 
Validation loss: 207.7867, Validation accuracy: 0.6400
Macro F1-score: 0.6189
Model performance on Angry speech (in validation): 
	Precision: 0.4898, Recall: 0.9600, F1_score: 0.6486
Model performance on Happy speech (in validation): 
	Precision: 0.1923, Recall: 0.1000, F1_score: 0.1316
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.6400, F1_score: 0.7805
Model performance on Sad speech (in validation): 
	Precision: 0.9773, Recall: 0.8600, F1_score: 0.9149
Epoch 5/100

Training Phase:
1186/1600 [00:50<00:17, 23.59it/s]Training:  89%|████████▉ | 1423/1600 [01:00<00:07, 23.58it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 235/1600 [00:10<00:58, 23.43it/s]Training:  30%|██▉       | 473/1600 [00:20<00:47, 23.61it/s]Training:  45%|████▌     | 723/1600 [00:30<00:36, 24.23it/s]Training:  61%|██████    | 975/1600 [00:40<00:25, 24.59it/s]Training:  77%|███████▋  | 1227/1600 [00:50<00:15, 24.69it/s]Training:  92%|█████████▏| 1476/1600 [01:00<00:05, 24.71it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 246/Training loss: 428.6894, Training accuracy: 0.8962
Macro F1-score: 0.8959
Model performance on Angry speech (in training): 
	Precision: 0.8374, Recall: 0.8500, F1_score: 0.8437
Model performance on Happy speech (in training): 
	Precision: 0.8269, Recall: 0.8000, F1_score: 0.8132
Model performance on Neutral speech (in training): 
	Precision: 0.9459, Recall: 0.9625, F1_score: 0.9542
Model performance on Sad speech (in training): 
	Precision: 0.9725, Recall: 0.9725, F1_score: 0.9725

Eval Phase: 
Validation loss: 60.6574, Validation accuracy: 0.8750
Macro F1-score: 0.8750
Model performance on Angry speech (in validation): 
	Precision: 0.7258, Recall: 0.9000, F1_score: 0.8036
Model performance on Happy speech (in validation): 
	Precision: 0.8293, Recall: 0.6800, F1_score: 0.7473
Model performance on Neutral speech (in validation): 
	Precision: 0.9792, Recall: 0.9400, F1_score: 0.9592
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
New best accuracy for layer 6 on epoch 5: 0.8750. Model saved.
Epoch 6/100

Training Phase:
1600 [00:10<00:55, 24.55it/s]Training:  31%|███       | 496/1600 [00:20<00:44, 24.79it/s]Training:  47%|████▋     | 749/1600 [00:30<00:34, 25.02it/s]Training:  63%|██████▎   | 1002/1600 [00:40<00:23, 25.12it/s]Training:  78%|███████▊  | 1256/1600 [00:50<00:13, 25.19it/s]Training:  94%|█████████▍| 1510/1600 [01:00<00:03, 25.13it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 240/1600 [00:10<00:56, 23.91it/s]Training:  30%|███       | 484/1600 [00:20<00:46, 24.16it/s]Training:  46%|████▌     | 731/1600 [00:30<00:35, 24.39it/s]Training:  61%|██████    | 978/1600 [00:40<00:25, 24.35it/s]Training:  76%|███████▋  | 1221/1600 [00:50<00:15, 24.29it/s]Training:  92%|█████████▏| Training loss: 359.4189, Training accuracy: 0.9187
Macro F1-score: 0.9186
Model performance on Angry speech (in training): 
	Precision: 0.8828, Recall: 0.8850, F1_score: 0.8839
Model performance on Happy speech (in training): 
	Precision: 0.8706, Recall: 0.8575, F1_score: 0.8640
Model performance on Neutral speech (in training): 
	Precision: 0.9412, Recall: 0.9600, F1_score: 0.9505
Model performance on Sad speech (in training): 
	Precision: 0.9798, Recall: 0.9725, F1_score: 0.9762

Eval Phase: 
Validation loss: 88.1994, Validation accuracy: 0.8550
Macro F1-score: 0.8456
Model performance on Angry speech (in validation): 
	Precision: 0.6575, Recall: 0.9600, F1_score: 0.7805
Model performance on Happy speech (in validation): 
	Precision: 0.9231, Recall: 0.4800, F1_score: 0.6316
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Epoch 7/100

Training Phase:
Training loss: 278.5769, Training accuracy: 0.9456
Macro F1-score: 0.9455
Model performance on Angry speech (in training): 
	Precision: 0.9056, Recall: 0.9350, F1_score: 0.9200
Model performance on Happy speech (in training): 
	Precision: 0.9346, Recall: 0.8925, F1_score: 0.9130
Model performance on Neutral speech (in training): 
	Precision: 0.9607, Recall: 0.9775, F1_score: 0.9690
Model performance on Sad speech (in training): 
	Precision: 0.9824, Recall: 0.9775, F1_score: 0.9799

Eval Phase: 
Validation loss: 80.7906, Validation accuracy: 0.8350
Macro F1-score: 0.8320
Model performance on Angry speech (in validation): 
	Precision: 0.8333, Recall: 0.9000, F1_score: 0.8654
Model performance on Happy speech (in validation): 
	Precision: 0.7193, Recall: 0.8200, F1_score: 0.7664
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.6400, F1_score: 0.7805
Model performance on Sad speech (in validation): 
	Precision: 0.8596, Recall: 0.9800, F1_score: 0.9159
Epoch 8/100

Training Phase:
1468/1600 [01:00<00:05, 24.41it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 245/1600 [00:10<00:55, 24.39it/s]Training:  31%|███       | 489/1600 [00:20<00:45, 24.28it/s]Training:  46%|████▌     | 733/1600 [00:30<00:35, 24.31it/s]Training:  61%|██████    | 977/1600 [00:40<00:25, 24.19it/s]Training:  76%|███████▌  | 1218/1600 [00:50<00:15, 24.11it/s]Training:  91%|█████████ | 1458/1600 [01:00<00:05, 24.02it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 246/1600 [00:10<00:55, 24.51it/s]Training:  31%|███       | 495/1600 [00:20<00:Training loss: 257.9079, Training accuracy: 0.9394
Macro F1-score: 0.9393
Model performance on Angry speech (in training): 
	Precision: 0.9152, Recall: 0.9175, F1_score: 0.9164
Model performance on Happy speech (in training): 
	Precision: 0.9066, Recall: 0.8975, F1_score: 0.9020
Model performance on Neutral speech (in training): 
	Precision: 0.9580, Recall: 0.9700, F1_score: 0.9640
Model performance on Sad speech (in training): 
	Precision: 0.9774, Recall: 0.9725, F1_score: 0.9749

Eval Phase: 
Validation loss: 104.7464, Validation accuracy: 0.8250
Macro F1-score: 0.8260
Model performance on Angry speech (in validation): 
	Precision: 0.7164, Recall: 0.9600, F1_score: 0.8205
Model performance on Happy speech (in validation): 
	Precision: 0.6735, Recall: 0.6600, F1_score: 0.6667
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.7200, F1_score: 0.8372
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Epoch 9/100

Training Phase:
44, 24.68it/s]Training:  46%|████▋     | 743/1600 [00:30<00:34, 24.72it/s]Training:  62%|██████▏   | 992/1600 [00:40<00:24, 24.78it/s]Training:  78%|███████▊  | 1241/1600 [00:50<00:14, 24.72it/s]Training:  93%|█████████▎| 1488/1600 [01:00<00:04, 24.40it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 238/1600 [00:10<00:57, 23.76it/s]Training:  30%|███       | 483/1600 [00:20<00:46, 24.17it/s]Training:  46%|████▌     | 729/1600 [00:30<00:35, 24.33it/s]Training:  61%|██████    | 975/1600 [00:40<00:25, 24.30it/s]Training:  76%|███████▌  | 1218/1600 [00:50<00:15, 24.25it/s]Training:  91%|█████████▏| 1460/1600 [01:00<00:05, 24.06it/s]                                                Training loss: 222.0045, Training accuracy: 0.9525
Macro F1-score: 0.9525
Model performance on Angry speech (in training): 
	Precision: 0.9310, Recall: 0.9450, F1_score: 0.9380
Model performance on Happy speech (in training): 
	Precision: 0.9412, Recall: 0.9200, F1_score: 0.9305
Model performance on Neutral speech (in training): 
	Precision: 0.9580, Recall: 0.9700, F1_score: 0.9640
Model performance on Sad speech (in training): 
	Precision: 0.9799, Recall: 0.9750, F1_score: 0.9774

Eval Phase: 
Validation loss: 226.1179, Validation accuracy: 0.7700
Macro F1-score: 0.7429
Model performance on Angry speech (in validation): 
	Precision: 0.5385, Recall: 0.9800, F1_score: 0.6950
Model performance on Happy speech (in validation): 
	Precision: 0.7333, Recall: 0.2200, F1_score: 0.3385
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.9200, F1_score: 0.9583
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Epoch 10/100

Training Phase:
Training loss: 186.7307, Training accuracy: 0.9613
Macro F1-score: 0.9612
Model performance on Angry speech (in training): 
	Precision: 0.9380, Recall: 0.9450, F1_score: 0.9415
Model performance on Happy speech (in training): 
	Precision: 0.9343, Recall: 0.9250, F1_score: 0.9296
Model performance on Neutral speech (in training): 
	Precision: 0.9850, Recall: 0.9825, F1_score: 0.9837
Model performance on Sad speech (in training): 
	Precision: 0.9876, Recall: 0.9925, F1_score: 0.9900

Eval Phase: 
Validation loss: 72.3315, Validation accuracy: 0.8600
Macro F1-score: 0.8586
Model performance on Angry speech (in validation): 
	Precision: 0.7121, Recall: 0.9400, F1_score: 0.8103
Model performance on Happy speech (in validation): 
	Precision: 0.7949, Recall: 0.6200, F1_score: 0.6966
Model performance on Neutral speech (in validation): 
	Precision: 0.9783, Recall: 0.9000, F1_score: 0.9375
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Epoch 11/100

Training Phase:
             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 240/1600 [00:10<00:56, 23.93it/s]Training:  30%|███       | 483/1600 [00:20<00:46, 24.14it/s]Training:  45%|████▌     | 726/1600 [00:30<00:36, 24.07it/s]Training:  60%|██████    | 966/1600 [00:40<00:26, 23.74it/s]Training:  76%|███████▌  | 1213/1600 [00:50<00:16, 24.07it/s]Training:  91%|█████████▏| 1462/1600 [01:00<00:05, 24.35it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 251/1600 [00:10<00:53, 25.07it/s]Training:  32%|███▏      | 504/1600 [00:20<00:43, 25.15it/s]Training:  47%|████▋     | 757/1600 [00:30<00:34, 24.7Training loss: 192.1446, Training accuracy: 0.9613
Macro F1-score: 0.9613
Model performance on Angry speech (in training): 
	Precision: 0.9390, Recall: 0.9625, F1_score: 0.9506
Model performance on Happy speech (in training): 
	Precision: 0.9565, Recall: 0.9350, F1_score: 0.9456
Model performance on Neutral speech (in training): 
	Precision: 0.9629, Recall: 0.9725, F1_score: 0.9677
Model performance on Sad speech (in training): 
	Precision: 0.9873, Recall: 0.9750, F1_score: 0.9811

Eval Phase: 
Validation loss: 221.2347, Validation accuracy: 0.7300
Macro F1-score: 0.6932
Model performance on Angry speech (in validation): 
	Precision: 0.5393, Recall: 0.9600, F1_score: 0.6906
Model performance on Happy speech (in validation): 
	Precision: 0.5333, Recall: 0.1600, F1_score: 0.2462
Model performance on Neutral speech (in validation): 
	Precision: 0.9149, Recall: 0.8600, F1_score: 0.8866
Model performance on Sad speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Epoch 12/100

Training Phase:
3it/s]Training:  47%|████▋     | 757/1600 [00:40<00:34, 24.73it/s]Training:  62%|██████▏   | 989/1600 [00:40<00:25, 24.12it/s]Training:  77%|███████▋  | 1226/1600 [00:50<00:15, 23.94it/s]Training:  92%|█████████▏| 1464/1600 [01:00<00:05, 23.87it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 234/1600 [00:10<00:58, 23.34it/s]Training:  30%|██▉       | 475/1600 [00:20<00:47, 23.78it/s]Training:  45%|████▌     | 727/1600 [00:30<00:35, 24.39it/s]Training:  61%|██████    | 979/1600 [00:40<00:25, 24.16it/s]Training:  76%|███████▌  | 1218/1600 [00:50<00:15, 23.92it/s]Training:  91%|█████████ | 1455/1600 [01:00<00:06, 23.82it/s]                                                          Training loss: 157.0853, Training accuracy: 0.9694
Macro F1-score: 0.9693
Model performance on Angry speech (in training): 
	Precision: 0.9501, Recall: 0.9525, F1_score: 0.9513
Model performance on Happy speech (in training): 
	Precision: 0.9570, Recall: 0.9450, F1_score: 0.9509
Model performance on Neutral speech (in training): 
	Precision: 0.9825, Recall: 0.9850, F1_score: 0.9838
Model performance on Sad speech (in training): 
	Precision: 0.9876, Recall: 0.9950, F1_score: 0.9913

Eval Phase: 
Validation loss: 374.7995, Validation accuracy: 0.6500
Macro F1-score: 0.6211
Model performance on Angry speech (in validation): 
	Precision: 0.5102, Recall: 1.0000, F1_score: 0.6757
Model performance on Happy speech (in validation): 
	Precision: 0.3333, Recall: 0.1600, F1_score: 0.2162
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.5400, F1_score: 0.7013
Model performance on Sad speech (in validation): 
	Precision: 0.8824, Recall: 0.9000, F1_score: 0.8911
Epoch 13/100

Training Phase:
Training loss: 140.8898, Training accuracy: 0.9669
Macro F1-score: 0.9669
Model performance on Angry speech (in training): 
	Precision: 0.9483, Recall: 0.9625, F1_score: 0.9553
Model performance on Happy speech (in training): 
	Precision: 0.9422, Recall: 0.9375, F1_score: 0.9398
Model performance on Neutral speech (in training): 
	Precision: 0.9899, Recall: 0.9850, F1_score: 0.9875
Model performance on Sad speech (in training): 
	Precision: 0.9874, Recall: 0.9825, F1_score: 0.9850

Eval Phase: 
Validation loss: 105.8697, Validation accuracy: 0.8750
Macro F1-score: 0.8682
Model performance on Angry speech (in validation): 
	Precision: 0.6944, Recall: 1.0000, F1_score: 0.8197
Model performance on Happy speech (in validation): 
	Precision: 0.9310, Recall: 0.5400, F1_score: 0.6835
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 14/100

Training Phase:
   Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 235/1600 [00:10<00:58, 23.43it/s]Training:  29%|██▉       | 471/1600 [00:20<00:47, 23.52it/s]Training:  45%|████▍     | 713/1600 [00:30<00:37, 23.79it/s]Training:  60%|██████    | 960/1600 [00:40<00:26, 24.11it/s]Training:  75%|███████▌  | 1207/1600 [00:50<00:16, 24.23it/s]Training:  91%|█████████ | 1452/1600 [01:00<00:06, 23.92it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 235/1600 [00:10<00:58, 23.50it/s]Training:  30%|██▉       | 472/1600 [00:20<00:47, 23.56it/s]Training:  44%|████▍     | 711/1600 [00:30<00:37, 23.70it/s]TraininTraining loss: 112.0337, Training accuracy: 0.9762
Macro F1-score: 0.9762
Model performance on Angry speech (in training): 
	Precision: 0.9724, Recall: 0.9675, F1_score: 0.9699
Model performance on Happy speech (in training): 
	Precision: 0.9674, Recall: 0.9650, F1_score: 0.9662
Model performance on Neutral speech (in training): 
	Precision: 0.9851, Recall: 0.9900, F1_score: 0.9875
Model performance on Sad speech (in training): 
	Precision: 0.9800, Recall: 0.9825, F1_score: 0.9813

Eval Phase: 
Validation loss: 209.1281, Validation accuracy: 0.7300
Macro F1-score: 0.7082
Model performance on Angry speech (in validation): 
	Precision: 0.6901, Recall: 0.9800, F1_score: 0.8099
Model performance on Happy speech (in validation): 
	Precision: 0.6875, Recall: 0.4400, F1_score: 0.5366
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Model performance on Sad speech (in validation): 
	Precision: 0.6944, Recall: 1.0000, F1_score: 0.8197
Epoch 15/100

Training Phase:
Training loss: 91.9378, Training accuracy: 0.9788
Macro F1-score: 0.9787
Model performance on Angry speech (in training): 
	Precision: 0.9798, Recall: 0.9725, F1_score: 0.9762
Model performance on Happy speech (in training): 
	Precision: 0.9677, Recall: 0.9725, F1_score: 0.9701
Model performance on Neutral speech (in training): 
	Precision: 0.9824, Recall: 0.9750, F1_score: 0.9787
Model performance on Sad speech (in training): 
	Precision: 0.9851, Recall: 0.9950, F1_score: 0.9900

Eval Phase: 
g:  59%|█████▉    | 950/1600 [00:40<00:27, 23.64it/s]Training:  74%|███████▍  | 1186/1600 [00:50<00:17, 23.54it/s]Training:  89%|████████▉ | 1424/1600 [01:00<00:07, 23.60it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 234/1600 [00:10<00:58, 23.37it/s]Training:  30%|███       | 488/1600 [00:20<00:45, 24.51it/s]Training:  46%|████▋     | 741/1600 [00:30<00:34, 24.56it/s]Training:  62%|██████▏   | 988/1600 [00:40<00:24, 24.55it/s]Training:  77%|███████▋  | 1239/1600 [00:50<00:14, 24.72it/s]Training:  93%|█████████▎| 1490/1600 [01:01<00:04, 24.25it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                            Validation loss: 368.1956, Validation accuracy: 0.6600
Macro F1-score: 0.6180
Model performance on Angry speech (in validation): 
	Precision: 0.5208, Recall: 1.0000, F1_score: 0.6849
Model performance on Happy speech (in validation): 
	Precision: 0.2941, Recall: 0.1000, F1_score: 0.1493
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.6400, F1_score: 0.7805
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.9000, F1_score: 0.8571
Validation loss does not decrease for 10 epochs. End training.
Model best accuracy on validation set: 0.8750

Test Phase: 
                       Testing:   0%|          | 0/200 [00:00<?, ?it/s]                                                Some weights of the model checkpoint at /work/tc062/tc062/zhan7721/saved_models/de were not used when initializing Wav2Vec2Model: ['encoder.layers.10.attention.k_proj.bias', 'encoder.layers.10.attention.k_proj.weight', 'encoder.layers.10.attention.out_proj.bias', 'encoder.layers.10.attention.out_proj.weight', 'encoder.layers.10.attention.q_proj.bias', 'encoder.layers.10.attention.q_proj.weight', 'encoder.layers.10.attention.v_proj.bias', 'encoder.layers.10.attention.v_proj.weight', 'encoder.layers.10.feed_forward.intermediate_dense.bias', 'encoder.layers.10.feed_forward.intermediate_dense.weight', 'encoder.layers.10.feed_forward.output_dense.bias', 'encoder.layers.10.feed_forward.output_dense.weight', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.10.layer_norm.bias', 'encoder.layers.10.layer_norm.weight', 'encoder.layers.11.attention.k_proj.bias', 'encoder.layers.11.attention.k_proj.weight', 'encoder.layers.11.attention.out_proj.bias', 'encoder.layers.11.attention.out_proj.weight', 'encoder.layers.11.attention.q_proj.bias', 'encoder.layers.11.attention.q_proj.weight', 'encoder.layers.11.attention.v_proj.bias', 'encoder.layers.11.attention.v_proj.weight', 'encoder.layers.11.feed_forward.intermediate_dense.bias', 'encoder.layers.11.feed_forward.intermediate_dense.weight', 'encoder.layers.11.feed_forward.output_dense.bias', 'encoder.layers.11.feed_forward.output_dense.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.11.layer_norm.bias', 'encoder.layers.11.layer_norm.weight', 'encoder.layers.7.attention.k_proj.bias', 'encoder.layers.7.attention.k_proj.weight', 'encoder.layers.7.attention.out_proj.bias', 'encoder.layers.7.attention.out_proj.weight', 'encoder.layers.7.attention.q_proj.bias', 'encoder.layers.7.attention.q_proj.weight', 'encoder.layers.7.attention.v_proj.bias', 'encoder.layers.7.attention.v_proj.weight', 'encoder.layers.7.feed_forward.intermediate_dense.bias', 'encoder.layers.7.feed_forward.intermediate_dense.weight', 'encoder.layers.7.feed_forward.output_dense.bias', 'encoder.layers.7.feed_forward.output_dense.weight', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.7.layer_norm.bias', 'encoder.layers.7.layer_norm.weight', 'encoder.layers.8.attention.k_proj.bias', 'encoder.layers.8.attention.k_proj.weight', 'encoder.layers.8.attention.out_proj.bias', 'encoder.layers.8.attention.out_proj.weight', 'encoder.layers.8.attention.q_proj.bias', 'encoder.layers.8.attention.q_proj.weight', 'encoder.layers.8.attention.v_proj.bias', 'encoder.layers.8.attention.v_proj.weight', 'encoder.layers.8.feed_forward.intermediate_dense.bias', 'encoder.layers.8.feed_forward.intermediate_dense.weight', 'encoder.layers.8.feed_forward.output_dense.bias', 'encoder.layers.8.feed_forward.output_dense.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.8.layer_norm.bias', 'encoder.layers.8.layer_norm.weight', 'encoder.layers.9.attention.k_proj.bias', 'encoder.layers.9.attention.k_proj.weight', 'encoder.layers.9.attention.out_proj.bias', 'encoder.layers.9.attention.out_proj.weight', 'encoder.layers.9.attention.q_proj.bias', 'encoder.layers.9.attention.q_proj.weight', 'encoder.layers.9.attention.v_proj.bias', 'encoder.layers.9.attention.v_proj.weight', 'encoder.layers.9.feed_forward.intermediate_dense.bias', 'encoder.layers.9.feed_forward.intermediate_dense.weight', 'encoder.layers.9.feed_forward.output_dense.bias', 'encoder.layers.9.feed_forward.output_dense.weight', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.layer_norm.bias', 'encoder.layers.9.layer_norm.weight']
- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Test loss: 67.3184, Test accuracy: 0.8800
Macro F1-score: 0.8816
Model performance on Angry speech (in test): 
	Precision: 0.7759, Recall: 0.9000, F1_score: 0.8333
Model performance on Happy speech (in test): 
	Precision: 0.7708, Recall: 0.7400, F1_score: 0.7551
Model performance on Neutral speech (in test): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Sad speech (in test): 
	Precision: 1.0000, Recall: 0.9200, F1_score: 0.9583

======================= This is fold_1 on cn =======================

Load dataset: 
Loading cn train data: fold_1...
Preprocess cn fold_1 data for cn model
Loading cn eval data: fold_1...
Preprocess cn fold_1 data for cn model
Loading cn test data: fold_1...
Preprocess cn fold_1 data for cn model
Use cn model to add lora
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training loss: 949.8413, Training accuracy: 0.7688
Macro F1-score: 0.7683
Model performance on Angry speech (in training): 
	Precision: 0.7087, Recall: 0.7300, F1_score: 0.7192
Model performance on Happy speech (in training): 
	Precision: 0.7116, Recall: 0.6600, F1_score: 0.6848
Model performance on Neutral speech (in training): 
	Precision: 0.7692, Recall: 0.8250, F1_score: 0.7961
Model performance on Sad speech (in training): 
	Precision: 0.8866, Recall: 0.8600, F1_score: 0.8731

Eval Phase: 
Validation loss: 165.4912, Validation accuracy: 0.6850
Macro F1-score: 0.6683
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.5600, F1_score: 0.7179
Model performance on Happy speech (in validation): 
	Precision: 0.4595, Recall: 0.3400, F1_score: 0.3908
Model performance on Neutral speech (in validation): 
	Precision: 0.6364, Recall: 0.8400, F1_score: 0.7241
Model performance on Sad speech (in validation): 
	Precision: 0.7246, Recall: 1.0000, F1_score: 0.8403
New best accuracy for layer 6 on epoch 1: 0.6850. Model saved.
Epoch 2/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 243/1600 [00:10<00:55, 24.27it/s]Training:  30%|███       | 486/1600 [00:20<00:46, 24.11it/s]Training:  45%|████▌     | 727/1600 [00:30<00:36, 23.92it/s]Training:  60%|██████    | 965/1600 [00:40<00:27, 23.48it/s]Training:  75%|███████▍  | 1194/1600 [00:50<00:17, 23.25it/s]Training:  89%|████████▉ | 1429/1600 [01:00<00:07, 23.31it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 243/1600 [00:10<00:55, 24.28it/s]Training:  30%|███       | 486/1600 [00:20<00:46, 24.19it/s]Training:  46%|████▌     | 728/1600 [00:30<00:36, 24.00it/s]Training:  60%|██████    | 966/1600 [00:40<00:26, 23.59it/s]Training:  75%|███████▍  | Training loss: 480.6172, Training accuracy: 0.8862
Macro F1-score: 0.8861
Model performance on Angry speech (in training): 
	Precision: 0.8242, Recall: 0.8675, F1_score: 0.8453
Model performance on Happy speech (in training): 
	Precision: 0.8488, Recall: 0.8000, F1_score: 0.8237
Model performance on Neutral speech (in training): 
	Precision: 0.9233, Recall: 0.9325, F1_score: 0.9279
Model performance on Sad speech (in training): 
	Precision: 0.9497, Recall: 0.9450, F1_score: 0.9474

Eval Phase: 
Validation loss: 113.8729, Validation accuracy: 0.8050
Macro F1-score: 0.7934
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9200, F1_score: 0.9583
Model performance on Happy speech (in validation): 
	Precision: 0.8261, Recall: 0.3800, F1_score: 0.5205
Model performance on Neutral speech (in validation): 
	Precision: 0.5952, Recall: 1.0000, F1_score: 0.7463
Model performance on Sad speech (in validation): 
	Precision: 0.9787, Recall: 0.9200, F1_score: 0.9485
New best accuracy for layer 6 on epoch 2: 0.8050. Model saved.
Epoch 3/100

Training Phase:
Training loss: 314.3203, Training accuracy: 0.9263
Macro F1-score: 0.9261
Model performance on Angry speech (in training): 
	Precision: 0.8905, Recall: 0.8950, F1_score: 0.8928
Model performance on Happy speech (in training): 
	Precision: 0.8980, Recall: 0.8800, F1_score: 0.8889
Model performance on Neutral speech (in training): 
	Precision: 0.9416, Recall: 0.9675, F1_score: 0.9544
Model performance on Sad speech (in training): 
	Precision: 0.9747, Recall: 0.9625, F1_score: 0.9686

Eval Phase: 
Validation loss: 144.6222, Validation accuracy: 0.7900
Macro F1-score: 0.7775
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.8600, F1_score: 0.9247
Model performance on Happy speech (in validation): 
	Precision: 0.7200, Recall: 0.3600, F1_score: 0.4800
Model performance on Neutral speech (in validation): 
	Precision: 0.5952, Recall: 1.0000, F1_score: 0.7463
Model performance on Sad speech (in validation): 
	Precision: 0.9792, Recall: 0.9400, F1_score: 0.9592
Epoch 4/100

Training Phase:
1196/1600 [00:50<00:17, 23.19it/s]Training:  89%|████████▉ | 1426/1600 [01:00<00:07, 23.11it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 234/1600 [00:10<00:58, 23.37it/s]Training:  29%|██▉       | 468/1600 [00:20<00:48, 23.29it/s]Training:  44%|████▍     | 707/1600 [00:30<00:37, 23.53it/s]Training:  59%|█████▉    | 946/1600 [00:40<00:28, 23.25it/s]Training:  74%|███████▎  | 1178/1600 [00:50<00:18, 23.22it/s]Training:  88%|████████▊ | 1410/1600 [01:00<00:08, 23.17it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 233/16Training loss: 275.2783, Training accuracy: 0.9344
Macro F1-score: 0.9343
Model performance on Angry speech (in training): 
	Precision: 0.8988, Recall: 0.9100, F1_score: 0.9043
Model performance on Happy speech (in training): 
	Precision: 0.9059, Recall: 0.8900, F1_score: 0.8979
Model performance on Neutral speech (in training): 
	Precision: 0.9554, Recall: 0.9650, F1_score: 0.9602
Model performance on Sad speech (in training): 
	Precision: 0.9774, Recall: 0.9725, F1_score: 0.9749

Eval Phase: 
Validation loss: 150.3842, Validation accuracy: 0.7450
Macro F1-score: 0.7351
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.5400, F1_score: 0.7013
Model performance on Happy speech (in validation): 
	Precision: 0.5556, Recall: 0.5000, F1_score: 0.5263
Model performance on Neutral speech (in validation): 
	Precision: 0.6667, Recall: 1.0000, F1_score: 0.8000
Model performance on Sad speech (in validation): 
	Precision: 0.8868, Recall: 0.9400, F1_score: 0.9126
Epoch 5/100

Training Phase:
00 [00:10<00:58, 23.22it/s]Training:  29%|██▉       | 466/1600 [00:20<00:49, 22.95it/s]Training:  44%|████▎     | 696/1600 [00:30<00:39, 22.96it/s]Training:  59%|█████▉    | 942/1600 [00:40<00:27, 23.58it/s]Training:  74%|███████▍  | 1188/1600 [00:50<00:17, 23.83it/s]Training:  89%|████████▉ | 1431/1600 [01:00<00:07, 23.59it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 229/1600 [00:10<01:00, 22.81it/s]Training:  29%|██▉       | 466/1600 [00:20<00:48, 23.33it/s]Training:  44%|████▍     | 709/1600 [00:30<00:37, 23.74it/s]Training:  60%|█████▉    | 956/1600 [00:40<00:26, 24.10it/s]Training:  75%|███████▌  | 1204/1600 [00:50<00:16, 24.33it/s]Training:  91%|█████████ | 1452/1600Training loss: 201.6711, Training accuracy: 0.9494
Macro F1-score: 0.9494
Model performance on Angry speech (in training): 
	Precision: 0.9328, Recall: 0.9375, F1_score: 0.9352
Model performance on Happy speech (in training): 
	Precision: 0.9250, Recall: 0.9250, F1_score: 0.9250
Model performance on Neutral speech (in training): 
	Precision: 0.9698, Recall: 0.9650, F1_score: 0.9674
Model performance on Sad speech (in training): 
	Precision: 0.9700, Recall: 0.9700, F1_score: 0.9700

Eval Phase: 
Validation loss: 81.9691, Validation accuracy: 0.8600
Macro F1-score: 0.8592
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.8600, F1_score: 0.9247
Model performance on Happy speech (in validation): 
	Precision: 0.8462, Recall: 0.6600, F1_score: 0.7416
Model performance on Neutral speech (in validation): 
	Precision: 0.7206, Recall: 0.9800, F1_score: 0.8305
Model performance on Sad speech (in validation): 
	Precision: 0.9400, Recall: 0.9400, F1_score: 0.9400
New best accuracy for layer 6 on epoch 5: 0.8600. Model saved.
Epoch 6/100

Training Phase:
Training loss: 157.0568, Training accuracy: 0.9606
Macro F1-score: 0.9606
Model performance on Angry speech (in training): 
	Precision: 0.9447, Recall: 0.9400, F1_score: 0.9424
Model performance on Happy speech (in training): 
	Precision: 0.9352, Recall: 0.9375, F1_score: 0.9363
Model performance on Neutral speech (in training): 
	Precision: 0.9751, Recall: 0.9775, F1_score: 0.9763
Model performance on Sad speech (in training): 
	Precision: 0.9875, Recall: 0.9875, F1_score: 0.9875

Eval Phase: 
Validation loss: 87.8984, Validation accuracy: 0.8600
Macro F1-score: 0.8599
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.8000, F1_score: 0.8889
Model performance on Happy speech (in validation): 
	Precision: 0.8333, Recall: 0.7000, F1_score: 0.7609
Model performance on Neutral speech (in validation): 
	Precision: 0.7246, Recall: 1.0000, F1_score: 0.8403
Model performance on Sad speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Epoch 7/100

Training Phase:
 [01:00<00:06, 24.14it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 234/1600 [00:10<00:58, 23.35it/s]Training:  29%|██▉       | 468/1600 [00:20<00:48, 23.35it/s]Training:  44%|████▍     | 702/1600 [00:30<00:38, 23.37it/s]Training:  59%|█████▉    | 940/1600 [00:40<00:28, 23.51it/s]Training:  74%|███████▎  | 1178/1600 [00:50<00:17, 23.47it/s]Training:  88%|████████▊ | 1414/1600 [01:00<00:07, 23.48it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 236/1600 [00:10<00:57, 23.53it/s]Training:  30%|██▉       | 472/1600 [00:20<00:48, 23.49Training loss: 158.7546, Training accuracy: 0.9675
Macro F1-score: 0.9675
Model performance on Angry speech (in training): 
	Precision: 0.9459, Recall: 0.9625, F1_score: 0.9542
Model performance on Happy speech (in training): 
	Precision: 0.9543, Recall: 0.9400, F1_score: 0.9471
Model performance on Neutral speech (in training): 
	Precision: 0.9800, Recall: 0.9825, F1_score: 0.9813
Model performance on Sad speech (in training): 
	Precision: 0.9899, Recall: 0.9850, F1_score: 0.9875

Eval Phase: 
Validation loss: 134.1859, Validation accuracy: 0.8250
Macro F1-score: 0.8247
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.7400, F1_score: 0.8506
Model performance on Happy speech (in validation): 
	Precision: 0.7750, Recall: 0.6200, F1_score: 0.6889
Model performance on Neutral speech (in validation): 
	Precision: 0.6667, Recall: 1.0000, F1_score: 0.8000
Model performance on Sad speech (in validation): 
	Precision: 0.9792, Recall: 0.9400, F1_score: 0.9592
Epoch 8/100

Training Phase:
Training loss: 158.1034, Training accuracy: 0.9675
Macro F1-score: 0.9675
Model performance on Angry speech (in training): 
	Precision: 0.9504, Recall: 0.9575, F1_score: 0.9539
Model performance on Happy speech (in training): 
	Precision: 0.9525, Recall: 0.9525, F1_score: 0.9525
Model performance on Neutral speech (in training): 
	Precision: 0.9848, Recall: 0.9750, F1_score: 0.9799
Model performance on Sad speech (in training): 
	Precision: 0.9825, Recall: 0.9850, F1_score: 0.9838

Eval Phase: 
it/s]Training:  44%|████▍     | 709/1600 [00:30<00:37, 23.55it/s]Training:  59%|█████▉    | 946/1600 [00:40<00:27, 23.43it/s]Training:  74%|███████▍  | 1185/1600 [00:50<00:17, 23.58it/s]Training:  89%|████████▉ | 1424/1600 [01:00<00:07, 23.53it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 236/1600 [00:10<00:57, 23.58it/s]Training:  30%|██▉       | 472/1600 [00:20<00:48, 23.43it/s]Training:  44%|████▍     | 708/1600 [00:30<00:37, 23.49it/s]Training:  59%|█████▉    | 944/1600 [00:40<00:28, 23.20it/s]Training:  74%|███████▎  | 1179/1600 [00:50<00:18, 23.29it/s]Training:  88%|████████▊ | 1414/1600 [01:00<00:07, 23.32it/s]                                                             Validation loss: 115.7638, Validation accuracy: 0.8250
Macro F1-score: 0.8227
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.7600, F1_score: 0.8636
Model performance on Happy speech (in validation): 
	Precision: 0.7381, Recall: 0.6200, F1_score: 0.6739
Model performance on Neutral speech (in validation): 
	Precision: 0.7143, Recall: 1.0000, F1_score: 0.8333
Model performance on Sad speech (in validation): 
	Precision: 0.9200, Recall: 0.9200, F1_score: 0.9200
Epoch 9/100

Training Phase:
Training loss: 137.9391, Training accuracy: 0.9663
Macro F1-score: 0.9662
Model performance on Angry speech (in training): 
	Precision: 0.9620, Recall: 0.9500, F1_score: 0.9560
Model performance on Happy speech (in training): 
	Precision: 0.9453, Recall: 0.9500, F1_score: 0.9476
Model performance on Neutral speech (in training): 
	Precision: 0.9705, Recall: 0.9875, F1_score: 0.9789
Model performance on Sad speech (in training): 
	Precision: 0.9874, Recall: 0.9775, F1_score: 0.9824

Eval Phase: 
Validation loss: 157.4732, Validation accuracy: 0.7850
Macro F1-score: 0.7723
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.7800, F1_score: 0.8764
Model performance on Happy speech (in validation): 
	Precision: 0.7500, Recall: 0.4200, F1_score: 0.5385
Model performance on Neutral speech (in validation): 
	Precision: 0.6494, Recall: 1.0000, F1_score: 0.7874
Model performance on Sad speech (in validation): 
	Precision: 0.8393, Recall: 0.9400, F1_score: 0.8868
Epoch 10/100

Training Phase:
Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 235/1600 [00:10<00:58, 23.49it/s]Training:  29%|██▉       | 470/1600 [00:20<00:48, 23.40it/s]Training:  44%|████▍     | 707/1600 [00:30<00:38, 23.49it/s]Training:  59%|█████▉    | 946/1600 [00:40<00:27, 23.62it/s]Training:  74%|███████▍  | 1185/1600 [00:50<00:17, 23.58it/s]Training:  89%|████████▉ | 1421/1600 [01:00<00:07, 23.51it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 236/1600 [00:10<00:57, 23.59it/s]Training:  30%|██▉       | 472/1600 [00:20<00:47, 23.51it/s]Training:  44%|████▍     | 707/1600 [00:30<00:38, 23.47it/s]Training:  5Training loss: 127.6302, Training accuracy: 0.9725
Macro F1-score: 0.9725
Model performance on Angry speech (in training): 
	Precision: 0.9622, Recall: 0.9550, F1_score: 0.9586
Model performance on Happy speech (in training): 
	Precision: 0.9507, Recall: 0.9650, F1_score: 0.9578
Model performance on Neutral speech (in training): 
	Precision: 0.9874, Recall: 0.9800, F1_score: 0.9837
Model performance on Sad speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900

Eval Phase: 
Validation loss: 368.0098, Validation accuracy: 0.6400
Macro F1-score: 0.6301
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.7400, F1_score: 0.8506
Model performance on Happy speech (in validation): 
	Precision: 0.7568, Recall: 0.5600, F1_score: 0.6437
Model performance on Neutral speech (in validation): 
	Precision: 0.4425, Recall: 1.0000, F1_score: 0.6135
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.2600, F1_score: 0.4127
Epoch 11/100

Training Phase:
Training loss: 125.2489, Training accuracy: 0.9744
Macro F1-score: 0.9744
Model performance on Angry speech (in training): 
	Precision: 0.9699, Recall: 0.9675, F1_score: 0.9687
Model performance on Happy speech (in training): 
	Precision: 0.9677, Recall: 0.9725, F1_score: 0.9701
Model performance on Neutral speech (in training): 
	Precision: 0.9751, Recall: 0.9775, F1_score: 0.9763
Model performance on Sad speech (in training): 
	Precision: 0.9849, Recall: 0.9800, F1_score: 0.9825

Eval Phase: 
9%|█████▉    | 942/1600 [00:40<00:28, 23.46it/s]Training:  74%|███████▎  | 1177/1600 [00:50<00:18, 23.44it/s]Training:  88%|████████▊ | 1412/1600 [01:00<00:08, 23.46it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 237/1600 [00:10<00:57, 23.70it/s]Training:  30%|██▉       | 475/1600 [00:20<00:47, 23.76it/s]Training:  45%|████▍     | 713/1600 [00:30<00:37, 23.60it/s]Training:  59%|█████▉    | 948/1600 [00:40<00:27, 23.47it/s]Training:  74%|███████▍  | 1181/1600 [00:50<00:17, 23.39it/s]Training:  88%|████████▊ | 1415/1600 [01:00<00:07, 23.38it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                     Validation loss: 236.4628, Validation accuracy: 0.6600
Macro F1-score: 0.6598
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.5600, F1_score: 0.7179
Model performance on Happy speech (in validation): 
	Precision: 0.5946, Recall: 0.4400, F1_score: 0.5057
Model performance on Neutral speech (in validation): 
	Precision: 0.5051, Recall: 1.0000, F1_score: 0.6711
Model performance on Sad speech (in validation): 
	Precision: 0.8889, Recall: 0.6400, F1_score: 0.7442
Epoch 12/100

Training Phase:
Training loss: 105.2104, Training accuracy: 0.9769
Macro F1-score: 0.9769
Model performance on Angry speech (in training): 
	Precision: 0.9675, Recall: 0.9675, F1_score: 0.9675
Model performance on Happy speech (in training): 
	Precision: 0.9674, Recall: 0.9650, F1_score: 0.9662
Model performance on Neutral speech (in training): 
	Precision: 0.9850, Recall: 0.9875, F1_score: 0.9863
Model performance on Sad speech (in training): 
	Precision: 0.9875, Recall: 0.9875, F1_score: 0.9875

Eval Phase: 
Validation loss: 101.6320, Validation accuracy: 0.8500
Macro F1-score: 0.8526
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.8000, F1_score: 0.8889
Model performance on Happy speech (in validation): 
	Precision: 0.8039, Recall: 0.8200, F1_score: 0.8119
Model performance on Neutral speech (in validation): 
	Precision: 0.7143, Recall: 1.0000, F1_score: 0.8333
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.7800, F1_score: 0.8764
Epoch 13/100

Training Phase:
              Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 236/1600 [00:10<00:57, 23.52it/s]Training:  30%|██▉       | 473/1600 [00:20<00:47, 23.59it/s]Training:  45%|████▍     | 714/1600 [00:30<00:37, 23.80it/s]Training:  60%|██████    | 961/1600 [00:40<00:26, 24.12it/s]Training:  76%|███████▌  | 1209/1600 [00:50<00:16, 24.36it/s]Training:  91%|█████████ | 1457/1600 [01:00<00:05, 24.41it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 246/1600 [00:10<00:55, 24.58it/s]Training:  31%|███       | 492/1600 [00:20<00:45, 24.54it/s]Training:  46%|████▌     | 738/1600 [00:30<00:35, 24.56it/s]Training:  62%|██████▏   | 984/1600 [00:40<00:25, 24.52it/s]Training:  77%|███Training loss: 89.7393, Training accuracy: 0.9769
Macro F1-score: 0.9769
Model performance on Angry speech (in training): 
	Precision: 0.9703, Recall: 0.9800, F1_score: 0.9751
Model performance on Happy speech (in training): 
	Precision: 0.9698, Recall: 0.9650, F1_score: 0.9674
Model performance on Neutral speech (in training): 
	Precision: 0.9751, Recall: 0.9800, F1_score: 0.9776
Model performance on Sad speech (in training): 
	Precision: 0.9924, Recall: 0.9825, F1_score: 0.9874

Eval Phase: 
Validation loss: 127.9069, Validation accuracy: 0.8400
Macro F1-score: 0.8409
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.7000, F1_score: 0.8235
Model performance on Happy speech (in validation): 
	Precision: 0.7451, Recall: 0.7600, F1_score: 0.7525
Model performance on Neutral speech (in validation): 
	Precision: 0.7246, Recall: 1.0000, F1_score: 0.8403
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9000, F1_score: 0.9474
Epoch 14/100

Training Phase:
Training loss: 110.6055, Training accuracy: 0.9731
Macro F1-score: 0.9731
Model performance on Angry speech (in training): 
	Precision: 0.9651, Recall: 0.9675, F1_score: 0.9663
Model performance on Happy speech (in training): 
	Precision: 0.9625, Recall: 0.9625, F1_score: 0.9625
Model performance on Neutral speech (in training): 
	Precision: 0.9849, Recall: 0.9800, F1_score: 0.9825
Model performance on Sad speech (in training): 
	Precision: 0.9800, Recall: 0.9825, F1_score: 0.9813

Eval Phase: 
Validation loss: 173.2709, Validation accuracy: 0.8100
Macro F1-score: 0.8041
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.8200, F1_score: 0.9011
Model performance on Happy speech (in validation): 
	Precision: 0.7931, Recall: 0.4600, F1_score: 0.5823
Model performance on Neutral speech (in validation): 
	Precision: 0.6173, Recall: 1.0000, F1_score: 0.7634
Model performance on Sad speech (in validation): 
	Precision: 0.9796, Recall: 0.9600, F1_score: 0.9697
Epoch 15/100

Training Phase:
███▋  | 1233/1600 [00:50<00:14, 24.65it/s]Training:  93%|█████████▎| 1482/1600 [01:00<00:04, 24.60it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 245/1600 [00:10<00:55, 24.43it/s]Training:  31%|███       | 495/1600 [00:20<00:44, 24.71it/s]Training:  47%|████▋     | 745/1600 [00:30<00:34, 24.82it/s]Training:  62%|██████▏   | 997/1600 [00:40<00:24, 24.93it/s]Training:  78%|███████▊  | 1249/1600 [00:50<00:14, 25.00it/s]Training:  94%|█████████▍| 1501/1600 [01:00<00:03, 24.92it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%Training loss: 64.3240, Training accuracy: 0.9838
Macro F1-score: 0.9837
Model performance on Angry speech (in training): 
	Precision: 0.9725, Recall: 0.9725, F1_score: 0.9725
Model performance on Happy speech (in training): 
	Precision: 0.9824, Recall: 0.9775, F1_score: 0.9799
Model performance on Neutral speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900
Model performance on Sad speech (in training): 
	Precision: 0.9900, Recall: 0.9950, F1_score: 0.9925

Eval Phase: 
Validation loss: 119.1472, Validation accuracy: 0.8600
Macro F1-score: 0.8547
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.8400, F1_score: 0.9130
Model performance on Happy speech (in validation): 
	Precision: 0.8571, Recall: 0.6000, F1_score: 0.7059
Model performance on Neutral speech (in validation): 
	Precision: 0.7353, Recall: 1.0000, F1_score: 0.8475
Model performance on Sad speech (in validation): 
	Precision: 0.9091, Recall: 1.0000, F1_score: 0.9524
Validation loss does not decrease for 10 epochs. End training.
Model best accuracy on validation set: 0.8600

Test Phase: 
|█▌        | 249/1600 [00:10<00:54, 24.86it/s]Training:  31%|███       | 499/1600 [00:20<00:44, 24.90it/s]Training:  47%|████▋     | 749/1600 [00:30<00:34, 24.91it/s]Training:  62%|██████▏   | 999/1600 [00:40<00:24, 24.82it/s]Training:  78%|███████▊  | 1246/1600 [00:50<00:14, 24.74it/s]Training:  94%|█████████▎| 1498/1600 [01:00<00:04, 24.89it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]                                                Some weights of the model checkpoint at /work/tc062/tc062/zhan7721/saved_models/de were not used when initializing Wav2Vec2Model: ['encoder.layers.10.attention.k_proj.bias', 'encoder.layers.10.attention.k_proj.weight', 'encoder.layers.10.attention.out_proj.bias', 'encoder.layers.10.attention.out_proj.weight', 'encoder.layers.10.attention.q_proj.bias', 'encoder.layers.10.attention.q_proj.weight', 'encoder.layers.10.attention.v_proj.bias', 'encoder.layers.10.attention.v_proj.weight', 'encoder.layers.10.feed_forward.intermediate_dense.bias', 'encoder.layers.10.feed_forward.intermediate_dense.weight', 'encoder.layers.10.feed_forward.output_dense.bias', 'encoder.layers.10.feed_forward.output_dense.weight', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.10.layer_norm.bias', 'encoder.layers.10.layer_norm.weight', 'encoder.layers.11.attention.k_proj.bias', 'encoder.layers.11.attention.k_proj.weight', 'encoder.layers.11.attention.out_proj.bias', 'encoder.layers.11.attention.out_proj.weight', 'encoder.layers.11.attention.q_proj.bias', 'encoder.layers.11.attention.q_proj.weight', 'encoder.layers.11.attention.v_proj.bias', 'encoder.layers.11.attention.v_proj.weight', 'encoder.layers.11.feed_forward.intermediate_dense.bias', 'encoder.layers.11.feed_forward.intermediate_dense.weight', 'encoder.layers.11.feed_forward.output_dense.bias', 'encoder.layers.11.feed_forward.output_dense.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.11.layer_norm.bias', 'encoder.layers.11.layer_norm.weight', 'encoder.layers.7.attention.k_proj.bias', 'encoder.layers.7.attention.k_proj.weight', 'encoder.layers.7.attention.out_proj.bias', 'encoder.layers.7.attention.out_proj.weight', 'encoder.layers.7.attention.q_proj.bias', 'encoder.layers.7.attention.q_proj.weight', 'encoder.layers.7.attention.v_proj.bias', 'encoder.layers.7.attention.v_proj.weight', 'encoder.layers.7.feed_forward.intermediate_dense.bias', 'encoder.layers.7.feed_forward.intermediate_dense.weight', 'encoder.layers.7.feed_forward.output_dense.bias', 'encoder.layers.7.feed_forward.output_dense.weight', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.7.layer_norm.bias', 'encoder.layers.7.layer_norm.weight', 'encoder.layers.8.attention.k_proj.bias', 'encoder.layers.8.attention.k_proj.weight', 'encoder.layers.8.attention.out_proj.bias', 'encoder.layers.8.attention.out_proj.weight', 'encoder.layers.8.attention.q_proj.bias', 'encoder.layers.8.attention.q_proj.weight', 'encoder.layers.8.attention.v_proj.bias', 'encoder.layers.8.attention.v_proj.weight', 'encoder.layers.8.feed_forward.intermediate_dense.bias', 'encoder.layers.8.feed_forward.intermediate_dense.weight', 'encoder.layers.8.feed_forward.output_dense.bias', 'encoder.layers.8.feed_forward.output_dense.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.8.layer_norm.bias', 'encoder.layers.8.layer_norm.weight', 'encoder.layers.9.attention.k_proj.bias', 'encoder.layers.9.attention.k_proj.weight', 'encoder.layers.9.attention.out_proj.bias', 'encoder.layers.9.attention.out_proj.weight', 'encoder.layers.9.attention.q_proj.bias', 'encoder.layers.9.attention.q_proj.weight', 'encoder.layers.9.attention.v_proj.bias', 'encoder.layers.9.attention.v_proj.weight', 'encoder.layers.9.feed_forward.intermediate_dense.bias', 'encoder.layers.9.feed_forward.intermediate_dense.weight', 'encoder.layers.9.feed_forward.output_dense.bias', 'encoder.layers.9.feed_forward.output_dense.weight', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.layer_norm.bias', 'encoder.layers.9.layer_norm.weight']
- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Test loss: 81.1097, Test accuracy: 0.8250
Macro F1-score: 0.8248
Model performance on Angry speech (in test): 
	Precision: 1.0000, Recall: 0.8200, F1_score: 0.9011
Model performance on Happy speech (in test): 
	Precision: 0.8205, Recall: 0.6400, F1_score: 0.7191
Model performance on Neutral speech (in test): 
	Precision: 0.6849, Recall: 1.0000, F1_score: 0.8130
Model performance on Sad speech (in test): 
	Precision: 0.8936, Recall: 0.8400, F1_score: 0.8660

======================= This is fold_2 on cn =======================

Load dataset: 
Loading cn train data: fold_2...
Preprocess cn fold_2 data for cn model
Loading cn eval data: fold_2...
Preprocess cn fold_2 data for cn model
Loading cn test data: fold_2...
Preprocess cn fold_2 data for cn model
Use cn model to add lora
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training loss: 681.4473, Training accuracy: 0.8387
Macro F1-score: 0.8386
Model performance on Angry speech (in training): 
	Precision: 0.8045, Recall: 0.8125, F1_score: 0.8085
Model performance on Happy speech (in training): 
	Precision: 0.7801, Recall: 0.7625, F1_score: 0.7712
Model performance on Neutral speech (in training): 
	Precision: 0.8444, Recall: 0.8550, F1_score: 0.8497
Model performance on Sad speech (in training): 
	Precision: 0.9250, Recall: 0.9250, F1_score: 0.9250

Eval Phase: 
Validation loss: 176.7623, Validation accuracy: 0.6800
Macro F1-score: 0.6419
Model performance on Angry speech (in validation): 
	Precision: 0.5275, Recall: 0.9600, F1_score: 0.6809
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1800, F1_score: 0.3051
Model performance on Neutral speech (in validation): 
	Precision: 0.7407, Recall: 0.8000, F1_score: 0.7692
Model performance on Sad speech (in validation): 
	Precision: 0.8478, Recall: 0.7800, F1_score: 0.8125
New best accuracy for layer 6 on epoch 1: 0.6800. Model saved.
Epoch 2/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:   9%|▊         | 139/1600 [00:10<01:45, 13.85it/s]Training:  20%|██        | 325/1600 [00:20<01:16, 16.61it/s]Training:  33%|███▎      | 529/1600 [00:30<00:58, 18.30it/s]Training:  47%|████▋     | 753/1600 [00:40<00:42, 19.90it/s]Training:  61%|██████    | 977/1600 [00:50<00:30, 20.68it/s]Training:  75%|███████▌  | 1202/1600 [01:00<00:18, 21.30it/s]Training:  89%|████████▉ | 1427/1600 [01:10<00:07, 21.65it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 230/1600 [00:10<00:59, 22.95it/s]Training:  29%|██▉       | 465/1600 [00:20<00:48, 23.24it/s]Training:  44%|████▍     | 703/1600 [00:30<00:38, 23.47it/s]Training:  59%|█████▉    | 941/1600 [00Training loss: 321.9686, Training accuracy: 0.9175
Macro F1-score: 0.9175
Model performance on Angry speech (in training): 
	Precision: 0.9095, Recall: 0.9050, F1_score: 0.9073
Model performance on Happy speech (in training): 
	Precision: 0.8747, Recall: 0.8725, F1_score: 0.8736
Model performance on Neutral speech (in training): 
	Precision: 0.9163, Recall: 0.9300, F1_score: 0.9231
Model performance on Sad speech (in training): 
	Precision: 0.9698, Recall: 0.9625, F1_score: 0.9661

Eval Phase: 
Validation loss: 179.8615, Validation accuracy: 0.7350
Macro F1-score: 0.7232
Model performance on Angry speech (in validation): 
	Precision: 0.6351, Recall: 0.9400, F1_score: 0.7581
Model performance on Happy speech (in validation): 
	Precision: 0.9615, Recall: 0.5000, F1_score: 0.6579
Model performance on Neutral speech (in validation): 
	Precision: 0.9310, Recall: 0.5400, F1_score: 0.6835
Model performance on Sad speech (in validation): 
	Precision: 0.6761, Recall: 0.9600, F1_score: 0.7934
New best accuracy for layer 6 on epoch 2: 0.7350. Model saved.
Epoch 3/100

Training Phase:
Training loss: 229.1731, Training accuracy: 0.9519
Macro F1-score: 0.9518
Model performance on Angry speech (in training): 
	Precision: 0.9544, Recall: 0.9425, F1_score: 0.9484
Model performance on Happy speech (in training): 
	Precision: 0.9271, Recall: 0.9225, F1_score: 0.9248
Model performance on Neutral speech (in training): 
	Precision: 0.9506, Recall: 0.9625, F1_score: 0.9565
Model performance on Sad speech (in training): 
	Precision: 0.9751, Recall: 0.9800, F1_score: 0.9776

Eval Phase: 
Validation loss: 153.6374, Validation accuracy: 0.7700
Macro F1-score: 0.7652
Model performance on Angry speech (in validation): 
	Precision: 0.6528, Recall: 0.9400, F1_score: 0.7705
Model performance on Happy speech (in validation): 
	Precision: 0.9000, Recall: 0.5400, F1_score: 0.6750
Model performance on Neutral speech (in validation): 
	Precision: 0.8085, Recall: 0.7600, F1_score: 0.7835
Model performance on Sad speech (in validation): 
	Precision: 0.8235, Recall: 0.8400, F1_score: 0.8317
New best accuracy for layer 6 on epoch 3: 0.7700. Model saved.
Epoch 4/100

Training Phase:
:40<00:28, 23.50it/s]Training:  74%|███████▎  | 1177/1600 [00:50<00:18, 23.42it/s]Training:  88%|████████▊ | 1412/1600 [01:00<00:08, 23.42it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 237/1600 [00:10<00:57, 23.64it/s]Training:  30%|██▉       | 474/1600 [00:20<00:47, 23.46it/s]Training:  44%|████▍     | 709/1600 [00:30<00:37, 23.46it/s]Training:  59%|█████▉    | 946/1600 [00:40<00:27, 23.52it/s]Training:  74%|███████▍  | 1183/1600 [00:50<00:17, 23.41it/s]Training:  89%|████████▊ | 1419/1600 [01:00<00:07, 23.46it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|        Training loss: 181.0179, Training accuracy: 0.9575
Macro F1-score: 0.9575
Model performance on Angry speech (in training): 
	Precision: 0.9575, Recall: 0.9575, F1_score: 0.9575
Model performance on Happy speech (in training): 
	Precision: 0.9471, Recall: 0.9400, F1_score: 0.9435
Model performance on Neutral speech (in training): 
	Precision: 0.9579, Recall: 0.9675, F1_score: 0.9627
Model performance on Sad speech (in training): 
	Precision: 0.9674, Recall: 0.9650, F1_score: 0.9662

Eval Phase: 
Validation loss: 158.4617, Validation accuracy: 0.7550
Macro F1-score: 0.7484
Model performance on Angry speech (in validation): 
	Precision: 0.6479, Recall: 0.9200, F1_score: 0.7603
Model performance on Happy speech (in validation): 
	Precision: 0.8667, Recall: 0.5200, F1_score: 0.6500
Model performance on Neutral speech (in validation): 
	Precision: 0.8333, Recall: 0.7000, F1_score: 0.7609
Model performance on Sad speech (in validation): 
	Precision: 0.7719, Recall: 0.8800, F1_score: 0.8224
Epoch 5/100

Training Phase:
  | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 236/1600 [00:10<00:57, 23.53it/s]Training:  30%|██▉       | 472/1600 [00:20<00:47, 23.51it/s]Training:  44%|████▍     | 712/1600 [00:30<00:37, 23.70it/s]Training:  60%|█████▉    | 955/1600 [00:40<00:26, 23.92it/s]Training:  75%|███████▌  | 1200/1600 [00:50<00:16, 24.11it/s]Training:  90%|█████████ | 1447/1600 [01:00<00:06, 24.29it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 246/1600 [00:10<00:55, 24.55it/s]Training:  31%|███       | 492/1600 [00:20<00:45, 24.41it/s]Training:  46%|████▌     | 737/1600 [00:30<00:35, 24.44it/s]Training:  61%|██████▏   | 982/1600 [00:40<00:25, 24.40it/s]Training:  77%|███████▋  | 1230/1600 [00:50<00:15Training loss: 148.8767, Training accuracy: 0.9675
Macro F1-score: 0.9675
Model performance on Angry speech (in training): 
	Precision: 0.9574, Recall: 0.9550, F1_score: 0.9562
Model performance on Happy speech (in training): 
	Precision: 0.9506, Recall: 0.9625, F1_score: 0.9565
Model performance on Neutral speech (in training): 
	Precision: 0.9749, Recall: 0.9725, F1_score: 0.9737
Model performance on Sad speech (in training): 
	Precision: 0.9874, Recall: 0.9800, F1_score: 0.9837

Eval Phase: 
Validation loss: 214.1242, Validation accuracy: 0.7200
Macro F1-score: 0.7101
Model performance on Angry speech (in validation): 
	Precision: 0.5974, Recall: 0.9200, F1_score: 0.7244
Model performance on Happy speech (in validation): 
	Precision: 0.9545, Recall: 0.4200, F1_score: 0.5833
Model performance on Neutral speech (in validation): 
	Precision: 0.7273, Recall: 0.8000, F1_score: 0.7619
Model performance on Sad speech (in validation): 
	Precision: 0.8043, Recall: 0.7400, F1_score: 0.7708
Epoch 6/100

Training Phase:
Training loss: 96.0205, Training accuracy: 0.9806
Macro F1-score: 0.9806
Model performance on Angry speech (in training): 
	Precision: 0.9824, Recall: 0.9750, F1_score: 0.9787
Model performance on Happy speech (in training): 
	Precision: 0.9701, Recall: 0.9725, F1_score: 0.9713
Model performance on Neutral speech (in training): 
	Precision: 0.9778, Recall: 0.9900, F1_score: 0.9839
Model performance on Sad speech (in training): 
	Precision: 0.9924, Recall: 0.9850, F1_score: 0.9887

Eval Phase: 
Validation loss: 412.6224, Validation accuracy: 0.6800
Macro F1-score: 0.6592
Model performance on Angry speech (in validation): 
	Precision: 0.5376, Recall: 1.0000, F1_score: 0.6993
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.3000, F1_score: 0.4615
Model performance on Neutral speech (in validation): 
	Precision: 0.7442, Recall: 0.6400, F1_score: 0.6882
Model performance on Sad speech (in validation): 
	Precision: 0.7959, Recall: 0.7800, F1_score: 0.7879
Epoch 7/100

Training Phase:
, 24.51it/s]Training:  93%|█████████▎| 1481/1600 [01:00<00:04, 24.68it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 247/1600 [00:10<00:54, 24.65it/s]Training:  31%|███       | 494/1600 [00:20<00:45, 24.49it/s]Training:  46%|████▌     | 738/1600 [00:30<00:35, 24.33it/s]Training:  61%|██████▏   | 983/1600 [00:40<00:25, 24.39it/s]Training:  77%|███████▋  | 1228/1600 [00:50<00:15, 24.39it/s]Training:  92%|█████████▏| 1473/1600 [01:00<00:05, 24.40it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 248/1600 [00:10<00:54,Training loss: 132.8082, Training accuracy: 0.9744
Macro F1-score: 0.9744
Model performance on Angry speech (in training): 
	Precision: 0.9678, Recall: 0.9775, F1_score: 0.9726
Model performance on Happy speech (in training): 
	Precision: 0.9621, Recall: 0.9525, F1_score: 0.9573
Model performance on Neutral speech (in training): 
	Precision: 0.9800, Recall: 0.9825, F1_score: 0.9813
Model performance on Sad speech (in training): 
	Precision: 0.9875, Recall: 0.9850, F1_score: 0.9862

Eval Phase: 
Validation loss: 202.2577, Validation accuracy: 0.7500
Macro F1-score: 0.7433
Model performance on Angry speech (in validation): 
	Precision: 0.6351, Recall: 0.9400, F1_score: 0.7581
Model performance on Happy speech (in validation): 
	Precision: 0.9259, Recall: 0.5000, F1_score: 0.6494
Model performance on Neutral speech (in validation): 
	Precision: 0.8182, Recall: 0.7200, F1_score: 0.7660
Model performance on Sad speech (in validation): 
	Precision: 0.7636, Recall: 0.8400, F1_score: 0.8000
Epoch 8/100

Training Phase:
 24.69it/s]Training:  31%|███       | 495/1600 [00:20<00:44, 24.68it/s]Training:  46%|████▋     | 742/1600 [00:30<00:34, 24.61it/s]Training:  62%|██████▏   | 989/1600 [00:40<00:24, 24.63it/s]Training:  77%|███████▋  | 1237/1600 [00:50<00:14, 24.66it/s]Training:  93%|█████████▎| 1485/1600 [01:00<00:04, 24.70it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 249/1600 [00:10<00:54, 24.89it/s]Training:  31%|███       | 499/1600 [00:20<00:44, 24.94it/s]Training:  47%|████▋     | 749/1600 [00:30<00:34, 24.77it/s]Training:  62%|██████▏   | 998/1600 [00:40<00:24, 24.80it/s]Training:  62%|██████▏   | 998/1600 [00:50<00:24, 24.80it/s]Training:  78%|███████▊  | 1244/1600 [00:50<00:14, Training loss: 112.5008, Training accuracy: 0.9731
Macro F1-score: 0.9731
Model performance on Angry speech (in training): 
	Precision: 0.9772, Recall: 0.9650, F1_score: 0.9711
Model performance on Happy speech (in training): 
	Precision: 0.9603, Recall: 0.9675, F1_score: 0.9639
Model performance on Neutral speech (in training): 
	Precision: 0.9701, Recall: 0.9725, F1_score: 0.9713
Model performance on Sad speech (in training): 
	Precision: 0.9850, Recall: 0.9875, F1_score: 0.9863

Eval Phase: 
Validation loss: 438.2754, Validation accuracy: 0.6550
Macro F1-score: 0.6098
Model performance on Angry speech (in validation): 
	Precision: 0.5161, Recall: 0.9600, F1_score: 0.6713
Model performance on Happy speech (in validation): 
	Precision: 0.8750, Recall: 0.1400, F1_score: 0.2414
Model performance on Neutral speech (in validation): 
	Precision: 0.6935, Recall: 0.8600, F1_score: 0.7679
Model performance on Sad speech (in validation): 
	Precision: 0.8919, Recall: 0.6600, F1_score: 0.7586
Epoch 9/100

Training Phase:
Training loss: 102.7459, Training accuracy: 0.9744
Macro F1-score: 0.9744
Model performance on Angry speech (in training): 
	Precision: 0.9726, Recall: 0.9775, F1_score: 0.9751
Model performance on Happy speech (in training): 
	Precision: 0.9672, Recall: 0.9575, F1_score: 0.9623
Model performance on Neutral speech (in training): 
	Precision: 0.9677, Recall: 0.9750, F1_score: 0.9714
Model performance on Sad speech (in training): 
	Precision: 0.9900, Recall: 0.9875, F1_score: 0.9887

Eval Phase: 
Validation loss: 228.2226, Validation accuracy: 0.7450
Macro F1-score: 0.7318
Model performance on Angry speech (in validation): 
	Precision: 0.6076, Recall: 0.9600, F1_score: 0.7442
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.4000, F1_score: 0.5714
Model performance on Neutral speech (in validation): 
	Precision: 0.8125, Recall: 0.7800, F1_score: 0.7959
Model performance on Sad speech (in validation): 
	Precision: 0.7925, Recall: 0.8400, F1_score: 0.8155
Epoch 10/100

Training Phase:
24.26it/s]Training:  92%|█████████▏| 1478/1600 [01:00<00:05, 23.86it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 232/1600 [00:10<00:59, 23.18it/s]Training:  29%|██▉       | 467/1600 [00:20<00:48, 23.32it/s]Training:  44%|████▍     | 703/1600 [00:30<00:38, 23.42it/s]Training:  59%|█████▉    | 941/1600 [00:40<00:27, 23.57it/s]Training:  74%|███████▎  | 1179/1600 [00:50<00:17, 23.60it/s]Training:  89%|████████▊ | 1417/1600 [01:00<00:07, 23.66it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 235/1600 [00:10<00:58, 23.43Training loss: 77.5560, Training accuracy: 0.9862
Macro F1-score: 0.9862
Model performance on Angry speech (in training): 
	Precision: 0.9899, Recall: 0.9800, F1_score: 0.9849
Model performance on Happy speech (in training): 
	Precision: 0.9776, Recall: 0.9800, F1_score: 0.9788
Model performance on Neutral speech (in training): 
	Precision: 0.9851, Recall: 0.9925, F1_score: 0.9888
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925

Eval Phase: 
Validation loss: 239.6518, Validation accuracy: 0.7600
Macro F1-score: 0.7454
Model performance on Angry speech (in validation): 
	Precision: 0.6184, Recall: 0.9400, F1_score: 0.7460
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.4000, F1_score: 0.5714
Model performance on Neutral speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Sad speech (in validation): 
	Precision: 0.9250, Recall: 0.7400, F1_score: 0.8222
Epoch 11/100

Training Phase:
it/s]Training:  30%|██▉       | 472/1600 [00:20<00:47, 23.53it/s]Training:  44%|████▍     | 709/1600 [00:30<00:38, 23.44it/s]Training:  59%|█████▉    | 945/1600 [00:40<00:27, 23.46it/s]Training:  74%|███████▍  | 1182/1600 [00:50<00:17, 23.54it/s]Training:  89%|████████▉ | 1428/1600 [01:00<00:07, 23.88it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 244/1600 [00:10<00:55, 24.33it/s]Training:  31%|███       | 491/1600 [00:20<00:45, 24.50it/s]Training:  46%|████▋     | 740/1600 [00:30<00:34, 24.65it/s]Training:  62%|██████▏   | 989/1600 [00:40<00:24, 24.68it/s]Training:  77%|███████▋  | 1237/1600 [00:50<00:14, 24.63it/s]Training:  93%|█████████▎| 1485/1600 [01:00<00:04, 24.Training loss: 82.4486, Training accuracy: 0.9856
Macro F1-score: 0.9856
Model performance on Angry speech (in training): 
	Precision: 0.9851, Recall: 0.9900, F1_score: 0.9875
Model performance on Happy speech (in training): 
	Precision: 0.9824, Recall: 0.9775, F1_score: 0.9799
Model performance on Neutral speech (in training): 
	Precision: 0.9802, Recall: 0.9900, F1_score: 0.9851
Model performance on Sad speech (in training): 
	Precision: 0.9949, Recall: 0.9850, F1_score: 0.9899

Eval Phase: 
Validation loss: 199.4428, Validation accuracy: 0.7700
Macro F1-score: 0.7610
Model performance on Angry speech (in validation): 
	Precision: 0.6286, Recall: 0.8800, F1_score: 0.7333
Model performance on Happy speech (in validation): 
	Precision: 0.9583, Recall: 0.4600, F1_score: 0.6216
Model performance on Neutral speech (in validation): 
	Precision: 0.8036, Recall: 0.9000, F1_score: 0.8491
Model performance on Sad speech (in validation): 
	Precision: 0.8400, Recall: 0.8400, F1_score: 0.8400
Epoch 12/100

Training Phase:
Training loss: 100.4391, Training accuracy: 0.9781
Macro F1-score: 0.9781
Model performance on Angry speech (in training): 
	Precision: 0.9775, Recall: 0.9775, F1_score: 0.9775
Model performance on Happy speech (in training): 
	Precision: 0.9677, Recall: 0.9725, F1_score: 0.9701
Model performance on Neutral speech (in training): 
	Precision: 0.9751, Recall: 0.9775, F1_score: 0.9763
Model performance on Sad speech (in training): 
	Precision: 0.9924, Recall: 0.9850, F1_score: 0.9887

Eval Phase: 
Validation loss: 239.8563, Validation accuracy: 0.7200
Macro F1-score: 0.7081
Model performance on Angry speech (in validation): 
	Precision: 0.6515, Recall: 0.8600, F1_score: 0.7414
Model performance on Happy speech (in validation): 
	Precision: 0.7647, Recall: 0.5200, F1_score: 0.6190
Model performance on Neutral speech (in validation): 
	Precision: 0.9630, Recall: 0.5200, F1_score: 0.6753
Model performance on Sad speech (in validation): 
	Precision: 0.6712, Recall: 0.9800, F1_score: 0.7967
Epoch 13/100

Training Phase:
67it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 248/1600 [00:10<00:54, 24.78it/s]Training:  31%|███       | 496/1600 [00:20<00:44, 24.63it/s]Training:  46%|████▋     | 742/1600 [00:30<00:35, 24.48it/s]Training:  62%|██████▏   | 986/1600 [00:40<00:25, 24.33it/s]Training:  77%|███████▋  | 1227/1600 [00:50<00:15, 23.97it/s]Training:  91%|█████████▏| 1463/1600 [01:00<00:05, 23.81it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 251/1600 [00:10<00:53, 24.99it/s]Training:  31%|███▏      | 501/1600 [00:20<00:44, 24.91it/s]TrainiTraining loss: 65.1686, Training accuracy: 0.9875
Macro F1-score: 0.9875
Model performance on Angry speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913
Model performance on Happy speech (in training): 
	Precision: 0.9849, Recall: 0.9800, F1_score: 0.9825
Model performance on Neutral speech (in training): 
	Precision: 0.9825, Recall: 0.9850, F1_score: 0.9838
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925

Eval Phase: 
Validation loss: 314.7587, Validation accuracy: 0.7500
Macro F1-score: 0.7258
Model performance on Angry speech (in validation): 
	Precision: 0.5581, Recall: 0.9600, F1_score: 0.7059
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.2800, F1_score: 0.4375
Model performance on Neutral speech (in validation): 
	Precision: 0.8958, Recall: 0.8600, F1_score: 0.8776
Model performance on Sad speech (in validation): 
	Precision: 0.8654, Recall: 0.9000, F1_score: 0.8824
Validation loss does not decrease for 10 epochs. End training.
Model best accuracy on validation set: 0.7700

Test Phase: 
ng:  47%|████▋     | 751/1600 [00:30<00:34, 24.91it/s]Training:  63%|██████▎   | 1002/1600 [00:40<00:23, 24.96it/s]Training:  78%|███████▊  | 1254/1600 [00:50<00:13, 25.01it/s]Training:  94%|█████████▍| 1506/1600 [01:00<00:03, 25.00it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]                                                Some weights of the model checkpoint at /work/tc062/tc062/zhan7721/saved_models/de were not used when initializing Wav2Vec2Model: ['encoder.layers.10.attention.k_proj.bias', 'encoder.layers.10.attention.k_proj.weight', 'encoder.layers.10.attention.out_proj.bias', 'encoder.layers.10.attention.out_proj.weight', 'encoder.layers.10.attention.q_proj.bias', 'encoder.layers.10.attention.q_proj.weight', 'encoder.layers.10.attention.v_proj.bias', 'encoder.layers.10.attention.v_proj.weight', 'encoder.layers.10.feed_forward.intermediate_dense.bias', 'encoder.layers.10.feed_forward.intermediate_dense.weight', 'encoder.layers.10.feed_forward.output_dense.bias', 'encoder.layers.10.feed_forward.output_dense.weight', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.10.layer_norm.bias', 'encoder.layers.10.layer_norm.weight', 'encoder.layers.11.attention.k_proj.bias', 'encoder.layers.11.attention.k_proj.weight', 'encoder.layers.11.attention.out_proj.bias', 'encoder.layers.11.attention.out_proj.weight', 'encoder.layers.11.attention.q_proj.bias', 'encoder.layers.11.attention.q_proj.weight', 'encoder.layers.11.attention.v_proj.bias', 'encoder.layers.11.attention.v_proj.weight', 'encoder.layers.11.feed_forward.intermediate_dense.bias', 'encoder.layers.11.feed_forward.intermediate_dense.weight', 'encoder.layers.11.feed_forward.output_dense.bias', 'encoder.layers.11.feed_forward.output_dense.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.11.layer_norm.bias', 'encoder.layers.11.layer_norm.weight', 'encoder.layers.7.attention.k_proj.bias', 'encoder.layers.7.attention.k_proj.weight', 'encoder.layers.7.attention.out_proj.bias', 'encoder.layers.7.attention.out_proj.weight', 'encoder.layers.7.attention.q_proj.bias', 'encoder.layers.7.attention.q_proj.weight', 'encoder.layers.7.attention.v_proj.bias', 'encoder.layers.7.attention.v_proj.weight', 'encoder.layers.7.feed_forward.intermediate_dense.bias', 'encoder.layers.7.feed_forward.intermediate_dense.weight', 'encoder.layers.7.feed_forward.output_dense.bias', 'encoder.layers.7.feed_forward.output_dense.weight', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.7.layer_norm.bias', 'encoder.layers.7.layer_norm.weight', 'encoder.layers.8.attention.k_proj.bias', 'encoder.layers.8.attention.k_proj.weight', 'encoder.layers.8.attention.out_proj.bias', 'encoder.layers.8.attention.out_proj.weight', 'encoder.layers.8.attention.q_proj.bias', 'encoder.layers.8.attention.q_proj.weight', 'encoder.layers.8.attention.v_proj.bias', 'encoder.layers.8.attention.v_proj.weight', 'encoder.layers.8.feed_forward.intermediate_dense.bias', 'encoder.layers.8.feed_forward.intermediate_dense.weight', 'encoder.layers.8.feed_forward.output_dense.bias', 'encoder.layers.8.feed_forward.output_dense.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.8.layer_norm.bias', 'encoder.layers.8.layer_norm.weight', 'encoder.layers.9.attention.k_proj.bias', 'encoder.layers.9.attention.k_proj.weight', 'encoder.layers.9.attention.out_proj.bias', 'encoder.layers.9.attention.out_proj.weight', 'encoder.layers.9.attention.q_proj.bias', 'encoder.layers.9.attention.q_proj.weight', 'encoder.layers.9.attention.v_proj.bias', 'encoder.layers.9.attention.v_proj.weight', 'encoder.layers.9.feed_forward.intermediate_dense.bias', 'encoder.layers.9.feed_forward.intermediate_dense.weight', 'encoder.layers.9.feed_forward.output_dense.bias', 'encoder.layers.9.feed_forward.output_dense.weight', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.layer_norm.bias', 'encoder.layers.9.layer_norm.weight']
- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Test loss: 133.0780, Test accuracy: 0.7850
Macro F1-score: 0.7769
Model performance on Angry speech (in test): 
	Precision: 0.6622, Recall: 0.9800, F1_score: 0.7903
Model performance on Happy speech (in test): 
	Precision: 0.9259, Recall: 0.5000, F1_score: 0.6494
Model performance on Neutral speech (in test): 
	Precision: 0.8163, Recall: 0.8000, F1_score: 0.8081
Model performance on Sad speech (in test): 
	Precision: 0.8600, Recall: 0.8600, F1_score: 0.8600

======================= This is fold_3 on cn =======================

Load dataset: 
Loading cn train data: fold_3...
Preprocess cn fold_3 data for cn model
Loading cn eval data: fold_3...
Preprocess cn fold_3 data for cn model
Loading cn test data: fold_3...
Preprocess cn fold_3 data for cn model
Use cn model to add lora
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training loss: 698.0936, Training accuracy: 0.8281
Macro F1-score: 0.8281
Model performance on Angry speech (in training): 
	Precision: 0.7696, Recall: 0.7600, F1_score: 0.7648
Model performance on Happy speech (in training): 
	Precision: 0.7700, Recall: 0.7700, F1_score: 0.7700
Model performance on Neutral speech (in training): 
	Precision: 0.8512, Recall: 0.8725, F1_score: 0.8617
Model performance on Sad speech (in training): 
	Precision: 0.9215, Recall: 0.9100, F1_score: 0.9157

Eval Phase: 
Validation loss: 46.8888, Validation accuracy: 0.9050
Macro F1-score: 0.9042
Model performance on Angry speech (in validation): 
	Precision: 0.9500, Recall: 0.7600, F1_score: 0.8444
Model performance on Happy speech (in validation): 
	Precision: 0.7857, Recall: 0.8800, F1_score: 0.8302
Model performance on Neutral speech (in validation): 
	Precision: 0.9074, Recall: 0.9800, F1_score: 0.9423
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
New best accuracy for layer 6 on epoch 1: 0.9050. Model saved.
Epoch 2/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 249/1600 [00:10<00:54, 24.85it/s]Training:  31%|███       | 499/1600 [00:20<00:44, 24.90it/s]Training:  47%|████▋     | 749/1600 [00:30<00:34, 24.89it/s]Training:  62%|██████▏   | 999/1600 [00:40<00:24, 24.93it/s]Training:  78%|███████▊  | 1249/1600 [00:50<00:14, 24.87it/s]Training:  94%|█████████▎| 1497/1600 [01:00<00:04, 24.81it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 246/1600 [00:10<00:55, 24.50it/s]Training:  31%|███       | 496/1600 [00:20<00:44, 24.79it/s]Training:  47%|████▋     | 746/1600 [00:30<00:34, 24.78it/s]Training:  62%|██████▏   | 994/1600 [00:40<00:24, 24.71it/s]Training:  78%|███████Training loss: 432.9634, Training accuracy: 0.8931
Macro F1-score: 0.8929
Model performance on Angry speech (in training): 
	Precision: 0.8515, Recall: 0.8600, F1_score: 0.8557
Model performance on Happy speech (in training): 
	Precision: 0.8355, Recall: 0.8125, F1_score: 0.8238
Model performance on Neutral speech (in training): 
	Precision: 0.9216, Recall: 0.9400, F1_score: 0.9307
Model performance on Sad speech (in training): 
	Precision: 0.9624, Recall: 0.9600, F1_score: 0.9612

Eval Phase: 
Validation loss: 38.5081, Validation accuracy: 0.9200
Macro F1-score: 0.9195
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.7400, F1_score: 0.8506
Model performance on Happy speech (in validation): 
	Precision: 0.7742, Recall: 0.9600, F1_score: 0.8571
Model performance on Neutral speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
New best accuracy for layer 6 on epoch 2: 0.9200. Model saved.
Epoch 3/100

Training Phase:
Training loss: 321.5905, Training accuracy: 0.9237
Macro F1-score: 0.9238
Model performance on Angry speech (in training): 
	Precision: 0.8829, Recall: 0.9050, F1_score: 0.8938
Model performance on Happy speech (in training): 
	Precision: 0.8977, Recall: 0.8775, F1_score: 0.8875
Model performance on Neutral speech (in training): 
	Precision: 0.9453, Recall: 0.9500, F1_score: 0.9476
Model performance on Sad speech (in training): 
	Precision: 0.9698, Recall: 0.9625, F1_score: 0.9661

Eval Phase: 
Validation loss: 20.6406, Validation accuracy: 0.9650
Macro F1-score: 0.9650
Model performance on Angry speech (in validation): 
	Precision: 0.9787, Recall: 0.9200, F1_score: 0.9485
Model performance on Happy speech (in validation): 
	Precision: 0.9231, Recall: 0.9600, F1_score: 0.9412
Model performance on Neutral speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
New best accuracy for layer 6 on epoch 3: 0.9650. Model saved.
Epoch 4/100

Training Phase:
  | 1242/1600 [00:50<00:14, 24.72it/s]Training:  93%|█████████▎| 1490/1600 [01:00<00:04, 24.67it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 252/1600 [00:10<00:53, 25.19it/s]Training:  32%|███▏      | 504/1600 [00:20<00:44, 24.89it/s]Training:  47%|████▋     | 751/1600 [00:30<00:34, 24.69it/s]Training:  47%|████▋     | 751/1600 [00:40<00:34, 24.69it/s]Training:  62%|██████▏   | 997/1600 [00:40<00:24, 24.61it/s]Training:  78%|███████▊  | 1246/1600 [00:50<00:14, 24.69it/s]Training:  93%|█████████▎| 1495/1600 [01:00<00:04, 24.58it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   TraTraining loss: 247.6666, Training accuracy: 0.9425
Macro F1-score: 0.9424
Model performance on Angry speech (in training): 
	Precision: 0.9209, Recall: 0.9025, F1_score: 0.9116
Model performance on Happy speech (in training): 
	Precision: 0.9125, Recall: 0.9125, F1_score: 0.9125
Model performance on Neutral speech (in training): 
	Precision: 0.9539, Recall: 0.9825, F1_score: 0.9680
Model performance on Sad speech (in training): 
	Precision: 0.9823, Recall: 0.9725, F1_score: 0.9774

Eval Phase: 
Validation loss: 35.6576, Validation accuracy: 0.9200
Macro F1-score: 0.9181
Model performance on Angry speech (in validation): 
	Precision: 0.9796, Recall: 0.9600, F1_score: 0.9697
Model performance on Happy speech (in validation): 
	Precision: 0.9423, Recall: 0.9800, F1_score: 0.9608
Model performance on Neutral speech (in validation): 
	Precision: 0.9737, Recall: 0.7400, F1_score: 0.8409
Model performance on Sad speech (in validation): 
	Precision: 0.8197, Recall: 1.0000, F1_score: 0.9009
Epoch 5/100

Training Phase:
ining:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 248/1600 [00:10<00:54, 24.78it/s]Training:  31%|███       | 496/1600 [00:20<00:44, 24.61it/s]Training:  46%|████▋     | 743/1600 [00:30<00:34, 24.64it/s]Training:  62%|██████▏   | 995/1600 [00:40<00:24, 24.82it/s]Training:  78%|███████▊  | 1246/1600 [00:50<00:14, 24.81it/s]Training:  93%|█████████▎| 1494/1600 [01:00<00:04, 24.77it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 249/1600 [00:10<00:54, 24.87it/s]Training:  31%|███       | 498/1600 [00:20<00:44, 24.79it/s]Training:  47%|████▋     | 747/1600 [00:30<00:34, 24.82it/s]Training:  62%|██████▏   | 997/1600 [00:40<00:24, 24.88it/s]Training:  78%|███████▊  Training loss: 232.2724, Training accuracy: 0.9444
Macro F1-score: 0.9444
Model performance on Angry speech (in training): 
	Precision: 0.9089, Recall: 0.9225, F1_score: 0.9156
Model performance on Happy speech (in training): 
	Precision: 0.9343, Recall: 0.9250, F1_score: 0.9296
Model performance on Neutral speech (in training): 
	Precision: 0.9624, Recall: 0.9600, F1_score: 0.9612
Model performance on Sad speech (in training): 
	Precision: 0.9724, Recall: 0.9700, F1_score: 0.9712

Eval Phase: 
Validation loss: 35.7197, Validation accuracy: 0.9400
Macro F1-score: 0.9399
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.8800, F1_score: 0.9362
Model performance on Happy speech (in validation): 
	Precision: 0.8868, Recall: 0.9400, F1_score: 0.9126
Model performance on Neutral speech (in validation): 
	Precision: 0.9400, Recall: 0.9400, F1_score: 0.9400
Model performance on Sad speech (in validation): 
	Precision: 0.9434, Recall: 1.0000, F1_score: 0.9709
Epoch 6/100

Training Phase:
Training loss: 160.4989, Training accuracy: 0.9600
Macro F1-score: 0.9600
Model performance on Angry speech (in training): 
	Precision: 0.9375, Recall: 0.9375, F1_score: 0.9375
Model performance on Happy speech (in training): 
	Precision: 0.9372, Recall: 0.9325, F1_score: 0.9348
Model performance on Neutral speech (in training): 
	Precision: 0.9775, Recall: 0.9775, F1_score: 0.9775
Model performance on Sad speech (in training): 
	Precision: 0.9876, Recall: 0.9925, F1_score: 0.9900

Eval Phase: 
Validation loss: 65.5925, Validation accuracy: 0.8800
Macro F1-score: 0.8781
Model performance on Angry speech (in validation): 
	Precision: 0.9773, Recall: 0.8600, F1_score: 0.9149
Model performance on Happy speech (in validation): 
	Precision: 0.7619, Recall: 0.9600, F1_score: 0.8496
Model performance on Neutral speech (in validation): 
	Precision: 0.9459, Recall: 0.7000, F1_score: 0.8046
Model performance on Sad speech (in validation): 
	Precision: 0.8929, Recall: 1.0000, F1_score: 0.9434
Epoch 7/100

Training Phase:
| 1247/1600 [00:50<00:14, 24.89it/s]Training:  94%|█████████▎| 1497/1600 [01:00<00:04, 24.90it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 246/1600 [00:10<00:55, 24.51it/s]Training:  31%|███       | 494/1600 [00:20<00:44, 24.65it/s]Training:  46%|████▋     | 744/1600 [00:30<00:34, 24.78it/s]Training:  62%|██████▏   | 994/1600 [00:40<00:24, 24.75it/s]Training:  78%|███████▊  | 1243/1600 [00:50<00:14, 24.79it/s]Training:  93%|█████████▎| 1492/1600 [01:00<00:04, 24.82it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        Training loss: 145.2803, Training accuracy: 0.9706
Macro F1-score: 0.9706
Model performance on Angry speech (in training): 
	Precision: 0.9547, Recall: 0.9475, F1_score: 0.9511
Model performance on Happy speech (in training): 
	Precision: 0.9526, Recall: 0.9550, F1_score: 0.9538
Model performance on Neutral speech (in training): 
	Precision: 0.9850, Recall: 0.9875, F1_score: 0.9863
Model performance on Sad speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913

Eval Phase: 
Validation loss: 91.5948, Validation accuracy: 0.8500
Macro F1-score: 0.8494
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.6600, F1_score: 0.7952
Model performance on Happy speech (in validation): 
	Precision: 0.6857, Recall: 0.9600, F1_score: 0.8000
Model performance on Neutral speech (in validation): 
	Precision: 0.9091, Recall: 0.8000, F1_score: 0.8511
Model performance on Sad speech (in validation): 
	Precision: 0.9245, Recall: 0.9800, F1_score: 0.9515
Epoch 8/100

Training Phase:
| 245/1600 [00:10<00:55, 24.43it/s]Training:  31%|███       | 494/1600 [00:20<00:44, 24.67it/s]Training:  46%|████▋     | 743/1600 [00:30<00:34, 24.70it/s]Training:  62%|██████▏   | 992/1600 [00:40<00:24, 24.75it/s]Training:  78%|███████▊  | 1242/1600 [00:50<00:14, 24.83it/s]Training:  93%|█████████▎| 1493/1600 [01:00<00:04, 24.90it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 249/1600 [00:10<00:54, 24.81it/s]Training:  31%|███       | 499/1600 [00:20<00:44, 24.90it/s]Training:  47%|████▋     | 749/1600 [00:30<00:34, 24.75it/s]Training:  62%|██████▏   | 996/1600 [00:40<00:24, 24.72it/s]Training:  78%|███████▊  | 1245/1600 [00:50<00:14, 24.77it/s]Training:  94%|████████Training loss: 169.3533, Training accuracy: 0.9619
Macro F1-score: 0.9619
Model performance on Angry speech (in training): 
	Precision: 0.9646, Recall: 0.9525, F1_score: 0.9585
Model performance on Happy speech (in training): 
	Precision: 0.9429, Recall: 0.9500, F1_score: 0.9465
Model performance on Neutral speech (in training): 
	Precision: 0.9677, Recall: 0.9725, F1_score: 0.9701
Model performance on Sad speech (in training): 
	Precision: 0.9725, Recall: 0.9725, F1_score: 0.9725

Eval Phase: 
Validation loss: 126.4705, Validation accuracy: 0.8450
Macro F1-score: 0.8414
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.7600, F1_score: 0.8636
Model performance on Happy speech (in validation): 
	Precision: 0.7869, Recall: 0.9600, F1_score: 0.8649
Model performance on Neutral speech (in validation): 
	Precision: 0.9167, Recall: 0.6600, F1_score: 0.7674
Model performance on Sad speech (in validation): 
	Precision: 0.7692, Recall: 1.0000, F1_score: 0.8696
Epoch 9/100

Training Phase:
Training loss: 144.9966, Training accuracy: 0.9663
Macro F1-score: 0.9663
Model performance on Angry speech (in training): 
	Precision: 0.9478, Recall: 0.9525, F1_score: 0.9501
Model performance on Happy speech (in training): 
	Precision: 0.9525, Recall: 0.9525, F1_score: 0.9525
Model performance on Neutral speech (in training): 
	Precision: 0.9775, Recall: 0.9775, F1_score: 0.9775
Model performance on Sad speech (in training): 
	Precision: 0.9874, Recall: 0.9825, F1_score: 0.9850

Eval Phase: 
Validation loss: 54.9255, Validation accuracy: 0.9050
Macro F1-score: 0.9034
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.8800, F1_score: 0.9362
Model performance on Happy speech (in validation): 
	Precision: 0.8621, Recall: 1.0000, F1_score: 0.9259
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.7400, F1_score: 0.8506
Model performance on Sad speech (in validation): 
	Precision: 0.8197, Recall: 1.0000, F1_score: 0.9009
Epoch 10/100

Training Phase:
▎| 1497/1600 [01:00<00:04, 24.91it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 251/1600 [00:10<00:53, 25.05it/s]Training:  31%|███▏      | 502/1600 [00:20<00:44, 24.77it/s]Training:  47%|████▋     | 756/1600 [00:30<00:33, 25.02it/s]Training:  63%|██████▎   | 1010/1600 [00:40<00:23, 24.99it/s]Training:  79%|███████▉  | 1260/1600 [00:50<00:13, 24.99it/s]Training:  79%|███████▉  | 1260/1600 [01:00<00:13, 24.99it/s]Training:  94%|█████████▍| 1510/1600 [01:00<00:03, 24.90it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌    Training loss: 132.6762, Training accuracy: 0.9725
Macro F1-score: 0.9725
Model performance on Angry speech (in training): 
	Precision: 0.9628, Recall: 0.9700, F1_score: 0.9664
Model performance on Happy speech (in training): 
	Precision: 0.9672, Recall: 0.9575, F1_score: 0.9623
Model performance on Neutral speech (in training): 
	Precision: 0.9800, Recall: 0.9825, F1_score: 0.9813
Model performance on Sad speech (in training): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800

Eval Phase: 
Validation loss: 81.8875, Validation accuracy: 0.8600
Macro F1-score: 0.8585
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.7800, F1_score: 0.8764
Model performance on Happy speech (in validation): 
	Precision: 0.7273, Recall: 0.9600, F1_score: 0.8276
Model performance on Neutral speech (in validation): 
	Precision: 0.9211, Recall: 0.7000, F1_score: 0.7955
Model performance on Sad speech (in validation): 
	Precision: 0.8772, Recall: 1.0000, F1_score: 0.9346
Epoch 11/100

Training Phase:
    | 253/1600 [00:10<00:53, 25.25it/s]Training:  32%|███▏      | 506/1600 [00:20<00:43, 24.99it/s]Training:  47%|████▋     | 755/1600 [00:30<00:33, 24.93it/s]Training:  63%|██████▎   | 1006/1600 [00:40<00:23, 24.96it/s]Training:  79%|███████▊  | 1257/1600 [00:50<00:13, 24.98it/s]Training:  94%|█████████▍| 1508/1600 [01:00<00:03, 24.98it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 251/1600 [00:10<00:53, 25.02it/s]Training:  31%|███▏      | 502/1600 [00:20<00:44, 24.91it/s]Training:  47%|████▋     | 751/1600 [00:30<00:34, 24.80it/s]Training:  62%|██████▏   | 999/1600 [00:40<00:24, 24.79it/s]Training:  78%|███████▊  | 1247/1600 [00:50<00:14, 24.78it/s]Training:  94%|█████Training loss: 117.0308, Training accuracy: 0.9712
Macro F1-score: 0.9712
Model performance on Angry speech (in training): 
	Precision: 0.9653, Recall: 0.9750, F1_score: 0.9701
Model performance on Happy speech (in training): 
	Precision: 0.9695, Recall: 0.9525, F1_score: 0.9609
Model performance on Neutral speech (in training): 
	Precision: 0.9631, Recall: 0.9800, F1_score: 0.9715
Model performance on Sad speech (in training): 
	Precision: 0.9874, Recall: 0.9775, F1_score: 0.9824

Eval Phase: 
Validation loss: 74.8768, Validation accuracy: 0.8950
Macro F1-score: 0.8919
Model performance on Angry speech (in validation): 
	Precision: 0.9787, Recall: 0.9200, F1_score: 0.9485
Model performance on Happy speech (in validation): 
	Precision: 0.8421, Recall: 0.9600, F1_score: 0.8972
Model performance on Neutral speech (in validation): 
	Precision: 0.9459, Recall: 0.7000, F1_score: 0.8046
Model performance on Sad speech (in validation): 
	Precision: 0.8475, Recall: 1.0000, F1_score: 0.9174
Epoch 12/100

Training Phase:
Training loss: 126.1148, Training accuracy: 0.9725
Macro F1-score: 0.9725
Model performance on Angry speech (in training): 
	Precision: 0.9596, Recall: 0.9500, F1_score: 0.9548
Model performance on Happy speech (in training): 
	Precision: 0.9554, Recall: 0.9650, F1_score: 0.9602
Model performance on Neutral speech (in training): 
	Precision: 0.9849, Recall: 0.9775, F1_score: 0.9812
Model performance on Sad speech (in training): 
	Precision: 0.9901, Recall: 0.9975, F1_score: 0.9938

Eval Phase: 
Validation loss: 102.9977, Validation accuracy: 0.8700
Macro F1-score: 0.8675
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.8400, F1_score: 0.9130
Model performance on Happy speech (in validation): 
	Precision: 0.8276, Recall: 0.9600, F1_score: 0.8889
Model performance on Neutral speech (in validation): 
	Precision: 0.9444, Recall: 0.6800, F1_score: 0.7907
Model performance on Sad speech (in validation): 
	Precision: 0.7812, Recall: 1.0000, F1_score: 0.8772
Epoch 13/100

Training Phase:
███▍| 1500/1600 [01:00<00:04, 24.94it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 249/1600 [00:10<00:54, 24.78it/s]Training:  31%|███       | 497/1600 [00:20<00:44, 24.76it/s]Training:  47%|████▋     | 746/1600 [00:30<00:34, 24.79it/s]Training:  62%|██████▏   | 997/1600 [00:40<00:24, 24.89it/s]Training:  78%|███████▊  | 1248/1600 [00:50<00:14, 24.96it/s]Training:  78%|███████▊  | 1248/1600 [01:00<00:14, 24.96it/s]Training:  94%|█████████▎| 1499/1600 [01:00<00:04, 24.90it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█Training loss: 85.3774, Training accuracy: 0.9812
Macro F1-score: 0.9812
Model performance on Angry speech (in training): 
	Precision: 0.9678, Recall: 0.9775, F1_score: 0.9726
Model performance on Happy speech (in training): 
	Precision: 0.9747, Recall: 0.9650, F1_score: 0.9698
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9875, F1_score: 0.9900
Model performance on Sad speech (in training): 
	Precision: 0.9900, Recall: 0.9950, F1_score: 0.9925

Eval Phase: 
Validation loss: 116.6610, Validation accuracy: 0.8700
Macro F1-score: 0.8668
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.8600, F1_score: 0.9247
Model performance on Happy speech (in validation): 
	Precision: 0.8276, Recall: 0.9600, F1_score: 0.8889
Model performance on Neutral speech (in validation): 
	Precision: 0.9429, Recall: 0.6600, F1_score: 0.7765
Model performance on Sad speech (in validation): 
	Precision: 0.7812, Recall: 1.0000, F1_score: 0.8772
Validation loss does not decrease for 10 epochs. End training.
Model best accuracy on validation set: 0.9650

Test Phase: 
        | 252/1600 [00:10<00:53, 25.14it/s]Training:  32%|███▏      | 504/1600 [00:22<00:49, 22.05it/s]Training:  47%|████▋     | 747/1600 [00:32<00:37, 23.00it/s]Training:  62%|██████▏   | 990/1600 [00:42<00:26, 23.44it/s]Training:  77%|███████▋  | 1238/1600 [00:52<00:15, 23.90it/s]Training:  93%|█████████▎| 1486/1600 [01:02<00:04, 23.94it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]                                                Some weights of the model checkpoint at /work/tc062/tc062/zhan7721/saved_models/de were not used when initializing Wav2Vec2Model: ['encoder.layers.10.attention.k_proj.bias', 'encoder.layers.10.attention.k_proj.weight', 'encoder.layers.10.attention.out_proj.bias', 'encoder.layers.10.attention.out_proj.weight', 'encoder.layers.10.attention.q_proj.bias', 'encoder.layers.10.attention.q_proj.weight', 'encoder.layers.10.attention.v_proj.bias', 'encoder.layers.10.attention.v_proj.weight', 'encoder.layers.10.feed_forward.intermediate_dense.bias', 'encoder.layers.10.feed_forward.intermediate_dense.weight', 'encoder.layers.10.feed_forward.output_dense.bias', 'encoder.layers.10.feed_forward.output_dense.weight', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.10.layer_norm.bias', 'encoder.layers.10.layer_norm.weight', 'encoder.layers.11.attention.k_proj.bias', 'encoder.layers.11.attention.k_proj.weight', 'encoder.layers.11.attention.out_proj.bias', 'encoder.layers.11.attention.out_proj.weight', 'encoder.layers.11.attention.q_proj.bias', 'encoder.layers.11.attention.q_proj.weight', 'encoder.layers.11.attention.v_proj.bias', 'encoder.layers.11.attention.v_proj.weight', 'encoder.layers.11.feed_forward.intermediate_dense.bias', 'encoder.layers.11.feed_forward.intermediate_dense.weight', 'encoder.layers.11.feed_forward.output_dense.bias', 'encoder.layers.11.feed_forward.output_dense.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.11.layer_norm.bias', 'encoder.layers.11.layer_norm.weight', 'encoder.layers.7.attention.k_proj.bias', 'encoder.layers.7.attention.k_proj.weight', 'encoder.layers.7.attention.out_proj.bias', 'encoder.layers.7.attention.out_proj.weight', 'encoder.layers.7.attention.q_proj.bias', 'encoder.layers.7.attention.q_proj.weight', 'encoder.layers.7.attention.v_proj.bias', 'encoder.layers.7.attention.v_proj.weight', 'encoder.layers.7.feed_forward.intermediate_dense.bias', 'encoder.layers.7.feed_forward.intermediate_dense.weight', 'encoder.layers.7.feed_forward.output_dense.bias', 'encoder.layers.7.feed_forward.output_dense.weight', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.7.layer_norm.bias', 'encoder.layers.7.layer_norm.weight', 'encoder.layers.8.attention.k_proj.bias', 'encoder.layers.8.attention.k_proj.weight', 'encoder.layers.8.attention.out_proj.bias', 'encoder.layers.8.attention.out_proj.weight', 'encoder.layers.8.attention.q_proj.bias', 'encoder.layers.8.attention.q_proj.weight', 'encoder.layers.8.attention.v_proj.bias', 'encoder.layers.8.attention.v_proj.weight', 'encoder.layers.8.feed_forward.intermediate_dense.bias', 'encoder.layers.8.feed_forward.intermediate_dense.weight', 'encoder.layers.8.feed_forward.output_dense.bias', 'encoder.layers.8.feed_forward.output_dense.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.8.layer_norm.bias', 'encoder.layers.8.layer_norm.weight', 'encoder.layers.9.attention.k_proj.bias', 'encoder.layers.9.attention.k_proj.weight', 'encoder.layers.9.attention.out_proj.bias', 'encoder.layers.9.attention.out_proj.weight', 'encoder.layers.9.attention.q_proj.bias', 'encoder.layers.9.attention.q_proj.weight', 'encoder.layers.9.attention.v_proj.bias', 'encoder.layers.9.attention.v_proj.weight', 'encoder.layers.9.feed_forward.intermediate_dense.bias', 'encoder.layers.9.feed_forward.intermediate_dense.weight', 'encoder.layers.9.feed_forward.output_dense.bias', 'encoder.layers.9.feed_forward.output_dense.weight', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.layer_norm.bias', 'encoder.layers.9.layer_norm.weight']
- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Test loss: 24.8863, Test accuracy: 0.9500
Macro F1-score: 0.9504
Model performance on Angry speech (in test): 
	Precision: 1.0000, Recall: 0.9400, F1_score: 0.9691
Model performance on Happy speech (in test): 
	Precision: 0.8929, Recall: 1.0000, F1_score: 0.9434
Model performance on Neutral speech (in test): 
	Precision: 0.9216, Recall: 0.9400, F1_score: 0.9307
Model performance on Sad speech (in test): 
	Precision: 1.0000, Recall: 0.9200, F1_score: 0.9583

======================= This is fold_4 on cn =======================

Load dataset: 
Loading cn train data: fold_4...
Preprocess cn fold_4 data for cn model
Loading cn eval data: fold_4...
Preprocess cn fold_4 data for cn model
Loading cn test data: fold_4...
Preprocess cn fold_4 data for cn model
Use cn model to add lora
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training loss: 594.5463, Training accuracy: 0.8612
Macro F1-score: 0.8612
Model performance on Angry speech (in training): 
	Precision: 0.8136, Recall: 0.8075, F1_score: 0.8105
Model performance on Happy speech (in training): 
	Precision: 0.7990, Recall: 0.7950, F1_score: 0.7970
Model performance on Neutral speech (in training): 
	Precision: 0.8875, Recall: 0.9075, F1_score: 0.8974
Model performance on Sad speech (in training): 
	Precision: 0.9444, Recall: 0.9350, F1_score: 0.9397

Eval Phase: 
Validation loss: 45.9478, Validation accuracy: 0.9000
Macro F1-score: 0.9009
Model performance on Angry speech (in validation): 
	Precision: 0.9756, Recall: 0.8000, F1_score: 0.8791
Model performance on Happy speech (in validation): 
	Precision: 0.7619, Recall: 0.9600, F1_score: 0.8496
Model performance on Neutral speech (in validation): 
	Precision: 0.9130, Recall: 0.8400, F1_score: 0.8750
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
New best accuracy for layer 6 on epoch 1: 0.9000. Model saved.
Epoch 2/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 248/1600 [00:10<00:54, 24.72it/s]Training:  31%|███       | 499/1600 [00:20<00:44, 24.80it/s]Training:  47%|████▋     | 748/1600 [00:31<00:36, 23.28it/s]Training:  61%|██████    | 969/1600 [00:41<00:27, 22.79it/s]Training:  74%|███████▍  | 1189/1600 [00:54<00:20, 20.17it/s]Training:  87%|████████▋ | 1385/1600 [01:05<00:10, 19.97it/s]Training: 100%|█████████▉| 1598/1600 [01:15<00:00, 20.36it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 230/1600 [00:10<01:00, 22.82it/s]Training:  29%|██▉       | 463/1600 [00:20<00:49, 23.10it/s]Training:  44%|████▎     | 696/1600 [00:30<00:39, 23.01it/s]Training:  58%|█████▊ Training loss: 352.7016, Training accuracy: 0.9131
Macro F1-score: 0.9128
Model performance on Angry speech (in training): 
	Precision: 0.8741, Recall: 0.9025, F1_score: 0.8881
Model performance on Happy speech (in training): 
	Precision: 0.8819, Recall: 0.8400, F1_score: 0.8604
Model performance on Neutral speech (in training): 
	Precision: 0.9407, Recall: 0.9525, F1_score: 0.9466
Model performance on Sad speech (in training): 
	Precision: 0.9551, Recall: 0.9575, F1_score: 0.9563

Eval Phase: 
Validation loss: 57.3787, Validation accuracy: 0.8750
Macro F1-score: 0.8773
Model performance on Angry speech (in validation): 
	Precision: 0.8667, Recall: 0.7800, F1_score: 0.8211
Model performance on Happy speech (in validation): 
	Precision: 0.7213, Recall: 0.8800, F1_score: 0.7928
Model performance on Neutral speech (in validation): 
	Precision: 0.9556, Recall: 0.8600, F1_score: 0.9053
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Epoch 3/100

Training Phase:
Training loss: 268.4684, Training accuracy: 0.9350
Macro F1-score: 0.9349
Model performance on Angry speech (in training): 
	Precision: 0.9104, Recall: 0.9150, F1_score: 0.9127
Model performance on Happy speech (in training): 
	Precision: 0.9031, Recall: 0.8850, F1_score: 0.8939
Model performance on Neutral speech (in training): 
	Precision: 0.9559, Recall: 0.9750, F1_score: 0.9653
Model performance on Sad speech (in training): 
	Precision: 0.9698, Recall: 0.9650, F1_score: 0.9674

Eval Phase: 
   | 930/1600 [00:40<00:28, 23.16it/s]Training:  73%|███████▎  | 1166/1600 [00:50<00:18, 23.29it/s]Training:  88%|████████▊ | 1402/1600 [01:00<00:08, 23.36it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 256/1600 [00:10<00:52, 25.52it/s]Training:  32%|███▏      | 512/1600 [00:20<00:42, 25.38it/s]Training:  48%|████▊     | 767/1600 [00:30<00:32, 25.42it/s]Training:  64%|██████▍   | 1022/1600 [00:40<00:22, 25.33it/s]Training:  80%|███████▉  | 1276/1600 [00:50<00:12, 25.32it/s]Training:  96%|█████████▌| 1530/1600 [01:00<00:02, 25.33it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Validation loss: 82.5369, Validation accuracy: 0.8450
Macro F1-score: 0.8468
Model performance on Angry speech (in validation): 
	Precision: 0.9487, Recall: 0.7400, F1_score: 0.8315
Model performance on Happy speech (in validation): 
	Precision: 0.6329, Recall: 1.0000, F1_score: 0.7752
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.6400, F1_score: 0.7805
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 4/100

Training Phase:
Training loss: 205.4627, Training accuracy: 0.9487
Macro F1-score: 0.9487
Model performance on Angry speech (in training): 
	Precision: 0.9300, Recall: 0.9300, F1_score: 0.9300
Model performance on Happy speech (in training): 
	Precision: 0.9316, Recall: 0.9200, F1_score: 0.9258
Model performance on Neutral speech (in training): 
	Precision: 0.9628, Recall: 0.9700, F1_score: 0.9664
Model performance on Sad speech (in training): 
	Precision: 0.9701, Recall: 0.9750, F1_score: 0.9726

Eval Phase: 
Validation loss: 42.4060, Validation accuracy: 0.9250
Macro F1-score: 0.9235
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.7600, F1_score: 0.8636
Model performance on Happy speech (in validation): 
	Precision: 0.8448, Recall: 0.9800, F1_score: 0.9074
Model performance on Neutral speech (in validation): 
	Precision: 0.8889, Recall: 0.9600, F1_score: 0.9231
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
New best accuracy for layer 6 on epoch 4: 0.9250. Model saved.
Epoch 5/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 254/1600 [00:10<00:53, 25.34it/s]Training:  32%|███▏      | 512/1600 [00:20<00:42, 25.58it/s]Training:  48%|████▊     | 770/1600 [00:30<00:32, 25.40it/s]Training:  64%|██████▍   | 1022/1600 [00:40<00:22, 25.29it/s]Training:  80%|███████▉  | 1274/1600 [00:50<00:12, 25.19it/s]Training:  95%|█████████▌| 1525/1600 [01:00<00:02, 25.14it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 254/1600 [00:10<00:53, 25.35it/s]Training:  32%|███▏      | 508/1600 [00:20<00:43, 25.06it/s]Training:  47%|████▋     | 757/1600 [00:30<00:34, 24.51it/s]Training:  62%|██████▏   | 996/1600 [00:40<00:24, 24.23it/s]Training:  77%|█████Training loss: 158.7632, Training accuracy: 0.9631
Macro F1-score: 0.9631
Model performance on Angry speech (in training): 
	Precision: 0.9573, Recall: 0.9525, F1_score: 0.9549
Model performance on Happy speech (in training): 
	Precision: 0.9527, Recall: 0.9575, F1_score: 0.9551
Model performance on Neutral speech (in training): 
	Precision: 0.9700, Recall: 0.9700, F1_score: 0.9700
Model performance on Sad speech (in training): 
	Precision: 0.9725, Recall: 0.9725, F1_score: 0.9725

Eval Phase: 
Validation loss: 41.4867, Validation accuracy: 0.8850
Macro F1-score: 0.8824
Model performance on Angry speech (in validation): 
	Precision: 0.9429, Recall: 0.6600, F1_score: 0.7765
Model performance on Happy speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Neutral speech (in validation): 
	Precision: 0.9020, Recall: 0.9200, F1_score: 0.9109
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 6/100

Training Phase:
Training loss: 157.0847, Training accuracy: 0.9650
Macro F1-score: 0.9650
Model performance on Angry speech (in training): 
	Precision: 0.9504, Recall: 0.9575, F1_score: 0.9539
Model performance on Happy speech (in training): 
	Precision: 0.9470, Recall: 0.9375, F1_score: 0.9422
Model performance on Neutral speech (in training): 
	Precision: 0.9775, Recall: 0.9775, F1_score: 0.9775
Model performance on Sad speech (in training): 
	Precision: 0.9850, Recall: 0.9875, F1_score: 0.9863

Eval Phase: 
Validation loss: 66.6324, Validation accuracy: 0.8600
Macro F1-score: 0.8578
Model performance on Angry speech (in validation): 
	Precision: 0.9688, Recall: 0.6200, F1_score: 0.7561
Model performance on Happy speech (in validation): 
	Precision: 0.7000, Recall: 0.9800, F1_score: 0.8167
Model performance on Neutral speech (in validation): 
	Precision: 0.8776, Recall: 0.8600, F1_score: 0.8687
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Epoch 7/100

Training Phase:
█▋  | 1235/1600 [00:50<00:15, 24.08it/s]Training:  92%|█████████▏| 1475/1600 [01:00<00:05, 24.02it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 241/1600 [00:10<00:56, 24.03it/s]Training:  30%|███       | 482/1600 [00:20<00:46, 23.89it/s]Training:  45%|████▌     | 723/1600 [00:30<00:36, 23.96it/s]Training:  60%|██████    | 964/1600 [00:40<00:26, 23.69it/s]Training:  75%|███████▌  | 1204/1600 [00:50<00:16, 23.77it/s]Training:  90%|█████████ | 1444/1600 [01:00<00:06, 23.80it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍   Training loss: 120.8197, Training accuracy: 0.9731
Macro F1-score: 0.9731
Model performance on Angry speech (in training): 
	Precision: 0.9583, Recall: 0.9775, F1_score: 0.9678
Model performance on Happy speech (in training): 
	Precision: 0.9744, Recall: 0.9525, F1_score: 0.9633
Model performance on Neutral speech (in training): 
	Precision: 0.9775, Recall: 0.9775, F1_score: 0.9775
Model performance on Sad speech (in training): 
	Precision: 0.9825, Recall: 0.9850, F1_score: 0.9838

Eval Phase: 
Validation loss: 55.2214, Validation accuracy: 0.8750
Macro F1-score: 0.8767
Model performance on Angry speech (in validation): 
	Precision: 0.8478, Recall: 0.7800, F1_score: 0.8125
Model performance on Happy speech (in validation): 
	Precision: 0.7458, Recall: 0.8800, F1_score: 0.8073
Model performance on Neutral speech (in validation): 
	Precision: 0.9362, Recall: 0.8800, F1_score: 0.9072
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Epoch 8/100

Training Phase:
     | 239/1600 [00:10<00:57, 23.86it/s]Training:  31%|███       | 494/1600 [00:20<00:44, 24.79it/s]Training:  47%|████▋     | 750/1600 [00:30<00:33, 25.14it/s]Training:  63%|██████▎   | 1006/1600 [00:40<00:23, 25.02it/s]Training:  63%|██████▎   | 1006/1600 [00:50<00:23, 25.02it/s]Training:  78%|███████▊  | 1242/1600 [00:50<00:14, 24.48it/s]Training:  92%|█████████▏| 1479/1600 [01:00<00:05, 24.17it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 238/1600 [00:10<00:57, 23.78it/s]Training:  30%|██▉       | 476/1600 [00:20<00:47, 23.66it/s]Training:  45%|████▍     | 716/1600 [00:30<00:37, 23.79it/s]Training:  60%|█████▉    | 956/1600 [00:40<00:26, 23.87it/s]Training:  75%|███████Training loss: 140.3758, Training accuracy: 0.9675
Macro F1-score: 0.9675
Model performance on Angry speech (in training): 
	Precision: 0.9672, Recall: 0.9575, F1_score: 0.9623
Model performance on Happy speech (in training): 
	Precision: 0.9497, Recall: 0.9450, F1_score: 0.9474
Model performance on Neutral speech (in training): 
	Precision: 0.9752, Recall: 0.9850, F1_score: 0.9801
Model performance on Sad speech (in training): 
	Precision: 0.9776, Recall: 0.9825, F1_score: 0.9800

Eval Phase: 
Validation loss: 46.0598, Validation accuracy: 0.9100
Macro F1-score: 0.9096
Model performance on Angry speech (in validation): 
	Precision: 0.9750, Recall: 0.7800, F1_score: 0.8667
Model performance on Happy speech (in validation): 
	Precision: 0.8065, Recall: 1.0000, F1_score: 0.8929
Model performance on Neutral speech (in validation): 
	Precision: 0.8980, Recall: 0.8800, F1_score: 0.8889
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Epoch 9/100

Training Phase:
Training loss: 110.8451, Training accuracy: 0.9725
Macro F1-score: 0.9725
Model performance on Angry speech (in training): 
	Precision: 0.9553, Recall: 0.9625, F1_score: 0.9589
Model performance on Happy speech (in training): 
	Precision: 0.9620, Recall: 0.9500, F1_score: 0.9560
Model performance on Neutral speech (in training): 
	Precision: 0.9826, Recall: 0.9900, F1_score: 0.9863
Model performance on Sad speech (in training): 
	Precision: 0.9900, Recall: 0.9875, F1_score: 0.9887

Eval Phase: 
Validation loss: 44.4317, Validation accuracy: 0.9250
Macro F1-score: 0.9249
Model performance on Angry speech (in validation): 
	Precision: 0.8936, Recall: 0.8400, F1_score: 0.8660
Model performance on Happy speech (in validation): 
	Precision: 0.9388, Recall: 0.9200, F1_score: 0.9293
Model performance on Neutral speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Epoch 10/100

Training Phase:
  | 1198/1600 [00:50<00:16, 23.96it/s]Training:  90%|█████████ | 1441/1600 [01:00<00:06, 24.06it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 238/1600 [00:10<00:57, 23.76it/s]Training:  30%|███       | 482/1600 [00:20<00:46, 24.09it/s]Training:  45%|████▌     | 726/1600 [00:30<00:36, 24.09it/s]Training:  60%|██████    | 967/1600 [00:40<00:26, 24.00it/s]Training:  76%|███████▌  | 1208/1600 [00:50<00:16, 24.00it/s]Training:  91%|█████████ | 1449/1600 [01:00<00:06, 24.02it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 2Training loss: 109.5943, Training accuracy: 0.9756
Macro F1-score: 0.9756
Model performance on Angry speech (in training): 
	Precision: 0.9701, Recall: 0.9725, F1_score: 0.9713
Model performance on Happy speech (in training): 
	Precision: 0.9750, Recall: 0.9750, F1_score: 0.9750
Model performance on Neutral speech (in training): 
	Precision: 0.9774, Recall: 0.9750, F1_score: 0.9762
Model performance on Sad speech (in training): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800

Eval Phase: 
Validation loss: 65.5518, Validation accuracy: 0.8850
Macro F1-score: 0.8830
Model performance on Angry speech (in validation): 
	Precision: 0.9722, Recall: 0.7000, F1_score: 0.8140
Model performance on Happy speech (in validation): 
	Precision: 0.7692, Recall: 1.0000, F1_score: 0.8696
Model performance on Neutral speech (in validation): 
	Precision: 0.8571, Recall: 0.8400, F1_score: 0.8485
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 11/100

Training Phase:
42/1600 [00:10<00:56, 24.13it/s]Training:  30%|███       | 484/1600 [00:20<00:46, 23.86it/s]Training:  45%|████▌     | 724/1600 [00:30<00:36, 23.88it/s]Training:  60%|██████    | 964/1600 [00:40<00:26, 23.92it/s]Training:  75%|███████▌  | 1204/1600 [00:50<00:16, 23.84it/s]Training:  90%|█████████ | 1441/1600 [01:00<00:06, 23.79it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 243/1600 [00:10<00:55, 24.30it/s]Training:  30%|███       | 486/1600 [00:20<00:46, 23.98it/s]Training:  45%|████▌     | 726/1600 [00:30<00:36, 23.95it/s]Training:  60%|██████    | 966/1600 [00:40<00:26, 23.88it/s]Training:  75%|███████▌  | 1206/1600 [00:50<00:16, 23.91it/s]Training:  90%|█████████ | 1447Training loss: 81.4901, Training accuracy: 0.9825
Macro F1-score: 0.9825
Model performance on Angry speech (in training): 
	Precision: 0.9873, Recall: 0.9700, F1_score: 0.9786
Model performance on Happy speech (in training): 
	Precision: 0.9655, Recall: 0.9800, F1_score: 0.9727
Model performance on Neutral speech (in training): 
	Precision: 0.9875, Recall: 0.9875, F1_score: 0.9875
Model performance on Sad speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913

Eval Phase: 
Validation loss: 40.8689, Validation accuracy: 0.9200
Macro F1-score: 0.9209
Model performance on Angry speech (in validation): 
	Precision: 0.9000, Recall: 0.9000, F1_score: 0.9000
Model performance on Happy speech (in validation): 
	Precision: 0.9574, Recall: 0.9000, F1_score: 0.9278
Model performance on Neutral speech (in validation): 
	Precision: 0.8393, Recall: 0.9400, F1_score: 0.8868
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9400, F1_score: 0.9691
Epoch 12/100

Training Phase:
Training loss: 97.5324, Training accuracy: 0.9794
Macro F1-score: 0.9794
Model performance on Angry speech (in training): 
	Precision: 0.9722, Recall: 0.9600, F1_score: 0.9660
Model performance on Happy speech (in training): 
	Precision: 0.9629, Recall: 0.9725, F1_score: 0.9677
Model performance on Neutral speech (in training): 
	Precision: 0.9876, Recall: 0.9950, F1_score: 0.9913
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9900, F1_score: 0.9925

Eval Phase: 
Validation loss: 56.0185, Validation accuracy: 0.8850
Macro F1-score: 0.8844
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 0.7895, Recall: 0.9000, F1_score: 0.8411
Model performance on Neutral speech (in validation): 
	Precision: 0.9184, Recall: 0.9000, F1_score: 0.9091
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 13/100

Training Phase:
/1600 [01:00<00:06, 23.94it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 239/1600 [00:10<00:57, 23.86it/s]Training:  30%|██▉       | 478/1600 [00:20<00:47, 23.75it/s]Training:  45%|████▌     | 720/1600 [00:30<00:36, 23.93it/s]Training:  60%|██████    | 962/1600 [00:40<00:26, 23.73it/s]Training:  75%|███████▍  | 1199/1600 [00:50<00:16, 23.68it/s]Training:  90%|████████▉ | 1439/1600 [01:00<00:06, 23.78it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 239/1600 [00:10<00:57, 23.83it/s]Training:  30%|██▉       | 478/1600 [00:20<00:47, Training loss: 86.6435, Training accuracy: 0.9825
Macro F1-score: 0.9825
Model performance on Angry speech (in training): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in training): 
	Precision: 0.9849, Recall: 0.9775, F1_score: 0.9812
Model performance on Neutral speech (in training): 
	Precision: 0.9776, Recall: 0.9825, F1_score: 0.9800
Model performance on Sad speech (in training): 
	Precision: 0.9875, Recall: 0.9900, F1_score: 0.9888

Eval Phase: 
Validation loss: 48.4299, Validation accuracy: 0.9100
Macro F1-score: 0.9108
Model performance on Angry speech (in validation): 
	Precision: 0.9200, Recall: 0.9200, F1_score: 0.9200
Model performance on Happy speech (in validation): 
	Precision: 0.8393, Recall: 0.9400, F1_score: 0.8868
Model performance on Neutral speech (in validation): 
	Precision: 0.8980, Recall: 0.8800, F1_score: 0.8889
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9000, F1_score: 0.9474
Epoch 14/100

Training Phase:
23.75it/s]Training:  45%|████▍     | 717/1600 [00:30<00:37, 23.82it/s]Training:  60%|█████▉    | 956/1600 [00:40<00:27, 23.83it/s]Training:  75%|███████▍  | 1195/1600 [00:50<00:17, 23.75it/s]Training:  90%|████████▉ | 1436/1600 [01:00<00:06, 23.85it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 239/1600 [00:10<00:57, 23.88it/s]Training:  30%|██▉       | 479/1600 [00:20<00:46, 23.92it/s]Training:  45%|████▍     | 719/1600 [00:30<00:36, 23.96it/s]Training:  60%|█████▉    | 959/1600 [00:40<00:26, 23.89it/s]Training:  75%|███████▍  | 1199/1600 [00:50<00:16, 23.91it/s]Training:  90%|████████▉ | 1439/1600 [01:00<00:06, 23.83it/s]                                                          Training loss: 79.2740, Training accuracy: 0.9831
Macro F1-score: 0.9831
Model performance on Angry speech (in training): 
	Precision: 0.9728, Recall: 0.9825, F1_score: 0.9776
Model performance on Happy speech (in training): 
	Precision: 0.9849, Recall: 0.9775, F1_score: 0.9812
Model performance on Neutral speech (in training): 
	Precision: 0.9851, Recall: 0.9900, F1_score: 0.9875
Model performance on Sad speech (in training): 
	Precision: 0.9899, Recall: 0.9825, F1_score: 0.9862

Eval Phase: 
Validation loss: 47.1326, Validation accuracy: 0.9350
Macro F1-score: 0.9349
Model performance on Angry speech (in validation): 
	Precision: 0.9362, Recall: 0.8800, F1_score: 0.9072
Model performance on Happy speech (in validation): 
	Precision: 0.9074, Recall: 0.9800, F1_score: 0.9423
Model performance on Neutral speech (in validation): 
	Precision: 0.9000, Recall: 0.9000, F1_score: 0.9000
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
New best accuracy for layer 6 on epoch 14: 0.9350. Model saved.
Epoch 15/100

Training Phase:
Training loss: 61.9470, Training accuracy: 0.9862
Macro F1-score: 0.9863
Model performance on Angry speech (in training): 
	Precision: 0.9825, Recall: 0.9800, F1_score: 0.9812
Model performance on Happy speech (in training): 
	Precision: 0.9800, Recall: 0.9825, F1_score: 0.9813
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9900, F1_score: 0.9925
Model performance on Sad speech (in training): 
	Precision: 0.9876, Recall: 0.9925, F1_score: 0.9900

Eval Phase: 
Validation loss: 105.6636, Validation accuracy: 0.8800
Macro F1-score: 0.8759
Model performance on Angry speech (in validation): 
	Precision: 0.7424, Recall: 0.9800, F1_score: 0.8448
Model performance on Happy speech (in validation): 
	Precision: 0.8679, Recall: 0.9200, F1_score: 0.8932
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.6200, F1_score: 0.7654
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 16/100

Training Phase:
   Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 238/1600 [00:10<00:57, 23.73it/s]Training:  30%|██▉       | 476/1600 [00:20<00:47, 23.65it/s]Training:  45%|████▍     | 716/1600 [00:30<00:37, 23.80it/s]Training:  60%|█████▉    | 957/1600 [00:40<00:26, 23.91it/s]Training:  75%|███████▍  | 1198/1600 [00:50<00:16, 23.76it/s]Training:  90%|████████▉ | 1439/1600 [01:00<00:06, 23.86it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 238/1600 [00:10<00:57, 23.70it/s]Training:  30%|██▉       | 476/1600 [00:20<00:47, 23.73it/s]Training:  45%|████▍     | 714/1600 [00:32<00:41, 21.48it/s]TraininTraining loss: 75.9101, Training accuracy: 0.9825
Macro F1-score: 0.9825
Model performance on Angry speech (in training): 
	Precision: 0.9801, Recall: 0.9850, F1_score: 0.9825
Model performance on Happy speech (in training): 
	Precision: 0.9824, Recall: 0.9750, F1_score: 0.9787
Model performance on Neutral speech (in training): 
	Precision: 0.9850, Recall: 0.9825, F1_score: 0.9837
Model performance on Sad speech (in training): 
	Precision: 0.9826, Recall: 0.9875, F1_score: 0.9850

Eval Phase: 
Validation loss: 106.7473, Validation accuracy: 0.8900
Macro F1-score: 0.8902
Model performance on Angry speech (in validation): 
	Precision: 0.7692, Recall: 1.0000, F1_score: 0.8696
Model performance on Happy speech (in validation): 
	Precision: 0.8511, Recall: 0.8000, F1_score: 0.8247
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.7800, F1_score: 0.8764
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Epoch 17/100

Training Phase:
Training loss: 75.2469, Training accuracy: 0.9869
Macro F1-score: 0.9869
Model performance on Angry speech (in training): 
	Precision: 0.9875, Recall: 0.9850, F1_score: 0.9862
Model performance on Happy speech (in training): 
	Precision: 0.9825, Recall: 0.9800, F1_score: 0.9812
Model performance on Neutral speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900
Model performance on Sad speech (in training): 
	Precision: 0.9876, Recall: 0.9925, F1_score: 0.9900

Eval Phase: 
g:  60%|█████▉    | 954/1600 [00:42<00:28, 22.40it/s]Training:  75%|███████▍  | 1194/1600 [00:52<00:17, 22.94it/s]Training:  90%|████████▉ | 1435/1600 [01:02<00:07, 23.31it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 239/1600 [00:10<00:56, 23.89it/s]Training:  30%|██▉       | 478/1600 [00:20<00:47, 23.75it/s]Training:  45%|████▍     | 718/1600 [00:30<00:36, 23.85it/s]Training:  60%|█████▉    | 958/1600 [00:40<00:26, 23.81it/s]Training:  75%|███████▍  | 1199/1600 [00:50<00:16, 23.91it/s]Training:  90%|█████████ | 1440/1600 [01:00<00:06, 23.94it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                Validation loss: 60.9671, Validation accuracy: 0.9250
Macro F1-score: 0.9256
Model performance on Angry speech (in validation): 
	Precision: 0.8654, Recall: 0.9000, F1_score: 0.8824
Model performance on Happy speech (in validation): 
	Precision: 0.8545, Recall: 0.9400, F1_score: 0.8952
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.8600, F1_score: 0.9247
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 18/100

Training Phase:
Training loss: 64.5788, Training accuracy: 0.9850
Macro F1-score: 0.9850
Model performance on Angry speech (in training): 
	Precision: 0.9727, Recall: 0.9800, F1_score: 0.9763
Model performance on Happy speech (in training): 
	Precision: 0.9798, Recall: 0.9725, F1_score: 0.9762
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925

Eval Phase: 
Validation loss: 108.3519, Validation accuracy: 0.8700
Macro F1-score: 0.8635
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.5800, F1_score: 0.7342
Model performance on Happy speech (in validation): 
	Precision: 0.8197, Recall: 1.0000, F1_score: 0.9009
Model performance on Neutral speech (in validation): 
	Precision: 0.7541, Recall: 0.9200, F1_score: 0.8288
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Epoch 19/100

Training Phase:
                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 242/1600 [00:10<00:56, 24.15it/s]Training:  30%|███       | 484/1600 [00:20<00:46, 23.76it/s]Training:  45%|████▌     | 724/1600 [00:30<00:36, 23.82it/s]Training:  60%|██████    | 964/1600 [00:40<00:26, 23.79it/s]Training:  75%|███████▌  | 1202/1600 [00:50<00:16, 23.77it/s]Training:  90%|█████████ | 1443/1600 [01:00<00:06, 23.88it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 240/1600 [00:10<00:56, 23.92it/s]Training:  30%|███       | 480/1600 [00:20<00:47, 23.76it/s]Training:  45%|████▍     | 717/1600 [00:30<00:37, 23.72it/s]Training:  60%|█████▉    | 955/1600 [00:40<00:27, 23.74it/s]Training:  75%|██Training loss: 52.3035, Training accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in training): 
	Precision: 0.9875, Recall: 0.9900, F1_score: 0.9888
Model performance on Happy speech (in training): 
	Precision: 0.9849, Recall: 0.9800, F1_score: 0.9825
Model performance on Neutral speech (in training): 
	Precision: 0.9901, Recall: 0.9975, F1_score: 0.9938
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9925, F1_score: 0.9950

Eval Phase: 
Validation loss: 77.9847, Validation accuracy: 0.8950
Macro F1-score: 0.8952
Model performance on Angry speech (in validation): 
	Precision: 0.8036, Recall: 0.9000, F1_score: 0.8491
Model performance on Happy speech (in validation): 
	Precision: 0.9524, Recall: 0.8000, F1_score: 0.8696
Model performance on Neutral speech (in validation): 
	Precision: 0.8654, Recall: 0.9000, F1_score: 0.8824
Model performance on Sad speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Epoch 20/100

Training Phase:
Training loss: 69.8927, Training accuracy: 0.9850
Macro F1-score: 0.9850
Model performance on Angry speech (in training): 
	Precision: 0.9875, Recall: 0.9850, F1_score: 0.9862
Model performance on Happy speech (in training): 
	Precision: 0.9750, Recall: 0.9750, F1_score: 0.9750
Model performance on Neutral speech (in training): 
	Precision: 0.9850, Recall: 0.9850, F1_score: 0.9850
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938

Eval Phase: 
Validation loss: 50.2504, Validation accuracy: 0.9250
Macro F1-score: 0.9252
Model performance on Angry speech (in validation): 
	Precision: 0.8846, Recall: 0.9200, F1_score: 0.9020
Model performance on Happy speech (in validation): 
	Precision: 0.9200, Recall: 0.9200, F1_score: 0.9200
Model performance on Neutral speech (in validation): 
	Precision: 0.8980, Recall: 0.8800, F1_score: 0.8889
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Epoch 21/100

Training Phase:
████▍  | 1193/1600 [00:50<00:17, 23.73it/s]Training:  90%|████████▉ | 1432/1600 [01:00<00:07, 23.77it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 240/1600 [00:10<00:56, 23.96it/s]Training:  30%|███       | 481/1600 [00:20<00:46, 24.03it/s]Training:  45%|████▌     | 722/1600 [00:30<00:36, 23.90it/s]Training:  60%|██████    | 961/1600 [00:40<00:26, 23.90it/s]Training:  75%|███████▌  | 1202/1600 [00:50<00:16, 23.94it/s]Training:  90%|█████████ | 1443/1600 [01:00<00:06, 23.90it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|Training loss: 50.3124, Training accuracy: 0.9875
Macro F1-score: 0.9875
Model performance on Angry speech (in training): 
	Precision: 0.9778, Recall: 0.9900, F1_score: 0.9839
Model performance on Happy speech (in training): 
	Precision: 0.9873, Recall: 0.9750, F1_score: 0.9811
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925

Eval Phase: 
Validation loss: 62.6714, Validation accuracy: 0.8900
Macro F1-score: 0.8910
Model performance on Angry speech (in validation): 
	Precision: 0.8936, Recall: 0.8400, F1_score: 0.8660
Model performance on Happy speech (in validation): 
	Precision: 0.7869, Recall: 0.9600, F1_score: 0.8649
Model performance on Neutral speech (in validation): 
	Precision: 0.9130, Recall: 0.8400, F1_score: 0.8750
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9200, F1_score: 0.9583
Validation loss does not decrease for 10 epochs. End training.
Model best accuracy on validation set: 0.9350

Test Phase: 
Test loss: 54.0302, Test accuracy: 0.9100
Macro F1-score: 0.9082
Model performance on Angry speech (in test): 
	Precision: 0.9268, Recall: 0.7600, F1_score: 0.8352
Model performance on Happy speech (in test): 
	Precision: 0.8333, Recall: 0.9000, F1_score: 0.8654
Model performance on Neutral speech (in test): 
	Precision: 0.9091, Recall: 1.0000, F1_score: 0.9524
Model performance on Sad speech (in test): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800

cn, all folds accuracy: ['0.8800', '0.8250', '0.7850', '0.9500', '0.9100']
cn, all folds emo precision: {'Angry': ['0.7759', '1.0000', '0.6622', '1.0000', '0.9268'], 'Happy': ['0.7708', '0.8205', '0.9259', '0.8929', '0.8333'], 'Neutral': ['1.0000', '0.6849', '0.8163', '0.9216', '0.9091'], 'Sad': ['1.0000', '0.8936', '0.8600', '1.0000', '0.9800']}
cn, all folds emo recall: {'Angry': ['0.9000', '0.8200', '0.9800', '0.9400', '0.7600'], 'Happy': ['0.7400', '0.6400', '0.5000', '1.0000', '0.9000'], 'Neutral': ['0.9600', '1.0000', '0.8000', '0.9400', '1.0000'], 'Sad': ['0.9200', '0.8400', '0.8600', '0.9200', '0.9800']}
cn, all folds emo f1score: {'Angry': ['0.8333', '0.9011', '0.7903', '0.9691', '0.8352'], 'Happy': ['0.7551', '0.7191', '0.6494', '0.9434', '0.8654'], 'Neutral': ['0.9796', '0.8130', '0.8081', '0.9307', '0.9524'], 'Sad': ['0.9583', '0.8660', '0.8600', '0.9583', '0.9800']}
▌        | 241/1600 [00:10<00:56, 24.05it/s]Training:  30%|███       | 484/1600 [00:20<00:46, 24.17it/s]Training:  45%|████▌     | 727/1600 [00:30<00:36, 24.13it/s]Training:  60%|██████    | 968/1600 [00:40<00:26, 23.97it/s]Training:  76%|███████▌  | 1208/1600 [00:50<00:16, 23.96it/s]Training:  90%|█████████ | 1448/1600 [01:00<00:06, 23.90it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]                                                ------------------NEXT SCRIPT: RUNNER_EN----------------------
/work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Matplotlib created a temporary cache directory at /dev/shm/zhan7721_5912051/matplotlib-g3wxrf_8 because the default path (/home/tc062/tc062/zhan7721/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.

======================= This is fold_0 on en =======================

Load dataset: 
Loading en train data: fold_0...
Preprocess en fold_0 data for en model
Loading en eval data: fold_0...
Preprocess en fold_0 data for en model
Loading en test data: fold_0...
Preprocess en fold_0 data for en model
Use en model to add lora
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:   0%|          | 1/1600 [00:36<16:21:49, 36.84s/it]Training:   8%|▊         | 132/1600 [00:46<06:39,  3.68it/s] Training:  17%|█▋        | 276/1600 [00:56<03:16,  6.73it/s]Training:  28%|██▊       | 442/1600 [01:06<02:00,  9.57it/s]Training:  39%|███▊      | 617/1600 [01:16<01:22, 11.89it/s]Training:  50%|████▉     | 792/1600 [01:27<01:00, 13.46it/s]Training:  60%|██████    | 964/1600 [01:37<00:43, 14.49it/s]Training:  71%|███████   | 1136/1600 [01:47<00:30, 15.27it/s]Training:  82%|████████▏ | 1319/1600 [01:57<00:17, 16.16it/s]Training:  94%|█████████▍| 1505/1600 [02:07<00:05, 16.87it/s]                                                             /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Training loss: 2037.7639, Training accuracy: 0.3881
Macro F1-score: 0.2918
Model performance on Angry speech (in training): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Happy speech (in training): 
	Precision: 0.3072, Recall: 0.7925, F1_score: 0.4427
Model performance on Neutral speech (in training): 
	Precision: 0.4483, Recall: 0.0650, F1_score: 0.1135
Model performance on Sad speech (in training): 
	Precision: 0.5451, Recall: 0.6950, F1_score: 0.6110

Eval Phase: 
Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 229.0400, Validation accuracy: 0.5000
Macro F1-score: 0.4379
Model performance on Angry speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Happy speech (in validation): 
	Precision: 0.3500, Recall: 0.5600, F1_score: 0.4308
Model performance on Neutral speech (in validation): 
	Precision: 0.4848, Recall: 0.6400, F1_score: 0.5517
Model performance on Sad speech (in validation): 
	Precision: 0.7407, Recall: 0.8000, F1_score: 0.7692
New best accuracy for layer 8 on epoch 1: 0.5000. Model saved.
Epoch 2/100

Training Phase:
Training loss: 1842.5779, Training accuracy: 0.4731
Macro F1-score: 0.4554
Model performance on Angry speech (in training): 
	Precision: 0.5291, Recall: 0.2275, F1_score: 0.3182
Model performance on Happy speech (in training): 
	Precision: 0.3528, Recall: 0.4825, F1_score: 0.4076
Model performance on Neutral speech (in training): 
	Precision: 0.4413, Recall: 0.3850, F1_score: 0.4112
Model performance on Sad speech (in training): 
	Precision: 0.5996, Recall: 0.7975, F1_score: 0.6845

Eval Phase: 
Validation loss: 210.9695, Validation accuracy: 0.5700
Macro F1-score: 0.5448
Model performance on Angry speech (in validation): 
	Precision: 0.7949, Recall: 0.6200, F1_score: 0.6966
Model performance on Happy speech (in validation): 
	Precision: 0.7500, Recall: 0.1200, F1_score: 0.2069
Model performance on Neutral speech (in validation): 
	Precision: 0.3774, Recall: 0.8000, F1_score: 0.5128
Model performance on Sad speech (in validation): 
	Precision: 0.7872, Recall: 0.7400, F1_score: 0.7629
New best accuracy for layer 8 on epoch 2: 0.5700. Model saved.
Epoch 3/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 197/1600 [00:10<01:12, 19.36it/s]Training:  24%|██▍       | 391/1600 [00:20<01:02, 19.23it/s]Training:  36%|███▋      | 583/1600 [00:30<00:53, 19.06it/s]Training:  49%|████▉     | 782/1600 [00:40<00:42, 19.34it/s]Training:  61%|██████▏   | 980/1600 [00:50<00:32, 19.31it/s]Training:  73%|███████▎  | 1174/1600 [01:00<00:22, 19.34it/s]Training:  86%|████████▌ | 1369/1600 [01:10<00:11, 19.37it/s]Training:  98%|█████████▊| 1564/1600 [01:21<00:01, 19.33it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 202/1600 [00:10<01:09, 20.19it/s]Training:  25%|██▌       | 404/1600 [00:20<01:01, 19.49it/s]Training:  37%|███▋      |Training loss: 1685.6706, Training accuracy: 0.5381
Macro F1-score: 0.5075
Model performance on Angry speech (in training): 
	Precision: 0.5553, Recall: 0.6900, F1_score: 0.6154
Model performance on Happy speech (in training): 
	Precision: 0.4583, Recall: 0.1650, F1_score: 0.2426
Model performance on Neutral speech (in training): 
	Precision: 0.4562, Recall: 0.5075, F1_score: 0.4805
Model performance on Sad speech (in training): 
	Precision: 0.6148, Recall: 0.7900, F1_score: 0.6915

Eval Phase: 
Validation loss: 194.8943, Validation accuracy: 0.5950
Macro F1-score: 0.5633
Model performance on Angry speech (in validation): 
	Precision: 0.8158, Recall: 0.6200, F1_score: 0.7045
Model performance on Happy speech (in validation): 
	Precision: 0.5455, Recall: 0.1200, F1_score: 0.1967
Model performance on Neutral speech (in validation): 
	Precision: 0.4200, Recall: 0.8400, F1_score: 0.5600
Model performance on Sad speech (in validation): 
	Precision: 0.7843, Recall: 0.8000, F1_score: 0.7921
New best accuracy for layer 8 on epoch 3: 0.5950. Model saved.
Epoch 4/100

Training Phase:
 595/1600 [00:30<00:52, 19.29it/s]Training:  49%|████▉     | 789/1600 [00:40<00:41, 19.33it/s]Training:  61%|██████▏   | 983/1600 [00:50<00:32, 19.18it/s]Training:  74%|███████▍  | 1181/1600 [01:01<00:21, 19.32it/s]Training:  86%|████████▌ | 1378/1600 [01:11<00:11, 19.26it/s]Training:  98%|█████████▊| 1573/1600 [01:21<00:01, 19.33it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 196/1600 [00:10<01:11, 19.54it/s]Training:  24%|██▍       | 392/1600 [00:20<01:03, 19.15it/s]Training:  37%|███▋      | 590/1600 [00:30<00:52, 19.42it/s]Training:  49%|████▉     | 788/1600 [00:40<00:41, 19.42it/s]Training:  62%|██████▏   | 985/1600 [00:50<00:31, 19.51it/s]Training:  62%|██████▏ Training loss: 1574.2281, Training accuracy: 0.5831
Macro F1-score: 0.5719
Model performance on Angry speech (in training): 
	Precision: 0.6316, Recall: 0.6600, F1_score: 0.6455
Model performance on Happy speech (in training): 
	Precision: 0.5315, Recall: 0.3375, F1_score: 0.4128
Model performance on Neutral speech (in training): 
	Precision: 0.5081, Recall: 0.5475, F1_score: 0.5271
Model performance on Sad speech (in training): 
	Precision: 0.6338, Recall: 0.7875, F1_score: 0.7023

Eval Phase: 
Validation loss: 196.6812, Validation accuracy: 0.5700
Macro F1-score: 0.5620
Model performance on Angry speech (in validation): 
	Precision: 0.9600, Recall: 0.4800, F1_score: 0.6400
Model performance on Happy speech (in validation): 
	Precision: 0.4419, Recall: 0.3800, F1_score: 0.4086
Model performance on Neutral speech (in validation): 
	Precision: 0.5814, Recall: 0.5000, F1_score: 0.5376
Model performance on Sad speech (in validation): 
	Precision: 0.5169, Recall: 0.9200, F1_score: 0.6619
Epoch 5/100

Training Phase:
  | 985/1600 [01:00<00:31, 19.51it/s]Training:  74%|███████▎  | 1176/1600 [01:00<00:21, 19.29it/s]Training:  86%|████████▌ | 1370/1600 [01:10<00:11, 19.26it/s]Training:  98%|█████████▊| 1563/1600 [01:20<00:01, 19.25it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 194/1600 [00:10<01:12, 19.32it/s]Training:  24%|██▍       | 388/1600 [00:20<01:05, 18.54it/s]Training:  36%|███▋      | 580/1600 [00:30<00:54, 18.82it/s]Training:  48%|████▊     | 774/1600 [00:40<00:43, 19.02it/s]Training:  61%|██████    | 970/1600 [00:50<00:32, 19.22it/s]Training:  73%|███████▎  | 1172/1600 [01:00<00:21, 19.55it/s]Training:  86%|████████▌ | 1374/1600 [01:11<00:11, 19.56it/s]Training:  98%|███Training loss: 1488.0350, Training accuracy: 0.6194
Macro F1-score: 0.6106
Model performance on Angry speech (in training): 
	Precision: 0.6826, Recall: 0.6775, F1_score: 0.6801
Model performance on Happy speech (in training): 
	Precision: 0.5891, Recall: 0.3800, F1_score: 0.4620
Model performance on Neutral speech (in training): 
	Precision: 0.5280, Recall: 0.6125, F1_score: 0.5671
Model performance on Sad speech (in training): 
	Precision: 0.6715, Recall: 0.8075, F1_score: 0.7333

Eval Phase: 
Validation loss: 168.0108, Validation accuracy: 0.6650
Macro F1-score: 0.6463
Model performance on Angry speech (in validation): 
	Precision: 0.6774, Recall: 0.8400, F1_score: 0.7500
Model performance on Happy speech (in validation): 
	Precision: 0.7143, Recall: 0.4000, F1_score: 0.5128
Model performance on Neutral speech (in validation): 
	Precision: 0.6250, Recall: 0.5000, F1_score: 0.5556
Model performance on Sad speech (in validation): 
	Precision: 0.6571, Recall: 0.9200, F1_score: 0.7667
New best accuracy for layer 8 on epoch 5: 0.6650. Model saved.
Epoch 6/100

Training Phase:
Training loss: 1430.4115, Training accuracy: 0.6288
Macro F1-score: 0.6203
Model performance on Angry speech (in training): 
	Precision: 0.6925, Recall: 0.6925, F1_score: 0.6925
Model performance on Happy speech (in training): 
	Precision: 0.5992, Recall: 0.3850, F1_score: 0.4688
Model performance on Neutral speech (in training): 
	Precision: 0.5433, Recall: 0.6425, F1_score: 0.5888
Model performance on Sad speech (in training): 
	Precision: 0.6766, Recall: 0.7950, F1_score: 0.7310

Eval Phase: 
██████▊| 1571/1600 [01:21<00:01, 19.58it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 192/1600 [00:10<01:13, 19.19it/s]Training:  24%|██▍       | 384/1600 [00:20<01:03, 19.02it/s]Training:  36%|███▌      | 574/1600 [00:30<00:54, 18.94it/s]Training:  48%|████▊     | 771/1600 [00:40<00:43, 19.21it/s]Training:  60%|██████    | 968/1600 [00:50<00:33, 19.00it/s]Training:  73%|███████▎  | 1168/1600 [01:00<00:22, 19.32it/s]Training:  86%|████████▌ | 1368/1600 [01:11<00:11, 19.39it/s]Training:  98%|█████████▊| 1570/1600 [01:21<00:01, 19.62it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                               Validation loss: 162.3767, Validation accuracy: 0.6750
Macro F1-score: 0.6706
Model performance on Angry speech (in validation): 
	Precision: 0.9474, Recall: 0.7200, F1_score: 0.8182
Model performance on Happy speech (in validation): 
	Precision: 0.5676, Recall: 0.4200, F1_score: 0.4828
Model performance on Neutral speech (in validation): 
	Precision: 0.5965, Recall: 0.6800, F1_score: 0.6355
Model performance on Sad speech (in validation): 
	Precision: 0.6471, Recall: 0.8800, F1_score: 0.7458
New best accuracy for layer 8 on epoch 6: 0.6750. Model saved.
Epoch 7/100

Training Phase:
Training loss: 1369.3094, Training accuracy: 0.6538
Macro F1-score: 0.6472
Model performance on Angry speech (in training): 
	Precision: 0.7108, Recall: 0.7250, F1_score: 0.7178
Model performance on Happy speech (in training): 
	Precision: 0.6241, Recall: 0.4400, F1_score: 0.5161
Model performance on Neutral speech (in training): 
	Precision: 0.5788, Recall: 0.6425, F1_score: 0.6090
Model performance on Sad speech (in training): 
	Precision: 0.6931, Recall: 0.8075, F1_score: 0.7460

Eval Phase: 
Validation loss: 150.2600, Validation accuracy: 0.7250
Macro F1-score: 0.7153
Model performance on Angry speech (in validation): 
	Precision: 0.8400, Recall: 0.8400, F1_score: 0.8400
Model performance on Happy speech (in validation): 
	Precision: 0.7097, Recall: 0.4400, F1_score: 0.5432
Model performance on Neutral speech (in validation): 
	Precision: 0.6379, Recall: 0.7400, F1_score: 0.6852
Model performance on Sad speech (in validation): 
	Precision: 0.7213, Recall: 0.8800, F1_score: 0.7928
New best accuracy for layer 8 on epoch 7: 0.7250. Model saved.
Epoch 8/100

Training Phase:
    Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 198/1600 [00:10<01:11, 19.73it/s]Training:  25%|██▍       | 396/1600 [00:20<01:01, 19.48it/s]Training:  37%|███▋      | 592/1600 [00:30<00:51, 19.51it/s]Training:  49%|████▉     | 788/1600 [00:40<00:42, 19.24it/s]Training:  62%|██████▏   | 989/1600 [00:50<00:31, 19.52it/s]Training:  74%|███████▍  | 1190/1600 [01:01<00:21, 19.45it/s]Training:  86%|████████▋ | 1384/1600 [01:11<00:11, 19.23it/s]Training:  99%|█████████▉| 1583/1600 [01:21<00:00, 19.40it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 192/1600 [00:10<01:13, 19.13it/s]Training:  24%|██▍       | 387/1600 [00:20<01:02, 19.32it/s]Training:  36%|███▋  Training loss: 1287.4445, Training accuracy: 0.6681
Macro F1-score: 0.6627
Model performance on Angry speech (in training): 
	Precision: 0.7224, Recall: 0.7350, F1_score: 0.7286
Model performance on Happy speech (in training): 
	Precision: 0.6497, Recall: 0.4775, F1_score: 0.5504
Model performance on Neutral speech (in training): 
	Precision: 0.5940, Recall: 0.6400, F1_score: 0.6161
Model performance on Sad speech (in training): 
	Precision: 0.7009, Recall: 0.8200, F1_score: 0.7558

Eval Phase: 
Validation loss: 191.2699, Validation accuracy: 0.6300
Macro F1-score: 0.6145
Model performance on Angry speech (in validation): 
	Precision: 0.8667, Recall: 0.7800, F1_score: 0.8211
Model performance on Happy speech (in validation): 
	Precision: 0.6667, Recall: 0.4000, F1_score: 0.5000
Model performance on Neutral speech (in validation): 
	Precision: 0.6333, Recall: 0.3800, F1_score: 0.4750
Model performance on Sad speech (in validation): 
	Precision: 0.5053, Recall: 0.9600, F1_score: 0.6621
Epoch 9/100

Training Phase:
    | 582/1600 [00:30<00:53, 19.12it/s]Training:  48%|████▊     | 771/1600 [00:40<00:43, 18.90it/s]Training:  60%|█████▉    | 959/1600 [00:50<00:34, 18.83it/s]Training:  72%|███████▏  | 1147/1600 [01:01<00:24, 18.54it/s]Training:  83%|████████▎ | 1332/1600 [01:11<00:14, 18.53it/s]Training:  95%|█████████▍| 1519/1600 [01:21<00:04, 18.58it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 198/1600 [00:10<01:11, 19.70it/s]Training:  25%|██▍       | 396/1600 [00:20<01:03, 18.82it/s]Training:  36%|███▋      | 580/1600 [00:30<00:54, 18.59it/s]Training:  48%|████▊     | 764/1600 [00:40<00:45, 18.50it/s]Training:  59%|█████▉    | 948/1600 [00:50<00:35, 18.45it/s]Training:  71%|███████Training loss: 1233.9496, Training accuracy: 0.6819
Macro F1-score: 0.6767
Model performance on Angry speech (in training): 
	Precision: 0.7421, Recall: 0.7625, F1_score: 0.7522
Model performance on Happy speech (in training): 
	Precision: 0.6838, Recall: 0.4975, F1_score: 0.5760
Model performance on Neutral speech (in training): 
	Precision: 0.5991, Recall: 0.6350, F1_score: 0.6165
Model performance on Sad speech (in training): 
	Precision: 0.7025, Recall: 0.8325, F1_score: 0.7620

Eval Phase: 
Validation loss: 186.5498, Validation accuracy: 0.6200
Macro F1-score: 0.6157
Model performance on Angry speech (in validation): 
	Precision: 0.8889, Recall: 0.4800, F1_score: 0.6234
Model performance on Happy speech (in validation): 
	Precision: 0.4444, Recall: 0.8000, F1_score: 0.5714
Model performance on Neutral speech (in validation): 
	Precision: 0.6786, Recall: 0.3800, F1_score: 0.4872
Model performance on Sad speech (in validation): 
	Precision: 0.7455, Recall: 0.8200, F1_score: 0.7810
Epoch 10/100

Training Phase:
   | 1137/1600 [01:01<00:24, 18.57it/s]Training:  83%|████████▎ | 1329/1600 [01:11<00:14, 18.76it/s]Training:  95%|█████████▌| 1521/1600 [01:21<00:04, 18.79it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 185/1600 [00:10<01:16, 18.39it/s]Training:  23%|██▎       | 370/1600 [00:20<01:06, 18.45it/s]Training:  35%|███▍      | 555/1600 [00:30<00:57, 18.24it/s]Training:  46%|████▌     | 736/1600 [00:40<00:47, 18.18it/s]Training:  57%|█████▋    | 917/1600 [00:50<00:37, 18.09it/s]Training:  69%|██████▉   | 1108/1600 [01:00<00:26, 18.41it/s]Training:  81%|████████  | 1299/1600 [01:10<00:16, 18.62it/s]Training:  93%|█████████▎| 1490/1600 [01:20<00:05, 18.56it/s]                      Training loss: 1197.1768, Training accuracy: 0.6975
Macro F1-score: 0.6934
Model performance on Angry speech (in training): 
	Precision: 0.7568, Recall: 0.7625, F1_score: 0.7597
Model performance on Happy speech (in training): 
	Precision: 0.7043, Recall: 0.5300, F1_score: 0.6049
Model performance on Neutral speech (in training): 
	Precision: 0.6256, Recall: 0.6600, F1_score: 0.6423
Model performance on Sad speech (in training): 
	Precision: 0.7068, Recall: 0.8375, F1_score: 0.7666

Eval Phase: 
Validation loss: 164.8884, Validation accuracy: 0.7100
Macro F1-score: 0.7051
Model performance on Angry speech (in validation): 
	Precision: 0.9286, Recall: 0.7800, F1_score: 0.8478
Model performance on Happy speech (in validation): 
	Precision: 0.6944, Recall: 0.5000, F1_score: 0.5814
Model performance on Neutral speech (in validation): 
	Precision: 0.6596, Recall: 0.6200, F1_score: 0.6392
Model performance on Sad speech (in validation): 
	Precision: 0.6267, Recall: 0.9400, F1_score: 0.7520
Epoch 11/100

Training Phase:
Training loss: 1110.1496, Training accuracy: 0.7250
Macro F1-score: 0.7216
Model performance on Angry speech (in training): 
	Precision: 0.7965, Recall: 0.7925, F1_score: 0.7945
Model performance on Happy speech (in training): 
	Precision: 0.7231, Recall: 0.5550, F1_score: 0.6280
Model performance on Neutral speech (in training): 
	Precision: 0.6430, Recall: 0.7025, F1_score: 0.6714
Model performance on Sad speech (in training): 
	Precision: 0.7424, Recall: 0.8500, F1_score: 0.7925

Eval Phase: 
Validation loss: 161.4653, Validation accuracy: 0.6950
Macro F1-score: 0.6878
Model performance on Angry speech (in validation): 
	Precision: 0.9211, Recall: 0.7000, F1_score: 0.7955
Model performance on Happy speech (in validation): 
	Precision: 0.6897, Recall: 0.4000, F1_score: 0.5063
Model performance on Neutral speech (in validation): 
	Precision: 0.5352, Recall: 0.7600, F1_score: 0.6281
Model performance on Sad speech (in validation): 
	Precision: 0.7419, Recall: 0.9200, F1_score: 0.8214
Epoch 12/100

Training Phase:
                                       Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  11%|█▏        | 182/1600 [00:10<01:18, 18.14it/s]Training:  23%|██▎       | 370/1600 [00:20<01:06, 18.52it/s]Training:  35%|███▍      | 558/1600 [00:30<00:56, 18.38it/s]Training:  35%|███▍      | 558/1600 [00:40<00:56, 18.38it/s]Training:  46%|████▌     | 739/1600 [00:40<00:47, 18.11it/s]Training:  58%|█████▊    | 923/1600 [00:50<00:37, 18.18it/s]Training:  69%|██████▉   | 1111/1600 [01:00<00:26, 18.37it/s]Training:  81%|████████  | 1299/1600 [01:10<00:16, 18.32it/s]Training:  94%|█████████▎| 1498/1600 [01:21<00:05, 18.81it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:Training loss: 1086.6256, Training accuracy: 0.7288
Macro F1-score: 0.7254
Model performance on Angry speech (in training): 
	Precision: 0.7783, Recall: 0.7900, F1_score: 0.7841
Model performance on Happy speech (in training): 
	Precision: 0.7040, Recall: 0.5650, F1_score: 0.6269
Model performance on Neutral speech (in training): 
	Precision: 0.6604, Recall: 0.7050, F1_score: 0.6820
Model performance on Sad speech (in training): 
	Precision: 0.7668, Recall: 0.8550, F1_score: 0.8085

Eval Phase: 
Validation loss: 211.0754, Validation accuracy: 0.6450
Macro F1-score: 0.6241
Model performance on Angry speech (in validation): 
	Precision: 0.9474, Recall: 0.7200, F1_score: 0.8182
Model performance on Happy speech (in validation): 
	Precision: 0.8125, Recall: 0.2600, F1_score: 0.3939
Model performance on Neutral speech (in validation): 
	Precision: 0.5345, Recall: 0.6200, F1_score: 0.5741
Model performance on Sad speech (in validation): 
	Precision: 0.5568, Recall: 0.9800, F1_score: 0.7101
Epoch 13/100

Training Phase:
   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 197/1600 [00:10<01:11, 19.65it/s]Training:  25%|██▍       | 394/1600 [00:20<01:01, 19.50it/s]Training:  37%|███▋      | 588/1600 [00:30<00:52, 19.41it/s]Training:  49%|████▉     | 782/1600 [00:40<00:42, 19.35it/s]Training:  61%|██████    | 975/1600 [00:50<00:33, 18.87it/s]Training:  72%|███████▏  | 1158/1600 [01:01<00:23, 18.66it/s]Training:  84%|████████▍ | 1341/1600 [01:11<00:14, 18.49it/s]Training:  95%|█████████▌| 1525/1600 [01:21<00:04, 18.43it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  11%|█▏        | 182/1600 [00:10<01:17, 18.20it/s]Training:  23%|██▎       | 366/1600 [00:20<01:07, 18.28it/s]Training:  34%|███▍      | 550/1600 [0Training loss: 1033.0405, Training accuracy: 0.7462
Macro F1-score: 0.7440
Model performance on Angry speech (in training): 
	Precision: 0.8090, Recall: 0.8050, F1_score: 0.8070
Model performance on Happy speech (in training): 
	Precision: 0.7599, Recall: 0.6250, F1_score: 0.6859
Model performance on Neutral speech (in training): 
	Precision: 0.6806, Recall: 0.6925, F1_score: 0.6865
Model performance on Sad speech (in training): 
	Precision: 0.7403, Recall: 0.8625, F1_score: 0.7968

Eval Phase: 
Validation loss: 183.4793, Validation accuracy: 0.6900
Macro F1-score: 0.6904
Model performance on Angry speech (in validation): 
	Precision: 0.8333, Recall: 0.8000, F1_score: 0.8163
Model performance on Happy speech (in validation): 
	Precision: 0.5690, Recall: 0.6600, F1_score: 0.6111
Model performance on Neutral speech (in validation): 
	Precision: 0.6667, Recall: 0.5600, F1_score: 0.6087
Model performance on Sad speech (in validation): 
	Precision: 0.7115, Recall: 0.7400, F1_score: 0.7255
Epoch 14/100

Training Phase:
0:30<00:57, 18.25it/s]Training:  46%|████▌     | 737/1600 [00:40<00:46, 18.41it/s]Training:  58%|█████▊    | 924/1600 [00:50<00:36, 18.43it/s]Training:  69%|██████▉   | 1109/1600 [01:00<00:26, 18.35it/s]Training:  81%|████████  | 1294/1600 [01:10<00:16, 18.35it/s]Training:  92%|█████████▏| 1479/1600 [01:20<00:06, 18.39it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  11%|█▏        | 182/1600 [00:10<01:18, 18.15it/s]Training:  23%|██▎       | 367/1600 [00:20<01:07, 18.21it/s]Training:  34%|███▍      | 550/1600 [00:30<00:58, 18.09it/s]Training:  46%|████▌     | 734/1600 [00:40<00:47, 18.20it/s]Training:  58%|█████▊    | 931/1600 [00:50<00:35, 18.73it/s]Training:  70%|███████   | 1128/1600 [01:00Training loss: 980.8847, Training accuracy: 0.7594
Macro F1-score: 0.7576
Model performance on Angry speech (in training): 
	Precision: 0.8254, Recall: 0.8275, F1_score: 0.8265
Model performance on Happy speech (in training): 
	Precision: 0.7620, Recall: 0.6325, F1_score: 0.6913
Model performance on Neutral speech (in training): 
	Precision: 0.6905, Recall: 0.7250, F1_score: 0.7073
Model performance on Sad speech (in training): 
	Precision: 0.7629, Recall: 0.8525, F1_score: 0.8052

Eval Phase: 
Validation loss: 177.7602, Validation accuracy: 0.6800
Macro F1-score: 0.6713
Model performance on Angry speech (in validation): 
	Precision: 0.9070, Recall: 0.7800, F1_score: 0.8387
Model performance on Happy speech (in validation): 
	Precision: 0.6579, Recall: 0.5000, F1_score: 0.5682
Model performance on Neutral speech (in validation): 
	Precision: 0.6316, Recall: 0.4800, F1_score: 0.5455
Model performance on Sad speech (in validation): 
	Precision: 0.5926, Recall: 0.9600, F1_score: 0.7328
Epoch 15/100

Training Phase:
<00:25, 18.68it/s]Training:  82%|████████▏ | 1315/1600 [01:11<00:15, 18.64it/s]Training:  94%|█████████▍| 1501/1600 [01:21<00:05, 18.21it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  11%|█▏        | 183/1600 [00:10<01:17, 18.25it/s]Training:  23%|██▎       | 367/1600 [00:20<01:07, 18.29it/s]Training:  35%|███▍      | 553/1600 [00:30<00:56, 18.42it/s]Training:  46%|████▌     | 739/1600 [00:40<00:47, 18.22it/s]Training:  57%|█████▋    | 919/1600 [00:50<00:37, 18.12it/s]Training:  69%|██████▊   | 1099/1600 [01:00<00:27, 18.08it/s]Training:  80%|████████  | 1285/1600 [01:10<00:17, 18.25it/s]Training:  92%|█████████▏| 1477/1600 [01:20<00:06, 18.50it/s]                                           Training loss: 946.2006, Training accuracy: 0.7700
Macro F1-score: 0.7678
Model performance on Angry speech (in training): 
	Precision: 0.8325, Recall: 0.8325, F1_score: 0.8325
Model performance on Happy speech (in training): 
	Precision: 0.7771, Recall: 0.6450, F1_score: 0.7049
Model performance on Neutral speech (in training): 
	Precision: 0.7000, Recall: 0.7175, F1_score: 0.7086
Model performance on Sad speech (in training): 
	Precision: 0.7729, Recall: 0.8850, F1_score: 0.8252

Eval Phase: 
Validation loss: 203.5392, Validation accuracy: 0.6950
Macro F1-score: 0.6870
Model performance on Angry speech (in validation): 
	Precision: 0.8837, Recall: 0.7600, F1_score: 0.8172
Model performance on Happy speech (in validation): 
	Precision: 0.6667, Recall: 0.6400, F1_score: 0.6531
Model performance on Neutral speech (in validation): 
	Precision: 0.7097, Recall: 0.4400, F1_score: 0.5432
Model performance on Sad speech (in validation): 
	Precision: 0.6026, Recall: 0.9400, F1_score: 0.7344
Epoch 16/100

Training Phase:
Training loss: 888.8650, Training accuracy: 0.7863
Macro F1-score: 0.7850
Model performance on Angry speech (in training): 
	Precision: 0.8325, Recall: 0.8325, F1_score: 0.8325
Model performance on Happy speech (in training): 
	Precision: 0.8123, Recall: 0.6925, F1_score: 0.7476
Model performance on Neutral speech (in training): 
	Precision: 0.7195, Recall: 0.7375, F1_score: 0.7284
Model performance on Sad speech (in training): 
	Precision: 0.7862, Recall: 0.8825, F1_score: 0.8316

Eval Phase: 
Validation loss: 186.4850, Validation accuracy: 0.6850
Macro F1-score: 0.6877
Model performance on Angry speech (in validation): 
	Precision: 0.8919, Recall: 0.6600, F1_score: 0.7586
Model performance on Happy speech (in validation): 
	Precision: 0.6000, Recall: 0.6600, F1_score: 0.6286
Model performance on Neutral speech (in validation): 
	Precision: 0.5660, Recall: 0.6000, F1_score: 0.5825
Model performance on Sad speech (in validation): 
	Precision: 0.7455, Recall: 0.8200, F1_score: 0.7810
Epoch 17/100

Training Phase:
                  Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 192/1600 [00:10<01:14, 19.01it/s]Training:  24%|██▍       | 383/1600 [00:20<01:06, 18.41it/s]Training:  35%|███▌      | 566/1600 [00:30<00:56, 18.34it/s]Training:  47%|████▋     | 749/1600 [00:41<00:47, 17.93it/s]Training:  59%|█████▊    | 937/1600 [00:51<00:36, 18.21it/s]Training:  70%|███████   | 1125/1600 [01:01<00:26, 18.19it/s]Training:  82%|████████▏ | 1309/1600 [01:11<00:15, 18.26it/s]Training:  94%|█████████▍| 1500/1600 [01:21<00:05, 18.52it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 187/1600 [00:10Training loss: 886.2069, Training accuracy: 0.7819
Macro F1-score: 0.7805
Model performance on Angry speech (in training): 
	Precision: 0.8612, Recall: 0.8375, F1_score: 0.8492
Model performance on Happy speech (in training): 
	Precision: 0.7771, Recall: 0.6625, F1_score: 0.7152
Model performance on Neutral speech (in training): 
	Precision: 0.7242, Recall: 0.7550, F1_score: 0.7393
Model performance on Sad speech (in training): 
	Precision: 0.7704, Recall: 0.8725, F1_score: 0.8183

Eval Phase: 
Validation loss: 257.9463, Validation accuracy: 0.6450
Macro F1-score: 0.6341
Model performance on Angry speech (in validation): 
	Precision: 0.8889, Recall: 0.6400, F1_score: 0.7442
Model performance on Happy speech (in validation): 
	Precision: 0.5600, Recall: 0.5600, F1_score: 0.5600
Model performance on Neutral speech (in validation): 
	Precision: 0.6897, Recall: 0.4000, F1_score: 0.5063
Model performance on Sad speech (in validation): 
	Precision: 0.5765, Recall: 0.9800, F1_score: 0.7259
Validation loss does not decrease for 10 epochs. End training.
Model best accuracy on validation set: 0.7250

Test Phase: 
Test loss: 177.9876, Test accuracy: 0.6400
Macro F1-score: 0.6243
Model performance on Angry speech (in test): 
	Precision: 0.7407, Recall: 0.8000, F1_score: 0.7692
Model performance on Happy speech (in test): 
	Precision: 0.5926, Recall: 0.3200, F1_score: 0.4156
Model performance on Neutral speech (in test): 
	Precision: 0.5614, Recall: 0.6400, F1_score: 0.5981
Model performance on Sad speech (in test): 
	Precision: 0.6452, Recall: 0.8000, F1_score: 0.7143

======================= This is fold_1 on en =======================

Load dataset: 
Loading en train data: fold_1...
Preprocess en fold_1 data for en model
Loading en eval data: fold_1...
Preprocess en fold_1 data for en model
Loading en test data: fold_1...
Preprocess en fold_1 data for en model
Use en model to add lora
Set optimizer and criterion
Epoch 1/100

Training Phase:
<01:15, 18.69it/s]Training:  23%|██▎       | 374/1600 [00:20<01:05, 18.64it/s]Training:  35%|███▌      | 566/1600 [00:30<00:54, 18.87it/s]Training:  47%|████▋     | 758/1600 [00:40<00:44, 18.78it/s]Training:  59%|█████▉    | 945/1600 [00:51<00:35, 18.29it/s]Training:  71%|███████   | 1130/1600 [01:01<00:25, 18.33it/s]Training:  82%|████████▏ | 1315/1600 [01:11<00:15, 18.36it/s]Training:  94%|█████████▍| 1500/1600 [01:21<00:05, 18.36it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]                                                Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:   8%|▊         | 125/1600 [00:10<01:58, 12.47it/s]Training:  17%|█▋        | 279/1600 [00:20<01:33, 14.18it/s]Training:  28%|██▊       | 444/1600Training loss: 1645.3431, Training accuracy: 0.5825
Macro F1-score: 0.5759
Model performance on Angry speech (in training): 
	Precision: 0.6382, Recall: 0.7275, F1_score: 0.6799
Model performance on Happy speech (in training): 
	Precision: 0.5415, Recall: 0.4400, F1_score: 0.4855
Model performance on Neutral speech (in training): 
	Precision: 0.5125, Recall: 0.4600, F1_score: 0.4848
Model performance on Sad speech (in training): 
	Precision: 0.6109, Recall: 0.7025, F1_score: 0.6535

Eval Phase: 
Validation loss: 197.8955, Validation accuracy: 0.5600
Macro F1-score: 0.4887
Model performance on Angry speech (in validation): 
	Precision: 0.4608, Recall: 0.9400, F1_score: 0.6184
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.5000, Recall: 0.5400, F1_score: 0.5192
Model performance on Sad speech (in validation): 
	Precision: 0.8837, Recall: 0.7600, F1_score: 0.8172
New best accuracy for layer 8 on epoch 1: 0.5600. Model saved.
Epoch 2/100

Training Phase:
 [00:30<01:15, 15.22it/s]Training:  38%|███▊      | 615/1600 [00:40<01:01, 15.92it/s]Training:  50%|████▉     | 793/1600 [00:50<00:48, 16.59it/s]Training:  61%|██████    | 971/1600 [01:00<00:38, 16.53it/s]Training:  71%|███████   | 1139/1600 [01:11<00:27, 16.60it/s]Training:  83%|████████▎ | 1324/1600 [01:21<00:16, 17.19it/s]Training:  94%|█████████▍| 1509/1600 [01:31<00:05, 17.49it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 193/1600 [00:10<01:13, 19.25it/s]Training:  24%|██▍       | 386/1600 [00:20<01:02, 19.27it/s]Training:  36%|███▌      | 579/1600 [00:30<00:53, 19.02it/s]Training:  48%|████▊     | 775/1600 [00:40<00:42, 19.21it/s]Training:  61%|██████    | 971/1600 [00:50<0Training loss: 1515.4819, Training accuracy: 0.6012
Macro F1-score: 0.5945
Model performance on Angry speech (in training): 
	Precision: 0.6713, Recall: 0.7200, F1_score: 0.6948
Model performance on Happy speech (in training): 
	Precision: 0.5610, Recall: 0.4025, F1_score: 0.4687
Model performance on Neutral speech (in training): 
	Precision: 0.5239, Recall: 0.5475, F1_score: 0.5355
Model performance on Sad speech (in training): 
	Precision: 0.6309, Recall: 0.7350, F1_score: 0.6790

Eval Phase: 
Validation loss: 176.3152, Validation accuracy: 0.6150
Macro F1-score: 0.5928
Model performance on Angry speech (in validation): 
	Precision: 0.5694, Recall: 0.8200, F1_score: 0.6721
Model performance on Happy speech (in validation): 
	Precision: 0.5882, Recall: 0.2000, F1_score: 0.2985
Model performance on Neutral speech (in validation): 
	Precision: 0.4930, Recall: 0.7000, F1_score: 0.5785
Model performance on Sad speech (in validation): 
	Precision: 0.9250, Recall: 0.7400, F1_score: 0.8222
New best accuracy for layer 8 on epoch 2: 0.6150. Model saved.
Epoch 3/100

Training Phase:
0:32, 19.21it/s]Training:  73%|███████▎  | 1164/1600 [01:00<00:22, 19.07it/s]Training:  85%|████████▌ | 1361/1600 [01:10<00:12, 19.26it/s]Training:  98%|█████████▊| 1560/1600 [01:20<00:02, 19.43it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 193/1600 [00:10<01:13, 19.16it/s]Training:  24%|██▍       | 385/1600 [00:20<01:03, 19.15it/s]Training:  36%|███▌      | 577/1600 [00:30<00:53, 19.01it/s]Training:  48%|████▊     | 767/1600 [00:40<00:43, 18.99it/s]Training:  61%|██████    | 969/1600 [00:50<00:32, 19.40it/s]Training:  61%|██████    | 969/1600 [01:01<00:32, 19.40it/s]Training:  73%|███████▎  | 1163/1600 [01:01<00:23, 18.88it/s]Training:  84%|████████▍ | 1343/16Training loss: 1416.2890, Training accuracy: 0.6294
Macro F1-score: 0.6251
Model performance on Angry speech (in training): 
	Precision: 0.6905, Recall: 0.7250, F1_score: 0.7073
Model performance on Happy speech (in training): 
	Precision: 0.5987, Recall: 0.4625, F1_score: 0.5219
Model performance on Neutral speech (in training): 
	Precision: 0.5534, Recall: 0.5825, F1_score: 0.5676
Model performance on Sad speech (in training): 
	Precision: 0.6644, Recall: 0.7475, F1_score: 0.7035

Eval Phase: 
Validation loss: 175.9076, Validation accuracy: 0.6150
Macro F1-score: 0.5637
Model performance on Angry speech (in validation): 
	Precision: 0.5412, Recall: 0.9200, F1_score: 0.6815
Model performance on Happy speech (in validation): 
	Precision: 0.5000, Recall: 0.1400, F1_score: 0.2188
Model performance on Neutral speech (in validation): 
	Precision: 0.6053, Recall: 0.4600, F1_score: 0.5227
Model performance on Sad speech (in validation): 
	Precision: 0.7460, Recall: 0.9400, F1_score: 0.8319
Epoch 4/100

Training Phase:
Training loss: 1344.1735, Training accuracy: 0.6550
Macro F1-score: 0.6518
Model performance on Angry speech (in training): 
	Precision: 0.7322, Recall: 0.7450, F1_score: 0.7385
Model performance on Happy speech (in training): 
	Precision: 0.6442, Recall: 0.5025, F1_score: 0.5646
Model performance on Neutral speech (in training): 
	Precision: 0.5905, Recall: 0.6200, F1_score: 0.6049
Model performance on Sad speech (in training): 
	Precision: 0.6529, Recall: 0.7525, F1_score: 0.6992

Eval Phase: 
00 [01:11<00:13, 18.60it/s]Training:  96%|█████████▌| 1531/1600 [01:21<00:03, 18.61it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  11%|█         | 179/1600 [00:10<01:19, 17.83it/s]Training:  22%|██▎       | 360/1600 [00:20<01:09, 17.97it/s]Training:  34%|███▍      | 541/1600 [00:30<00:59, 17.78it/s]Training:  46%|████▌     | 738/1600 [00:40<00:46, 18.50it/s]Training:  58%|█████▊    | 935/1600 [00:50<00:35, 18.79it/s]Training:  71%|███████   | 1130/1600 [01:00<00:24, 19.02it/s]Training:  83%|████████▎ | 1325/1600 [01:10<00:14, 19.07it/s]Training:  95%|█████████▌| 1523/1600 [01:20<00:03, 19.27it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]Validation loss: 167.0931, Validation accuracy: 0.6600
Macro F1-score: 0.6348
Model performance on Angry speech (in validation): 
	Precision: 0.6133, Recall: 0.9200, F1_score: 0.7360
Model performance on Happy speech (in validation): 
	Precision: 0.6190, Recall: 0.2600, F1_score: 0.3662
Model performance on Neutral speech (in validation): 
	Precision: 0.5556, Recall: 0.6000, F1_score: 0.5769
Model performance on Sad speech (in validation): 
	Precision: 0.8600, Recall: 0.8600, F1_score: 0.8600
New best accuracy for layer 8 on epoch 4: 0.6600. Model saved.
Epoch 5/100

Training Phase:
Training loss: 1304.0342, Training accuracy: 0.6750
Macro F1-score: 0.6720
Model performance on Angry speech (in training): 
	Precision: 0.7494, Recall: 0.7700, F1_score: 0.7596
Model performance on Happy speech (in training): 
	Precision: 0.6857, Recall: 0.5400, F1_score: 0.6042
Model performance on Neutral speech (in training): 
	Precision: 0.5946, Recall: 0.6050, F1_score: 0.5998
Model performance on Sad speech (in training): 
	Precision: 0.6724, Recall: 0.7850, F1_score: 0.7243

Eval Phase: 
Validation loss: 180.9050, Validation accuracy: 0.6000
Macro F1-score: 0.5628
Model performance on Angry speech (in validation): 
	Precision: 0.6119, Recall: 0.8200, F1_score: 0.7009
Model performance on Happy speech (in validation): 
	Precision: 0.4167, Recall: 0.1000, F1_score: 0.1613
Model performance on Neutral speech (in validation): 
	Precision: 0.4500, Recall: 0.7200, F1_score: 0.5538
Model performance on Sad speech (in validation): 
	Precision: 0.9268, Recall: 0.7600, F1_score: 0.8352
Epoch 6/100

Training Phase:
                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  11%|█▏        | 180/1600 [00:10<01:19, 17.93it/s]Training:  23%|██▎       | 365/1600 [00:20<01:07, 18.23it/s]Training:  34%|███▍      | 551/1600 [00:30<00:57, 18.38it/s]Training:  46%|████▋     | 742/1600 [00:40<00:46, 18.65it/s]Training:  58%|█████▊    | 933/1600 [00:50<00:36, 18.53it/s]Training:  70%|██████▉   | 1118/1600 [01:00<00:26, 18.49it/s]Training:  81%|████████▏ | 1303/1600 [01:11<00:16, 18.17it/s]Training:  93%|█████████▎| 1481/1600 [01:21<00:06, 18.05it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  11%|█         | 179/1600 [00:10<01:19, 17.84it/s]Training:  23%|██▎       | 369/1600 [00:20<01:06Training loss: 1201.2655, Training accuracy: 0.6987
Macro F1-score: 0.6960
Model performance on Angry speech (in training): 
	Precision: 0.7702, Recall: 0.7875, F1_score: 0.7787
Model performance on Happy speech (in training): 
	Precision: 0.6957, Recall: 0.5600, F1_score: 0.6205
Model performance on Neutral speech (in training): 
	Precision: 0.6341, Recall: 0.6500, F1_score: 0.6420
Model performance on Sad speech (in training): 
	Precision: 0.6950, Recall: 0.7975, F1_score: 0.7427

Eval Phase: 
Validation loss: 214.0640, Validation accuracy: 0.6150
Macro F1-score: 0.5697
Model performance on Angry speech (in validation): 
	Precision: 0.5155, Recall: 1.0000, F1_score: 0.6803
Model performance on Happy speech (in validation): 
	Precision: 0.6667, Recall: 0.1600, F1_score: 0.2581
Model performance on Neutral speech (in validation): 
	Precision: 0.5897, Recall: 0.4600, F1_score: 0.5169
Model performance on Sad speech (in validation): 
	Precision: 0.8077, Recall: 0.8400, F1_score: 0.8235
Epoch 7/100

Training Phase:
, 18.48it/s]Training:  35%|███▍      | 559/1600 [00:30<00:55, 18.65it/s]Training:  47%|████▋     | 748/1600 [00:40<00:46, 18.45it/s]Training:  59%|█████▊    | 937/1600 [00:50<00:35, 18.58it/s]Training:  70%|███████   | 1126/1600 [01:01<00:25, 18.34it/s]Training:  82%|████████▏ | 1308/1600 [01:11<00:15, 18.29it/s]Training:  93%|█████████▎| 1490/1600 [01:21<00:06, 18.22it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 185/1600 [00:10<01:16, 18.49it/s]Training:  23%|██▎       | 370/1600 [00:20<01:08, 18.01it/s]Training:  35%|███▍      | 556/1600 [00:30<00:57, 18.25it/s]Training:  46%|████▋     | 742/1600 [00:40<00:47, 18.18it/s]Training:  58%|█████▊    | 930/1600 [00:50<00:36, 18.38itTraining loss: 1197.9788, Training accuracy: 0.6887
Macro F1-score: 0.6847
Model performance on Angry speech (in training): 
	Precision: 0.7718, Recall: 0.7950, F1_score: 0.7833
Model performance on Happy speech (in training): 
	Precision: 0.6688, Recall: 0.5250, F1_score: 0.5882
Model performance on Neutral speech (in training): 
	Precision: 0.5913, Recall: 0.6150, F1_score: 0.6029
Model performance on Sad speech (in training): 
	Precision: 0.7162, Recall: 0.8200, F1_score: 0.7646

Eval Phase: 
Validation loss: 176.3076, Validation accuracy: 0.6500
Macro F1-score: 0.6186
Model performance on Angry speech (in validation): 
	Precision: 0.6438, Recall: 0.9400, F1_score: 0.7642
Model performance on Happy speech (in validation): 
	Precision: 0.6000, Recall: 0.2400, F1_score: 0.3429
Model performance on Neutral speech (in validation): 
	Precision: 0.5192, Recall: 0.5400, F1_score: 0.5294
Model performance on Sad speech (in validation): 
	Precision: 0.8000, Recall: 0.8800, F1_score: 0.8381
Epoch 8/100

Training Phase:
/s]Training:  70%|██████▉   | 1118/1600 [01:00<00:26, 18.43it/s]Training:  82%|████████▏ | 1304/1600 [01:11<00:16, 18.31it/s]Training:  93%|█████████▎| 1485/1600 [01:21<00:06, 18.19it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  11%|█         | 169/1600 [00:10<01:25, 16.83it/s]Training:  22%|██▏       | 354/1600 [00:20<01:10, 17.80it/s]Training:  34%|███▎      | 539/1600 [00:30<00:58, 18.06it/s]Training:  45%|████▌     | 725/1600 [00:40<00:47, 18.26it/s]Training:  57%|█████▋    | 914/1600 [00:50<00:37, 18.47it/s]Training:  69%|██████▉   | 1103/1600 [01:00<00:26, 18.49it/s]Training:  81%|████████  | 1289/1600 [01:10<00:16, 18.33it/s]Training:  92%|█████████▏| 1474/1600 [01:20<00Training loss: 1084.3614, Training accuracy: 0.7244
Macro F1-score: 0.7226
Model performance on Angry speech (in training): 
	Precision: 0.8200, Recall: 0.8200, F1_score: 0.8200
Model performance on Happy speech (in training): 
	Precision: 0.7040, Recall: 0.6125, F1_score: 0.6551
Model performance on Neutral speech (in training): 
	Precision: 0.6484, Recall: 0.6500, F1_score: 0.6492
Model performance on Sad speech (in training): 
	Precision: 0.7228, Recall: 0.8150, F1_score: 0.7662

Eval Phase: 
Validation loss: 218.5334, Validation accuracy: 0.5600
Macro F1-score: 0.5254
Model performance on Angry speech (in validation): 
	Precision: 0.5647, Recall: 0.9600, F1_score: 0.7111
Model performance on Happy speech (in validation): 
	Precision: 0.4667, Recall: 0.1400, F1_score: 0.2154
Model performance on Neutral speech (in validation): 
	Precision: 0.4286, Recall: 0.6000, F1_score: 0.5000
Model performance on Sad speech (in validation): 
	Precision: 0.9000, Recall: 0.5400, F1_score: 0.6750
Epoch 9/100

Training Phase:
Training loss: 1058.0917, Training accuracy: 0.7312
Macro F1-score: 0.7283
Model performance on Angry speech (in training): 
	Precision: 0.8081, Recall: 0.8000, F1_score: 0.8040
Model performance on Happy speech (in training): 
	Precision: 0.7387, Recall: 0.5725, F1_score: 0.6451
Model performance on Neutral speech (in training): 
	Precision: 0.6643, Recall: 0.7075, F1_score: 0.6852
Model performance on Sad speech (in training): 
	Precision: 0.7222, Recall: 0.8450, F1_score: 0.7788

Eval Phase: 
Validation loss: 230.1560, Validation accuracy: 0.6200
Macro F1-score: 0.5828
Model performance on Angry speech (in validation): 
	Precision: 0.5444, Recall: 0.9800, F1_score: 0.7000
Model performance on Happy speech (in validation): 
	Precision: 0.4800, Recall: 0.2400, F1_score: 0.3200
Model performance on Neutral speech (in validation): 
	Precision: 0.6552, Recall: 0.3800, F1_score: 0.4810
Model performance on Sad speech (in validation): 
	Precision: 0.7857, Recall: 0.8800, F1_score: 0.8302
Epoch 10/100

Training Phase:
:06, 18.34it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  11%|█         | 176/1600 [00:10<01:21, 17.52it/s]Training:  22%|██▏       | 359/1600 [00:20<01:09, 17.98it/s]Training:  34%|███▍      | 544/1600 [00:30<00:58, 18.19it/s]Training:  46%|████▌     | 731/1600 [00:40<00:47, 18.36it/s]Training:  57%|█████▋    | 918/1600 [00:50<00:37, 18.41it/s]Training:  70%|██████▉   | 1112/1600 [01:00<00:26, 18.72it/s]Training:  82%|████████▏ | 1306/1600 [01:10<00:15, 18.60it/s]Training:  94%|█████████▍| 1501/1600 [01:20<00:05, 18.87it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00Training loss: 1010.0496, Training accuracy: 0.7669
Macro F1-score: 0.7655
Model performance on Angry speech (in training): 
	Precision: 0.8413, Recall: 0.8350, F1_score: 0.8381
Model performance on Happy speech (in training): 
	Precision: 0.7834, Recall: 0.6600, F1_score: 0.7164
Model performance on Neutral speech (in training): 
	Precision: 0.7069, Recall: 0.7175, F1_score: 0.7122
Model performance on Sad speech (in training): 
	Precision: 0.7435, Recall: 0.8550, F1_score: 0.7953

Eval Phase: 
Validation loss: 230.2062, Validation accuracy: 0.5750
Macro F1-score: 0.5395
Model performance on Angry speech (in validation): 
	Precision: 0.5158, Recall: 0.9800, F1_score: 0.6759
Model performance on Happy speech (in validation): 
	Precision: 0.4571, Recall: 0.3200, F1_score: 0.3765
Model performance on Neutral speech (in validation): 
	Precision: 0.4783, Recall: 0.2200, F1_score: 0.3014
Model performance on Sad speech (in validation): 
	Precision: 0.8298, Recall: 0.7800, F1_score: 0.8041
Epoch 11/100

Training Phase:
<?, ?it/s]Training:  12%|█▏        | 187/1600 [00:10<01:15, 18.69it/s]Training:  23%|██▎       | 374/1600 [00:20<01:09, 17.67it/s]Training:  35%|███▌      | 563/1600 [00:31<00:56, 18.21it/s]Training:  47%|████▋     | 758/1600 [00:41<00:45, 18.70it/s]Training:  60%|█████▉    | 953/1600 [00:51<00:34, 18.62it/s]Training:  72%|███████▏  | 1149/1600 [01:01<00:23, 18.92it/s]Training:  84%|████████▍ | 1346/1600 [01:11<00:13, 19.15it/s]Training:  96%|█████████▋| 1543/1600 [01:22<00:02, 19.08it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 197/1600 [00:10<01:11, 19.66it/s]Training:  25%|██▍       | 394/1600 [00:20<01:02, 19.39it/s]Training:  37%|███▋      | 587/1600 [00:30<00:53, 19.06it/s]TrainingTraining loss: 980.4610, Training accuracy: 0.7631
Macro F1-score: 0.7620
Model performance on Angry speech (in training): 
	Precision: 0.8438, Recall: 0.8375, F1_score: 0.8407
Model performance on Happy speech (in training): 
	Precision: 0.7988, Recall: 0.6450, F1_score: 0.7137
Model performance on Neutral speech (in training): 
	Precision: 0.7050, Recall: 0.7350, F1_score: 0.7197
Model performance on Sad speech (in training): 
	Precision: 0.7214, Recall: 0.8350, F1_score: 0.7740

Eval Phase: 
Validation loss: 321.0971, Validation accuracy: 0.5500
Macro F1-score: 0.4994
Model performance on Angry speech (in validation): 
	Precision: 0.4505, Recall: 1.0000, F1_score: 0.6211
Model performance on Happy speech (in validation): 
	Precision: 0.4118, Recall: 0.1400, F1_score: 0.2090
Model performance on Neutral speech (in validation): 
	Precision: 0.5417, Recall: 0.2600, F1_score: 0.3514
Model performance on Sad speech (in validation): 
	Precision: 0.8333, Recall: 0.8000, F1_score: 0.8163
Epoch 12/100

Training Phase:
:  49%|████▉     | 780/1600 [00:40<00:42, 19.12it/s]Training:  61%|██████    | 974/1600 [00:50<00:32, 19.20it/s]Training:  73%|███████▎  | 1170/1600 [01:00<00:22, 19.29it/s]Training:  85%|████████▌ | 1367/1600 [01:10<00:12, 19.40it/s]Training:  98%|█████████▊| 1564/1600 [01:20<00:01, 19.45it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 189/1600 [00:10<01:14, 18.88it/s]Training:  24%|██▍       | 387/1600 [00:20<01:02, 19.38it/s]Training:  37%|███▋      | 590/1600 [00:30<00:51, 19.78it/s]Training:  37%|███▋      | 590/1600 [00:40<00:51, 19.78it/s]Training:  49%|████▉     | 788/1600 [00:40<00:41, 19.47it/s]Training:  61%|██████    | 979/1600 [00:50<00:32, 19.21it/s]Training:  73%|Training loss: 917.4174, Training accuracy: 0.7762
Macro F1-score: 0.7753
Model performance on Angry speech (in training): 
	Precision: 0.8532, Recall: 0.8425, F1_score: 0.8478
Model performance on Happy speech (in training): 
	Precision: 0.8024, Recall: 0.6700, F1_score: 0.7302
Model performance on Neutral speech (in training): 
	Precision: 0.6896, Recall: 0.7275, F1_score: 0.7080
Model performance on Sad speech (in training): 
	Precision: 0.7706, Recall: 0.8650, F1_score: 0.8151

Eval Phase: 
Validation loss: 247.4028, Validation accuracy: 0.5900
Macro F1-score: 0.5717
Model performance on Angry speech (in validation): 
	Precision: 0.5465, Recall: 0.9400, F1_score: 0.6912
Model performance on Happy speech (in validation): 
	Precision: 0.5200, Recall: 0.2600, F1_score: 0.3467
Model performance on Neutral speech (in validation): 
	Precision: 0.4808, Recall: 0.5000, F1_score: 0.4902
Model performance on Sad speech (in validation): 
	Precision: 0.8919, Recall: 0.6600, F1_score: 0.7586
Epoch 13/100

Training Phase:
███████▎  | 1167/1600 [01:00<00:22, 19.00it/s]Training:  85%|████████▍ | 1354/1600 [01:10<00:13, 18.89it/s]Training:  98%|█████████▊| 1560/1600 [01:20<00:02, 19.43it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 191/1600 [00:10<01:13, 19.08it/s]Training:  24%|██▍       | 382/1600 [00:20<01:04, 18.97it/s]Training:  36%|███▌      | 571/1600 [00:30<00:54, 18.93it/s]Training:  48%|████▊     | 761/1600 [00:40<00:44, 18.94it/s]Training:  59%|█████▉    | 951/1600 [00:50<00:34, 18.96it/s]Training:  72%|███████▏  | 1147/1600 [01:00<00:23, 19.17it/s]Training:  84%|████████▍ | 1344/1600 [01:10<00:13, 19.32it/s]Training:  96%|█████████▋| 1541/1600 [01:20<00:03, 19.19iTraining loss: 893.1588, Training accuracy: 0.7775
Macro F1-score: 0.7760
Model performance on Angry speech (in training): 
	Precision: 0.8618, Recall: 0.8575, F1_score: 0.8596
Model performance on Happy speech (in training): 
	Precision: 0.7868, Recall: 0.6550, F1_score: 0.7149
Model performance on Neutral speech (in training): 
	Precision: 0.7167, Recall: 0.7400, F1_score: 0.7282
Model performance on Sad speech (in training): 
	Precision: 0.7522, Recall: 0.8575, F1_score: 0.8014

Eval Phase: 
Validation loss: 293.8381, Validation accuracy: 0.5550
Macro F1-score: 0.5239
Model performance on Angry speech (in validation): 
	Precision: 0.4804, Recall: 0.9800, F1_score: 0.6447
Model performance on Happy speech (in validation): 
	Precision: 0.4545, Recall: 0.2000, F1_score: 0.2778
Model performance on Neutral speech (in validation): 
	Precision: 0.4722, Recall: 0.3400, F1_score: 0.3953
Model performance on Sad speech (in validation): 
	Precision: 0.8750, Recall: 0.7000, F1_score: 0.7778
Epoch 14/100

Training Phase:
Training loss: 857.1880, Training accuracy: 0.7887
Macro F1-score: 0.7874
Model performance on Angry speech (in training): 
	Precision: 0.8607, Recall: 0.8650, F1_score: 0.8628
Model performance on Happy speech (in training): 
	Precision: 0.8091, Recall: 0.6675, F1_score: 0.7315
Model performance on Neutral speech (in training): 
	Precision: 0.7362, Recall: 0.7675, F1_score: 0.7515
Model performance on Sad speech (in training): 
	Precision: 0.7583, Recall: 0.8550, F1_score: 0.8038

Eval Phase: 
Validation loss: 232.9940, Validation accuracy: 0.6000
Macro F1-score: 0.5890
Model performance on Angry speech (in validation): 
	Precision: 0.6316, Recall: 0.9600, F1_score: 0.7619
Model performance on Happy speech (in validation): 
	Precision: 0.4737, Recall: 0.3600, F1_score: 0.4091
Model performance on Neutral speech (in validation): 
	Precision: 0.4510, Recall: 0.4600, F1_score: 0.4554
Model performance on Sad speech (in validation): 
	Precision: 0.8857, Recall: 0.6200, F1_score: 0.7294
Validation loss does not decrease for 10 epochs. End training.
Model best accuracy on validation set: 0.6600

Test Phase: 
t/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 191/1600 [00:10<01:13, 19.07it/s]Training:  24%|██▍       | 382/1600 [00:20<01:06, 18.41it/s]Training:  36%|███▌      | 571/1600 [00:30<00:55, 18.60it/s]Training:  48%|████▊     | 763/1600 [00:40<00:44, 18.82it/s]Training:  60%|█████▉    | 955/1600 [00:50<00:34, 18.85it/s]Training:  72%|███████▏  | 1149/1600 [01:00<00:23, 19.00it/s]Training:  84%|████████▍ | 1342/1600 [01:11<00:13, 19.02it/s]Training:  96%|█████████▋| 1544/1600 [01:21<00:02, 19.38it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/sTest loss: 198.1249, Test accuracy: 0.5700
Macro F1-score: 0.5501
Model performance on Angry speech (in test): 
	Precision: 0.5405, Recall: 0.8000, F1_score: 0.6452
Model performance on Happy speech (in test): 
	Precision: 0.7857, Recall: 0.2200, F1_score: 0.3438
Model performance on Neutral speech (in test): 
	Precision: 0.4328, Recall: 0.5800, F1_score: 0.4957
Model performance on Sad speech (in test): 
	Precision: 0.7556, Recall: 0.6800, F1_score: 0.7158

======================= This is fold_2 on en =======================

Load dataset: 
Loading en train data: fold_2...
Preprocess en fold_2 data for en model
Loading en eval data: fold_2...
Preprocess en fold_2 data for en model
Loading en test data: fold_2...
Preprocess en fold_2 data for en model
Use en model to add lora
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training loss: 1529.5954, Training accuracy: 0.5925
Macro F1-score: 0.5894
Model performance on Angry speech (in training): 
	Precision: 0.6402, Recall: 0.6850, F1_score: 0.6618
Model performance on Happy speech (in training): 
	Precision: 0.5234, Recall: 0.4475, F1_score: 0.4825
Model performance on Neutral speech (in training): 
	Precision: 0.5172, Recall: 0.5275, F1_score: 0.5223
Model performance on Sad speech (in training): 
	Precision: 0.6730, Recall: 0.7100, F1_score: 0.6910

Eval Phase: 
Validation loss: 223.7825, Validation accuracy: 0.5500
Macro F1-score: 0.5103
Model performance on Angry speech (in validation): 
	Precision: 0.7561, Recall: 0.6200, F1_score: 0.6813
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1400, F1_score: 0.2456
Model performance on Neutral speech (in validation): 
	Precision: 0.5106, Recall: 0.4800, F1_score: 0.4948
Model performance on Sad speech (in validation): 
	Precision: 0.4571, Recall: 0.9600, F1_score: 0.6194
New best accuracy for layer 8 on epoch 1: 0.5500. Model saved.
Epoch 2/100

Training Phase:
]                                                Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:   8%|▊         | 127/1600 [00:10<01:56, 12.69it/s]Training:  17%|█▋        | 269/1600 [00:20<01:38, 13.52it/s]Training:  26%|██▋       | 421/1600 [00:30<01:22, 14.24it/s]Training:  37%|███▋      | 586/1600 [00:40<01:07, 15.12it/s]Training:  47%|████▋     | 755/1600 [00:50<00:53, 15.74it/s]Training:  58%|█████▊    | 926/1600 [01:00<00:41, 16.20it/s]Training:  69%|██████▊   | 1097/1600 [01:10<00:30, 16.27it/s]Training:  79%|███████▉  | 1264/1600 [01:20<00:20, 16.40it/s]Training:  90%|████████▉ | 1439/1600 [01:30<00:09, 16.74it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 185/1600 [00:10<01:16, 18.43iTraining loss: 1431.6311, Training accuracy: 0.6338
Macro F1-score: 0.6291
Model performance on Angry speech (in training): 
	Precision: 0.6840, Recall: 0.7250, F1_score: 0.7039
Model performance on Happy speech (in training): 
	Precision: 0.5684, Recall: 0.4675, F1_score: 0.5130
Model performance on Neutral speech (in training): 
	Precision: 0.5675, Recall: 0.5675, F1_score: 0.5675
Model performance on Sad speech (in training): 
	Precision: 0.6935, Recall: 0.7750, F1_score: 0.7320

Eval Phase: 
Validation loss: 275.0385, Validation accuracy: 0.5100
Macro F1-score: 0.4535
Model performance on Angry speech (in validation): 
	Precision: 0.7059, Recall: 0.7200, F1_score: 0.7129
Model performance on Happy speech (in validation): 
	Precision: 0.8571, Recall: 0.2400, F1_score: 0.3750
Model performance on Neutral speech (in validation): 
	Precision: 0.6250, Recall: 0.1000, F1_score: 0.1724
Model performance on Sad speech (in validation): 
	Precision: 0.3858, Recall: 0.9800, F1_score: 0.5537
Epoch 3/100

Training Phase:
t/s]Training:  24%|██▍       | 386/1600 [00:20<01:02, 19.41it/s]Training:  24%|██▍       | 386/1600 [00:30<01:02, 19.41it/s]Training:  36%|███▌      | 577/1600 [00:30<00:53, 19.14it/s]Training:  48%|████▊     | 771/1600 [00:40<00:43, 19.21it/s]Training:  60%|██████    | 965/1600 [00:50<00:32, 19.24it/s]Training:  73%|███████▎  | 1163/1600 [01:00<00:22, 19.38it/s]Training:  85%|████████▌ | 1360/1600 [01:10<00:12, 19.32it/s]Training:  97%|█████████▋| 1553/1600 [01:20<00:02, 19.15it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 197/1600 [00:10<01:11, 19.67it/s]Training:  25%|██▍       | 394/1600 [00:20<01:03, 18.97it/s]Training:  36%|███▋      | 582/1600 [00:30<00:53, 18.87it/s]Training:  4Training loss: 1352.3923, Training accuracy: 0.6469
Macro F1-score: 0.6424
Model performance on Angry speech (in training): 
	Precision: 0.6916, Recall: 0.7625, F1_score: 0.7253
Model performance on Happy speech (in training): 
	Precision: 0.6355, Recall: 0.5100, F1_score: 0.5659
Model performance on Neutral speech (in training): 
	Precision: 0.5590, Recall: 0.5450, F1_score: 0.5519
Model performance on Sad speech (in training): 
	Precision: 0.6875, Recall: 0.7700, F1_score: 0.7264

Eval Phase: 
Validation loss: 192.9243, Validation accuracy: 0.6100
Macro F1-score: 0.5878
Model performance on Angry speech (in validation): 
	Precision: 0.7273, Recall: 0.8000, F1_score: 0.7619
Model performance on Happy speech (in validation): 
	Precision: 0.5556, Recall: 0.4000, F1_score: 0.4651
Model performance on Neutral speech (in validation): 
	Precision: 0.6538, Recall: 0.3400, F1_score: 0.4474
Model performance on Sad speech (in validation): 
	Precision: 0.5422, Recall: 0.9000, F1_score: 0.6767
New best accuracy for layer 8 on epoch 3: 0.6100. Model saved.
Epoch 4/100

Training Phase:
8%|████▊     | 775/1600 [00:40<00:43, 19.02it/s]Training:  61%|██████    | 973/1600 [00:50<00:32, 19.29it/s]Training:  73%|███████▎  | 1171/1600 [01:00<00:22, 19.45it/s]Training:  86%|████████▌ | 1369/1600 [01:11<00:11, 19.39it/s]Training:  98%|█████████▊| 1562/1600 [01:21<00:01, 19.34it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 195/1600 [00:10<01:12, 19.43it/s]Training:  25%|██▍       | 396/1600 [00:20<01:00, 19.79it/s]Training:  37%|███▋      | 597/1600 [00:30<00:51, 19.32it/s]Training:  50%|████▉     | 792/1600 [00:40<00:41, 19.36it/s]Training:  62%|██████▏   | 987/1600 [00:50<00:31, 19.37it/s]Training:  74%|███████▍  | 1182/1600 [01:01<00:21, 19.10it/s]TrainingTraining loss: 1273.6346, Training accuracy: 0.6706
Macro F1-score: 0.6669
Model performance on Angry speech (in training): 
	Precision: 0.7176, Recall: 0.7750, F1_score: 0.7452
Model performance on Happy speech (in training): 
	Precision: 0.6314, Recall: 0.5225, F1_score: 0.5718
Model performance on Neutral speech (in training): 
	Precision: 0.5955, Recall: 0.6000, F1_score: 0.5978
Model performance on Sad speech (in training): 
	Precision: 0.7235, Recall: 0.7850, F1_score: 0.7530

Eval Phase: 
Validation loss: 196.9862, Validation accuracy: 0.6200
Macro F1-score: 0.6051
Model performance on Angry speech (in validation): 
	Precision: 0.7708, Recall: 0.7400, F1_score: 0.7551
Model performance on Happy speech (in validation): 
	Precision: 0.7083, Recall: 0.3400, F1_score: 0.4595
Model performance on Neutral speech (in validation): 
	Precision: 0.6667, Recall: 0.4800, F1_score: 0.5581
Model performance on Sad speech (in validation): 
	Precision: 0.5000, Recall: 0.9200, F1_score: 0.6479
New best accuracy for layer 8 on epoch 4: 0.6200. Model saved.
Epoch 5/100

Training Phase:
Training loss: 1203.5169, Training accuracy: 0.6931
Macro F1-score: 0.6894
Model performance on Angry speech (in training): 
	Precision: 0.7628, Recall: 0.7800, F1_score: 0.7713
Model performance on Happy speech (in training): 
	Precision: 0.6556, Recall: 0.5425, F1_score: 0.5937
Model performance on Neutral speech (in training): 
	Precision: 0.6194, Recall: 0.6225, F1_score: 0.6209
Model performance on Sad speech (in training): 
	Precision: 0.7227, Recall: 0.8275, F1_score: 0.7716

Eval Phase: 
:  86%|████████▌ | 1378/1600 [01:11<00:11, 19.24it/s]Training:  98%|█████████▊| 1574/1600 [01:21<00:01, 19.14it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 198/1600 [00:10<01:11, 19.72it/s]Training:  25%|██▍       | 396/1600 [00:20<01:01, 19.44it/s]Training:  37%|███▋      | 592/1600 [00:30<00:51, 19.49it/s]Training:  49%|████▉     | 788/1600 [00:40<00:41, 19.44it/s]Training:  61%|██████▏   | 982/1600 [00:50<00:32, 19.22it/s]Training:  73%|███████▎  | 1171/1600 [01:01<00:22, 18.70it/s]Training:  85%|████████▍ | 1353/1600 [01:11<00:13, 18.52it/s]Training:  96%|█████████▌| 1536/1600 [01:21<00:03, 18.43it/s]                                                             EValidation loss: 201.4969, Validation accuracy: 0.6300
Macro F1-score: 0.6180
Model performance on Angry speech (in validation): 
	Precision: 0.8158, Recall: 0.6200, F1_score: 0.7045
Model performance on Happy speech (in validation): 
	Precision: 0.7727, Recall: 0.3400, F1_score: 0.4722
Model performance on Neutral speech (in validation): 
	Precision: 0.5667, Recall: 0.6800, F1_score: 0.6182
Model performance on Sad speech (in validation): 
	Precision: 0.5500, Recall: 0.8800, F1_score: 0.6769
New best accuracy for layer 8 on epoch 5: 0.6300. Model saved.
Epoch 6/100

Training Phase:
Training loss: 1199.8506, Training accuracy: 0.6875
Macro F1-score: 0.6847
Model performance on Angry speech (in training): 
	Precision: 0.7598, Recall: 0.7750, F1_score: 0.7673
Model performance on Happy speech (in training): 
	Precision: 0.6575, Recall: 0.5375, F1_score: 0.5915
Model performance on Neutral speech (in training): 
	Precision: 0.6000, Recall: 0.6375, F1_score: 0.6182
Model performance on Sad speech (in training): 
	Precision: 0.7273, Recall: 0.8000, F1_score: 0.7619

Eval Phase: 
Validation loss: 182.7431, Validation accuracy: 0.6250
Macro F1-score: 0.6164
Model performance on Angry speech (in validation): 
	Precision: 0.8250, Recall: 0.6600, F1_score: 0.7333
Model performance on Happy speech (in validation): 
	Precision: 0.6250, Recall: 0.4000, F1_score: 0.4878
Model performance on Neutral speech (in validation): 
	Precision: 0.5870, Recall: 0.5400, F1_score: 0.5625
Model performance on Sad speech (in validation): 
	Precision: 0.5488, Recall: 0.9000, F1_score: 0.6818
Epoch 7/100

Training Phase:
valuating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 189/1600 [00:10<01:14, 18.86it/s]Training:  24%|██▎       | 378/1600 [00:20<01:06, 18.49it/s]Training:  35%|███▌      | 561/1600 [00:30<00:56, 18.30it/s]Training:  47%|████▋     | 748/1600 [00:40<00:46, 18.43it/s]Training:  58%|█████▊    | 936/1600 [00:50<00:35, 18.54it/s]Training:  70%|███████   | 1124/1600 [01:00<00:25, 18.57it/s]Training:  82%|████████▏ | 1311/1600 [01:10<00:15, 18.56it/s]Training:  94%|█████████▎| 1497/1600 [01:20<00:05, 18.47it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 185/1600 [00:10<01:16, 18.47it/s]TrTraining loss: 1087.4785, Training accuracy: 0.7244
Macro F1-score: 0.7224
Model performance on Angry speech (in training): 
	Precision: 0.7941, Recall: 0.8100, F1_score: 0.8020
Model performance on Happy speech (in training): 
	Precision: 0.6941, Recall: 0.6125, F1_score: 0.6507
Model performance on Neutral speech (in training): 
	Precision: 0.6709, Recall: 0.6625, F1_score: 0.6667
Model performance on Sad speech (in training): 
	Precision: 0.7320, Recall: 0.8125, F1_score: 0.7701

Eval Phase: 
Validation loss: 213.6501, Validation accuracy: 0.6200
Macro F1-score: 0.6054
Model performance on Angry speech (in validation): 
	Precision: 0.7083, Recall: 0.6800, F1_score: 0.6939
Model performance on Happy speech (in validation): 
	Precision: 0.8889, Recall: 0.3200, F1_score: 0.4706
Model performance on Neutral speech (in validation): 
	Precision: 0.5636, Recall: 0.6200, F1_score: 0.5905
Model performance on Sad speech (in validation): 
	Precision: 0.5443, Recall: 0.8600, F1_score: 0.6667
Epoch 8/100

Training Phase:
aining:  23%|██▎       | 370/1600 [00:20<01:07, 18.18it/s]Training:  34%|███▍      | 550/1600 [00:30<00:58, 18.06it/s]Training:  46%|████▌     | 730/1600 [00:40<00:48, 17.96it/s]Training:  57%|█████▋    | 912/1600 [00:50<00:38, 18.02it/s]Training:  68%|██████▊   | 1094/1600 [01:00<00:28, 18.02it/s]Training:  80%|████████  | 1288/1600 [01:10<00:16, 18.45it/s]Training:  93%|█████████▎| 1482/1600 [01:20<00:06, 18.67it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 196/1600 [00:10<01:12, 19.40it/s]Training:  25%|██▍       | 394/1600 [00:20<01:01, 19.62it/s]Training:  37%|███▋      | 592/1600 [00:30<00:51, 19.49it/s]Training:  49%|████▉     | 786/1600 [00:40<00:42, 19.08it/s]Training:  61%|█Training loss: 1074.4894, Training accuracy: 0.7262
Macro F1-score: 0.7243
Model performance on Angry speech (in training): 
	Precision: 0.7729, Recall: 0.8000, F1_score: 0.7862
Model performance on Happy speech (in training): 
	Precision: 0.7159, Recall: 0.6175, F1_score: 0.6631
Model performance on Neutral speech (in training): 
	Precision: 0.6527, Recall: 0.6625, F1_score: 0.6576
Model performance on Sad speech (in training): 
	Precision: 0.7586, Recall: 0.8250, F1_score: 0.7904

Eval Phase: 
Validation loss: 202.8936, Validation accuracy: 0.6450
Macro F1-score: 0.6354
Model performance on Angry speech (in validation): 
	Precision: 0.7778, Recall: 0.7000, F1_score: 0.7368
Model performance on Happy speech (in validation): 
	Precision: 0.8696, Recall: 0.4000, F1_score: 0.5479
Model performance on Neutral speech (in validation): 
	Precision: 0.6279, Recall: 0.5400, F1_score: 0.5806
Model performance on Sad speech (in validation): 
	Precision: 0.5281, Recall: 0.9400, F1_score: 0.6763
New best accuracy for layer 8 on epoch 8: 0.6450. Model saved.
Epoch 9/100

Training Phase:
████    | 973/1600 [00:50<00:33, 18.95it/s]Training:  73%|███████▎  | 1171/1600 [01:00<00:22, 19.22it/s]Training:  86%|████████▌ | 1369/1600 [01:11<00:12, 19.17it/s]Training:  98%|█████████▊| 1560/1600 [01:21<00:02, 19.15it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 189/1600 [00:10<01:14, 18.90it/s]Training:  24%|██▎       | 378/1600 [00:20<01:05, 18.56it/s]Training:  36%|███▌      | 570/1600 [00:30<00:54, 18.84it/s]Training:  48%|████▊     | 770/1600 [00:40<00:43, 19.26it/s]Training:  61%|██████    | 970/1600 [00:50<00:32, 19.13it/s]Training:  73%|███████▎  | 1171/1600 [01:00<00:22, 19.43it/s]Training:  86%|████████▌ | 1372/1600 [01:11<00:11, 19.25it/s]TrainingTraining loss: 999.6165, Training accuracy: 0.7550
Macro F1-score: 0.7529
Model performance on Angry speech (in training): 
	Precision: 0.8168, Recall: 0.8250, F1_score: 0.8209
Model performance on Happy speech (in training): 
	Precision: 0.7456, Recall: 0.6300, F1_score: 0.6829
Model performance on Neutral speech (in training): 
	Precision: 0.6763, Recall: 0.7000, F1_score: 0.6880
Model performance on Sad speech (in training): 
	Precision: 0.7793, Recall: 0.8650, F1_score: 0.8199

Eval Phase: 
Validation loss: 257.8238, Validation accuracy: 0.6100
Macro F1-score: 0.6011
Model performance on Angry speech (in validation): 
	Precision: 0.8000, Recall: 0.6400, F1_score: 0.7111
Model performance on Happy speech (in validation): 
	Precision: 0.7778, Recall: 0.4200, F1_score: 0.5455
Model performance on Neutral speech (in validation): 
	Precision: 0.6562, Recall: 0.4200, F1_score: 0.5122
Model performance on Sad speech (in validation): 
	Precision: 0.4752, Recall: 0.9600, F1_score: 0.6358
Epoch 10/100

Training Phase:
Training loss: 944.7706, Training accuracy: 0.7650
Macro F1-score: 0.7639
Model performance on Angry speech (in training): 
	Precision: 0.8440, Recall: 0.8250, F1_score: 0.8344
Model performance on Happy speech (in training): 
	Precision: 0.7479, Recall: 0.6675, F1_score: 0.7054
Model performance on Neutral speech (in training): 
	Precision: 0.6878, Recall: 0.7050, F1_score: 0.6963
Model performance on Sad speech (in training): 
	Precision: 0.7805, Recall: 0.8625, F1_score: 0.8195

Eval Phase: 
:  98%|█████████▊| 1569/1600 [01:21<00:01, 19.36it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 191/1600 [00:10<01:13, 19.06it/s]Training:  24%|██▍       | 383/1600 [00:20<01:03, 19.11it/s]Training:  36%|███▌      | 575/1600 [00:30<00:53, 19.12it/s]Training:  48%|████▊     | 768/1600 [00:40<00:43, 19.18it/s]Training:  61%|██████    | 969/1600 [00:50<00:32, 19.41it/s]Training:  73%|███████▎  | 1168/1600 [01:00<00:22, 19.54it/s]Training:  85%|████████▌ | 1366/1600 [01:10<00:12, 19.22it/s]Training:  98%|█████████▊| 1561/1600 [01:20<00:02, 19.29it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                               Validation loss: 195.3554, Validation accuracy: 0.6550
Macro F1-score: 0.6476
Model performance on Angry speech (in validation): 
	Precision: 0.6981, Recall: 0.7400, F1_score: 0.7184
Model performance on Happy speech (in validation): 
	Precision: 0.7419, Recall: 0.4600, F1_score: 0.5679
Model performance on Neutral speech (in validation): 
	Precision: 0.6304, Recall: 0.5800, F1_score: 0.6042
Model performance on Sad speech (in validation): 
	Precision: 0.6000, Recall: 0.8400, F1_score: 0.7000
New best accuracy for layer 8 on epoch 10: 0.6550. Model saved.
Epoch 11/100

Training Phase:
Training loss: 915.5181, Training accuracy: 0.7756
Macro F1-score: 0.7741
Model performance on Angry speech (in training): 
	Precision: 0.8507, Recall: 0.8550, F1_score: 0.8529
Model performance on Happy speech (in training): 
	Precision: 0.7556, Recall: 0.6725, F1_score: 0.7116
Model performance on Neutral speech (in training): 
	Precision: 0.7168, Recall: 0.7150, F1_score: 0.7159
Model performance on Sad speech (in training): 
	Precision: 0.7765, Recall: 0.8600, F1_score: 0.8161

Eval Phase: 
Validation loss: 243.6500, Validation accuracy: 0.6450
Macro F1-score: 0.6369
Model performance on Angry speech (in validation): 
	Precision: 0.8750, Recall: 0.5600, F1_score: 0.6829
Model performance on Happy speech (in validation): 
	Precision: 0.7241, Recall: 0.4200, F1_score: 0.5316
Model performance on Neutral speech (in validation): 
	Precision: 0.6346, Recall: 0.6600, F1_score: 0.6471
Model performance on Sad speech (in validation): 
	Precision: 0.5402, Recall: 0.9400, F1_score: 0.6861
Epoch 12/100

Training Phase:
                    Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 196/1600 [00:10<01:11, 19.58it/s]Training:  24%|██▍       | 392/1600 [00:20<01:02, 19.26it/s]Training:  37%|███▋      | 585/1600 [00:30<00:52, 19.26it/s]Training:  49%|████▊     | 779/1600 [00:40<00:42, 19.31it/s]Training:  61%|██████    | 973/1600 [00:50<00:32, 19.25it/s]Training:  73%|███████▎  | 1172/1600 [01:00<00:22, 19.44it/s]Training:  86%|████████▌ | 1371/1600 [01:10<00:11, 19.40it/s]Training:  98%|█████████▊| 1565/1600 [01:21<00:01, 19.20it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 196/1600 [00:10<01:11, 19.54it/s]Training:  24%|██▍       | 392/1600 [00:20<01:02, 19.47it/s]Training:  37%|Training loss: 863.3670, Training accuracy: 0.7863
Macro F1-score: 0.7857
Model performance on Angry speech (in training): 
	Precision: 0.8496, Recall: 0.8475, F1_score: 0.8486
Model performance on Happy speech (in training): 
	Precision: 0.7660, Recall: 0.7200, F1_score: 0.7423
Model performance on Neutral speech (in training): 
	Precision: 0.7264, Recall: 0.7300, F1_score: 0.7282
Model performance on Sad speech (in training): 
	Precision: 0.8014, Recall: 0.8475, F1_score: 0.8238

Eval Phase: 
Validation loss: 238.1789, Validation accuracy: 0.6250
Macro F1-score: 0.6001
Model performance on Angry speech (in validation): 
	Precision: 0.6604, Recall: 0.7000, F1_score: 0.6796
Model performance on Happy speech (in validation): 
	Precision: 0.8667, Recall: 0.2600, F1_score: 0.4000
Model performance on Neutral speech (in validation): 
	Precision: 0.5593, Recall: 0.6600, F1_score: 0.6055
Model performance on Sad speech (in validation): 
	Precision: 0.6027, Recall: 0.8800, F1_score: 0.7154
Epoch 13/100

Training Phase:
███▋      | 590/1600 [00:30<00:51, 19.61it/s]Training:  49%|████▉     | 788/1600 [00:40<00:42, 19.15it/s]Training:  61%|██████▏   | 981/1600 [00:50<00:32, 19.20it/s]Training:  61%|██████▏   | 981/1600 [01:00<00:32, 19.20it/s]Training:  73%|███████▎  | 1168/1600 [01:00<00:22, 19.00it/s]Training:  85%|████████▌ | 1363/1600 [01:10<00:12, 19.15it/s]Training:  98%|█████████▊| 1562/1600 [01:20<00:01, 19.38it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 189/1600 [00:10<01:14, 18.86it/s]Training:  24%|██▍       | 380/1600 [00:20<01:04, 19.00it/s]Training:  36%|███▌      | 571/1600 [00:30<00:54, 18.93it/s]Training:  48%|████▊     | 765/1600 [00:40<00:43, 19.09it/s]Training:  60%|█Training loss: 799.6275, Training accuracy: 0.8037
Macro F1-score: 0.8033
Model performance on Angry speech (in training): 
	Precision: 0.8832, Recall: 0.8700, F1_score: 0.8766
Model performance on Happy speech (in training): 
	Precision: 0.8089, Recall: 0.7300, F1_score: 0.7674
Model performance on Neutral speech (in training): 
	Precision: 0.7129, Recall: 0.7325, F1_score: 0.7226
Model performance on Sad speech (in training): 
	Precision: 0.8134, Recall: 0.8825, F1_score: 0.8465

Eval Phase: 
Validation loss: 224.8986, Validation accuracy: 0.6350
Macro F1-score: 0.6315
Model performance on Angry speech (in validation): 
	Precision: 0.7083, Recall: 0.6800, F1_score: 0.6939
Model performance on Happy speech (in validation): 
	Precision: 0.6486, Recall: 0.4800, F1_score: 0.5517
Model performance on Neutral speech (in validation): 
	Precision: 0.5849, Recall: 0.6200, F1_score: 0.6019
Model performance on Sad speech (in validation): 
	Precision: 0.6129, Recall: 0.7600, F1_score: 0.6786
Epoch 14/100

Training Phase:
████▉    | 959/1600 [00:51<00:35, 18.06it/s]Training:  72%|███████▏  | 1150/1600 [01:01<00:24, 18.38it/s]Training:  84%|████████▍ | 1342/1600 [01:11<00:13, 18.64it/s]Training:  96%|█████████▌| 1538/1600 [01:22<00:03, 18.92it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 193/1600 [00:10<01:13, 19.25it/s]Training:  24%|██▍       | 386/1600 [00:20<01:04, 18.93it/s]Training:  36%|███▌      | 577/1600 [00:30<00:53, 18.95it/s]Training:  48%|████▊     | 767/1600 [00:40<00:44, 18.78it/s]Training:  60%|█████▉    | 953/1600 [00:50<00:34, 18.71it/s]Training:  71%|███████▏  | 1140/1600 [01:00<00:24, 18.69it/s]Training:  83%|████████▎ | 1327/1600 [01:10<00:14, 18.57it/s]TraininTraining loss: 764.7522, Training accuracy: 0.8150
Macro F1-score: 0.8143
Model performance on Angry speech (in training): 
	Precision: 0.8769, Recall: 0.8725, F1_score: 0.8747
Model performance on Happy speech (in training): 
	Precision: 0.8189, Recall: 0.7350, F1_score: 0.7747
Model performance on Neutral speech (in training): 
	Precision: 0.7482, Recall: 0.7650, F1_score: 0.7565
Model performance on Sad speech (in training): 
	Precision: 0.8180, Recall: 0.8875, F1_score: 0.8513

Eval Phase: 
Validation loss: 230.1192, Validation accuracy: 0.6450
Macro F1-score: 0.6369
Model performance on Angry speech (in validation): 
	Precision: 0.7907, Recall: 0.6800, F1_score: 0.7312
Model performance on Happy speech (in validation): 
	Precision: 0.7692, Recall: 0.4000, F1_score: 0.5263
Model performance on Neutral speech (in validation): 
	Precision: 0.5962, Recall: 0.6200, F1_score: 0.6078
Model performance on Sad speech (in validation): 
	Precision: 0.5570, Recall: 0.8800, F1_score: 0.6822
Epoch 15/100

Training Phase:
Training loss: 753.7028, Training accuracy: 0.8119
Macro F1-score: 0.8112
Model performance on Angry speech (in training): 
	Precision: 0.8753, Recall: 0.8600, F1_score: 0.8676
Model performance on Happy speech (in training): 
	Precision: 0.7909, Recall: 0.7375, F1_score: 0.7633
Model performance on Neutral speech (in training): 
	Precision: 0.7650, Recall: 0.7650, F1_score: 0.7650
Model performance on Sad speech (in training): 
	Precision: 0.8157, Recall: 0.8850, F1_score: 0.8489

Eval Phase: 
g:  94%|█████████▍| 1511/1600 [01:20<00:04, 18.50it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 190/1600 [00:10<01:14, 18.96it/s]Training:  24%|██▍       | 380/1600 [00:20<01:05, 18.73it/s]Training:  35%|███▌      | 566/1600 [00:30<00:55, 18.55it/s]Training:  47%|████▋     | 754/1600 [00:40<00:45, 18.62it/s]Training:  59%|█████▉    | 942/1600 [00:50<00:35, 18.64it/s]Training:  71%|███████   | 1129/1600 [01:01<00:25, 18.33it/s]Training:  82%|████████▏ | 1314/1600 [01:11<00:15, 18.37it/s]Training:  94%|█████████▎| 1499/1600 [01:21<00:05, 18.25it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                Validation loss: 241.2783, Validation accuracy: 0.6550
Macro F1-score: 0.6355
Model performance on Angry speech (in validation): 
	Precision: 0.7170, Recall: 0.7600, F1_score: 0.7379
Model performance on Happy speech (in validation): 
	Precision: 0.8000, Recall: 0.3200, F1_score: 0.4571
Model performance on Neutral speech (in validation): 
	Precision: 0.5926, Recall: 0.6400, F1_score: 0.6154
Model performance on Sad speech (in validation): 
	Precision: 0.6164, Recall: 0.9000, F1_score: 0.7317
Epoch 16/100

Training Phase:
Training loss: 673.3557, Training accuracy: 0.8363
Macro F1-score: 0.8359
Model performance on Angry speech (in training): 
	Precision: 0.9040, Recall: 0.8950, F1_score: 0.8995
Model performance on Happy speech (in training): 
	Precision: 0.8338, Recall: 0.7650, F1_score: 0.7979
Model performance on Neutral speech (in training): 
	Precision: 0.7670, Recall: 0.7900, F1_score: 0.7783
Model performance on Sad speech (in training): 
	Precision: 0.8424, Recall: 0.8950, F1_score: 0.8679

Eval Phase: 
Validation loss: 329.0737, Validation accuracy: 0.6350
Macro F1-score: 0.6323
Model performance on Angry speech (in validation): 
	Precision: 0.8750, Recall: 0.5600, F1_score: 0.6829
Model performance on Happy speech (in validation): 
	Precision: 0.7586, Recall: 0.4400, F1_score: 0.5570
Model performance on Neutral speech (in validation): 
	Precision: 0.6739, Recall: 0.6200, F1_score: 0.6458
Model performance on Sad speech (in validation): 
	Precision: 0.4946, Recall: 0.9200, F1_score: 0.6434
Validation loss does not decrease for 10 epochs. End training.
Model best accuracy on validation set: 0.6550

Test Phase: 
Test loss: 210.3008, Test accuracy: 0.6100
Macro F1-score: 0.6038
Model performance on Angry speech (in test): 
	Precision: 0.6154, Recall: 0.8000, F1_score: 0.6957
Model performance on Happy speech (in test): 
	Precision: 0.7097, Recall: 0.4400, F1_score: 0.5432
Model performance on Neutral speech (in test): 
	Precision: 0.5192, Recall: 0.5400, F1_score: 0.5294
Model performance on Sad speech (in test): 
	Precision: 0.6346, Recall: 0.6600, F1_score: 0.6471

======================= This is fold_3 on en =======================

Load dataset: 
Loading en train data: fold_3...
Preprocess en fold_3 data for en model
Loading en eval data: fold_3...
Preprocess en fold_3 data for en model
Loading en test data: fold_3...
Preprocess en fold_3 data for en model
Use en model to add lora
Set optimizer and criterion
Epoch 1/100

Training Phase:
                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  11%|█▏        | 183/1600 [00:10<01:17, 18.23it/s]Training:  23%|██▎       | 375/1600 [00:20<01:05, 18.75it/s]Training:  35%|███▌      | 567/1600 [00:30<00:54, 18.83it/s]Training:  35%|███▌      | 567/1600 [00:40<00:54, 18.83it/s]Training:  47%|████▋     | 753/1600 [00:40<00:45, 18.68it/s]Training:  59%|█████▊    | 938/1600 [00:50<00:36, 18.27it/s]Training:  70%|███████   | 1120/1600 [01:00<00:26, 18.22it/s]Training:  82%|████████▏ | 1305/1600 [01:10<00:16, 18.31it/s]Training:  93%|█████████▎| 1490/1600 [01:20<00:05, 18.35it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]                                                Training:   0%|          | 0/1600Training loss: 1514.9539, Training accuracy: 0.5950
Macro F1-score: 0.5897
Model performance on Angry speech (in training): 
	Precision: 0.6212, Recall: 0.6725, F1_score: 0.6459
Model performance on Happy speech (in training): 
	Precision: 0.5273, Recall: 0.4350, F1_score: 0.4767
Model performance on Neutral speech (in training): 
	Precision: 0.5431, Recall: 0.5200, F1_score: 0.5313
Model performance on Sad speech (in training): 
	Precision: 0.6630, Recall: 0.7525, F1_score: 0.7049

Eval Phase: 
Validation loss: 192.8166, Validation accuracy: 0.5800
Macro F1-score: 0.5618
Model performance on Angry speech (in validation): 
	Precision: 0.8333, Recall: 0.6000, F1_score: 0.6977
Model performance on Happy speech (in validation): 
	Precision: 0.6897, Recall: 0.4000, F1_score: 0.5063
Model performance on Neutral speech (in validation): 
	Precision: 0.4444, Recall: 0.3200, F1_score: 0.3721
Model performance on Sad speech (in validation): 
	Precision: 0.5051, Recall: 1.0000, F1_score: 0.6711
New best accuracy for layer 8 on epoch 1: 0.5800. Model saved.
Epoch 2/100

Training Phase:
 [00:00<?, ?it/s]Training:   8%|▊         | 131/1600 [00:10<01:52, 13.02it/s]Training:  17%|█▋        | 277/1600 [00:20<01:35, 13.93it/s]Training:  27%|██▋       | 435/1600 [00:30<01:18, 14.75it/s]Training:  37%|███▋      | 598/1600 [00:40<01:05, 15.35it/s]Training:  48%|████▊     | 768/1600 [00:50<00:52, 15.92it/s]Training:  59%|█████▊    | 938/1600 [01:00<00:40, 16.15it/s]Training:  70%|██████▉   | 1114/1600 [01:10<00:29, 16.61it/s]Training:  81%|████████  | 1290/1600 [01:20<00:18, 16.71it/s]Training:  92%|█████████▏| 1465/1600 [01:30<00:07, 16.92it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 185/1600 [00:10<01:16, 18.43it/s]Training:  23%|██▎       | 373/1600 [00:20<01:05, 18.64it/s]Training:  Training loss: 1385.9843, Training accuracy: 0.6488
Macro F1-score: 0.6435
Model performance on Angry speech (in training): 
	Precision: 0.6981, Recall: 0.7400, F1_score: 0.7184
Model performance on Happy speech (in training): 
	Precision: 0.5988, Recall: 0.4850, F1_score: 0.5359
Model performance on Neutral speech (in training): 
	Precision: 0.6047, Recall: 0.5775, F1_score: 0.5908
Model performance on Sad speech (in training): 
	Precision: 0.6745, Recall: 0.7925, F1_score: 0.7287

Eval Phase: 
Validation loss: 162.0846, Validation accuracy: 0.6300
Macro F1-score: 0.6193
Model performance on Angry speech (in validation): 
	Precision: 0.8378, Recall: 0.6200, F1_score: 0.7126
Model performance on Happy speech (in validation): 
	Precision: 0.7308, Recall: 0.3800, F1_score: 0.5000
Model performance on Neutral speech (in validation): 
	Precision: 0.5179, Recall: 0.5800, F1_score: 0.5472
Model performance on Sad speech (in validation): 
	Precision: 0.5802, Recall: 0.9400, F1_score: 0.7176
New best accuracy for layer 8 on epoch 2: 0.6300. Model saved.
Epoch 3/100

Training Phase:
35%|███▌      | 562/1600 [00:30<00:55, 18.75it/s]Training:  47%|████▋     | 751/1600 [00:40<00:45, 18.73it/s]Training:  59%|█████▊    | 939/1600 [00:50<00:35, 18.71it/s]Training:  70%|███████   | 1127/1600 [01:00<00:25, 18.72it/s]Training:  83%|████████▎ | 1322/1600 [01:10<00:14, 18.94it/s]Training:  95%|█████████▍| 1516/1600 [01:20<00:04, 18.74it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 186/1600 [00:10<01:16, 18.58it/s]Training:  23%|██▎       | 375/1600 [00:20<01:05, 18.73it/s]Training:  35%|███▌      | 564/1600 [00:30<00:56, 18.40it/s]Training:  47%|████▋     | 750/1600 [00:40<00:46, 18.46it/s]Training:  59%|█████▊    | 937/1600 [00:50<00:35, 18.53it/s]Training:  70%|█Training loss: 1339.2304, Training accuracy: 0.6494
Macro F1-score: 0.6437
Model performance on Angry speech (in training): 
	Precision: 0.7190, Recall: 0.7550, F1_score: 0.7366
Model performance on Happy speech (in training): 
	Precision: 0.6106, Recall: 0.4625, F1_score: 0.5263
Model performance on Neutral speech (in training): 
	Precision: 0.5780, Recall: 0.5925, F1_score: 0.5852
Model performance on Sad speech (in training): 
	Precision: 0.6745, Recall: 0.7875, F1_score: 0.7266

Eval Phase: 
Validation loss: 153.3557, Validation accuracy: 0.6750
Macro F1-score: 0.6616
Model performance on Angry speech (in validation): 
	Precision: 0.7455, Recall: 0.8200, F1_score: 0.7810
Model performance on Happy speech (in validation): 
	Precision: 0.8214, Recall: 0.4600, F1_score: 0.5897
Model performance on Neutral speech (in validation): 
	Precision: 0.6667, Recall: 0.4800, F1_score: 0.5581
Model performance on Sad speech (in validation): 
	Precision: 0.5802, Recall: 0.9400, F1_score: 0.7176
New best accuracy for layer 8 on epoch 3: 0.6750. Model saved.
Epoch 4/100

Training Phase:
█████   | 1124/1600 [01:00<00:25, 18.52it/s]Training:  82%|████████▏ | 1315/1600 [01:10<00:15, 18.70it/s]Training:  82%|████████▏ | 1315/1600 [01:20<00:15, 18.70it/s]Training:  94%|█████████▍| 1506/1600 [01:20<00:05, 18.75it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  11%|█▏        | 182/1600 [00:10<01:18, 18.12it/s]Training:  23%|██▎       | 372/1600 [00:20<01:05, 18.61it/s]Training:  35%|███▌      | 562/1600 [00:30<00:55, 18.58it/s]Training:  35%|███▌      | 562/1600 [00:40<00:55, 18.58it/s]Training:  47%|████▋     | 747/1600 [00:40<00:46, 18.27it/s]Training:  58%|█████▊    | 932/1600 [00:50<00:36, 18.32it/s]Training:  70%|███████   | 1124/1600 [01:00<00:25, 18.61it/s]Training:  82%|Training loss: 1291.3967, Training accuracy: 0.6725
Macro F1-score: 0.6683
Model performance on Angry speech (in training): 
	Precision: 0.7286, Recall: 0.7450, F1_score: 0.7367
Model performance on Happy speech (in training): 
	Precision: 0.6358, Recall: 0.5325, F1_score: 0.5796
Model performance on Neutral speech (in training): 
	Precision: 0.6098, Recall: 0.5900, F1_score: 0.5997
Model performance on Sad speech (in training): 
	Precision: 0.7015, Recall: 0.8225, F1_score: 0.7572

Eval Phase: 
Validation loss: 186.6143, Validation accuracy: 0.6000
Macro F1-score: 0.5689
Model performance on Angry speech (in validation): 
	Precision: 0.7358, Recall: 0.7800, F1_score: 0.7573
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.2600, F1_score: 0.4127
Model performance on Neutral speech (in validation): 
	Precision: 0.5588, Recall: 0.3800, F1_score: 0.4524
Model performance on Sad speech (in validation): 
	Precision: 0.4900, Recall: 0.9800, F1_score: 0.6533
Epoch 5/100

Training Phase:
Training loss: 1224.0163, Training accuracy: 0.6937
Macro F1-score: 0.6916
Model performance on Angry speech (in training): 
	Precision: 0.7817, Recall: 0.7700, F1_score: 0.7758
Model performance on Happy speech (in training): 
	Precision: 0.6894, Recall: 0.5550, F1_score: 0.6150
Model performance on Neutral speech (in training): 
	Precision: 0.6051, Recall: 0.6475, F1_score: 0.6256
Model performance on Sad speech (in training): 
	Precision: 0.7039, Recall: 0.8025, F1_score: 0.7500

Eval Phase: 
███████▏ | 1316/1600 [01:10<00:15, 18.71it/s]Training:  94%|█████████▍| 1508/1600 [01:20<00:04, 18.84it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 195/1600 [00:10<01:12, 19.42it/s]Training:  25%|██▍       | 394/1600 [00:20<01:01, 19.65it/s]Training:  37%|███▋      | 596/1600 [00:30<00:50, 19.87it/s]Training:  50%|████▉     | 798/1600 [00:40<00:40, 19.71it/s]Training:  62%|██████▏   | 993/1600 [00:51<00:31, 19.21it/s]Training:  74%|███████▎  | 1178/1600 [01:01<00:22, 18.97it/s]Training:  86%|████████▌ | 1376/1600 [01:11<00:11, 19.18it/s]Training:  99%|█████████▊| 1579/1600 [01:21<00:01, 19.51it/s]                                                             EvaluatingValidation loss: 203.5076, Validation accuracy: 0.5800
Macro F1-score: 0.5667
Model performance on Angry speech (in validation): 
	Precision: 0.8857, Recall: 0.6200, F1_score: 0.7294
Model performance on Happy speech (in validation): 
	Precision: 0.8095, Recall: 0.3400, F1_score: 0.4789
Model performance on Neutral speech (in validation): 
	Precision: 0.4750, Recall: 0.3800, F1_score: 0.4222
Model performance on Sad speech (in validation): 
	Precision: 0.4712, Recall: 0.9800, F1_score: 0.6364
Epoch 6/100

Training Phase:
Training loss: 1134.9017, Training accuracy: 0.7094
Macro F1-score: 0.7066
Model performance on Angry speech (in training): 
	Precision: 0.7940, Recall: 0.7900, F1_score: 0.7920
Model performance on Happy speech (in training): 
	Precision: 0.6787, Recall: 0.5650, F1_score: 0.6166
Model performance on Neutral speech (in training): 
	Precision: 0.6320, Recall: 0.6525, F1_score: 0.6421
Model performance on Sad speech (in training): 
	Precision: 0.7281, Recall: 0.8300, F1_score: 0.7757

Eval Phase: 
Validation loss: 165.6571, Validation accuracy: 0.6800
Macro F1-score: 0.6642
Model performance on Angry speech (in validation): 
	Precision: 0.7679, Recall: 0.8600, F1_score: 0.8113
Model performance on Happy speech (in validation): 
	Precision: 0.7857, Recall: 0.4400, F1_score: 0.5641
Model performance on Neutral speech (in validation): 
	Precision: 0.6667, Recall: 0.4800, F1_score: 0.5581
Model performance on Sad speech (in validation): 
	Precision: 0.5875, Recall: 0.9400, F1_score: 0.7231
New best accuracy for layer 8 on epoch 6: 0.6800. Model saved.
Epoch 7/100

Training Phase:
:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 189/1600 [00:10<01:14, 18.84it/s]Training:  24%|██▍       | 383/1600 [00:20<01:03, 19.13it/s]Training:  36%|███▋      | 584/1600 [00:30<00:51, 19.56it/s]Training:  49%|████▉     | 785/1600 [00:40<00:41, 19.58it/s]Training:  61%|██████▏   | 982/1600 [00:50<00:31, 19.62it/s]Training:  74%|███████▎  | 1179/1600 [01:00<00:21, 19.62it/s]Training:  86%|████████▋ | 1383/1600 [01:10<00:10, 19.85it/s]Training:  99%|█████████▉| 1587/1600 [01:20<00:00, 19.71it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 196/1600 [00:10<01:11, 19.59it/s]TraininTraining loss: 1120.8799, Training accuracy: 0.7231
Macro F1-score: 0.7208
Model performance on Angry speech (in training): 
	Precision: 0.7980, Recall: 0.7800, F1_score: 0.7889
Model performance on Happy speech (in training): 
	Precision: 0.7045, Recall: 0.5900, F1_score: 0.6422
Model performance on Neutral speech (in training): 
	Precision: 0.6514, Recall: 0.6775, F1_score: 0.6642
Model performance on Sad speech (in training): 
	Precision: 0.7380, Recall: 0.8450, F1_score: 0.7879

Eval Phase: 
Validation loss: 160.5417, Validation accuracy: 0.6250
Macro F1-score: 0.6250
Model performance on Angry speech (in validation): 
	Precision: 0.9091, Recall: 0.6000, F1_score: 0.7229
Model performance on Happy speech (in validation): 
	Precision: 0.6571, Recall: 0.4600, F1_score: 0.5412
Model performance on Neutral speech (in validation): 
	Precision: 0.4603, Recall: 0.5800, F1_score: 0.5133
Model performance on Sad speech (in validation): 
	Precision: 0.6232, Recall: 0.8600, F1_score: 0.7227
Epoch 8/100

Training Phase:
g:  24%|██▍       | 392/1600 [00:20<01:01, 19.54it/s]Training:  37%|███▋      | 590/1600 [00:30<00:51, 19.64it/s]Training:  49%|████▉     | 788/1600 [00:40<00:41, 19.52it/s]Training:  62%|██████▏   | 989/1600 [00:50<00:31, 19.69it/s]Training:  74%|███████▍  | 1189/1600 [01:00<00:21, 19.54it/s]Training:  86%|████████▋ | 1384/1600 [01:10<00:11, 19.51it/s]Training:  99%|█████████▉| 1585/1600 [01:20<00:00, 19.69it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 193/1600 [00:10<01:12, 19.28it/s]Training:  24%|██▍       | 392/1600 [00:20<01:01, 19.62it/s]Training:  37%|███▋      | 591/1600 [00:30<00:51, 19.66it/s]Training:  49%|████▉     | 790/1600 [00:40<00:41, 19.73it/s]Training:  62%|█Training loss: 1051.2642, Training accuracy: 0.7450
Macro F1-score: 0.7433
Model performance on Angry speech (in training): 
	Precision: 0.8163, Recall: 0.8000, F1_score: 0.8081
Model performance on Happy speech (in training): 
	Precision: 0.7361, Recall: 0.6275, F1_score: 0.6775
Model performance on Neutral speech (in training): 
	Precision: 0.6902, Recall: 0.7075, F1_score: 0.6988
Model performance on Sad speech (in training): 
	Precision: 0.7396, Recall: 0.8450, F1_score: 0.7888

Eval Phase: 
Validation loss: 172.4395, Validation accuracy: 0.6750
Macro F1-score: 0.6554
Model performance on Angry speech (in validation): 
	Precision: 0.7049, Recall: 0.8600, F1_score: 0.7748
Model performance on Happy speech (in validation): 
	Precision: 0.8889, Recall: 0.3200, F1_score: 0.4706
Model performance on Neutral speech (in validation): 
	Precision: 0.5574, Recall: 0.6800, F1_score: 0.6126
Model performance on Sad speech (in validation): 
	Precision: 0.7000, Recall: 0.8400, F1_score: 0.7636
Epoch 9/100

Training Phase:
█████▏   | 989/1600 [00:50<00:31, 19.68it/s]Training:  74%|███████▍  | 1186/1600 [01:00<00:21, 19.53it/s]Training:  87%|████████▋ | 1388/1600 [01:10<00:10, 19.72it/s]Training:  99%|█████████▉| 1590/1600 [01:21<00:00, 19.54it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▎        | 200/1600 [00:10<01:10, 19.90it/s]Training:  25%|██▌       | 402/1600 [00:20<00:59, 20.06it/s]Training:  38%|███▊      | 604/1600 [00:30<00:50, 19.55it/s]Training:  50%|████▉     | 799/1600 [00:40<00:41, 19.52it/s]Training:  62%|██████▏   | 996/1600 [00:50<00:30, 19.56it/s]Training:  75%|███████▍  | 1193/1600 [01:00<00:20, 19.49it/s]Training:  87%|████████▋ | 1392/1600 [01:10<00:10, 19.60it/s]TraTraining loss: 1011.9807, Training accuracy: 0.7475
Macro F1-score: 0.7452
Model performance on Angry speech (in training): 
	Precision: 0.8105, Recall: 0.8125, F1_score: 0.8115
Model performance on Happy speech (in training): 
	Precision: 0.7412, Recall: 0.6300, F1_score: 0.6811
Model performance on Neutral speech (in training): 
	Precision: 0.6970, Recall: 0.6900, F1_score: 0.6935
Model performance on Sad speech (in training): 
	Precision: 0.7408, Recall: 0.8575, F1_score: 0.7949

Eval Phase: 
Validation loss: 189.8164, Validation accuracy: 0.6350
Macro F1-score: 0.6235
Model performance on Angry speech (in validation): 
	Precision: 0.8462, Recall: 0.6600, F1_score: 0.7416
Model performance on Happy speech (in validation): 
	Precision: 0.7826, Recall: 0.3600, F1_score: 0.4932
Model performance on Neutral speech (in validation): 
	Precision: 0.5179, Recall: 0.5800, F1_score: 0.5472
Model performance on Sad speech (in validation): 
	Precision: 0.5732, Recall: 0.9400, F1_score: 0.7121
Epoch 10/100

Training Phase:
Training loss: 995.0095, Training accuracy: 0.7488
Macro F1-score: 0.7475
Model performance on Angry speech (in training): 
	Precision: 0.8299, Recall: 0.8175, F1_score: 0.8237
Model performance on Happy speech (in training): 
	Precision: 0.7596, Recall: 0.6400, F1_score: 0.6947
Model performance on Neutral speech (in training): 
	Precision: 0.6731, Recall: 0.7000, F1_score: 0.6863
Model performance on Sad speech (in training): 
	Precision: 0.7395, Recall: 0.8375, F1_score: 0.7855

Eval Phase: 
ining:  99%|█████████▉| 1591/1600 [01:21<00:00, 19.62it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 196/1600 [00:10<01:11, 19.57it/s]Training:  12%|█▏        | 196/1600 [00:20<01:11, 19.57it/s]Training:  24%|██▍       | 390/1600 [00:20<01:02, 19.42it/s]Training:  36%|███▋      | 584/1600 [00:30<00:52, 19.28it/s]Training:  48%|████▊     | 776/1600 [00:40<00:42, 19.17it/s]Training:  61%|██████    | 978/1600 [00:50<00:31, 19.53it/s]Training:  74%|███████▍  | 1180/1600 [01:00<00:21, 19.56it/s]Training:  86%|████████▋ | 1383/1600 [01:10<00:10, 19.76it/s]Training:  99%|█████████▉| 1585/1600 [01:20<00:00, 19.82it/s]                                                             Evaluating:  Validation loss: 164.8667, Validation accuracy: 0.6850
Macro F1-score: 0.6744
Model performance on Angry speech (in validation): 
	Precision: 0.8750, Recall: 0.8400, F1_score: 0.8571
Model performance on Happy speech (in validation): 
	Precision: 0.7500, Recall: 0.3600, F1_score: 0.4865
Model performance on Neutral speech (in validation): 
	Precision: 0.5373, Recall: 0.7200, F1_score: 0.6154
Model performance on Sad speech (in validation): 
	Precision: 0.6721, Recall: 0.8200, F1_score: 0.7387
New best accuracy for layer 8 on epoch 10: 0.6850. Model saved.
Epoch 11/100

Training Phase:
Training loss: 937.1206, Training accuracy: 0.7625
Macro F1-score: 0.7601
Model performance on Angry speech (in training): 
	Precision: 0.8253, Recall: 0.8150, F1_score: 0.8201
Model performance on Happy speech (in training): 
	Precision: 0.7478, Recall: 0.6450, F1_score: 0.6926
Model performance on Neutral speech (in training): 
	Precision: 0.7096, Recall: 0.7025, F1_score: 0.7060
Model performance on Sad speech (in training): 
	Precision: 0.7651, Recall: 0.8875, F1_score: 0.8218

Eval Phase: 
Validation loss: 192.2049, Validation accuracy: 0.6400
Macro F1-score: 0.6334
Model performance on Angry speech (in validation): 
	Precision: 0.8684, Recall: 0.6600, F1_score: 0.7500
Model performance on Happy speech (in validation): 
	Precision: 0.6667, Recall: 0.4400, F1_score: 0.5301
Model performance on Neutral speech (in validation): 
	Precision: 0.5745, Recall: 0.5400, F1_score: 0.5567
Model performance on Sad speech (in validation): 
	Precision: 0.5610, Recall: 0.9200, F1_score: 0.6970
Epoch 12/100

Training Phase:
 0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 189/1600 [00:10<01:14, 18.89it/s]Training:  24%|██▍       | 386/1600 [00:20<01:02, 19.32it/s]Training:  36%|███▋      | 583/1600 [00:30<00:52, 19.44it/s]Training:  49%|████▊     | 779/1600 [00:40<00:42, 19.25it/s]Training:  61%|██████    | 977/1600 [00:50<00:32, 19.45it/s]Training:  74%|███████▎  | 1177/1600 [01:00<00:21, 19.60it/s]Training:  86%|████████▌ | 1379/1600 [01:10<00:11, 19.77it/s]Training:  99%|█████████▉| 1582/1600 [01:20<00:00, 19.91it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 191/1600 [00:10<01:14, 19.01it/s]Training:  2Training loss: 843.6493, Training accuracy: 0.7944
Macro F1-score: 0.7934
Model performance on Angry speech (in training): 
	Precision: 0.8438, Recall: 0.8375, F1_score: 0.8407
Model performance on Happy speech (in training): 
	Precision: 0.7769, Recall: 0.7050, F1_score: 0.7392
Model performance on Neutral speech (in training): 
	Precision: 0.7562, Recall: 0.7675, F1_score: 0.7618
Model performance on Sad speech (in training): 
	Precision: 0.7995, Recall: 0.8675, F1_score: 0.8321

Eval Phase: 
Validation loss: 192.3586, Validation accuracy: 0.6650
Macro F1-score: 0.6493
Model performance on Angry speech (in validation): 
	Precision: 0.7333, Recall: 0.8800, F1_score: 0.8000
Model performance on Happy speech (in validation): 
	Precision: 0.8095, Recall: 0.3400, F1_score: 0.4789
Model performance on Neutral speech (in validation): 
	Precision: 0.5323, Recall: 0.6600, F1_score: 0.5893
Model performance on Sad speech (in validation): 
	Precision: 0.6842, Recall: 0.7800, F1_score: 0.7290
Epoch 13/100

Training Phase:
4%|██▍       | 391/1600 [00:20<01:01, 19.58it/s]Training:  37%|███▋      | 591/1600 [00:30<00:51, 19.57it/s]Training:  49%|████▉     | 788/1600 [00:40<00:41, 19.61it/s]Training:  62%|██████▏   | 985/1600 [00:50<00:31, 19.54it/s]Training:  74%|███████▍  | 1188/1600 [01:00<00:20, 19.78it/s]Training:  74%|███████▍  | 1188/1600 [01:10<00:20, 19.78it/s]Training:  87%|████████▋ | 1391/1600 [01:10<00:10, 19.73it/s]Training:  99%|█████████▉| 1589/1600 [01:20<00:00, 19.73it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 194/1600 [00:10<01:12, 19.38it/s]Training:  24%|██▍       | 391/1600 [00:20<01:01, 19.53it/s]Training:  37%|███▋      | 588/1600 [00:30<00:51, 19.51it/s]Training:  49%|Training loss: 773.7696, Training accuracy: 0.8144
Macro F1-score: 0.8130
Model performance on Angry speech (in training): 
	Precision: 0.8744, Recall: 0.8700, F1_score: 0.8722
Model performance on Happy speech (in training): 
	Precision: 0.8171, Recall: 0.7150, F1_score: 0.7627
Model performance on Neutral speech (in training): 
	Precision: 0.7574, Recall: 0.7650, F1_score: 0.7612
Model performance on Sad speech (in training): 
	Precision: 0.8103, Recall: 0.9075, F1_score: 0.8561

Eval Phase: 
Validation loss: 208.5908, Validation accuracy: 0.6650
Macro F1-score: 0.6449
Model performance on Angry speech (in validation): 
	Precision: 0.7636, Recall: 0.8400, F1_score: 0.8000
Model performance on Happy speech (in validation): 
	Precision: 0.7917, Recall: 0.3800, F1_score: 0.5135
Model performance on Neutral speech (in validation): 
	Precision: 0.5854, Recall: 0.4800, F1_score: 0.5275
Model performance on Sad speech (in validation): 
	Precision: 0.6000, Recall: 0.9600, F1_score: 0.7385
Validation loss does not decrease for 10 epochs. End training.
Model best accuracy on validation set: 0.6850

Test Phase: 
Test loss: 158.9160, Test accuracy: 0.7100
Macro F1-score: 0.7058
Model performance on Angry speech (in test): 
	Precision: 0.7963, Recall: 0.8600, F1_score: 0.8269
Model performance on Happy speech (in test): 
	Precision: 0.7647, Recall: 0.5200, F1_score: 0.6190
Model performance on Neutral speech (in test): 
	Precision: 0.6071, Recall: 0.6800, F1_score: 0.6415
Model performance on Sad speech (in test): 
	Precision: 0.6964, Recall: 0.7800, F1_score: 0.7358

======================= This is fold_4 on en =======================

Load dataset: 
Loading en train data: fold_4...
Preprocess en fold_4 data for en model
Loading en eval data: fold_4...
Preprocess en fold_4 data for en model
Loading en test data: fold_4...
Preprocess en fold_4 data for en model
Use en model to add lora
Set optimizer and criterion
Epoch 1/100

Training Phase:
███▉     | 783/1600 [00:40<00:42, 19.30it/s]Training:  62%|██████▏   | 985/1600 [00:50<00:31, 19.62it/s]Training:  74%|███████▍  | 1187/1600 [01:00<00:21, 19.53it/s]Training:  87%|████████▋ | 1387/1600 [01:10<00:10, 19.64it/s]Training:  99%|█████████▉| 1586/1600 [01:21<00:00, 19.65it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]                                                Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:   8%|▊         | 131/1600 [00:10<01:53, 12.99it/s]Training:  17%|█▋        | 278/1600 [00:20<01:34, 13.97it/s]Training:  28%|██▊       | 440/1600 [00:30<01:17, 14.96it/s]Training:  38%|███▊      | 602/1600 [00:40<01:05, 15.27it/s]Training:  48%|████▊     | 769/1600 [00:50<00:52, 15.75it/s]TTraining loss: 1431.4951, Training accuracy: 0.6306
Macro F1-score: 0.6260
Model performance on Angry speech (in training): 
	Precision: 0.6877, Recall: 0.7100, F1_score: 0.6986
Model performance on Happy speech (in training): 
	Precision: 0.5976, Recall: 0.5050, F1_score: 0.5474
Model performance on Neutral speech (in training): 
	Precision: 0.5532, Recall: 0.5200, F1_score: 0.5361
Model performance on Sad speech (in training): 
	Precision: 0.6660, Recall: 0.7875, F1_score: 0.7216

Eval Phase: 
Validation loss: 167.8487, Validation accuracy: 0.6550
Macro F1-score: 0.6375
Model performance on Angry speech (in validation): 
	Precision: 0.7593, Recall: 0.8200, F1_score: 0.7885
Model performance on Happy speech (in validation): 
	Precision: 0.7500, Recall: 0.3000, F1_score: 0.4286
Model performance on Neutral speech (in validation): 
	Precision: 0.5333, Recall: 0.8000, F1_score: 0.6400
Model performance on Sad speech (in validation): 
	Precision: 0.6863, Recall: 0.7000, F1_score: 0.6931
New best accuracy for layer 8 on epoch 1: 0.6550. Model saved.
Epoch 2/100

Training Phase:
raining:  59%|█████▉    | 943/1600 [01:00<00:40, 16.25it/s]Training:  70%|███████   | 1122/1600 [01:10<00:28, 16.77it/s]Training:  81%|████████▏ | 1302/1600 [01:20<00:17, 17.13it/s]Training:  93%|█████████▎| 1482/1600 [01:32<00:07, 16.70it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 194/1600 [00:10<01:12, 19.36it/s]Training:  24%|██▍       | 391/1600 [00:20<01:01, 19.54it/s]Training:  37%|███▋      | 588/1600 [00:30<00:52, 19.43it/s]Training:  49%|████▉     | 786/1600 [00:40<00:41, 19.53it/s]Training:  61%|██████▏   | 983/1600 [00:50<00:31, 19.59it/s]Training:  74%|███████▍  | 1180/1600 [01:00<00:21, 19.35it/s]Training:  86%|████████▌ | 1374/1600 [01:10<00:11, 1Training loss: 1325.0851, Training accuracy: 0.6606
Macro F1-score: 0.6567
Model performance on Angry speech (in training): 
	Precision: 0.7275, Recall: 0.7275, F1_score: 0.7275
Model performance on Happy speech (in training): 
	Precision: 0.6294, Recall: 0.5350, F1_score: 0.5784
Model performance on Neutral speech (in training): 
	Precision: 0.5814, Recall: 0.5625, F1_score: 0.5718
Model performance on Sad speech (in training): 
	Precision: 0.6913, Recall: 0.8175, F1_score: 0.7491

Eval Phase: 
Validation loss: 168.7022, Validation accuracy: 0.6500
Macro F1-score: 0.6301
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.7800, F1_score: 0.7647
Model performance on Happy speech (in validation): 
	Precision: 0.7368, Recall: 0.2800, F1_score: 0.4058
Model performance on Neutral speech (in validation): 
	Precision: 0.5233, Recall: 0.9000, F1_score: 0.6618
Model performance on Sad speech (in validation): 
	Precision: 0.7442, Recall: 0.6400, F1_score: 0.6882
Epoch 3/100

Training Phase:
Training loss: 1256.9234, Training accuracy: 0.6813
Macro F1-score: 0.6755
Model performance on Angry speech (in training): 
	Precision: 0.7271, Recall: 0.7525, F1_score: 0.7396
Model performance on Happy speech (in training): 
	Precision: 0.6444, Recall: 0.5075, F1_score: 0.5678
Model performance on Neutral speech (in training): 
	Precision: 0.6121, Recall: 0.6075, F1_score: 0.6098
Model performance on Sad speech (in training): 
	Precision: 0.7236, Recall: 0.8575, F1_score: 0.7849

Eval Phase: 
9.36it/s]Training:  98%|█████████▊| 1569/1600 [01:20<00:01, 19.40it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 195/1600 [00:10<01:12, 19.45it/s]Training:  24%|██▍       | 391/1600 [00:20<01:01, 19.53it/s]Training:  37%|███▋      | 587/1600 [00:30<00:52, 19.23it/s]Training:  49%|████▉     | 780/1600 [00:40<00:42, 19.25it/s]Training:  61%|██████    | 974/1600 [00:50<00:32, 19.29it/s]Training:  73%|███████▎  | 1172/1600 [01:00<00:22, 19.43it/s]Training:  86%|████████▌ | 1370/1600 [01:10<00:11, 19.52it/s]Training:  98%|█████████▊| 1568/1600 [01:20<00:01, 19.45it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]             Validation loss: 187.7916, Validation accuracy: 0.6150
Macro F1-score: 0.5958
Model performance on Angry speech (in validation): 
	Precision: 0.5714, Recall: 0.8800, F1_score: 0.6929
Model performance on Happy speech (in validation): 
	Precision: 0.6818, Recall: 0.3000, F1_score: 0.4167
Model performance on Neutral speech (in validation): 
	Precision: 0.5965, Recall: 0.6800, F1_score: 0.6355
Model performance on Sad speech (in validation): 
	Precision: 0.6818, Recall: 0.6000, F1_score: 0.6383
Epoch 4/100

Training Phase:
Training loss: 1224.5135, Training accuracy: 0.6794
Macro F1-score: 0.6760
Model performance on Angry speech (in training): 
	Precision: 0.7348, Recall: 0.7550, F1_score: 0.7448
Model performance on Happy speech (in training): 
	Precision: 0.6509, Recall: 0.5500, F1_score: 0.5962
Model performance on Neutral speech (in training): 
	Precision: 0.6091, Recall: 0.6000, F1_score: 0.6045
Model performance on Sad speech (in training): 
	Precision: 0.7112, Recall: 0.8125, F1_score: 0.7585

Eval Phase: 
Validation loss: 196.5720, Validation accuracy: 0.5850
Macro F1-score: 0.5593
Model performance on Angry speech (in validation): 
	Precision: 0.8750, Recall: 0.5600, F1_score: 0.6829
Model performance on Happy speech (in validation): 
	Precision: 0.6667, Recall: 0.2000, F1_score: 0.3077
Model performance on Neutral speech (in validation): 
	Precision: 0.4730, Recall: 0.7000, F1_score: 0.5645
Model performance on Sad speech (in validation): 
	Precision: 0.5570, Recall: 0.8800, F1_score: 0.6822
Epoch 5/100

Training Phase:
                                      Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 193/1600 [00:10<01:13, 19.25it/s]Training:  24%|██▍       | 387/1600 [00:20<01:02, 19.33it/s]Training:  37%|███▋      | 586/1600 [00:30<00:51, 19.55it/s]Training:  37%|███▋      | 586/1600 [00:40<00:51, 19.55it/s]Training:  49%|████▉     | 784/1600 [00:40<00:41, 19.48it/s]Training:  61%|██████▏   | 982/1600 [00:50<00:31, 19.59it/s]Training:  74%|███████▍  | 1180/1600 [01:00<00:21, 19.56it/s]Training:  86%|████████▌ | 1376/1600 [01:10<00:11, 19.30it/s]Training:  98%|█████████▊| 1565/1600 [01:20<00:01, 19.15it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 195/1600 [00:10<01:12, 19.4Training loss: 1186.7414, Training accuracy: 0.7113
Macro F1-score: 0.7082
Model performance on Angry speech (in training): 
	Precision: 0.7698, Recall: 0.7775, F1_score: 0.7736
Model performance on Happy speech (in training): 
	Precision: 0.6896, Recall: 0.5775, F1_score: 0.6286
Model performance on Neutral speech (in training): 
	Precision: 0.6370, Recall: 0.6450, F1_score: 0.6410
Model performance on Sad speech (in training): 
	Precision: 0.7412, Recall: 0.8450, F1_score: 0.7897

Eval Phase: 
Validation loss: 180.9110, Validation accuracy: 0.6050
Macro F1-score: 0.5898
Model performance on Angry speech (in validation): 
	Precision: 0.7292, Recall: 0.7000, F1_score: 0.7143
Model performance on Happy speech (in validation): 
	Precision: 0.7368, Recall: 0.2800, F1_score: 0.4058
Model performance on Neutral speech (in validation): 
	Precision: 0.4937, Recall: 0.7800, F1_score: 0.6047
Model performance on Sad speech (in validation): 
	Precision: 0.6111, Recall: 0.6600, F1_score: 0.6346
Epoch 6/100

Training Phase:
2it/s]Training:  25%|██▍       | 394/1600 [00:20<01:01, 19.68it/s]Training:  37%|███▋      | 593/1600 [00:30<00:52, 19.24it/s]Training:  49%|████▉     | 784/1600 [00:40<00:42, 19.16it/s]Training:  62%|██████▏   | 984/1600 [00:50<00:31, 19.43it/s]Training:  74%|███████▍  | 1184/1600 [01:01<00:21, 19.45it/s]Training:  86%|████████▌ | 1379/1600 [01:11<00:11, 19.24it/s]Training:  98%|█████████▊| 1575/1600 [01:21<00:01, 19.34it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 190/1600 [00:10<01:14, 18.88it/s]Training:  12%|█▏        | 190/1600 [00:20<01:14, 18.88it/s]Training:  24%|██▍       | 390/1600 [00:20<01:02, 19.50it/s]Training:  37%|███▋      | 590/1600 [00:30<00:51, 19.52it/s]Training: Training loss: 1116.7335, Training accuracy: 0.7150
Macro F1-score: 0.7126
Model performance on Angry speech (in training): 
	Precision: 0.7665, Recall: 0.7550, F1_score: 0.7607
Model performance on Happy speech (in training): 
	Precision: 0.7126, Recall: 0.5950, F1_score: 0.6485
Model performance on Neutral speech (in training): 
	Precision: 0.6432, Recall: 0.6625, F1_score: 0.6527
Model performance on Sad speech (in training): 
	Precision: 0.7370, Recall: 0.8475, F1_score: 0.7884

Eval Phase: 
Validation loss: 191.9592, Validation accuracy: 0.6150
Macro F1-score: 0.5876
Model performance on Angry speech (in validation): 
	Precision: 0.7018, Recall: 0.8000, F1_score: 0.7477
Model performance on Happy speech (in validation): 
	Precision: 0.6111, Recall: 0.2200, F1_score: 0.3235
Model performance on Neutral speech (in validation): 
	Precision: 0.5119, Recall: 0.8600, F1_score: 0.6418
Model performance on Sad speech (in validation): 
	Precision: 0.7073, Recall: 0.5800, F1_score: 0.6374
Epoch 7/100

Training Phase:
 49%|████▉     | 788/1600 [00:40<00:41, 19.61it/s]Training:  62%|██████▏   | 986/1600 [00:50<00:31, 19.63it/s]Training:  74%|███████▍  | 1183/1600 [01:00<00:21, 19.45it/s]Training:  86%|████████▌ | 1375/1600 [01:10<00:11, 19.30it/s]Training:  98%|█████████▊| 1568/1600 [01:20<00:01, 19.29it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  11%|█▏        | 183/1600 [00:10<01:17, 18.17it/s]Training:  23%|██▎       | 370/1600 [00:20<01:06, 18.45it/s]Training:  35%|███▍      | 557/1600 [00:30<00:56, 18.43it/s]Training:  46%|████▋     | 743/1600 [00:40<00:46, 18.48it/s]Training:  58%|█████▊    | 930/1600 [00:50<00:36, 18.54it/s]Training:  70%|██████▉   | 1117/1600 [01:00<00:26, 18.56it/s]TrainingTraining loss: 1068.6388, Training accuracy: 0.7262
Macro F1-score: 0.7237
Model performance on Angry speech (in training): 
	Precision: 0.7717, Recall: 0.7775, F1_score: 0.7746
Model performance on Happy speech (in training): 
	Precision: 0.7321, Recall: 0.6150, F1_score: 0.6685
Model performance on Neutral speech (in training): 
	Precision: 0.6493, Recall: 0.6525, F1_score: 0.6509
Model performance on Sad speech (in training): 
	Precision: 0.7495, Recall: 0.8600, F1_score: 0.8009

Eval Phase: 
Validation loss: 215.1529, Validation accuracy: 0.6100
Macro F1-score: 0.5739
Model performance on Angry speech (in validation): 
	Precision: 0.6557, Recall: 0.8000, F1_score: 0.7207
Model performance on Happy speech (in validation): 
	Precision: 0.8333, Recall: 0.2000, F1_score: 0.3226
Model performance on Neutral speech (in validation): 
	Precision: 0.6279, Recall: 0.5400, F1_score: 0.5806
Model performance on Sad speech (in validation): 
	Precision: 0.5357, Recall: 0.9000, F1_score: 0.6716
Epoch 8/100

Training Phase:
Training loss: 1028.6515, Training accuracy: 0.7281
Macro F1-score: 0.7262
Model performance on Angry speech (in training): 
	Precision: 0.7841, Recall: 0.7900, F1_score: 0.7870
Model performance on Happy speech (in training): 
	Precision: 0.7236, Recall: 0.6350, F1_score: 0.6764
Model performance on Neutral speech (in training): 
	Precision: 0.6641, Recall: 0.6525, F1_score: 0.6583
Model performance on Sad speech (in training): 
	Precision: 0.7373, Recall: 0.8350, F1_score: 0.7831

Eval Phase: 
:  82%|████████▏ | 1304/1600 [01:10<00:15, 18.57it/s]Training:  93%|█████████▎| 1490/1600 [01:20<00:06, 18.30it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  11%|█▏        | 182/1600 [00:10<01:18, 18.14it/s]Training:  23%|██▎       | 364/1600 [00:20<01:09, 17.87it/s]Training:  34%|███▍      | 552/1600 [00:30<00:57, 18.27it/s]Training:  46%|████▋     | 740/1600 [00:40<00:47, 18.13it/s]Training:  58%|█████▊    | 930/1600 [00:50<00:36, 18.42it/s]Training:  70%|███████   | 1120/1600 [01:01<00:26, 18.39it/s]Training:  82%|████████▏ | 1306/1600 [01:11<00:15, 18.45it/s]Training:  93%|█████████▎| 1494/1600 [01:21<00:05, 18.54it/s]                                                             EvaluValidation loss: 185.9290, Validation accuracy: 0.6300
Macro F1-score: 0.6035
Model performance on Angry speech (in validation): 
	Precision: 0.6557, Recall: 0.8000, F1_score: 0.7207
Model performance on Happy speech (in validation): 
	Precision: 0.7059, Recall: 0.2400, F1_score: 0.3582
Model performance on Neutral speech (in validation): 
	Precision: 0.5455, Recall: 0.8400, F1_score: 0.6614
Model performance on Sad speech (in validation): 
	Precision: 0.7111, Recall: 0.6400, F1_score: 0.6737
Epoch 9/100

Training Phase:
Training loss: 963.5675, Training accuracy: 0.7494
Macro F1-score: 0.7481
Model performance on Angry speech (in training): 
	Precision: 0.7990, Recall: 0.7850, F1_score: 0.7919
Model performance on Happy speech (in training): 
	Precision: 0.7586, Recall: 0.6600, F1_score: 0.7059
Model performance on Neutral speech (in training): 
	Precision: 0.6683, Recall: 0.6900, F1_score: 0.6790
Model performance on Sad speech (in training): 
	Precision: 0.7735, Recall: 0.8625, F1_score: 0.8156

Eval Phase: 
Validation loss: 189.2953, Validation accuracy: 0.6500
Macro F1-score: 0.6422
Model performance on Angry speech (in validation): 
	Precision: 0.8293, Recall: 0.6800, F1_score: 0.7473
Model performance on Happy speech (in validation): 
	Precision: 0.5938, Recall: 0.3800, F1_score: 0.4634
Model performance on Neutral speech (in validation): 
	Precision: 0.5714, Recall: 0.8000, F1_score: 0.6667
Model performance on Sad speech (in validation): 
	Precision: 0.6491, Recall: 0.7400, F1_score: 0.6916
Epoch 10/100

Training Phase:
ating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  11%|█▏        | 182/1600 [00:10<01:18, 18.11it/s]Training:  23%|██▎       | 369/1600 [00:20<01:06, 18.38it/s]Training:  35%|███▍      | 556/1600 [00:30<00:56, 18.52it/s]Training:  46%|████▋     | 743/1600 [00:40<00:46, 18.28it/s]Training:  58%|█████▊    | 928/1600 [00:50<00:36, 18.31it/s]Training:  70%|██████▉   | 1112/1600 [01:00<00:26, 18.13it/s]Training:  81%|████████  | 1299/1600 [01:11<00:16, 18.29it/s]Training:  93%|█████████▎| 1486/1600 [01:21<00:06, 18.40it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 188/1600 [00:10<01:15, 18.72it/s]TrainingTraining loss: 963.3467, Training accuracy: 0.7550
Macro F1-score: 0.7542
Model performance on Angry speech (in training): 
	Precision: 0.8117, Recall: 0.7975, F1_score: 0.8045
Model performance on Happy speech (in training): 
	Precision: 0.7660, Recall: 0.6875, F1_score: 0.7246
Model performance on Neutral speech (in training): 
	Precision: 0.6716, Recall: 0.6850, F1_score: 0.6782
Model performance on Sad speech (in training): 
	Precision: 0.7727, Recall: 0.8500, F1_score: 0.8095

Eval Phase: 
Validation loss: 205.7904, Validation accuracy: 0.6450
Macro F1-score: 0.6335
Model performance on Angry speech (in validation): 
	Precision: 0.8095, Recall: 0.6800, F1_score: 0.7391
Model performance on Happy speech (in validation): 
	Precision: 0.6538, Recall: 0.3400, F1_score: 0.4474
Model performance on Neutral speech (in validation): 
	Precision: 0.5227, Recall: 0.9200, F1_score: 0.6667
Model performance on Sad speech (in validation): 
	Precision: 0.7273, Recall: 0.6400, F1_score: 0.6809
Epoch 11/100

Training Phase:
:  24%|██▎       | 376/1600 [00:20<01:06, 18.43it/s]Training:  35%|███▌      | 565/1600 [00:30<00:55, 18.63it/s]Training:  47%|████▋     | 754/1600 [00:40<00:46, 18.34it/s]Training:  59%|█████▊    | 938/1600 [00:50<00:36, 18.32it/s]Training:  70%|███████   | 1121/1600 [01:01<00:26, 18.20it/s]Training:  82%|████████▏ | 1310/1600 [01:11<00:15, 18.41it/s]Training:  94%|█████████▎| 1499/1600 [01:21<00:05, 18.44it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 185/1600 [00:10<01:16, 18.44it/s]Training:  23%|██▎       | 370/1600 [00:20<01:07, 18.26it/s]Training:  34%|███▍      | 552/1600 [00:30<00:58, 17.99it/s]Training:  46%|████▋     | 741/1600 [00:40<00:46, 18.32it/s]Training:  58%|██Training loss: 871.8482, Training accuracy: 0.7669
Macro F1-score: 0.7654
Model performance on Angry speech (in training): 
	Precision: 0.8182, Recall: 0.8100, F1_score: 0.8141
Model performance on Happy speech (in training): 
	Precision: 0.7736, Recall: 0.6750, F1_score: 0.7210
Model performance on Neutral speech (in training): 
	Precision: 0.7107, Recall: 0.7125, F1_score: 0.7116
Model performance on Sad speech (in training): 
	Precision: 0.7665, Recall: 0.8700, F1_score: 0.8150

Eval Phase: 
Validation loss: 213.7784, Validation accuracy: 0.6350
Macro F1-score: 0.6275
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.5000, Recall: 0.3400, F1_score: 0.4048
Model performance on Neutral speech (in validation): 
	Precision: 0.5467, Recall: 0.8200, F1_score: 0.6560
Model performance on Sad speech (in validation): 
	Precision: 0.6800, Recall: 0.6800, F1_score: 0.6800
Validation loss does not decrease for 10 epochs. End training.
Model best accuracy on validation set: 0.6550

Test Phase: 
Test loss: 158.1843, Test accuracy: 0.6850
Macro F1-score: 0.6651
Model performance on Angry speech (in test): 
	Precision: 0.7018, Recall: 0.8000, F1_score: 0.7477
Model performance on Happy speech (in test): 
	Precision: 0.8421, Recall: 0.3200, F1_score: 0.4638
Model performance on Neutral speech (in test): 
	Precision: 0.5921, Recall: 0.9000, F1_score: 0.7143
Model performance on Sad speech (in test): 
	Precision: 0.7500, Recall: 0.7200, F1_score: 0.7347

en, all folds accuracy: ['0.6400', '0.5700', '0.6100', '0.7100', '0.6850']
en, all folds emo precision: {'Angry': ['0.7407', '0.5405', '0.6154', '0.7963', '0.7018'], 'Happy': ['0.5926', '0.7857', '0.7097', '0.7647', '0.8421'], 'Neutral': ['0.5614', '0.4328', '0.5192', '0.6071', '0.5921'], 'Sad': ['0.6452', '0.7556', '0.6346', '0.6964', '0.7500']}
en, all folds emo recall: {'Angry': ['0.8000', '0.8000', '0.8000', '0.8600', '0.8000'], 'Happy': ['0.3200', '0.2200', '0.4400', '0.5200', '0.3200'], 'Neutral': ['0.6400', '0.5800', '0.5400', '0.6800', '0.9000'], 'Sad': ['0.8000', '0.6800', '0.6600', '0.7800', '0.7200']}
en, all folds emo f1score: {'Angry': ['0.7692', '0.6452', '0.6957', '0.8269', '0.7477'], 'Happy': ['0.4156', '0.3438', '0.5432', '0.6190', '0.4638'], 'Neutral': ['0.5981', '0.4957', '0.5294', '0.6415', '0.7143'], 'Sad': ['0.7143', '0.7158', '0.6471', '0.7358', '0.7347']}
██▊    | 930/1600 [00:50<00:36, 18.43it/s]Training:  70%|██████▉   | 1117/1600 [01:00<00:26, 18.42it/s]Training:  82%|████████▏ | 1304/1600 [01:10<00:16, 18.49it/s]Training:  93%|█████████▎| 1491/1600 [01:21<00:05, 18.45it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]                                                