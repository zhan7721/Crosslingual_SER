Loading python/3.10.8-gpu
  Loading requirement: nvidia/nvhpc-nompi/22.2 gcc/10.2.0
    openmpi/4.1.6-cuda-11.6
Loading pytorch/1.13.1-gpu
  Loading requirement: nvidia/cudnn/8.6.0-cuda-11.6 nvidia/tensorrt/8.4.3.1-u2
    libsndfile/1.0.28
------------------MODELS FINETUNED ON EN DATA----------------------
------------------NEXT SCRIPT: RUNNER_CN----------------------
/work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Matplotlib created a temporary cache directory at /dev/shm/zhan7721_5912054/matplotlib-g9j53760 because the default path (/home/tc062/tc062/zhan7721/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Some weights of the model checkpoint at /work/tc062/tc062/zhan7721/saved_models/de were not used when initializing Wav2Vec2Model: ['encoder.layers.10.attention.k_proj.bias', 'encoder.layers.10.attention.k_proj.weight', 'encoder.layers.10.attention.out_proj.bias', 'encoder.layers.10.attention.out_proj.weight', 'encoder.layers.10.attention.q_proj.bias', 'encoder.layers.10.attention.q_proj.weight', 'encoder.layers.10.attention.v_proj.bias', 'encoder.layers.10.attention.v_proj.weight', 'encoder.layers.10.feed_forward.intermediate_dense.bias', 'encoder.layers.10.feed_forward.intermediate_dense.weight', 'encoder.layers.10.feed_forward.output_dense.bias', 'encoder.layers.10.feed_forward.output_dense.weight', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.10.layer_norm.bias', 'encoder.layers.10.layer_norm.weight', 'encoder.layers.11.attention.k_proj.bias', 'encoder.layers.11.attention.k_proj.weight', 'encoder.layers.11.attention.out_proj.bias', 'encoder.layers.11.attention.out_proj.weight', 'encoder.layers.11.attention.q_proj.bias', 'encoder.layers.11.attention.q_proj.weight', 'encoder.layers.11.attention.v_proj.bias', 'encoder.layers.11.attention.v_proj.weight', 'encoder.layers.11.feed_forward.intermediate_dense.bias', 'encoder.layers.11.feed_forward.intermediate_dense.weight', 'encoder.layers.11.feed_forward.output_dense.bias', 'encoder.layers.11.feed_forward.output_dense.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.11.layer_norm.bias', 'encoder.layers.11.layer_norm.weight', 'encoder.layers.5.attention.k_proj.bias', 'encoder.layers.5.attention.k_proj.weight', 'encoder.layers.5.attention.out_proj.bias', 'encoder.layers.5.attention.out_proj.weight', 'encoder.layers.5.attention.q_proj.bias', 'encoder.layers.5.attention.q_proj.weight', 'encoder.layers.5.attention.v_proj.bias', 'encoder.layers.5.attention.v_proj.weight', 'encoder.layers.5.feed_forward.intermediate_dense.bias', 'encoder.layers.5.feed_forward.intermediate_dense.weight', 'encoder.layers.5.feed_forward.output_dense.bias', 'encoder.layers.5.feed_forward.output_dense.weight', 'encoder.layers.5.final_layer_norm.bias', 'encoder.layers.5.final_layer_norm.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.6.attention.k_proj.bias', 'encoder.layers.6.attention.k_proj.weight', 'encoder.layers.6.attention.out_proj.bias', 'encoder.layers.6.attention.out_proj.weight', 'encoder.layers.6.attention.q_proj.bias', 'encoder.layers.6.attention.q_proj.weight', 'encoder.layers.6.attention.v_proj.bias', 'encoder.layers.6.attention.v_proj.weight', 'encoder.layers.6.feed_forward.intermediate_dense.bias', 'encoder.layers.6.feed_forward.intermediate_dense.weight', 'encoder.layers.6.feed_forward.output_dense.bias', 'encoder.layers.6.feed_forward.output_dense.weight', 'encoder.layers.6.final_layer_norm.bias', 'encoder.layers.6.final_layer_norm.weight', 'encoder.layers.6.layer_norm.bias', 'encoder.layers.6.layer_norm.weight', 'encoder.layers.7.attention.k_proj.bias', 'encoder.layers.7.attention.k_proj.weight', 'encoder.layers.7.attention.out_proj.bias', 'encoder.layers.7.attention.out_proj.weight', 'encoder.layers.7.attention.q_proj.bias', 'encoder.layers.7.attention.q_proj.weight', 'encoder.layers.7.attention.v_proj.bias', 'encoder.layers.7.attention.v_proj.weight', 'encoder.layers.7.feed_forward.intermediate_dense.bias', 'encoder.layers.7.feed_forward.intermediate_dense.weight', 'encoder.layers.7.feed_forward.output_dense.bias', 'encoder.layers.7.feed_forward.output_dense.weight', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.7.layer_norm.bias', 'encoder.layers.7.layer_norm.weight', 'encoder.layers.8.attention.k_proj.bias', 'encoder.layers.8.attention.k_proj.weight', 'encoder.layers.8.attention.out_proj.bias', 'encoder.layers.8.attention.out_proj.weight', 'encoder.layers.8.attention.q_proj.bias', 'encoder.layers.8.attention.q_proj.weight', 'encoder.layers.8.attention.v_proj.bias', 'encoder.layers.8.attention.v_proj.weight', 'encoder.layers.8.feed_forward.intermediate_dense.bias', 'encoder.layers.8.feed_forward.intermediate_dense.weight', 'encoder.layers.8.feed_forward.output_dense.bias', 'encoder.layers.8.feed_forward.output_dense.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.8.layer_norm.bias', 'encoder.layers.8.layer_norm.weight', 'encoder.layers.9.attention.k_proj.bias', 'encoder.layers.9.attention.k_proj.weight', 'encoder.layers.9.attention.out_proj.bias', 'encoder.layers.9.attention.out_proj.weight', 'encoder.layers.9.attention.q_proj.bias', 'encoder.layers.9.attention.q_proj.weight', 'encoder.layers.9.attention.v_proj.bias', 'encoder.layers.9.attention.v_proj.weight', 'encoder.layers.9.feed_forward.intermediate_dense.bias', 'encoder.layers.9.feed_forward.intermediate_dense.weight', 'encoder.layers.9.feed_forward.output_dense.bias', 'encoder.layers.9.feed_forward.output_dense.weight', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.layer_norm.bias', 'encoder.layers.9.layer_norm.weight']
- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).

======================= This is fold_0 on cn =======================

Load dataset: 
Loading en train data: fold_0...
Preprocess en fold_0 data for cn model
Loading en eval data: fold_0...
Preprocess en fold_0 data for cn model
Loading en test data: fold_0...
Preprocess en fold_0 data for cn model
Use cn model to add lora
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:   0%|          | 1/1600 [00:47<20:56:26, 47.15s/it]Training:  10%|â–‰         | 155/1600 [00:57<06:41,  3.60it/s] Training:  22%|â–ˆâ–ˆâ–       | 347/1600 [01:07<02:47,  7.48it/s]Training:  34%|â–ˆâ–ˆâ–ˆâ–      | 551/1600 [01:17<01:36, 10.86it/s]Training:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 760/1600 [01:27<01:01, 13.60it/s]Training:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 977/1600 [01:37<00:39, 15.86it/s]Training:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1194/1600 [01:47<00:23, 17.48it/s]Training:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1418/1600 [01:57<00:09, 18.89it/s]                                                             /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Training loss: 2058.2914, Training accuracy: 0.3800
Macro F1-score: 0.2813
Model performance on Angry speech (in training): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Happy speech (in training): 
	Precision: 0.3018, Recall: 0.7500, F1_score: 0.4304
Model performance on Neutral speech (in training): 
	Precision: 0.3448, Recall: 0.0500, F1_score: 0.0873
Model performance on Sad speech (in training): 
	Precision: 0.5255, Recall: 0.7200, F1_score: 0.6076

Eval Phase: 
Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 240.5747, Validation accuracy: 0.3650
Macro F1-score: 0.2808
Model performance on Angry speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Happy speech (in validation): 
	Precision: 0.2987, Recall: 0.9200, F1_score: 0.4510
Model performance on Neutral speech (in validation): 
	Precision: 0.1429, Recall: 0.0400, F1_score: 0.0625
Model performance on Sad speech (in validation): 
	Precision: 0.7812, Recall: 0.5000, F1_score: 0.6098
New best accuracy for layer 4 on epoch 1: 0.3650. Model saved.
Epoch 2/100

Training Phase:
Training loss: 1809.2582, Training accuracy: 0.4606
Macro F1-score: 0.4181
Model performance on Angry speech (in training): 
	Precision: 0.7234, Recall: 0.0850, F1_score: 0.1521
Model performance on Happy speech (in training): 
	Precision: 0.3494, Recall: 0.6150, F1_score: 0.4457
Model performance on Neutral speech (in training): 
	Precision: 0.4373, Recall: 0.3575, F1_score: 0.3934
Model performance on Sad speech (in training): 
	Precision: 0.6015, Recall: 0.7850, F1_score: 0.6811

Eval Phase: 
Validation loss: 201.0874, Validation accuracy: 0.5850
Macro F1-score: 0.5365
Model performance on Angry speech (in validation): 
	Precision: 0.6721, Recall: 0.8200, F1_score: 0.7387
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0800, F1_score: 0.1481
Model performance on Neutral speech (in validation): 
	Precision: 0.4239, Recall: 0.7800, F1_score: 0.5493
Model performance on Sad speech (in validation): 
	Precision: 0.7674, Recall: 0.6600, F1_score: 0.7097
New best accuracy for layer 4 on epoch 2: 0.5850. Model saved.
Epoch 3/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–Œ        | 240/1600 [00:10<00:57, 23.85it/s]Training:  31%|â–ˆâ–ˆâ–ˆ       | 496/1600 [00:20<00:44, 24.83it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 752/1600 [00:30<00:33, 25.10it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1007/1600 [00:40<00:23, 24.86it/s]Training:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1257/1600 [00:50<00:13, 24.90it/s]Training:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1509/1600 [01:00<00:03, 24.98it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|â–ˆâ–Œ        | 251/1600 [00:10<00:53, 25.10it/s]Training:  31%|â–ˆâ–ˆâ–ˆâ–      | 503/1600 [00:20<00:43, 25.14it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 758/1600 [00:30<00:33, 25.30it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1013/1600 [00:40<00:23, 25.20it/s]Training:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆTraining loss: 1622.1189, Training accuracy: 0.5663
Macro F1-score: 0.5512
Model performance on Angry speech (in training): 
	Precision: 0.6315, Recall: 0.6725, F1_score: 0.6513
Model performance on Happy speech (in training): 
	Precision: 0.4770, Recall: 0.2850, F1_score: 0.3568
Model performance on Neutral speech (in training): 
	Precision: 0.4631, Recall: 0.5025, F1_score: 0.4820
Model performance on Sad speech (in training): 
	Precision: 0.6427, Recall: 0.8050, F1_score: 0.7148

Eval Phase: 
Validation loss: 183.2655, Validation accuracy: 0.6300
Macro F1-score: 0.6264
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 0.7500, Recall: 0.3600, F1_score: 0.4865
Model performance on Neutral speech (in validation): 
	Precision: 0.4583, Recall: 0.6600, F1_score: 0.5410
Model performance on Sad speech (in validation): 
	Precision: 0.6333, Recall: 0.7600, F1_score: 0.6909
New best accuracy for layer 4 on epoch 3: 0.6300. Model saved.
Epoch 4/100

Training Phase:
Training loss: 1517.9742, Training accuracy: 0.6012
Macro F1-score: 0.5933
Model performance on Angry speech (in training): 
	Precision: 0.6813, Recall: 0.7000, F1_score: 0.6905
Model performance on Happy speech (in training): 
	Precision: 0.5355, Recall: 0.3775, F1_score: 0.4428
Model performance on Neutral speech (in training): 
	Precision: 0.4885, Recall: 0.5325, F1_score: 0.5096
Model performance on Sad speech (in training): 
	Precision: 0.6752, Recall: 0.7950, F1_score: 0.7302

Eval Phase: 
Validation loss: 185.8392, Validation accuracy: 0.6250
Macro F1-score: 0.5843
Model performance on Angry speech (in validation): 
	Precision: 0.8235, Recall: 0.8400, F1_score: 0.8317
Model performance on Happy speech (in validation): 
	Precision: 0.8000, Recall: 0.1600, F1_score: 0.2667
Model performance on Neutral speech (in validation): 
	Precision: 0.5088, Recall: 0.5800, F1_score: 0.5421
Model performance on Sad speech (in validation): 
	Precision: 0.5610, Recall: 0.9200, F1_score: 0.6970
Epoch 5/100

Training Phase:
â–ˆâ–‰  | 1266/1600 [00:50<00:13, 25.21it/s]Training:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1519/1600 [01:00<00:03, 25.08it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|â–ˆâ–Œ        | 254/1600 [00:10<00:53, 25.32it/s]Training:  32%|â–ˆâ–ˆâ–ˆâ–      | 508/1600 [00:20<00:44, 24.77it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 756/1600 [00:30<00:34, 24.75it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1004/1600 [00:40<00:24, 24.40it/s]Training:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1243/1600 [00:51<00:14, 23.96it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1492/1600 [01:01<00:04, 24.23it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|â–ˆTraining loss: 1451.5927, Training accuracy: 0.6288
Macro F1-score: 0.6200
Model performance on Angry speech (in training): 
	Precision: 0.7041, Recall: 0.7375, F1_score: 0.7204
Model performance on Happy speech (in training): 
	Precision: 0.5755, Recall: 0.4000, F1_score: 0.4720
Model performance on Neutral speech (in training): 
	Precision: 0.5296, Recall: 0.5600, F1_score: 0.5443
Model performance on Sad speech (in training): 
	Precision: 0.6813, Recall: 0.8175, F1_score: 0.7432

Eval Phase: 
Validation loss: 166.4718, Validation accuracy: 0.6950
Macro F1-score: 0.6918
Model performance on Angry speech (in validation): 
	Precision: 0.9524, Recall: 0.8000, F1_score: 0.8696
Model performance on Happy speech (in validation): 
	Precision: 0.7188, Recall: 0.4600, F1_score: 0.5610
Model performance on Neutral speech (in validation): 
	Precision: 0.6038, Recall: 0.6400, F1_score: 0.6214
Model performance on Sad speech (in validation): 
	Precision: 0.6027, Recall: 0.8800, F1_score: 0.7154
New best accuracy for layer 4 on epoch 5: 0.6950. Model saved.
Epoch 6/100

Training Phase:
â–Œ        | 249/1600 [00:10<00:54, 24.86it/s]Training:  31%|â–ˆâ–ˆâ–ˆ       | 498/1600 [00:20<00:45, 24.15it/s]Training:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 735/1600 [00:30<00:36, 23.86it/s]Training:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 971/1600 [00:40<00:26, 23.62it/s]Training:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1205/1600 [00:50<00:16, 23.54it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1440/1600 [01:00<00:06, 23.52it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–Œ        | 241/1600 [00:10<00:56, 24.04it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 484/1600 [00:20<00:46, 24.17it/s]Training:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 727/1600 [00:30<00:36, 24.01it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 966/1600 [00:40<00:26, 23.74it/s]Training:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1200/1600 [00:50<00:16, 23.58it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Training loss: 1348.4500, Training accuracy: 0.6581
Macro F1-score: 0.6529
Model performance on Angry speech (in training): 
	Precision: 0.7544, Recall: 0.7525, F1_score: 0.7534
Model performance on Happy speech (in training): 
	Precision: 0.6071, Recall: 0.4675, F1_score: 0.5282
Model performance on Neutral speech (in training): 
	Precision: 0.5677, Recall: 0.5975, F1_score: 0.5822
Model performance on Sad speech (in training): 
	Precision: 0.6907, Recall: 0.8150, F1_score: 0.7477

Eval Phase: 
Validation loss: 151.0912, Validation accuracy: 0.7050
Macro F1-score: 0.7080
Model performance on Angry speech (in validation): 
	Precision: 0.9268, Recall: 0.7600, F1_score: 0.8352
Model performance on Happy speech (in validation): 
	Precision: 0.6250, Recall: 0.6000, F1_score: 0.6122
Model performance on Neutral speech (in validation): 
	Precision: 0.5893, Recall: 0.6600, F1_score: 0.6226
Model performance on Sad speech (in validation): 
	Precision: 0.7273, Recall: 0.8000, F1_score: 0.7619
New best accuracy for layer 4 on epoch 6: 0.7050. Model saved.
Epoch 7/100

Training Phase:
Training loss: 1283.9439, Training accuracy: 0.6631
Macro F1-score: 0.6572
Model performance on Angry speech (in training): 
	Precision: 0.7488, Recall: 0.7600, F1_score: 0.7543
Model performance on Happy speech (in training): 
	Precision: 0.5901, Recall: 0.4750, F1_score: 0.5263
Model performance on Neutral speech (in training): 
	Precision: 0.5789, Recall: 0.5775, F1_score: 0.5782
Model performance on Sad speech (in training): 
	Precision: 0.7104, Recall: 0.8400, F1_score: 0.7698

Eval Phase: 
Validation loss: 180.9026, Validation accuracy: 0.6800
Macro F1-score: 0.6736
Model performance on Angry speech (in validation): 
	Precision: 0.9487, Recall: 0.7400, F1_score: 0.8315
Model performance on Happy speech (in validation): 
	Precision: 0.6383, Recall: 0.6000, F1_score: 0.6186
Model performance on Neutral speech (in validation): 
	Precision: 0.7500, Recall: 0.4200, F1_score: 0.5385
Model performance on Sad speech (in validation): 
	Precision: 0.5581, Recall: 0.9600, F1_score: 0.7059
Epoch 8/100

Training Phase:
ˆâ–ˆâ–‰ | 1436/1600 [01:00<00:06, 23.58it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–        | 233/1600 [00:10<00:58, 23.30it/s]Training:  30%|â–ˆâ–ˆâ–‰       | 472/1600 [00:20<00:47, 23.62it/s]Training:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 714/1600 [00:30<00:37, 23.85it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 956/1600 [00:40<00:26, 23.96it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 956/1600 [00:50<00:26, 23.96it/s]Training:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1193/1600 [00:50<00:17, 23.71it/s]Training:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1430/1600 [01:00<00:07, 23.68it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–        | 238Training loss: 1223.7270, Training accuracy: 0.6937
Macro F1-score: 0.6885
Model performance on Angry speech (in training): 
	Precision: 0.7560, Recall: 0.7900, F1_score: 0.7726
Model performance on Happy speech (in training): 
	Precision: 0.6667, Recall: 0.5200, F1_score: 0.5843
Model performance on Neutral speech (in training): 
	Precision: 0.6144, Recall: 0.6175, F1_score: 0.6160
Model performance on Sad speech (in training): 
	Precision: 0.7244, Recall: 0.8475, F1_score: 0.7811

Eval Phase: 
Validation loss: 163.7592, Validation accuracy: 0.7100
Macro F1-score: 0.7126
Model performance on Angry speech (in validation): 
	Precision: 0.9143, Recall: 0.6400, F1_score: 0.7529
Model performance on Happy speech (in validation): 
	Precision: 0.5833, Recall: 0.7000, F1_score: 0.6364
Model performance on Neutral speech (in validation): 
	Precision: 0.6800, Recall: 0.6800, F1_score: 0.6800
Model performance on Sad speech (in validation): 
	Precision: 0.7455, Recall: 0.8200, F1_score: 0.7810
New best accuracy for layer 4 on epoch 8: 0.7100. Model saved.
Epoch 9/100

Training Phase:
/1600 [00:10<00:57, 23.70it/s]Training:  30%|â–ˆâ–ˆâ–‰       | 475/1600 [00:20<00:47, 23.67it/s]Training:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 712/1600 [00:30<00:37, 23.65it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 958/1600 [00:40<00:26, 23.99it/s]Training:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1204/1600 [00:50<00:16, 24.04it/s]Training:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1204/1600 [01:00<00:16, 24.04it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1444/1600 [01:00<00:06, 23.67it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–        | 237/1600 [00:10<00:57, 23.62it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 482/1600 [00:20<00:46, 24.12it/s]Training:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 727/1600 [00:30<00:35, 24.29it/s]Training:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 972/1600 [00:40<00:26, 23.84it/s]Training:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1204/160Training loss: 1126.4321, Training accuracy: 0.7281
Macro F1-score: 0.7245
Model performance on Angry speech (in training): 
	Precision: 0.7935, Recall: 0.7975, F1_score: 0.7955
Model performance on Happy speech (in training): 
	Precision: 0.7152, Recall: 0.5525, F1_score: 0.6234
Model performance on Neutral speech (in training): 
	Precision: 0.6393, Recall: 0.7000, F1_score: 0.6683
Model performance on Sad speech (in training): 
	Precision: 0.7650, Recall: 0.8625, F1_score: 0.8108

Eval Phase: 
Validation loss: 157.7509, Validation accuracy: 0.6850
Macro F1-score: 0.6831
Model performance on Angry speech (in validation): 
	Precision: 0.8636, Recall: 0.7600, F1_score: 0.8085
Model performance on Happy speech (in validation): 
	Precision: 0.6000, Recall: 0.6000, F1_score: 0.6000
Model performance on Neutral speech (in validation): 
	Precision: 0.6279, Recall: 0.5400, F1_score: 0.5806
Model performance on Sad speech (in validation): 
	Precision: 0.6667, Recall: 0.8400, F1_score: 0.7434
Epoch 10/100

Training Phase:
Training loss: 1076.4180, Training accuracy: 0.7300
Macro F1-score: 0.7276
Model performance on Angry speech (in training): 
	Precision: 0.8122, Recall: 0.8000, F1_score: 0.8060
Model performance on Happy speech (in training): 
	Precision: 0.6753, Recall: 0.5875, F1_score: 0.6283
Model performance on Neutral speech (in training): 
	Precision: 0.6683, Recall: 0.6850, F1_score: 0.6765
Model performance on Sad speech (in training): 
	Precision: 0.7567, Recall: 0.8475, F1_score: 0.7995

Eval Phase: 
Validation loss: 155.5568, Validation accuracy: 0.6900
Macro F1-score: 0.6839
Model performance on Angry speech (in validation): 
	Precision: 0.8333, Recall: 0.8000, F1_score: 0.8163
Model performance on Happy speech (in validation): 
	Precision: 0.6765, Recall: 0.4600, F1_score: 0.5476
Model performance on Neutral speech (in validation): 
	Precision: 0.5714, Recall: 0.6400, F1_score: 0.6038
Model performance on Sad speech (in validation): 
	Precision: 0.6935, Recall: 0.8600, F1_score: 0.7679
Epoch 11/100

Training Phase:
0 [00:50<00:16, 23.51it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1447/1600 [01:00<00:06, 23.74it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–        | 237/1600 [00:10<00:57, 23.66it/s]Training:  30%|â–ˆâ–ˆâ–‰       | 477/1600 [00:20<00:47, 23.83it/s]Training:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 717/1600 [00:30<00:37, 23.73it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 958/1600 [00:40<00:26, 23.87it/s]Training:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1199/1600 [00:50<00:16, 23.81it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1437/1600 [01:00<00:06, 23.77it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–        | 237/1600 [00:1Training loss: 1038.0358, Training accuracy: 0.7394
Macro F1-score: 0.7366
Model performance on Angry speech (in training): 
	Precision: 0.8098, Recall: 0.8300, F1_score: 0.8198
Model performance on Happy speech (in training): 
	Precision: 0.7151, Recall: 0.6025, F1_score: 0.6540
Model performance on Neutral speech (in training): 
	Precision: 0.6601, Recall: 0.6700, F1_score: 0.6650
Model performance on Sad speech (in training): 
	Precision: 0.7651, Recall: 0.8550, F1_score: 0.8076

Eval Phase: 
Validation loss: 168.5950, Validation accuracy: 0.6950
Macro F1-score: 0.6807
Model performance on Angry speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Happy speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Model performance on Neutral speech (in validation): 
	Precision: 0.5862, Recall: 0.6800, F1_score: 0.6296
Model performance on Sad speech (in validation): 
	Precision: 0.6301, Recall: 0.9200, F1_score: 0.7480
Epoch 12/100

Training Phase:
0<00:57, 23.65it/s]Training:  30%|â–ˆâ–ˆâ–‰       | 474/1600 [00:20<00:49, 22.90it/s]Training:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 721/1600 [00:30<00:37, 23.67it/s]Training:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 969/1600 [00:40<00:26, 24.07it/s]Training:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1217/1600 [00:51<00:16, 23.80it/s]Training:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1451/1600 [01:01<00:06, 23.66it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–Œ        | 244/1600 [00:10<00:55, 24.39it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 488/1600 [00:20<00:47, 23.49it/s]Training:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 720/1600 [00:30<00:37, 23.34it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 961/1600 [00:40<00:27, 23.61it/s]Training:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1202/1600 [00:51<00:16, 23.53it/s]Training:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1453/1600 [01:01<Training loss: 953.1390, Training accuracy: 0.7788
Macro F1-score: 0.7768
Model performance on Angry speech (in training): 
	Precision: 0.8430, Recall: 0.8325, F1_score: 0.8377
Model performance on Happy speech (in training): 
	Precision: 0.7529, Recall: 0.6550, F1_score: 0.7005
Model performance on Neutral speech (in training): 
	Precision: 0.7248, Recall: 0.7375, F1_score: 0.7311
Model performance on Sad speech (in training): 
	Precision: 0.7911, Recall: 0.8900, F1_score: 0.8376

Eval Phase: 
Validation loss: 241.2963, Validation accuracy: 0.6050
Macro F1-score: 0.5958
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.5400, F1_score: 0.7013
Model performance on Happy speech (in validation): 
	Precision: 0.5778, Recall: 0.5200, F1_score: 0.5474
Model performance on Neutral speech (in validation): 
	Precision: 0.5938, Recall: 0.3800, F1_score: 0.4634
Model performance on Sad speech (in validation): 
	Precision: 0.5104, Recall: 0.9800, F1_score: 0.6712
Epoch 13/100

Training Phase:
Training loss: 926.7253, Training accuracy: 0.7712
Macro F1-score: 0.7687
Model performance on Angry speech (in training): 
	Precision: 0.8387, Recall: 0.8450, F1_score: 0.8418
Model performance on Happy speech (in training): 
	Precision: 0.7412, Recall: 0.6300, F1_score: 0.6811
Model performance on Neutral speech (in training): 
	Precision: 0.7277, Recall: 0.7350, F1_score: 0.7313
Model performance on Sad speech (in training): 
	Precision: 0.7726, Recall: 0.8750, F1_score: 0.8206

Eval Phase: 
Validation loss: 200.7190, Validation accuracy: 0.6800
Macro F1-score: 0.6872
Model performance on Angry speech (in validation): 
	Precision: 0.8649, Recall: 0.6400, F1_score: 0.7356
Model performance on Happy speech (in validation): 
	Precision: 0.6415, Recall: 0.6800, F1_score: 0.6602
Model performance on Neutral speech (in validation): 
	Precision: 0.5077, Recall: 0.6600, F1_score: 0.5739
Model performance on Sad speech (in validation): 
	Precision: 0.8222, Recall: 0.7400, F1_score: 0.7789
Epoch 14/100

Training Phase:
00:06, 24.04it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–        | 237/1600 [00:10<00:57, 23.61it/s]Training:  30%|â–ˆâ–ˆâ–‰       | 474/1600 [00:20<00:48, 23.29it/s]Training:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 725/1600 [00:30<00:36, 24.06it/s]Training:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 975/1600 [00:41<00:26, 23.83it/s]Training:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1222/1600 [00:51<00:15, 24.09it/s]Training:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1468/1600 [01:01<00:05, 23.86it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–Œ        | 241/1600 [00:10<00:56, 23.98it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 484/1600 [00:20<00:46, 24.12it/s]Training loss: 859.5111, Training accuracy: 0.7919
Macro F1-score: 0.7895
Model performance on Angry speech (in training): 
	Precision: 0.8412, Recall: 0.8475, F1_score: 0.8443
Model performance on Happy speech (in training): 
	Precision: 0.7618, Recall: 0.6475, F1_score: 0.7000
Model performance on Neutral speech (in training): 
	Precision: 0.7494, Recall: 0.7775, F1_score: 0.7632
Model performance on Sad speech (in training): 
	Precision: 0.8100, Recall: 0.8950, F1_score: 0.8504

Eval Phase: 
Validation loss: 185.6954, Validation accuracy: 0.7150
Macro F1-score: 0.7158
Model performance on Angry speech (in validation): 
	Precision: 0.8667, Recall: 0.7800, F1_score: 0.8211
Model performance on Happy speech (in validation): 
	Precision: 0.7273, Recall: 0.6400, F1_score: 0.6809
Model performance on Neutral speech (in validation): 
	Precision: 0.5849, Recall: 0.6200, F1_score: 0.6019
Model performance on Sad speech (in validation): 
	Precision: 0.7069, Recall: 0.8200, F1_score: 0.7593
New best accuracy for layer 4 on epoch 14: 0.7150. Model saved.
Epoch 15/100

Training Phase:
Training loss: 828.0267, Training accuracy: 0.8056
Macro F1-score: 0.8034
Model performance on Angry speech (in training): 
	Precision: 0.8617, Recall: 0.8725, F1_score: 0.8671
Model performance on Happy speech (in training): 
	Precision: 0.7830, Recall: 0.6675, F1_score: 0.7206
Model performance on Neutral speech (in training): 
	Precision: 0.7567, Recall: 0.7775, F1_score: 0.7670
Model performance on Sad speech (in training): 
	Precision: 0.8172, Recall: 0.9050, F1_score: 0.8588

Eval Phase: 
Training:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 728/1600 [00:30<00:36, 24.20it/s]Training:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 972/1600 [00:40<00:26, 23.96it/s]Training:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1215/1600 [00:50<00:15, 24.07it/s]Training:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1458/1600 [01:00<00:05, 23.87it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–Œ        | 243/1600 [00:10<00:56, 24.22it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 486/1600 [00:20<00:46, 24.20it/s]Training:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 728/1600 [00:30<00:36, 24.01it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 966/1600 [00:40<00:26, 23.76it/s]Training:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1204/1600 [00:50<00:16, 23.76it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1442/1600 [01:00<00:06, 23.69it/s]                                                             EvaluaValidation loss: 193.7161, Validation accuracy: 0.7050
Macro F1-score: 0.7035
Model performance on Angry speech (in validation): 
	Precision: 0.8837, Recall: 0.7600, F1_score: 0.8172
Model performance on Happy speech (in validation): 
	Precision: 0.6829, Recall: 0.5600, F1_score: 0.6154
Model performance on Neutral speech (in validation): 
	Precision: 0.6275, Recall: 0.6400, F1_score: 0.6337
Model performance on Sad speech (in validation): 
	Precision: 0.6615, Recall: 0.8600, F1_score: 0.7478
Epoch 16/100

Training Phase:
Training loss: 774.3130, Training accuracy: 0.8119
Macro F1-score: 0.8109
Model performance on Angry speech (in training): 
	Precision: 0.8946, Recall: 0.8700, F1_score: 0.8821
Model performance on Happy speech (in training): 
	Precision: 0.7889, Recall: 0.7100, F1_score: 0.7474
Model performance on Neutral speech (in training): 
	Precision: 0.7385, Recall: 0.7625, F1_score: 0.7503
Model performance on Sad speech (in training): 
	Precision: 0.8265, Recall: 0.9050, F1_score: 0.8640

Eval Phase: 
Validation loss: 232.7843, Validation accuracy: 0.6150
Macro F1-score: 0.6087
Model performance on Angry speech (in validation): 
	Precision: 0.9615, Recall: 0.5000, F1_score: 0.6579
Model performance on Happy speech (in validation): 
	Precision: 0.5593, Recall: 0.6600, F1_score: 0.6055
Model performance on Neutral speech (in validation): 
	Precision: 0.5122, Recall: 0.4200, F1_score: 0.4615
Model performance on Sad speech (in validation): 
	Precision: 0.5946, Recall: 0.8800, F1_score: 0.7097
Validation loss does not decrease for 10 epochs. End training.
Model best accuracy on validation set: 0.7150

Test Phase: 
ting:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–        | 238/1600 [00:10<00:57, 23.78it/s]Training:  30%|â–ˆâ–ˆâ–‰       | 476/1600 [00:20<00:48, 23.33it/s]Training:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 717/1600 [00:30<00:37, 23.65it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 958/1600 [00:40<00:26, 23.81it/s]Training:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1199/1600 [00:50<00:17, 23.58it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1439/1600 [01:00<00:06, 23.71it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]                                                Some weights of the model checkpoint at /work/tc062/tc062/zhan7721/saved_models/de were not used when initializing Wav2Vec2Model: ['encoder.layers.10.attention.k_proj.bias', 'encoder.layers.10.attention.k_proj.weight', 'encoder.layers.10.attention.out_proj.bias', 'encoder.layers.10.attention.out_proj.weight', 'encoder.layers.10.attention.q_proj.bias', 'encoder.layers.10.attention.q_proj.weight', 'encoder.layers.10.attention.v_proj.bias', 'encoder.layers.10.attention.v_proj.weight', 'encoder.layers.10.feed_forward.intermediate_dense.bias', 'encoder.layers.10.feed_forward.intermediate_dense.weight', 'encoder.layers.10.feed_forward.output_dense.bias', 'encoder.layers.10.feed_forward.output_dense.weight', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.10.layer_norm.bias', 'encoder.layers.10.layer_norm.weight', 'encoder.layers.11.attention.k_proj.bias', 'encoder.layers.11.attention.k_proj.weight', 'encoder.layers.11.attention.out_proj.bias', 'encoder.layers.11.attention.out_proj.weight', 'encoder.layers.11.attention.q_proj.bias', 'encoder.layers.11.attention.q_proj.weight', 'encoder.layers.11.attention.v_proj.bias', 'encoder.layers.11.attention.v_proj.weight', 'encoder.layers.11.feed_forward.intermediate_dense.bias', 'encoder.layers.11.feed_forward.intermediate_dense.weight', 'encoder.layers.11.feed_forward.output_dense.bias', 'encoder.layers.11.feed_forward.output_dense.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.11.layer_norm.bias', 'encoder.layers.11.layer_norm.weight', 'encoder.layers.5.attention.k_proj.bias', 'encoder.layers.5.attention.k_proj.weight', 'encoder.layers.5.attention.out_proj.bias', 'encoder.layers.5.attention.out_proj.weight', 'encoder.layers.5.attention.q_proj.bias', 'encoder.layers.5.attention.q_proj.weight', 'encoder.layers.5.attention.v_proj.bias', 'encoder.layers.5.attention.v_proj.weight', 'encoder.layers.5.feed_forward.intermediate_dense.bias', 'encoder.layers.5.feed_forward.intermediate_dense.weight', 'encoder.layers.5.feed_forward.output_dense.bias', 'encoder.layers.5.feed_forward.output_dense.weight', 'encoder.layers.5.final_layer_norm.bias', 'encoder.layers.5.final_layer_norm.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.6.attention.k_proj.bias', 'encoder.layers.6.attention.k_proj.weight', 'encoder.layers.6.attention.out_proj.bias', 'encoder.layers.6.attention.out_proj.weight', 'encoder.layers.6.attention.q_proj.bias', 'encoder.layers.6.attention.q_proj.weight', 'encoder.layers.6.attention.v_proj.bias', 'encoder.layers.6.attention.v_proj.weight', 'encoder.layers.6.feed_forward.intermediate_dense.bias', 'encoder.layers.6.feed_forward.intermediate_dense.weight', 'encoder.layers.6.feed_forward.output_dense.bias', 'encoder.layers.6.feed_forward.output_dense.weight', 'encoder.layers.6.final_layer_norm.bias', 'encoder.layers.6.final_layer_norm.weight', 'encoder.layers.6.layer_norm.bias', 'encoder.layers.6.layer_norm.weight', 'encoder.layers.7.attention.k_proj.bias', 'encoder.layers.7.attention.k_proj.weight', 'encoder.layers.7.attention.out_proj.bias', 'encoder.layers.7.attention.out_proj.weight', 'encoder.layers.7.attention.q_proj.bias', 'encoder.layers.7.attention.q_proj.weight', 'encoder.layers.7.attention.v_proj.bias', 'encoder.layers.7.attention.v_proj.weight', 'encoder.layers.7.feed_forward.intermediate_dense.bias', 'encoder.layers.7.feed_forward.intermediate_dense.weight', 'encoder.layers.7.feed_forward.output_dense.bias', 'encoder.layers.7.feed_forward.output_dense.weight', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.7.layer_norm.bias', 'encoder.layers.7.layer_norm.weight', 'encoder.layers.8.attention.k_proj.bias', 'encoder.layers.8.attention.k_proj.weight', 'encoder.layers.8.attention.out_proj.bias', 'encoder.layers.8.attention.out_proj.weight', 'encoder.layers.8.attention.q_proj.bias', 'encoder.layers.8.attention.q_proj.weight', 'encoder.layers.8.attention.v_proj.bias', 'encoder.layers.8.attention.v_proj.weight', 'encoder.layers.8.feed_forward.intermediate_dense.bias', 'encoder.layers.8.feed_forward.intermediate_dense.weight', 'encoder.layers.8.feed_forward.output_dense.bias', 'encoder.layers.8.feed_forward.output_dense.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.8.layer_norm.bias', 'encoder.layers.8.layer_norm.weight', 'encoder.layers.9.attention.k_proj.bias', 'encoder.layers.9.attention.k_proj.weight', 'encoder.layers.9.attention.out_proj.bias', 'encoder.layers.9.attention.out_proj.weight', 'encoder.layers.9.attention.q_proj.bias', 'encoder.layers.9.attention.q_proj.weight', 'encoder.layers.9.attention.v_proj.bias', 'encoder.layers.9.attention.v_proj.weight', 'encoder.layers.9.feed_forward.intermediate_dense.bias', 'encoder.layers.9.feed_forward.intermediate_dense.weight', 'encoder.layers.9.feed_forward.output_dense.bias', 'encoder.layers.9.feed_forward.output_dense.weight', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.layer_norm.bias', 'encoder.layers.9.layer_norm.weight']
- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Test loss: 234.2741, Test accuracy: 0.6550
Macro F1-score: 0.6548
Model performance on Angry speech (in test): 
	Precision: 0.8261, Recall: 0.7600, F1_score: 0.7917
Model performance on Happy speech (in test): 
	Precision: 0.5778, Recall: 0.5200, F1_score: 0.5474
Model performance on Neutral speech (in test): 
	Precision: 0.5472, Recall: 0.5800, F1_score: 0.5631
Model performance on Sad speech (in test): 
	Precision: 0.6786, Recall: 0.7600, F1_score: 0.7170

======================= This is fold_1 on cn =======================

Load dataset: 
Loading en train data: fold_1...
Preprocess en fold_1 data for cn model
Loading en eval data: fold_1...
Preprocess en fold_1 data for cn model
Loading en test data: fold_1...
Preprocess en fold_1 data for cn model
Use cn model to add lora
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training loss: 1662.8375, Training accuracy: 0.5569
Macro F1-score: 0.5511
Model performance on Angry speech (in training): 
	Precision: 0.6329, Recall: 0.6725, F1_score: 0.6521
Model performance on Happy speech (in training): 
	Precision: 0.5157, Recall: 0.4525, F1_score: 0.4820
Model performance on Neutral speech (in training): 
	Precision: 0.4426, Recall: 0.3950, F1_score: 0.4174
Model performance on Sad speech (in training): 
	Precision: 0.6060, Recall: 0.7075, F1_score: 0.6528

Eval Phase: 
Validation loss: 196.3333, Validation accuracy: 0.6000
Macro F1-score: 0.5636
Model performance on Angry speech (in validation): 
	Precision: 0.5054, Recall: 0.9400, F1_score: 0.6573
Model performance on Happy speech (in validation): 
	Precision: 0.4815, Recall: 0.2600, F1_score: 0.3377
Model performance on Neutral speech (in validation): 
	Precision: 0.7273, Recall: 0.3200, F1_score: 0.4444
Model performance on Sad speech (in validation): 
	Precision: 0.7586, Recall: 0.8800, F1_score: 0.8148
New best accuracy for layer 4 on epoch 1: 0.6000. Model saved.
Epoch 2/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:   9%|â–‰         | 142/1600 [00:10<01:42, 14.17it/s]Training:  20%|â–ˆâ–‰        | 319/1600 [00:20<01:19, 16.19it/s]Training:  32%|â–ˆâ–ˆâ–ˆâ–      | 513/1600 [00:30<01:01, 17.65it/s]Training:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 725/1600 [00:40<00:46, 18.96it/s]Training:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 941/1600 [00:50<00:33, 19.89it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1163/1600 [01:00<00:21, 20.67it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1385/1600 [01:10<00:10, 20.97it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|â–ˆâ–Œ        | 252/1600 [00:10<00:53, 25.07it/s]Training:  31%|â–ˆâ–ˆâ–ˆâ–      | 503/1600 [00:20<00:44, 24.91it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 751/1600 [00:30<00:34, 24.61it/s]Training:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 997/1600Training loss: 1459.8828, Training accuracy: 0.6256
Macro F1-score: 0.6217
Model performance on Angry speech (in training): 
	Precision: 0.6930, Recall: 0.7225, F1_score: 0.7075
Model performance on Happy speech (in training): 
	Precision: 0.5748, Recall: 0.4900, F1_score: 0.5290
Model performance on Neutral speech (in training): 
	Precision: 0.5476, Recall: 0.5325, F1_score: 0.5399
Model performance on Sad speech (in training): 
	Precision: 0.6689, Recall: 0.7575, F1_score: 0.7104

Eval Phase: 
Validation loss: 159.0462, Validation accuracy: 0.6650
Macro F1-score: 0.6520
Model performance on Angry speech (in validation): 
	Precision: 0.7213, Recall: 0.8800, F1_score: 0.7928
Model performance on Happy speech (in validation): 
	Precision: 0.6207, Recall: 0.3600, F1_score: 0.4557
Model performance on Neutral speech (in validation): 
	Precision: 0.5172, Recall: 0.6000, F1_score: 0.5556
Model performance on Sad speech (in validation): 
	Precision: 0.7885, Recall: 0.8200, F1_score: 0.8039
New best accuracy for layer 4 on epoch 2: 0.6650. Model saved.
Epoch 3/100

Training Phase:
Training loss: 1354.3147, Training accuracy: 0.6369
Macro F1-score: 0.6326
Model performance on Angry speech (in training): 
	Precision: 0.7345, Recall: 0.7400, F1_score: 0.7372
Model performance on Happy speech (in training): 
	Precision: 0.6013, Recall: 0.4750, F1_score: 0.5307
Model performance on Neutral speech (in training): 
	Precision: 0.5515, Recall: 0.5625, F1_score: 0.5569
Model performance on Sad speech (in training): 
	Precision: 0.6512, Recall: 0.7700, F1_score: 0.7056

Eval Phase: 
Validation loss: 183.1932, Validation accuracy: 0.6100
Macro F1-score: 0.5898
Model performance on Angry speech (in validation): 
	Precision: 0.5412, Recall: 0.9200, F1_score: 0.6815
Model performance on Happy speech (in validation): 
	Precision: 0.6250, Recall: 0.3000, F1_score: 0.4054
Model performance on Neutral speech (in validation): 
	Precision: 0.5000, Recall: 0.4400, F1_score: 0.4681
Model performance on Sad speech (in validation): 
	Precision: 0.8298, Recall: 0.7800, F1_score: 0.8041
Epoch 4/100

Training Phase:
 [00:40<00:24, 24.60it/s]Training:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1243/1600 [00:50<00:14, 24.48it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1486/1600 [01:00<00:04, 24.05it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–        | 222/1600 [00:10<01:02, 22.15it/s]Training:  28%|â–ˆâ–ˆâ–Š       | 444/1600 [00:20<00:52, 22.00it/s]Training:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 670/1600 [00:30<00:41, 22.27it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 912/1600 [00:40<00:29, 23.02it/s]Training:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1154/1600 [00:50<00:19, 23.17it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1391/1600 [01:00<00:08, 23.33it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|  Training loss: 1267.5024, Training accuracy: 0.6700
Macro F1-score: 0.6672
Model performance on Angry speech (in training): 
	Precision: 0.7557, Recall: 0.7500, F1_score: 0.7528
Model performance on Happy speech (in training): 
	Precision: 0.6624, Recall: 0.5150, F1_score: 0.5795
Model performance on Neutral speech (in training): 
	Precision: 0.5767, Recall: 0.6300, F1_score: 0.6022
Model performance on Sad speech (in training): 
	Precision: 0.6901, Recall: 0.7850, F1_score: 0.7345

Eval Phase: 
Validation loss: 204.0118, Validation accuracy: 0.5750
Macro F1-score: 0.5427
Model performance on Angry speech (in validation): 
	Precision: 0.4660, Recall: 0.9600, F1_score: 0.6275
Model performance on Happy speech (in validation): 
	Precision: 0.4545, Recall: 0.2000, F1_score: 0.2778
Model performance on Neutral speech (in validation): 
	Precision: 0.6429, Recall: 0.3600, F1_score: 0.4615
Model performance on Sad speech (in validation): 
	Precision: 0.8298, Recall: 0.7800, F1_score: 0.8041
Epoch 5/100

Training Phase:
        | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–Œ        | 241/1600 [00:10<00:56, 23.95it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 481/1600 [00:20<00:47, 23.56it/s]Training:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 714/1600 [00:30<00:37, 23.35it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 953/1600 [00:40<00:27, 23.55it/s]Training:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1192/1600 [00:50<00:17, 23.45it/s]Training:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1426/1600 [01:00<00:07, 23.40it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–        | 234/1600 [00:10<00:58, 23.38it/s]Training:  29%|â–ˆâ–ˆâ–‰       | 468/1600 [00:20<00:48, 23.35it/s]Training:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 707/1600 [00:30<00:37, 23.59it/s]Training:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 950/1600 [00:40<00:27, 23.84it/s]Training:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1193/1600 [00:50<0Training loss: 1175.6508, Training accuracy: 0.7063
Macro F1-score: 0.7038
Model performance on Angry speech (in training): 
	Precision: 0.7850, Recall: 0.7850, F1_score: 0.7850
Model performance on Happy speech (in training): 
	Precision: 0.7111, Recall: 0.5600, F1_score: 0.6266
Model performance on Neutral speech (in training): 
	Precision: 0.6134, Recall: 0.6625, F1_score: 0.6370
Model performance on Sad speech (in training): 
	Precision: 0.7219, Recall: 0.8175, F1_score: 0.7667

Eval Phase: 
Validation loss: 183.4592, Validation accuracy: 0.6650
Macro F1-score: 0.6503
Model performance on Angry speech (in validation): 
	Precision: 0.5974, Recall: 0.9200, F1_score: 0.7244
Model performance on Happy speech (in validation): 
	Precision: 0.5806, Recall: 0.3600, F1_score: 0.4444
Model performance on Neutral speech (in validation): 
	Precision: 0.6364, Recall: 0.5600, F1_score: 0.5957
Model performance on Sad speech (in validation): 
	Precision: 0.8542, Recall: 0.8200, F1_score: 0.8367
Epoch 6/100

Training Phase:
Training loss: 1112.9626, Training accuracy: 0.7163
Macro F1-score: 0.7145
Model performance on Angry speech (in training): 
	Precision: 0.8025, Recall: 0.7925, F1_score: 0.7975
Model performance on Happy speech (in training): 
	Precision: 0.7109, Recall: 0.6025, F1_score: 0.6522
Model performance on Neutral speech (in training): 
	Precision: 0.6485, Recall: 0.6550, F1_score: 0.6517
Model performance on Sad speech (in training): 
	Precision: 0.7056, Recall: 0.8150, F1_score: 0.7564

Eval Phase: 
Validation loss: 206.4531, Validation accuracy: 0.6100
Macro F1-score: 0.5780
Model performance on Angry speech (in validation): 
	Precision: 0.5161, Recall: 0.9600, F1_score: 0.6713
Model performance on Happy speech (in validation): 
	Precision: 0.4545, Recall: 0.2000, F1_score: 0.2778
Model performance on Neutral speech (in validation): 
	Precision: 0.5946, Recall: 0.4400, F1_score: 0.5057
Model performance on Sad speech (in validation): 
	Precision: 0.8750, Recall: 0.8400, F1_score: 0.8571
Epoch 7/100

Training Phase:
0:17, 23.77it/s]Training:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1430/1600 [01:00<00:07, 23.52it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–        | 239/1600 [00:10<00:57, 23.86it/s]Training:  30%|â–ˆâ–ˆâ–‰       | 478/1600 [00:20<00:47, 23.60it/s]Training:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 715/1600 [00:30<00:37, 23.64it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 953/1600 [00:40<00:27, 23.69it/s]Training:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1191/1600 [00:50<00:17, 23.46it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1432/1600 [01:00<00:07, 23.63it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–Œ        | 243/1600 [00:10<00:55, 2Training loss: 1079.9625, Training accuracy: 0.7312
Macro F1-score: 0.7288
Model performance on Angry speech (in training): 
	Precision: 0.8120, Recall: 0.8100, F1_score: 0.8110
Model performance on Happy speech (in training): 
	Precision: 0.7231, Recall: 0.5875, F1_score: 0.6483
Model performance on Neutral speech (in training): 
	Precision: 0.6540, Recall: 0.6900, F1_score: 0.6715
Model performance on Sad speech (in training): 
	Precision: 0.7379, Recall: 0.8375, F1_score: 0.7845

Eval Phase: 
Validation loss: 236.0652, Validation accuracy: 0.6100
Macro F1-score: 0.5717
Model performance on Angry speech (in validation): 
	Precision: 0.5052, Recall: 0.9800, F1_score: 0.6667
Model performance on Happy speech (in validation): 
	Precision: 0.5000, Recall: 0.1800, F1_score: 0.2647
Model performance on Neutral speech (in validation): 
	Precision: 0.6471, Recall: 0.4400, F1_score: 0.5238
Model performance on Sad speech (in validation): 
	Precision: 0.8235, Recall: 0.8400, F1_score: 0.8317
Epoch 8/100

Training Phase:
4.26it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 486/1600 [00:20<00:46, 23.94it/s]Training:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 724/1600 [00:30<00:36, 23.82it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 961/1600 [00:40<00:27, 23.50it/s]Training:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1193/1600 [00:50<00:17, 23.36it/s]Training:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1428/1600 [01:00<00:07, 23.39it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–        | 225/1600 [00:10<01:01, 22.43it/s]Training:  29%|â–ˆâ–ˆâ–‰       | 464/1600 [00:20<00:48, 23.28it/s]Training:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 703/1600 [00:30<00:38, 23.53it/s]Training:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 942/1600 [00:40<00:27, 23.60it/s]Training:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1187/1600 [00:50<00:17, 23.90it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1432/1600 [01:00<00:06, 24.Training loss: 987.7708, Training accuracy: 0.7581
Macro F1-score: 0.7561
Model performance on Angry speech (in training): 
	Precision: 0.8378, Recall: 0.8525, F1_score: 0.8451
Model performance on Happy speech (in training): 
	Precision: 0.7546, Recall: 0.6150, F1_score: 0.6777
Model performance on Neutral speech (in training): 
	Precision: 0.6885, Recall: 0.7350, F1_score: 0.7110
Model performance on Sad speech (in training): 
	Precision: 0.7545, Recall: 0.8300, F1_score: 0.7905

Eval Phase: 
Validation loss: 232.7859, Validation accuracy: 0.6100
Macro F1-score: 0.5812
Model performance on Angry speech (in validation): 
	Precision: 0.5053, Recall: 0.9600, F1_score: 0.6621
Model performance on Happy speech (in validation): 
	Precision: 0.5000, Recall: 0.2200, F1_score: 0.3056
Model performance on Neutral speech (in validation): 
	Precision: 0.6111, Recall: 0.4400, F1_score: 0.5116
Model performance on Sad speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Epoch 9/100

Training Phase:
Training loss: 940.2770, Training accuracy: 0.7788
Macro F1-score: 0.7772
Model performance on Angry speech (in training): 
	Precision: 0.8444, Recall: 0.8275, F1_score: 0.8359
Model performance on Happy speech (in training): 
	Precision: 0.7615, Recall: 0.6625, F1_score: 0.7086
Model performance on Neutral speech (in training): 
	Precision: 0.7396, Recall: 0.7525, F1_score: 0.7460
Model performance on Sad speech (in training): 
	Precision: 0.7704, Recall: 0.8725, F1_score: 0.8183

Eval Phase: 
Validation loss: 341.9250, Validation accuracy: 0.5350
Macro F1-score: 0.4822
Model performance on Angry speech (in validation): 
	Precision: 0.4310, Recall: 1.0000, F1_score: 0.6024
Model performance on Happy speech (in validation): 
	Precision: 0.3333, Recall: 0.1000, F1_score: 0.1538
Model performance on Neutral speech (in validation): 
	Precision: 0.5417, Recall: 0.2600, F1_score: 0.3514
Model performance on Sad speech (in validation): 
	Precision: 0.8667, Recall: 0.7800, F1_score: 0.8211
Epoch 10/100

Training Phase:
05it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–        | 236/1600 [00:10<00:57, 23.56it/s]Training:  30%|â–ˆâ–ˆâ–‰       | 473/1600 [00:20<00:47, 23.63it/s]Training:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 713/1600 [00:30<00:37, 23.76it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 953/1600 [00:40<00:27, 23.73it/s]Training:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1191/1600 [00:50<00:17, 23.75it/s]Training:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1429/1600 [01:00<00:07, 23.73it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–        | 233/1600 [00:10<00:58, 23.21it/s]Training:  29%|â–ˆâ–ˆâ–‰       | 466/1600 [00:20<00:48, 23.24it/s]Training:  4Training loss: 923.8909, Training accuracy: 0.7812
Macro F1-score: 0.7799
Model performance on Angry speech (in training): 
	Precision: 0.8483, Recall: 0.8525, F1_score: 0.8504
Model performance on Happy speech (in training): 
	Precision: 0.7768, Recall: 0.6700, F1_score: 0.7195
Model performance on Neutral speech (in training): 
	Precision: 0.7198, Recall: 0.7450, F1_score: 0.7322
Model performance on Sad speech (in training): 
	Precision: 0.7813, Recall: 0.8575, F1_score: 0.8176

Eval Phase: 
Validation loss: 312.4536, Validation accuracy: 0.5500
Macro F1-score: 0.5058
Model performance on Angry speech (in validation): 
	Precision: 0.4900, Recall: 0.9800, F1_score: 0.6533
Model performance on Happy speech (in validation): 
	Precision: 0.4167, Recall: 0.2000, F1_score: 0.2703
Model performance on Neutral speech (in validation): 
	Precision: 0.4444, Recall: 0.2400, F1_score: 0.3117
Model performance on Sad speech (in validation): 
	Precision: 0.7959, Recall: 0.7800, F1_score: 0.7879
Epoch 11/100

Training Phase:
Training loss: 820.5143, Training accuracy: 0.8044
Macro F1-score: 0.8031
Model performance on Angry speech (in training): 
	Precision: 0.8861, Recall: 0.8750, F1_score: 0.8805
Model performance on Happy speech (in training): 
	Precision: 0.7930, Recall: 0.6800, F1_score: 0.7322
Model performance on Neutral speech (in training): 
	Precision: 0.7536, Recall: 0.7950, F1_score: 0.7737
Model performance on Sad speech (in training): 
	Precision: 0.7886, Recall: 0.8675, F1_score: 0.8262

Eval Phase: 
4%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 699/1600 [00:30<00:38, 23.16it/s]Training:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 948/1600 [00:40<00:27, 23.82it/s]Training:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1197/1600 [00:50<00:16, 24.08it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1443/1600 [01:00<00:06, 24.06it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–        | 229/1600 [00:10<00:59, 22.88it/s]Training:  29%|â–ˆâ–ˆâ–‰       | 470/1600 [00:20<00:48, 23.53it/s]Training:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 710/1600 [00:30<00:37, 23.70it/s]Training:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 950/1600 [00:40<00:27, 23.81it/s]Training:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1190/1600 [00:50<00:17, 23.76it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1432/1600 [01:00<00:07, 23.88it/s]                                                             Evaluating:   0%| Validation loss: 219.6141, Validation accuracy: 0.6500
Macro F1-score: 0.6153
Model performance on Angry speech (in validation): 
	Precision: 0.6571, Recall: 0.9200, F1_score: 0.7667
Model performance on Happy speech (in validation): 
	Precision: 0.5106, Recall: 0.4800, F1_score: 0.4948
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 12/100

Training Phase:
Training loss: 780.1729, Training accuracy: 0.8094
Macro F1-score: 0.8089
Model performance on Angry speech (in training): 
	Precision: 0.8863, Recall: 0.8575, F1_score: 0.8717
Model performance on Happy speech (in training): 
	Precision: 0.8066, Recall: 0.7300, F1_score: 0.7664
Model performance on Neutral speech (in training): 
	Precision: 0.7731, Recall: 0.7750, F1_score: 0.7740
Model performance on Sad speech (in training): 
	Precision: 0.7778, Recall: 0.8750, F1_score: 0.8235

Eval Phase: 
Validation loss: 229.0930, Validation accuracy: 0.6500
Macro F1-score: 0.6293
Model performance on Angry speech (in validation): 
	Precision: 0.7333, Recall: 0.8800, F1_score: 0.8000
Model performance on Happy speech (in validation): 
	Precision: 0.5556, Recall: 0.3000, F1_score: 0.3896
Model performance on Neutral speech (in validation): 
	Precision: 0.5185, Recall: 0.5600, F1_score: 0.5385
Model performance on Sad speech (in validation): 
	Precision: 0.7288, Recall: 0.8600, F1_score: 0.7890
Validation loss does not decrease for 10 epochs. End training.
Model best accuracy on validation set: 0.6650

Test Phase: 
         | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–Œ        | 245/1600 [00:10<00:55, 24.48it/s]Training:  31%|â–ˆâ–ˆâ–ˆ       | 490/1600 [00:20<00:45, 24.24it/s]Training:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 731/1600 [00:30<00:36, 23.95it/s]Training:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 969/1600 [00:40<00:26, 23.89it/s]Training:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1207/1600 [00:50<00:16, 23.51it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1444/1600 [01:00<00:06, 23.57it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]                                                Some weights of the model checkpoint at /work/tc062/tc062/zhan7721/saved_models/de were not used when initializing Wav2Vec2Model: ['encoder.layers.10.attention.k_proj.bias', 'encoder.layers.10.attention.k_proj.weight', 'encoder.layers.10.attention.out_proj.bias', 'encoder.layers.10.attention.out_proj.weight', 'encoder.layers.10.attention.q_proj.bias', 'encoder.layers.10.attention.q_proj.weight', 'encoder.layers.10.attention.v_proj.bias', 'encoder.layers.10.attention.v_proj.weight', 'encoder.layers.10.feed_forward.intermediate_dense.bias', 'encoder.layers.10.feed_forward.intermediate_dense.weight', 'encoder.layers.10.feed_forward.output_dense.bias', 'encoder.layers.10.feed_forward.output_dense.weight', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.10.layer_norm.bias', 'encoder.layers.10.layer_norm.weight', 'encoder.layers.11.attention.k_proj.bias', 'encoder.layers.11.attention.k_proj.weight', 'encoder.layers.11.attention.out_proj.bias', 'encoder.layers.11.attention.out_proj.weight', 'encoder.layers.11.attention.q_proj.bias', 'encoder.layers.11.attention.q_proj.weight', 'encoder.layers.11.attention.v_proj.bias', 'encoder.layers.11.attention.v_proj.weight', 'encoder.layers.11.feed_forward.intermediate_dense.bias', 'encoder.layers.11.feed_forward.intermediate_dense.weight', 'encoder.layers.11.feed_forward.output_dense.bias', 'encoder.layers.11.feed_forward.output_dense.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.11.layer_norm.bias', 'encoder.layers.11.layer_norm.weight', 'encoder.layers.5.attention.k_proj.bias', 'encoder.layers.5.attention.k_proj.weight', 'encoder.layers.5.attention.out_proj.bias', 'encoder.layers.5.attention.out_proj.weight', 'encoder.layers.5.attention.q_proj.bias', 'encoder.layers.5.attention.q_proj.weight', 'encoder.layers.5.attention.v_proj.bias', 'encoder.layers.5.attention.v_proj.weight', 'encoder.layers.5.feed_forward.intermediate_dense.bias', 'encoder.layers.5.feed_forward.intermediate_dense.weight', 'encoder.layers.5.feed_forward.output_dense.bias', 'encoder.layers.5.feed_forward.output_dense.weight', 'encoder.layers.5.final_layer_norm.bias', 'encoder.layers.5.final_layer_norm.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.6.attention.k_proj.bias', 'encoder.layers.6.attention.k_proj.weight', 'encoder.layers.6.attention.out_proj.bias', 'encoder.layers.6.attention.out_proj.weight', 'encoder.layers.6.attention.q_proj.bias', 'encoder.layers.6.attention.q_proj.weight', 'encoder.layers.6.attention.v_proj.bias', 'encoder.layers.6.attention.v_proj.weight', 'encoder.layers.6.feed_forward.intermediate_dense.bias', 'encoder.layers.6.feed_forward.intermediate_dense.weight', 'encoder.layers.6.feed_forward.output_dense.bias', 'encoder.layers.6.feed_forward.output_dense.weight', 'encoder.layers.6.final_layer_norm.bias', 'encoder.layers.6.final_layer_norm.weight', 'encoder.layers.6.layer_norm.bias', 'encoder.layers.6.layer_norm.weight', 'encoder.layers.7.attention.k_proj.bias', 'encoder.layers.7.attention.k_proj.weight', 'encoder.layers.7.attention.out_proj.bias', 'encoder.layers.7.attention.out_proj.weight', 'encoder.layers.7.attention.q_proj.bias', 'encoder.layers.7.attention.q_proj.weight', 'encoder.layers.7.attention.v_proj.bias', 'encoder.layers.7.attention.v_proj.weight', 'encoder.layers.7.feed_forward.intermediate_dense.bias', 'encoder.layers.7.feed_forward.intermediate_dense.weight', 'encoder.layers.7.feed_forward.output_dense.bias', 'encoder.layers.7.feed_forward.output_dense.weight', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.7.layer_norm.bias', 'encoder.layers.7.layer_norm.weight', 'encoder.layers.8.attention.k_proj.bias', 'encoder.layers.8.attention.k_proj.weight', 'encoder.layers.8.attention.out_proj.bias', 'encoder.layers.8.attention.out_proj.weight', 'encoder.layers.8.attention.q_proj.bias', 'encoder.layers.8.attention.q_proj.weight', 'encoder.layers.8.attention.v_proj.bias', 'encoder.layers.8.attention.v_proj.weight', 'encoder.layers.8.feed_forward.intermediate_dense.bias', 'encoder.layers.8.feed_forward.intermediate_dense.weight', 'encoder.layers.8.feed_forward.output_dense.bias', 'encoder.layers.8.feed_forward.output_dense.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.8.layer_norm.bias', 'encoder.layers.8.layer_norm.weight', 'encoder.layers.9.attention.k_proj.bias', 'encoder.layers.9.attention.k_proj.weight', 'encoder.layers.9.attention.out_proj.bias', 'encoder.layers.9.attention.out_proj.weight', 'encoder.layers.9.attention.q_proj.bias', 'encoder.layers.9.attention.q_proj.weight', 'encoder.layers.9.attention.v_proj.bias', 'encoder.layers.9.attention.v_proj.weight', 'encoder.layers.9.feed_forward.intermediate_dense.bias', 'encoder.layers.9.feed_forward.intermediate_dense.weight', 'encoder.layers.9.feed_forward.output_dense.bias', 'encoder.layers.9.feed_forward.output_dense.weight', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.layer_norm.bias', 'encoder.layers.9.layer_norm.weight']
- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Test loss: 170.5786, Test accuracy: 0.6400
Macro F1-score: 0.6295
Model performance on Angry speech (in test): 
	Precision: 0.6316, Recall: 0.7200, F1_score: 0.6729
Model performance on Happy speech (in test): 
	Precision: 0.6667, Recall: 0.3600, F1_score: 0.4675
Model performance on Neutral speech (in test): 
	Precision: 0.5323, Recall: 0.6600, F1_score: 0.5893
Model performance on Sad speech (in test): 
	Precision: 0.7593, Recall: 0.8200, F1_score: 0.7885

======================= This is fold_2 on cn =======================

Load dataset: 
Loading en train data: fold_2...
Preprocess en fold_2 data for cn model
Loading en eval data: fold_2...
Preprocess en fold_2 data for cn model
Loading en test data: fold_2...
Preprocess en fold_2 data for cn model
Use cn model to add lora
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training loss: 1521.0296, Training accuracy: 0.6000
Macro F1-score: 0.5963
Model performance on Angry speech (in training): 
	Precision: 0.6564, Recall: 0.6925, F1_score: 0.6740
Model performance on Happy speech (in training): 
	Precision: 0.5585, Recall: 0.4775, F1_score: 0.5148
Model performance on Neutral speech (in training): 
	Precision: 0.5000, Recall: 0.4900, F1_score: 0.4949
Model performance on Sad speech (in training): 
	Precision: 0.6667, Recall: 0.7400, F1_score: 0.7014

Eval Phase: 
Validation loss: 226.9076, Validation accuracy: 0.5750
Macro F1-score: 0.5522
Model performance on Angry speech (in validation): 
	Precision: 0.7556, Recall: 0.6800, F1_score: 0.7158
Model performance on Happy speech (in validation): 
	Precision: 0.8125, Recall: 0.2600, F1_score: 0.3939
Model performance on Neutral speech (in validation): 
	Precision: 0.6250, Recall: 0.4000, F1_score: 0.4878
Model performance on Sad speech (in validation): 
	Precision: 0.4486, Recall: 0.9600, F1_score: 0.6115
New best accuracy for layer 4 on epoch 1: 0.5750. Model saved.
Epoch 2/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:   8%|â–Š         | 134/1600 [00:10<01:49, 13.40it/s]Training:  20%|â–ˆâ–‰        | 319/1600 [00:20<01:18, 16.38it/s]Training:  32%|â–ˆâ–ˆâ–ˆâ–      | 515/1600 [00:30<01:00, 17.85it/s]Training:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 734/1600 [00:40<00:44, 19.41it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 953/1600 [00:50<00:32, 19.99it/s]Training:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1176/1600 [01:00<00:20, 20.76it/s]Training:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1408/1600 [01:10<00:08, 21.52it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–Œ        | 244/1600 [00:10<00:55, 24.36it/s]Training:  31%|â–ˆâ–ˆâ–ˆâ–      | 500/1600 [00:20<00:43, 25.03it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 756/1600 [00:30<00:34, 24.65it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1010/160Training loss: 1337.4666, Training accuracy: 0.6475
Macro F1-score: 0.6424
Model performance on Angry speech (in training): 
	Precision: 0.6993, Recall: 0.7500, F1_score: 0.7238
Model performance on Happy speech (in training): 
	Precision: 0.6050, Recall: 0.4825, F1_score: 0.5369
Model performance on Neutral speech (in training): 
	Precision: 0.5611, Recall: 0.5625, F1_score: 0.5618
Model performance on Sad speech (in training): 
	Precision: 0.7051, Recall: 0.7950, F1_score: 0.7474

Eval Phase: 
Validation loss: 231.7741, Validation accuracy: 0.5550
Macro F1-score: 0.5332
Model performance on Angry speech (in validation): 
	Precision: 0.8000, Recall: 0.5600, F1_score: 0.6588
Model performance on Happy speech (in validation): 
	Precision: 0.8000, Recall: 0.2400, F1_score: 0.3692
Model performance on Neutral speech (in validation): 
	Precision: 0.5227, Recall: 0.4600, F1_score: 0.4894
Model performance on Sad speech (in validation): 
	Precision: 0.4528, Recall: 0.9600, F1_score: 0.6154
Epoch 3/100

Training Phase:
Training loss: 1218.0225, Training accuracy: 0.7025
Macro F1-score: 0.6984
Model performance on Angry speech (in training): 
	Precision: 0.7559, Recall: 0.7975, F1_score: 0.7762
Model performance on Happy speech (in training): 
	Precision: 0.6769, Recall: 0.5500, F1_score: 0.6069
Model performance on Neutral speech (in training): 
	Precision: 0.6348, Recall: 0.6300, F1_score: 0.6324
Model performance on Sad speech (in training): 
	Precision: 0.7303, Recall: 0.8325, F1_score: 0.7780

Eval Phase: 
Validation loss: 210.8719, Validation accuracy: 0.6200
Macro F1-score: 0.5919
Model performance on Angry speech (in validation): 
	Precision: 0.7400, Recall: 0.7400, F1_score: 0.7400
Model performance on Happy speech (in validation): 
	Precision: 0.9231, Recall: 0.2400, F1_score: 0.3810
Model performance on Neutral speech (in validation): 
	Precision: 0.5714, Recall: 0.5600, F1_score: 0.5657
Model performance on Sad speech (in validation): 
	Precision: 0.5341, Recall: 0.9400, F1_score: 0.6812
New best accuracy for layer 4 on epoch 3: 0.6200. Model saved.
Epoch 4/100

Training Phase:
0 [00:40<00:23, 24.91it/s]Training:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1269/1600 [00:50<00:13, 25.24it/s]Training:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1528/1600 [01:01<00:02, 24.89it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–Œ        | 241/1600 [00:10<00:56, 24.01it/s]Training:  31%|â–ˆâ–ˆâ–ˆ       | 494/1600 [00:20<00:44, 24.76it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 747/1600 [00:30<00:34, 24.61it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1013/1600 [00:40<00:23, 25.36it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1279/1600 [00:51<00:12, 24.83it/s]Training:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1526/1600 [01:01<00:02, 24.77it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:  Training loss: 1144.7310, Training accuracy: 0.7081
Macro F1-score: 0.7050
Model performance on Angry speech (in training): 
	Precision: 0.7789, Recall: 0.7925, F1_score: 0.7856
Model performance on Happy speech (in training): 
	Precision: 0.6687, Recall: 0.5600, F1_score: 0.6095
Model performance on Neutral speech (in training): 
	Precision: 0.6422, Recall: 0.6550, F1_score: 0.6485
Model performance on Sad speech (in training): 
	Precision: 0.7333, Recall: 0.8250, F1_score: 0.7765

Eval Phase: 
Validation loss: 220.0147, Validation accuracy: 0.5800
Macro F1-score: 0.5402
Model performance on Angry speech (in validation): 
	Precision: 0.8158, Recall: 0.6200, F1_score: 0.7045
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1400, F1_score: 0.2456
Model performance on Neutral speech (in validation): 
	Precision: 0.4921, Recall: 0.6200, F1_score: 0.5487
Model performance on Sad speech (in validation): 
	Precision: 0.5109, Recall: 0.9400, F1_score: 0.6620
Epoch 5/100

Training Phase:
 0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–Œ        | 244/1600 [00:10<00:55, 24.39it/s]Training:  31%|â–ˆâ–ˆâ–ˆ       | 491/1600 [00:20<00:45, 24.55it/s]Training:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 740/1600 [00:30<00:34, 24.71it/s]Training:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 993/1600 [00:40<00:24, 24.91it/s]Training:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1246/1600 [00:50<00:14, 24.82it/s]Training:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1498/1600 [01:00<00:04, 24.94it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–Œ        | 244/1600 [00:10<00:55, 24.39it/s]Training:  31%|â–ˆâ–ˆâ–ˆ       | 499/1600 [00:20<00:44, 25.01it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 754/1600 [00:30<00:33, 25.17it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1008/1600 [00:40<00:23, 24.88it/s]Training:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1254/Training loss: 1087.1752, Training accuracy: 0.7281
Macro F1-score: 0.7256
Model performance on Angry speech (in training): 
	Precision: 0.7936, Recall: 0.8075, F1_score: 0.8005
Model performance on Happy speech (in training): 
	Precision: 0.6974, Recall: 0.6050, F1_score: 0.6479
Model performance on Neutral speech (in training): 
	Precision: 0.6583, Recall: 0.6550, F1_score: 0.6566
Model performance on Sad speech (in training): 
	Precision: 0.7545, Recall: 0.8450, F1_score: 0.7972

Eval Phase: 
Validation loss: 289.4830, Validation accuracy: 0.5450
Macro F1-score: 0.5243
Model performance on Angry speech (in validation): 
	Precision: 0.8125, Recall: 0.5200, F1_score: 0.6341
Model performance on Happy speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Neutral speech (in validation): 
	Precision: 0.5385, Recall: 0.4200, F1_score: 0.4719
Model performance on Sad speech (in validation): 
	Precision: 0.4414, Recall: 0.9800, F1_score: 0.6087
Epoch 6/100

Training Phase:
Training loss: 1049.0172, Training accuracy: 0.7362
Macro F1-score: 0.7336
Model performance on Angry speech (in training): 
	Precision: 0.8039, Recall: 0.8300, F1_score: 0.8167
Model performance on Happy speech (in training): 
	Precision: 0.7126, Recall: 0.5950, F1_score: 0.6485
Model performance on Neutral speech (in training): 
	Precision: 0.6602, Recall: 0.6800, F1_score: 0.6700
Model performance on Sad speech (in training): 
	Precision: 0.7619, Recall: 0.8400, F1_score: 0.7990

Eval Phase: 
Validation loss: 288.5854, Validation accuracy: 0.5600
Macro F1-score: 0.5462
Model performance on Angry speech (in validation): 
	Precision: 0.8710, Recall: 0.5400, F1_score: 0.6667
Model performance on Happy speech (in validation): 
	Precision: 0.6800, Recall: 0.3400, F1_score: 0.4533
Model performance on Neutral speech (in validation): 
	Precision: 0.5588, Recall: 0.3800, F1_score: 0.4524
Model performance on Sad speech (in validation): 
	Precision: 0.4455, Recall: 0.9800, F1_score: 0.6125
Epoch 7/100

Training Phase:
1600 [00:50<00:13, 24.77it/s]Training:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1508/1600 [01:00<00:03, 24.97it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–        | 234/1600 [00:10<00:58, 23.32it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 483/1600 [00:20<00:46, 24.23it/s]Training:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 732/1600 [00:30<00:36, 24.08it/s]Training:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 972/1600 [00:40<00:26, 23.97it/s]Training:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1211/1600 [00:51<00:16, 23.41it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1447/1600 [01:01<00:06, 23.45it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–Œ        | 240/1600 Training loss: 980.7870, Training accuracy: 0.7538
Macro F1-score: 0.7516
Model performance on Angry speech (in training): 
	Precision: 0.8142, Recall: 0.8325, F1_score: 0.8232
Model performance on Happy speech (in training): 
	Precision: 0.7229, Recall: 0.6325, F1_score: 0.6747
Model performance on Neutral speech (in training): 
	Precision: 0.6749, Recall: 0.6850, F1_score: 0.6799
Model performance on Sad speech (in training): 
	Precision: 0.7954, Recall: 0.8650, F1_score: 0.8287

Eval Phase: 
Validation loss: 268.9560, Validation accuracy: 0.5900
Macro F1-score: 0.5709
Model performance on Angry speech (in validation): 
	Precision: 0.8108, Recall: 0.6000, F1_score: 0.6897
Model performance on Happy speech (in validation): 
	Precision: 0.7143, Recall: 0.3000, F1_score: 0.4225
Model performance on Neutral speech (in validation): 
	Precision: 0.5217, Recall: 0.4800, F1_score: 0.5000
Model performance on Sad speech (in validation): 
	Precision: 0.5104, Recall: 0.9800, F1_score: 0.6712
Epoch 8/100

Training Phase:
[00:10<00:56, 23.99it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 480/1600 [00:20<00:48, 23.24it/s]Training:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 721/1600 [00:30<00:37, 23.60it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 962/1600 [00:40<00:27, 23.60it/s]Training:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1209/1600 [00:50<00:16, 23.99it/s]Training:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1456/1600 [01:01<00:06, 23.79it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–Œ        | 246/1600 [00:10<00:55, 24.54it/s]Training:  31%|â–ˆâ–ˆâ–ˆ       | 492/1600 [00:20<00:46, 23.65it/s]Training:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 730/1600 [00:30<00:36, 23.69it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 968/1600 [00:40<00:26, 23.63it/s]Training:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1204/1600 [00:51<00:16, 23.40it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1444/1600 [0Training loss: 931.4075, Training accuracy: 0.7775
Macro F1-score: 0.7767
Model performance on Angry speech (in training): 
	Precision: 0.8469, Recall: 0.8300, F1_score: 0.8384
Model performance on Happy speech (in training): 
	Precision: 0.7813, Recall: 0.6700, F1_score: 0.7214
Model performance on Neutral speech (in training): 
	Precision: 0.6984, Recall: 0.7525, F1_score: 0.7244
Model performance on Sad speech (in training): 
	Precision: 0.7903, Recall: 0.8575, F1_score: 0.8225

Eval Phase: 
Validation loss: 234.2345, Validation accuracy: 0.6200
Macro F1-score: 0.6026
Model performance on Angry speech (in validation): 
	Precision: 0.7857, Recall: 0.6600, F1_score: 0.7174
Model performance on Happy speech (in validation): 
	Precision: 0.9375, Recall: 0.3000, F1_score: 0.4545
Model performance on Neutral speech (in validation): 
	Precision: 0.5088, Recall: 0.5800, F1_score: 0.5421
Model performance on Sad speech (in validation): 
	Precision: 0.5529, Recall: 0.9400, F1_score: 0.6963
Epoch 9/100

Training Phase:
Training loss: 831.1299, Training accuracy: 0.8013
Macro F1-score: 0.8000
Model performance on Angry speech (in training): 
	Precision: 0.8750, Recall: 0.8750, F1_score: 0.8750
Model performance on Happy speech (in training): 
	Precision: 0.8006, Recall: 0.6925, F1_score: 0.7426
Model performance on Neutral speech (in training): 
	Precision: 0.7271, Recall: 0.7525, F1_score: 0.7396
Model performance on Sad speech (in training): 
	Precision: 0.8045, Recall: 0.8850, F1_score: 0.8429

Eval Phase: 
Validation loss: 246.0121, Validation accuracy: 0.6250
Macro F1-score: 0.6062
Model performance on Angry speech (in validation): 
	Precision: 0.8182, Recall: 0.7200, F1_score: 0.7660
Model performance on Happy speech (in validation): 
	Precision: 0.8750, Recall: 0.2800, F1_score: 0.4242
Model performance on Neutral speech (in validation): 
	Precision: 0.5472, Recall: 0.5800, F1_score: 0.5631
Model performance on Sad speech (in validation): 
	Precision: 0.5287, Recall: 0.9200, F1_score: 0.6715
New best accuracy for layer 4 on epoch 9: 0.6250. Model saved.
Epoch 10/100

Training Phase:
1:01<00:06, 23.59it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–        | 235/1600 [00:10<00:58, 23.45it/s]Training:  29%|â–ˆâ–ˆâ–‰       | 470/1600 [00:20<00:48, 23.29it/s]Training:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 710/1600 [00:30<00:37, 23.60it/s]Training:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 950/1600 [00:40<00:27, 23.70it/s]Training:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1189/1600 [00:50<00:17, 23.76it/s]Training:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1428/1600 [01:00<00:07, 23.76it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–Œ        | 246/1600 [00:10<00:55, 24.53it/s]Training:  31%|â–ˆâ–ˆâ–ˆ       | 492/1600 [00:20<00:47, 23.26it/Training loss: 775.7571, Training accuracy: 0.8194
Macro F1-score: 0.8178
Model performance on Angry speech (in training): 
	Precision: 0.8756, Recall: 0.8800, F1_score: 0.8778
Model performance on Happy speech (in training): 
	Precision: 0.8080, Recall: 0.7050, F1_score: 0.7530
Model performance on Neutral speech (in training): 
	Precision: 0.7561, Recall: 0.7750, F1_score: 0.7654
Model performance on Sad speech (in training): 
	Precision: 0.8360, Recall: 0.9175, F1_score: 0.8749

Eval Phase: 
Validation loss: 278.2631, Validation accuracy: 0.6000
Macro F1-score: 0.5875
Model performance on Angry speech (in validation): 
	Precision: 0.9091, Recall: 0.4000, F1_score: 0.5556
Model performance on Happy speech (in validation): 
	Precision: 0.6765, Recall: 0.4600, F1_score: 0.5476
Model performance on Neutral speech (in validation): 
	Precision: 0.5085, Recall: 0.6000, F1_score: 0.5505
Model performance on Sad speech (in validation): 
	Precision: 0.5529, Recall: 0.9400, F1_score: 0.6963
Epoch 11/100

Training Phase:
Training loss: 749.4153, Training accuracy: 0.8187
Macro F1-score: 0.8180
Model performance on Angry speech (in training): 
	Precision: 0.8747, Recall: 0.8725, F1_score: 0.8736
Model performance on Happy speech (in training): 
	Precision: 0.8157, Recall: 0.7525, F1_score: 0.7828
Model performance on Neutral speech (in training): 
	Precision: 0.7525, Recall: 0.7525, F1_score: 0.7525
Model performance on Sad speech (in training): 
	Precision: 0.8310, Recall: 0.8975, F1_score: 0.8630

Eval Phase: 
s]Training:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 731/1600 [00:30<00:36, 23.53it/s]Training:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 970/1600 [00:41<00:26, 23.39it/s]Training:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1205/1600 [00:51<00:16, 23.40it/s]Training:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1449/1600 [01:01<00:06, 23.72it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–        | 228/1600 [00:10<01:00, 22.78it/s]Training:  29%|â–ˆâ–ˆâ–‰       | 464/1600 [00:20<00:48, 23.23it/s]Training:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 700/1600 [00:30<00:38, 23.32it/s]Training:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 938/1600 [00:40<00:28, 23.50it/s]Training:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1184/1600 [00:50<00:17, 23.88it/s]Training:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1430/1600 [01:00<00:07, 23.80it/s]                                                             EvaValidation loss: 336.0608, Validation accuracy: 0.5550
Macro F1-score: 0.5314
Model performance on Angry speech (in validation): 
	Precision: 0.8889, Recall: 0.4800, F1_score: 0.6234
Model performance on Happy speech (in validation): 
	Precision: 0.8462, Recall: 0.2200, F1_score: 0.3492
Model performance on Neutral speech (in validation): 
	Precision: 0.4677, Recall: 0.5800, F1_score: 0.5179
Model performance on Sad speech (in validation): 
	Precision: 0.4796, Recall: 0.9400, F1_score: 0.6351
Epoch 12/100

Training Phase:
Training loss: 717.1342, Training accuracy: 0.8356
Macro F1-score: 0.8351
Model performance on Angry speech (in training): 
	Precision: 0.8970, Recall: 0.8925, F1_score: 0.8947
Model performance on Happy speech (in training): 
	Precision: 0.8430, Recall: 0.7650, F1_score: 0.8021
Model performance on Neutral speech (in training): 
	Precision: 0.7827, Recall: 0.7925, F1_score: 0.7876
Model performance on Sad speech (in training): 
	Precision: 0.8226, Recall: 0.8925, F1_score: 0.8561

Eval Phase: 
Validation loss: 327.5804, Validation accuracy: 0.5700
Macro F1-score: 0.5548
Model performance on Angry speech (in validation): 
	Precision: 0.8800, Recall: 0.4400, F1_score: 0.5867
Model performance on Happy speech (in validation): 
	Precision: 0.7273, Recall: 0.3200, F1_score: 0.4444
Model performance on Neutral speech (in validation): 
	Precision: 0.4839, Recall: 0.6000, F1_score: 0.5357
Model performance on Sad speech (in validation): 
	Precision: 0.5055, Recall: 0.9200, F1_score: 0.6525
Epoch 13/100

Training Phase:
luating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–        | 227/1600 [00:10<01:00, 22.60it/s]Training:  29%|â–ˆâ–ˆâ–‰       | 469/1600 [00:20<00:48, 23.52it/s]Training:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 711/1600 [00:30<00:37, 23.59it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 953/1600 [00:40<00:27, 23.82it/s]Training:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1195/1600 [00:50<00:17, 23.82it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1434/1600 [01:00<00:07, 23.68it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–        | 234/1600 [00:10<00:58, 23.40it/s]Training:  29%|â–ˆâ–ˆâ–‰       | 468/1600 [00:20<00:48, 23.33it/s]Training:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 707/1600 [00:30<00:37, 23.59it/s]Training:  59%|Training loss: 666.4389, Training accuracy: 0.8387
Macro F1-score: 0.8380
Model performance on Angry speech (in training): 
	Precision: 0.8707, Recall: 0.8925, F1_score: 0.8815
Model performance on Happy speech (in training): 
	Precision: 0.8388, Recall: 0.7675, F1_score: 0.8016
Model performance on Neutral speech (in training): 
	Precision: 0.7896, Recall: 0.7975, F1_score: 0.7935
Model performance on Sad speech (in training): 
	Precision: 0.8548, Recall: 0.8975, F1_score: 0.8756

Eval Phase: 
Validation loss: 312.4503, Validation accuracy: 0.5800
Macro F1-score: 0.5621
Model performance on Angry speech (in validation): 
	Precision: 0.7895, Recall: 0.6000, F1_score: 0.6818
Model performance on Happy speech (in validation): 
	Precision: 0.7000, Recall: 0.2800, F1_score: 0.4000
Model performance on Neutral speech (in validation): 
	Precision: 0.4815, Recall: 0.5200, F1_score: 0.5000
Model performance on Sad speech (in validation): 
	Precision: 0.5227, Recall: 0.9200, F1_score: 0.6667
Validation loss does not decrease for 10 epochs. End training.
Model best accuracy on validation set: 0.6250

Test Phase: 
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 946/1600 [00:40<00:27, 23.50it/s]Training:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1185/1600 [00:50<00:17, 23.62it/s]Training:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1425/1600 [01:00<00:07, 23.72it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]                                                Some weights of the model checkpoint at /work/tc062/tc062/zhan7721/saved_models/de were not used when initializing Wav2Vec2Model: ['encoder.layers.10.attention.k_proj.bias', 'encoder.layers.10.attention.k_proj.weight', 'encoder.layers.10.attention.out_proj.bias', 'encoder.layers.10.attention.out_proj.weight', 'encoder.layers.10.attention.q_proj.bias', 'encoder.layers.10.attention.q_proj.weight', 'encoder.layers.10.attention.v_proj.bias', 'encoder.layers.10.attention.v_proj.weight', 'encoder.layers.10.feed_forward.intermediate_dense.bias', 'encoder.layers.10.feed_forward.intermediate_dense.weight', 'encoder.layers.10.feed_forward.output_dense.bias', 'encoder.layers.10.feed_forward.output_dense.weight', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.10.layer_norm.bias', 'encoder.layers.10.layer_norm.weight', 'encoder.layers.11.attention.k_proj.bias', 'encoder.layers.11.attention.k_proj.weight', 'encoder.layers.11.attention.out_proj.bias', 'encoder.layers.11.attention.out_proj.weight', 'encoder.layers.11.attention.q_proj.bias', 'encoder.layers.11.attention.q_proj.weight', 'encoder.layers.11.attention.v_proj.bias', 'encoder.layers.11.attention.v_proj.weight', 'encoder.layers.11.feed_forward.intermediate_dense.bias', 'encoder.layers.11.feed_forward.intermediate_dense.weight', 'encoder.layers.11.feed_forward.output_dense.bias', 'encoder.layers.11.feed_forward.output_dense.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.11.layer_norm.bias', 'encoder.layers.11.layer_norm.weight', 'encoder.layers.5.attention.k_proj.bias', 'encoder.layers.5.attention.k_proj.weight', 'encoder.layers.5.attention.out_proj.bias', 'encoder.layers.5.attention.out_proj.weight', 'encoder.layers.5.attention.q_proj.bias', 'encoder.layers.5.attention.q_proj.weight', 'encoder.layers.5.attention.v_proj.bias', 'encoder.layers.5.attention.v_proj.weight', 'encoder.layers.5.feed_forward.intermediate_dense.bias', 'encoder.layers.5.feed_forward.intermediate_dense.weight', 'encoder.layers.5.feed_forward.output_dense.bias', 'encoder.layers.5.feed_forward.output_dense.weight', 'encoder.layers.5.final_layer_norm.bias', 'encoder.layers.5.final_layer_norm.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.6.attention.k_proj.bias', 'encoder.layers.6.attention.k_proj.weight', 'encoder.layers.6.attention.out_proj.bias', 'encoder.layers.6.attention.out_proj.weight', 'encoder.layers.6.attention.q_proj.bias', 'encoder.layers.6.attention.q_proj.weight', 'encoder.layers.6.attention.v_proj.bias', 'encoder.layers.6.attention.v_proj.weight', 'encoder.layers.6.feed_forward.intermediate_dense.bias', 'encoder.layers.6.feed_forward.intermediate_dense.weight', 'encoder.layers.6.feed_forward.output_dense.bias', 'encoder.layers.6.feed_forward.output_dense.weight', 'encoder.layers.6.final_layer_norm.bias', 'encoder.layers.6.final_layer_norm.weight', 'encoder.layers.6.layer_norm.bias', 'encoder.layers.6.layer_norm.weight', 'encoder.layers.7.attention.k_proj.bias', 'encoder.layers.7.attention.k_proj.weight', 'encoder.layers.7.attention.out_proj.bias', 'encoder.layers.7.attention.out_proj.weight', 'encoder.layers.7.attention.q_proj.bias', 'encoder.layers.7.attention.q_proj.weight', 'encoder.layers.7.attention.v_proj.bias', 'encoder.layers.7.attention.v_proj.weight', 'encoder.layers.7.feed_forward.intermediate_dense.bias', 'encoder.layers.7.feed_forward.intermediate_dense.weight', 'encoder.layers.7.feed_forward.output_dense.bias', 'encoder.layers.7.feed_forward.output_dense.weight', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.7.layer_norm.bias', 'encoder.layers.7.layer_norm.weight', 'encoder.layers.8.attention.k_proj.bias', 'encoder.layers.8.attention.k_proj.weight', 'encoder.layers.8.attention.out_proj.bias', 'encoder.layers.8.attention.out_proj.weight', 'encoder.layers.8.attention.q_proj.bias', 'encoder.layers.8.attention.q_proj.weight', 'encoder.layers.8.attention.v_proj.bias', 'encoder.layers.8.attention.v_proj.weight', 'encoder.layers.8.feed_forward.intermediate_dense.bias', 'encoder.layers.8.feed_forward.intermediate_dense.weight', 'encoder.layers.8.feed_forward.output_dense.bias', 'encoder.layers.8.feed_forward.output_dense.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.8.layer_norm.bias', 'encoder.layers.8.layer_norm.weight', 'encoder.layers.9.attention.k_proj.bias', 'encoder.layers.9.attention.k_proj.weight', 'encoder.layers.9.attention.out_proj.bias', 'encoder.layers.9.attention.out_proj.weight', 'encoder.layers.9.attention.q_proj.bias', 'encoder.layers.9.attention.q_proj.weight', 'encoder.layers.9.attention.v_proj.bias', 'encoder.layers.9.attention.v_proj.weight', 'encoder.layers.9.feed_forward.intermediate_dense.bias', 'encoder.layers.9.feed_forward.intermediate_dense.weight', 'encoder.layers.9.feed_forward.output_dense.bias', 'encoder.layers.9.feed_forward.output_dense.weight', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.layer_norm.bias', 'encoder.layers.9.layer_norm.weight']
- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Test loss: 225.2744, Test accuracy: 0.6450
Macro F1-score: 0.6195
Model performance on Angry speech (in test): 
	Precision: 0.7170, Recall: 0.7600, F1_score: 0.7379
Model performance on Happy speech (in test): 
	Precision: 0.8125, Recall: 0.2600, F1_score: 0.3939
Model performance on Neutral speech (in test): 
	Precision: 0.6182, Recall: 0.6800, F1_score: 0.6476
Model performance on Sad speech (in test): 
	Precision: 0.5789, Recall: 0.8800, F1_score: 0.6984

======================= This is fold_3 on cn =======================

Load dataset: 
Loading en train data: fold_3...
Preprocess en fold_3 data for cn model
Loading en eval data: fold_3...
Preprocess en fold_3 data for cn model
Loading en test data: fold_3...
Preprocess en fold_3 data for cn model
Use cn model to add lora
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training loss: 1465.9964, Training accuracy: 0.6188
Macro F1-score: 0.6156
Model performance on Angry speech (in training): 
	Precision: 0.6765, Recall: 0.6900, F1_score: 0.6832
Model performance on Happy speech (in training): 
	Precision: 0.5843, Recall: 0.5025, F1_score: 0.5403
Model performance on Neutral speech (in training): 
	Precision: 0.5459, Recall: 0.5350, F1_score: 0.5404
Model performance on Sad speech (in training): 
	Precision: 0.6557, Recall: 0.7475, F1_score: 0.6986

Eval Phase: 
Validation loss: 235.3032, Validation accuracy: 0.5600
Macro F1-score: 0.5373
Model performance on Angry speech (in validation): 
	Precision: 0.8108, Recall: 0.6000, F1_score: 0.6897
Model performance on Happy speech (in validation): 
	Precision: 0.8571, Recall: 0.2400, F1_score: 0.3750
Model performance on Neutral speech (in validation): 
	Precision: 0.4151, Recall: 0.4400, F1_score: 0.4272
Model performance on Sad speech (in validation): 
	Precision: 0.5000, Recall: 0.9600, F1_score: 0.6575
New best accuracy for layer 4 on epoch 1: 0.5600. Model saved.
Epoch 2/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  10%|â–‰         | 158/1600 [00:10<01:31, 15.77it/s]Training:  22%|â–ˆâ–ˆâ–       | 359/1600 [00:20<01:07, 18.28it/s]Training:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 568/1600 [00:30<00:53, 19.43it/s]Training:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 782/1600 [00:40<00:40, 20.17it/s]Training:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 995/1600 [00:50<00:29, 20.43it/s]Training:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1214/1600 [01:00<00:18, 20.90it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1433/1600 [01:10<00:07, 21.02it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–        | 238/1600 [00:10<00:57, 23.73it/s]Training:  30%|â–ˆâ–ˆâ–‰       | 476/1600 [00:20<00:47, 23.42it/s]Training:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 709/1600 [00:30<00:38, 23.26it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 958/1600Training loss: 1315.1057, Training accuracy: 0.6650
Macro F1-score: 0.6611
Model performance on Angry speech (in training): 
	Precision: 0.7199, Recall: 0.7325, F1_score: 0.7261
Model performance on Happy speech (in training): 
	Precision: 0.6324, Recall: 0.5075, F1_score: 0.5631
Model performance on Neutral speech (in training): 
	Precision: 0.5952, Recall: 0.6175, F1_score: 0.6061
Model performance on Sad speech (in training): 
	Precision: 0.7024, Recall: 0.8025, F1_score: 0.7491

Eval Phase: 
Validation loss: 182.4863, Validation accuracy: 0.6200
Macro F1-score: 0.6100
Model performance on Angry speech (in validation): 
	Precision: 0.8684, Recall: 0.6600, F1_score: 0.7500
Model performance on Happy speech (in validation): 
	Precision: 0.7059, Recall: 0.4800, F1_score: 0.5714
Model performance on Neutral speech (in validation): 
	Precision: 0.5429, Recall: 0.3800, F1_score: 0.4471
Model performance on Sad speech (in validation): 
	Precision: 0.5161, Recall: 0.9600, F1_score: 0.6713
New best accuracy for layer 4 on epoch 2: 0.6200. Model saved.
Epoch 3/100

Training Phase:
Training loss: 1221.4783, Training accuracy: 0.6956
Macro F1-score: 0.6923
Model performance on Angry speech (in training): 
	Precision: 0.7475, Recall: 0.7625, F1_score: 0.7550
Model performance on Happy speech (in training): 
	Precision: 0.6515, Recall: 0.5375, F1_score: 0.5890
Model performance on Neutral speech (in training): 
	Precision: 0.6277, Recall: 0.6575, F1_score: 0.6422
Model performance on Sad speech (in training): 
	Precision: 0.7449, Recall: 0.8250, F1_score: 0.7829

Eval Phase: 
 [00:40<00:26, 23.89it/s]Training:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1207/1600 [00:50<00:16, 23.86it/s]Training:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1450/1600 [01:00<00:06, 24.00it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–Œ        | 241/1600 [00:10<00:56, 24.05it/s]Training:  15%|â–ˆâ–Œ        | 241/1600 [00:20<00:56, 24.05it/s]Training:  30%|â–ˆâ–ˆâ–‰       | 478/1600 [00:20<00:47, 23.50it/s]Training:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 710/1600 [00:30<00:38, 23.19it/s]Training:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 949/1600 [00:40<00:27, 23.44it/s]Training:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1193/1600 [00:50<00:17, 23.75it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1443/1600 [01:00<00:06, 24.16it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]       Validation loss: 230.2891, Validation accuracy: 0.5750
Macro F1-score: 0.5461
Model performance on Angry speech (in validation): 
	Precision: 0.7347, Recall: 0.7200, F1_score: 0.7273
Model performance on Happy speech (in validation): 
	Precision: 0.7619, Recall: 0.3200, F1_score: 0.4507
Model performance on Neutral speech (in validation): 
	Precision: 0.5833, Recall: 0.2800, F1_score: 0.3784
Model performance on Sad speech (in validation): 
	Precision: 0.4623, Recall: 0.9800, F1_score: 0.6282
Epoch 4/100

Training Phase:
Training loss: 1144.4025, Training accuracy: 0.7081
Macro F1-score: 0.7040
Model performance on Angry speech (in training): 
	Precision: 0.7610, Recall: 0.7800, F1_score: 0.7704
Model performance on Happy speech (in training): 
	Precision: 0.6885, Recall: 0.5525, F1_score: 0.6130
Model performance on Neutral speech (in training): 
	Precision: 0.6509, Recall: 0.6525, F1_score: 0.6517
Model performance on Sad speech (in training): 
	Precision: 0.7244, Recall: 0.8475, F1_score: 0.7811

Eval Phase: 
Validation loss: 188.5573, Validation accuracy: 0.6100
Macro F1-score: 0.6027
Model performance on Angry speech (in validation): 
	Precision: 0.9143, Recall: 0.6400, F1_score: 0.7529
Model performance on Happy speech (in validation): 
	Precision: 0.7419, Recall: 0.4600, F1_score: 0.5679
Model performance on Neutral speech (in validation): 
	Precision: 0.5135, Recall: 0.3800, F1_score: 0.4368
Model performance on Sad speech (in validation): 
	Precision: 0.4948, Recall: 0.9600, F1_score: 0.6531
Epoch 5/100

Training Phase:
                                            Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–        | 238/1600 [00:10<00:57, 23.77it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 483/1600 [00:20<00:46, 24.18it/s]Training:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 728/1600 [00:30<00:36, 23.81it/s]Training:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 971/1600 [00:40<00:26, 24.00it/s]Training:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1214/1600 [00:50<00:16, 23.93it/s]Training:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1453/1600 [01:00<00:06, 23.80it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–Œ        | 244/1600 [00:10<00:55, 24.37it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 488/1600 [00:20<00:46, 23.81it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 488/1600 [00:30<00:46, 23.81it/s]Training:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 722/1600 [00:30<00:37, 23.45it/s]TraiTraining loss: 1095.3442, Training accuracy: 0.7406
Macro F1-score: 0.7387
Model performance on Angry speech (in training): 
	Precision: 0.8203, Recall: 0.8100, F1_score: 0.8151
Model performance on Happy speech (in training): 
	Precision: 0.7057, Recall: 0.6175, F1_score: 0.6587
Model performance on Neutral speech (in training): 
	Precision: 0.6732, Recall: 0.6850, F1_score: 0.6791
Model performance on Sad speech (in training): 
	Precision: 0.7589, Recall: 0.8500, F1_score: 0.8019

Eval Phase: 
Validation loss: 187.6068, Validation accuracy: 0.6250
Macro F1-score: 0.6181
Model performance on Angry speech (in validation): 
	Precision: 0.9189, Recall: 0.6800, F1_score: 0.7816
Model performance on Happy speech (in validation): 
	Precision: 0.7812, Recall: 0.5000, F1_score: 0.6098
Model performance on Neutral speech (in validation): 
	Precision: 0.5143, Recall: 0.3600, F1_score: 0.4235
Model performance on Sad speech (in validation): 
	Precision: 0.5000, Recall: 0.9600, F1_score: 0.6575
New best accuracy for layer 4 on epoch 5: 0.6250. Model saved.
Epoch 6/100

Training Phase:
Training loss: 1017.8210, Training accuracy: 0.7538
Macro F1-score: 0.7517
Model performance on Angry speech (in training): 
	Precision: 0.8275, Recall: 0.8275, F1_score: 0.8275
Model performance on Happy speech (in training): 
	Precision: 0.7507, Recall: 0.6400, F1_score: 0.6910
Model performance on Neutral speech (in training): 
	Precision: 0.6850, Recall: 0.6850, F1_score: 0.6850
Model performance on Sad speech (in training): 
	Precision: 0.7516, Recall: 0.8625, F1_score: 0.8033

Eval Phase: 
ning:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 962/1600 [00:40<00:26, 23.66it/s]Training:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1202/1600 [00:50<00:16, 23.78it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1448/1600 [01:00<00:06, 24.04it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–Œ        | 240/1600 [00:10<00:56, 23.88it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 481/1600 [00:20<00:46, 24.00it/s]Training:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 722/1600 [00:30<00:36, 23.78it/s]Training:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 969/1600 [00:40<00:26, 24.13it/s]Training:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1216/1600 [00:50<00:16, 23.86it/s]Training:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1461/1600 [01:00<00:05, 24.07it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                           Validation loss: 185.5872, Validation accuracy: 0.6600
Macro F1-score: 0.6559
Model performance on Angry speech (in validation): 
	Precision: 0.9231, Recall: 0.7200, F1_score: 0.8090
Model performance on Happy speech (in validation): 
	Precision: 0.7931, Recall: 0.4600, F1_score: 0.5823
Model performance on Neutral speech (in validation): 
	Precision: 0.5098, Recall: 0.5200, F1_score: 0.5149
Model performance on Sad speech (in validation): 
	Precision: 0.5802, Recall: 0.9400, F1_score: 0.7176
New best accuracy for layer 4 on epoch 6: 0.6600. Model saved.
Epoch 7/100

Training Phase:
Training loss: 959.0876, Training accuracy: 0.7631
Macro F1-score: 0.7611
Model performance on Angry speech (in training): 
	Precision: 0.8253, Recall: 0.8150, F1_score: 0.8201
Model performance on Happy speech (in training): 
	Precision: 0.7522, Recall: 0.6450, F1_score: 0.6945
Model performance on Neutral speech (in training): 
	Precision: 0.6961, Recall: 0.7100, F1_score: 0.7030
Model performance on Sad speech (in training): 
	Precision: 0.7775, Recall: 0.8825, F1_score: 0.8267

Eval Phase: 
Validation loss: 223.7707, Validation accuracy: 0.5850
Macro F1-score: 0.5545
Model performance on Angry speech (in validation): 
	Precision: 0.7308, Recall: 0.7600, F1_score: 0.7451
Model performance on Happy speech (in validation): 
	Precision: 0.8125, Recall: 0.2600, F1_score: 0.3939
Model performance on Neutral speech (in validation): 
	Precision: 0.5625, Recall: 0.3600, F1_score: 0.4390
Model performance on Sad speech (in validation): 
	Precision: 0.4800, Recall: 0.9600, F1_score: 0.6400
Epoch 8/100

Training Phase:
                        Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–Œ        | 244/1600 [00:10<00:55, 24.32it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 488/1600 [00:20<00:46, 24.10it/s]Training:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 728/1600 [00:30<00:36, 23.84it/s]Training:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 970/1600 [00:40<00:26, 23.97it/s]Training:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1212/1600 [00:50<00:16, 23.95it/s]Training:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1452/1600 [01:00<00:06, 23.70it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–        | 235/1600 [00:10<00:58, 23.48it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 487/1600 [00:20<00:45, 24.49it/s]Training:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 739/1600 [00:30<00:35, 24.40it/s]Training:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 983/1600 [00:40<00:25, 23.91it/s]Training:  76%|âTraining loss: 881.5845, Training accuracy: 0.7937
Macro F1-score: 0.7920
Model performance on Angry speech (in training): 
	Precision: 0.8446, Recall: 0.8425, F1_score: 0.8436
Model performance on Happy speech (in training): 
	Precision: 0.7890, Recall: 0.6825, F1_score: 0.7319
Model performance on Neutral speech (in training): 
	Precision: 0.7371, Recall: 0.7500, F1_score: 0.7435
Model performance on Sad speech (in training): 
	Precision: 0.8036, Recall: 0.9000, F1_score: 0.8491

Eval Phase: 
Validation loss: 214.7265, Validation accuracy: 0.6350
Macro F1-score: 0.6218
Model performance on Angry speech (in validation): 
	Precision: 0.8837, Recall: 0.7600, F1_score: 0.8172
Model performance on Happy speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Model performance on Neutral speech (in validation): 
	Precision: 0.4792, Recall: 0.4600, F1_score: 0.4694
Model performance on Sad speech (in validation): 
	Precision: 0.5517, Recall: 0.9600, F1_score: 0.7007
Epoch 9/100

Training Phase:
Training loss: 823.5381, Training accuracy: 0.8087
Macro F1-score: 0.8063
Model performance on Angry speech (in training): 
	Precision: 0.8544, Recall: 0.8800, F1_score: 0.8670
Model performance on Happy speech (in training): 
	Precision: 0.8024, Recall: 0.6800, F1_score: 0.7361
Model performance on Neutral speech (in training): 
	Precision: 0.7556, Recall: 0.7575, F1_score: 0.7566
Model performance on Sad speech (in training): 
	Precision: 0.8192, Recall: 0.9175, F1_score: 0.8656

Eval Phase: 
Validation loss: 219.1855, Validation accuracy: 0.6550
Macro F1-score: 0.6496
Model performance on Angry speech (in validation): 
	Precision: 0.8636, Recall: 0.7600, F1_score: 0.8085
Model performance on Happy speech (in validation): 
	Precision: 0.7188, Recall: 0.4600, F1_score: 0.5610
Model performance on Neutral speech (in validation): 
	Precision: 0.5417, Recall: 0.5200, F1_score: 0.5306
Model performance on Sad speech (in validation): 
	Precision: 0.5789, Recall: 0.8800, F1_score: 0.6984
Epoch 10/100

Training Phase:
–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1219/1600 [00:50<00:16, 23.77it/s]Training:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1467/1600 [01:00<00:05, 24.11it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–Œ        | 244/1600 [00:10<00:55, 24.40it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 488/1600 [00:20<00:46, 24.14it/s]Training:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 728/1600 [00:30<00:36, 23.62it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 967/1600 [00:40<00:26, 23.72it/s]Training:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1211/1600 [00:50<00:16, 23.93it/s]Training:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1455/1600 [01:00<00:06, 23.95it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]TrainingTraining loss: 792.8591, Training accuracy: 0.8087
Macro F1-score: 0.8070
Model performance on Angry speech (in training): 
	Precision: 0.8596, Recall: 0.8575, F1_score: 0.8586
Model performance on Happy speech (in training): 
	Precision: 0.8171, Recall: 0.6925, F1_score: 0.7497
Model performance on Neutral speech (in training): 
	Precision: 0.7518, Recall: 0.7725, F1_score: 0.7620
Model performance on Sad speech (in training): 
	Precision: 0.8093, Recall: 0.9125, F1_score: 0.8578

Eval Phase: 
Validation loss: 211.4244, Validation accuracy: 0.6350
Macro F1-score: 0.6249
Model performance on Angry speech (in validation): 
	Precision: 0.7800, Recall: 0.7800, F1_score: 0.7800
Model performance on Happy speech (in validation): 
	Precision: 0.7500, Recall: 0.3600, F1_score: 0.4865
Model performance on Neutral speech (in validation): 
	Precision: 0.5263, Recall: 0.6000, F1_score: 0.5607
Model performance on Sad speech (in validation): 
	Precision: 0.5797, Recall: 0.8000, F1_score: 0.6723
Epoch 11/100

Training Phase:
:  16%|â–ˆâ–Œ        | 248/1600 [00:10<00:54, 24.77it/s]Training:  31%|â–ˆâ–ˆâ–ˆ       | 496/1600 [00:20<00:45, 24.36it/s]Training:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 737/1600 [00:30<00:36, 23.73it/s]Training:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 979/1600 [00:40<00:25, 23.90it/s]Training:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1221/1600 [00:51<00:16, 23.61it/s]Training:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1469/1600 [01:01<00:05, 24.00it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–        | 231/1600 [00:10<00:59, 23.00it/s]Training:  29%|â–ˆâ–ˆâ–‰       | 470/1600 [00:20<00:48, 23.52it/s]Training:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 717/1600 [00:30<00:36, 24.06it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 964/1600 [00:40<00:26, 24.02it/s]Training:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1208/1600 [00:50<00:16, 24.13it/s]Training:  91%|â–ˆâ–ˆâ–Training loss: 730.7476, Training accuracy: 0.8237
Macro F1-score: 0.8229
Model performance on Angry speech (in training): 
	Precision: 0.8697, Recall: 0.8675, F1_score: 0.8686
Model performance on Happy speech (in training): 
	Precision: 0.8453, Recall: 0.7375, F1_score: 0.7877
Model performance on Neutral speech (in training): 
	Precision: 0.7683, Recall: 0.7875, F1_score: 0.7778
Model performance on Sad speech (in training): 
	Precision: 0.8167, Recall: 0.9025, F1_score: 0.8575

Eval Phase: 
Validation loss: 271.1291, Validation accuracy: 0.6300
Macro F1-score: 0.5984
Model performance on Angry speech (in validation): 
	Precision: 0.7049, Recall: 0.8600, F1_score: 0.7748
Model performance on Happy speech (in validation): 
	Precision: 0.8125, Recall: 0.2600, F1_score: 0.3939
Model performance on Neutral speech (in validation): 
	Precision: 0.6000, Recall: 0.4800, F1_score: 0.5333
Model performance on Sad speech (in validation): 
	Precision: 0.5542, Recall: 0.9200, F1_score: 0.6917
Epoch 12/100

Training Phase:
Training loss: 676.5074, Training accuracy: 0.8462
Macro F1-score: 0.8460
Model performance on Angry speech (in training): 
	Precision: 0.9182, Recall: 0.8975, F1_score: 0.9077
Model performance on Happy speech (in training): 
	Precision: 0.8391, Recall: 0.7825, F1_score: 0.8098
Model performance on Neutral speech (in training): 
	Precision: 0.8035, Recall: 0.8075, F1_score: 0.8055
Model performance on Sad speech (in training): 
	Precision: 0.8272, Recall: 0.8975, F1_score: 0.8609

Eval Phase: 
Validation loss: 206.1023, Validation accuracy: 0.6700
Macro F1-score: 0.6674
Model performance on Angry speech (in validation): 
	Precision: 0.8636, Recall: 0.7600, F1_score: 0.8085
Model performance on Happy speech (in validation): 
	Precision: 0.7419, Recall: 0.4600, F1_score: 0.5679
Model performance on Neutral speech (in validation): 
	Precision: 0.5614, Recall: 0.6400, F1_score: 0.5981
Model performance on Sad speech (in validation): 
	Precision: 0.6029, Recall: 0.8200, F1_score: 0.6949
New best accuracy for layer 4 on epoch 12: 0.6700. Model saved.
Validation loss does not decrease for 10 epochs. End training.
Model best accuracy on validation set: 0.6700

Test Phase: 
ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1452/1600 [01:00<00:06, 23.96it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–        | 237/1600 [00:10<00:57, 23.68it/s]Training:  30%|â–ˆâ–ˆâ–‰       | 474/1600 [00:20<00:47, 23.66it/s]Training:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 711/1600 [00:30<00:37, 23.64it/s]Training:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 948/1600 [00:40<00:27, 23.65it/s]Training:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1194/1600 [00:50<00:16, 23.97it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1440/1600 [01:00<00:06, 24.12it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]                                                Some weights of the model checkpoint at /work/tc062/tc062/zhan7721/saved_models/de were not used when initializing Wav2Vec2Model: ['encoder.layers.10.attention.k_proj.bias', 'encoder.layers.10.attention.k_proj.weight', 'encoder.layers.10.attention.out_proj.bias', 'encoder.layers.10.attention.out_proj.weight', 'encoder.layers.10.attention.q_proj.bias', 'encoder.layers.10.attention.q_proj.weight', 'encoder.layers.10.attention.v_proj.bias', 'encoder.layers.10.attention.v_proj.weight', 'encoder.layers.10.feed_forward.intermediate_dense.bias', 'encoder.layers.10.feed_forward.intermediate_dense.weight', 'encoder.layers.10.feed_forward.output_dense.bias', 'encoder.layers.10.feed_forward.output_dense.weight', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.10.layer_norm.bias', 'encoder.layers.10.layer_norm.weight', 'encoder.layers.11.attention.k_proj.bias', 'encoder.layers.11.attention.k_proj.weight', 'encoder.layers.11.attention.out_proj.bias', 'encoder.layers.11.attention.out_proj.weight', 'encoder.layers.11.attention.q_proj.bias', 'encoder.layers.11.attention.q_proj.weight', 'encoder.layers.11.attention.v_proj.bias', 'encoder.layers.11.attention.v_proj.weight', 'encoder.layers.11.feed_forward.intermediate_dense.bias', 'encoder.layers.11.feed_forward.intermediate_dense.weight', 'encoder.layers.11.feed_forward.output_dense.bias', 'encoder.layers.11.feed_forward.output_dense.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.11.layer_norm.bias', 'encoder.layers.11.layer_norm.weight', 'encoder.layers.5.attention.k_proj.bias', 'encoder.layers.5.attention.k_proj.weight', 'encoder.layers.5.attention.out_proj.bias', 'encoder.layers.5.attention.out_proj.weight', 'encoder.layers.5.attention.q_proj.bias', 'encoder.layers.5.attention.q_proj.weight', 'encoder.layers.5.attention.v_proj.bias', 'encoder.layers.5.attention.v_proj.weight', 'encoder.layers.5.feed_forward.intermediate_dense.bias', 'encoder.layers.5.feed_forward.intermediate_dense.weight', 'encoder.layers.5.feed_forward.output_dense.bias', 'encoder.layers.5.feed_forward.output_dense.weight', 'encoder.layers.5.final_layer_norm.bias', 'encoder.layers.5.final_layer_norm.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.6.attention.k_proj.bias', 'encoder.layers.6.attention.k_proj.weight', 'encoder.layers.6.attention.out_proj.bias', 'encoder.layers.6.attention.out_proj.weight', 'encoder.layers.6.attention.q_proj.bias', 'encoder.layers.6.attention.q_proj.weight', 'encoder.layers.6.attention.v_proj.bias', 'encoder.layers.6.attention.v_proj.weight', 'encoder.layers.6.feed_forward.intermediate_dense.bias', 'encoder.layers.6.feed_forward.intermediate_dense.weight', 'encoder.layers.6.feed_forward.output_dense.bias', 'encoder.layers.6.feed_forward.output_dense.weight', 'encoder.layers.6.final_layer_norm.bias', 'encoder.layers.6.final_layer_norm.weight', 'encoder.layers.6.layer_norm.bias', 'encoder.layers.6.layer_norm.weight', 'encoder.layers.7.attention.k_proj.bias', 'encoder.layers.7.attention.k_proj.weight', 'encoder.layers.7.attention.out_proj.bias', 'encoder.layers.7.attention.out_proj.weight', 'encoder.layers.7.attention.q_proj.bias', 'encoder.layers.7.attention.q_proj.weight', 'encoder.layers.7.attention.v_proj.bias', 'encoder.layers.7.attention.v_proj.weight', 'encoder.layers.7.feed_forward.intermediate_dense.bias', 'encoder.layers.7.feed_forward.intermediate_dense.weight', 'encoder.layers.7.feed_forward.output_dense.bias', 'encoder.layers.7.feed_forward.output_dense.weight', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.7.layer_norm.bias', 'encoder.layers.7.layer_norm.weight', 'encoder.layers.8.attention.k_proj.bias', 'encoder.layers.8.attention.k_proj.weight', 'encoder.layers.8.attention.out_proj.bias', 'encoder.layers.8.attention.out_proj.weight', 'encoder.layers.8.attention.q_proj.bias', 'encoder.layers.8.attention.q_proj.weight', 'encoder.layers.8.attention.v_proj.bias', 'encoder.layers.8.attention.v_proj.weight', 'encoder.layers.8.feed_forward.intermediate_dense.bias', 'encoder.layers.8.feed_forward.intermediate_dense.weight', 'encoder.layers.8.feed_forward.output_dense.bias', 'encoder.layers.8.feed_forward.output_dense.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.8.layer_norm.bias', 'encoder.layers.8.layer_norm.weight', 'encoder.layers.9.attention.k_proj.bias', 'encoder.layers.9.attention.k_proj.weight', 'encoder.layers.9.attention.out_proj.bias', 'encoder.layers.9.attention.out_proj.weight', 'encoder.layers.9.attention.q_proj.bias', 'encoder.layers.9.attention.q_proj.weight', 'encoder.layers.9.attention.v_proj.bias', 'encoder.layers.9.attention.v_proj.weight', 'encoder.layers.9.feed_forward.intermediate_dense.bias', 'encoder.layers.9.feed_forward.intermediate_dense.weight', 'encoder.layers.9.feed_forward.output_dense.bias', 'encoder.layers.9.feed_forward.output_dense.weight', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.layer_norm.bias', 'encoder.layers.9.layer_norm.weight']
- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Test loss: 243.0314, Test accuracy: 0.6500
Macro F1-score: 0.6460
Model performance on Angry speech (in test): 
	Precision: 0.6852, Recall: 0.7400, F1_score: 0.7115
Model performance on Happy speech (in test): 
	Precision: 0.6857, Recall: 0.4800, F1_score: 0.5647
Model performance on Neutral speech (in test): 
	Precision: 0.5818, Recall: 0.6400, F1_score: 0.6095
Model performance on Sad speech (in test): 
	Precision: 0.6607, Recall: 0.7400, F1_score: 0.6981

======================= This is fold_4 on cn =======================

Load dataset: 
Loading en train data: fold_4...
Preprocess en fold_4 data for cn model
Loading en eval data: fold_4...
Preprocess en fold_4 data for cn model
Loading en test data: fold_4...
Preprocess en fold_4 data for cn model
Use cn model to add lora
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training loss: 1379.4922, Training accuracy: 0.6494
Macro F1-score: 0.6447
Model performance on Angry speech (in training): 
	Precision: 0.7229, Recall: 0.7500, F1_score: 0.7362
Model performance on Happy speech (in training): 
	Precision: 0.6170, Recall: 0.5075, F1_score: 0.5569
Model performance on Neutral speech (in training): 
	Precision: 0.5688, Recall: 0.5475, F1_score: 0.5580
Model performance on Sad speech (in training): 
	Precision: 0.6730, Recall: 0.7925, F1_score: 0.7279

Eval Phase: 
Validation loss: 145.5430, Validation accuracy: 0.7150
Macro F1-score: 0.7088
Model performance on Angry speech (in validation): 
	Precision: 0.7419, Recall: 0.9200, F1_score: 0.8214
Model performance on Happy speech (in validation): 
	Precision: 0.6667, Recall: 0.5200, F1_score: 0.5843
Model performance on Neutral speech (in validation): 
	Precision: 0.6538, Recall: 0.6800, F1_score: 0.6667
Model performance on Sad speech (in validation): 
	Precision: 0.7872, Recall: 0.7400, F1_score: 0.7629
New best accuracy for layer 4 on epoch 1: 0.7150. Model saved.
Epoch 2/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:   8%|â–Š         | 134/1600 [00:10<01:49, 13.36it/s]Training:  19%|â–ˆâ–‰        | 308/1600 [00:20<01:22, 15.63it/s]Training:  31%|â–ˆâ–ˆâ–ˆ       | 499/1600 [00:30<01:04, 17.19it/s]Training:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 696/1600 [00:40<00:49, 18.17it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 907/1600 [00:50<00:36, 19.22it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1121/1600 [01:00<00:24, 19.95it/s]Training:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 1337/1600 [01:10<00:12, 20.47it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1553/1600 [01:20<00:02, 20.52it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–        | 236/1600 [00:10<00:58, 23.48it/s]Training:  30%|â–ˆâ–ˆâ–‰       | 476/1600 [00:20<00:47, 23.74it/s]Training:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 716/160Training loss: 1269.4180, Training accuracy: 0.6731
Macro F1-score: 0.6688
Model performance on Angry speech (in training): 
	Precision: 0.7178, Recall: 0.7250, F1_score: 0.7214
Model performance on Happy speech (in training): 
	Precision: 0.6528, Recall: 0.5500, F1_score: 0.5970
Model performance on Neutral speech (in training): 
	Precision: 0.6154, Recall: 0.5800, F1_score: 0.5972
Model performance on Sad speech (in training): 
	Precision: 0.6950, Recall: 0.8375, F1_score: 0.7596

Eval Phase: 
Validation loss: 145.7977, Validation accuracy: 0.7300
Macro F1-score: 0.7185
Model performance on Angry speech (in validation): 
	Precision: 0.7895, Recall: 0.9000, F1_score: 0.8411
Model performance on Happy speech (in validation): 
	Precision: 0.8800, Recall: 0.4400, F1_score: 0.5867
Model performance on Neutral speech (in validation): 
	Precision: 0.6250, Recall: 0.7000, F1_score: 0.6604
Model performance on Sad speech (in validation): 
	Precision: 0.7097, Recall: 0.8800, F1_score: 0.7857
New best accuracy for layer 4 on epoch 2: 0.7300. Model saved.
Epoch 3/100

Training Phase:
0 [00:30<00:37, 23.34it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 957/1600 [00:40<00:27, 23.62it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 957/1600 [00:51<00:27, 23.62it/s]Training:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1194/1600 [00:51<00:17, 22.63it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1442/1600 [01:01<00:06, 23.33it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–Œ        | 243/1600 [00:10<00:55, 24.26it/s]Training:  32%|â–ˆâ–ˆâ–ˆâ–      | 504/1600 [00:20<00:43, 25.33it/s]Training:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 765/1600 [00:30<00:33, 24.76it/s]Training:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 765/1600 [00:40<00:33, 24.76it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1014/1600 [00:40<00:23, 24.78it/s]Training:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1270/1600 [00:50<00:13, 25.06it/s]Training:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Training loss: 1210.5261, Training accuracy: 0.6944
Macro F1-score: 0.6918
Model performance on Angry speech (in training): 
	Precision: 0.7487, Recall: 0.7450, F1_score: 0.7469
Model performance on Happy speech (in training): 
	Precision: 0.6814, Recall: 0.5775, F1_score: 0.6252
Model performance on Neutral speech (in training): 
	Precision: 0.6318, Recall: 0.6350, F1_score: 0.6334
Model performance on Sad speech (in training): 
	Precision: 0.7115, Recall: 0.8200, F1_score: 0.7619

Eval Phase: 
Validation loss: 177.4270, Validation accuracy: 0.6650
Macro F1-score: 0.6200
Model performance on Angry speech (in validation): 
	Precision: 0.6818, Recall: 0.9000, F1_score: 0.7759
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1800, F1_score: 0.3051
Model performance on Neutral speech (in validation): 
	Precision: 0.6667, Recall: 0.6800, F1_score: 0.6733
Model performance on Sad speech (in validation): 
	Precision: 0.6081, Recall: 0.9000, F1_score: 0.7258
Epoch 4/100

Training Phase:
Training loss: 1096.1169, Training accuracy: 0.7212
Macro F1-score: 0.7181
Model performance on Angry speech (in training): 
	Precision: 0.7886, Recall: 0.7925, F1_score: 0.7905
Model performance on Happy speech (in training): 
	Precision: 0.7122, Recall: 0.6000, F1_score: 0.6513
Model performance on Neutral speech (in training): 
	Precision: 0.6546, Recall: 0.6350, F1_score: 0.6447
Model performance on Sad speech (in training): 
	Precision: 0.7252, Recall: 0.8575, F1_score: 0.7858

Eval Phase: 
Validation loss: 142.6246, Validation accuracy: 0.7100
Macro F1-score: 0.7035
Model performance on Angry speech (in validation): 
	Precision: 0.8148, Recall: 0.8800, F1_score: 0.8462
Model performance on Happy speech (in validation): 
	Precision: 0.6667, Recall: 0.4800, F1_score: 0.5581
Model performance on Neutral speech (in validation): 
	Precision: 0.6545, Recall: 0.7200, F1_score: 0.6857
Model performance on Sad speech (in validation): 
	Precision: 0.6909, Recall: 0.7600, F1_score: 0.7238
Epoch 5/100

Training Phase:
Œ| 1526/1600 [01:01<00:02, 24.71it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|â–ˆâ–Œ        | 252/1600 [00:10<00:53, 25.13it/s]Training:  32%|â–ˆâ–ˆâ–ˆâ–      | 504/1600 [00:20<00:44, 24.54it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 756/1600 [00:30<00:34, 24.80it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1008/1600 [00:40<00:23, 24.81it/s]Training:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1257/1600 [00:50<00:13, 24.77it/s]Training:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1510/1600 [01:00<00:03, 24.92it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|â–ˆâ–Œ        | 250/1600 [00:10<00:54, 25.00it/s]Training:  31%|â–ˆâ–ˆâ–ˆâ–      | 502/160Training loss: 1045.1435, Training accuracy: 0.7294
Macro F1-score: 0.7267
Model performance on Angry speech (in training): 
	Precision: 0.7985, Recall: 0.7825, F1_score: 0.7904
Model performance on Happy speech (in training): 
	Precision: 0.7067, Recall: 0.6025, F1_score: 0.6505
Model performance on Neutral speech (in training): 
	Precision: 0.6609, Recall: 0.6675, F1_score: 0.6642
Model performance on Sad speech (in training): 
	Precision: 0.7473, Recall: 0.8650, F1_score: 0.8019

Eval Phase: 
Validation loss: 168.1133, Validation accuracy: 0.7000
Macro F1-score: 0.6751
Model performance on Angry speech (in validation): 
	Precision: 0.7636, Recall: 0.8400, F1_score: 0.8000
Model performance on Happy speech (in validation): 
	Precision: 0.9333, Recall: 0.2800, F1_score: 0.4308
Model performance on Neutral speech (in validation): 
	Precision: 0.5714, Recall: 0.8800, F1_score: 0.6929
Model performance on Sad speech (in validation): 
	Precision: 0.7547, Recall: 0.8000, F1_score: 0.7767
Epoch 6/100

Training Phase:
0 [00:20<00:43, 25.06it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 754/1600 [00:30<00:33, 24.91it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1012/1600 [00:40<00:23, 25.25it/s]Training:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1270/1600 [00:50<00:13, 24.91it/s]Training:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1517/1600 [01:00<00:03, 24.81it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|â–ˆâ–Œ        | 251/1600 [00:10<00:53, 25.05it/s]Training:  32%|â–ˆâ–ˆâ–ˆâ–      | 504/1600 [00:20<00:43, 25.15it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 757/1600 [00:30<00:34, 24.73it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1006/1600 [00:40<00:23, 24.78it/s]Training:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1259/1600 [00:50<00:13, 24.95it/s]Training:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1512/1600 [01:00<00:03, 25.05it/s]                              Training loss: 990.4901, Training accuracy: 0.7550
Macro F1-score: 0.7530
Model performance on Angry speech (in training): 
	Precision: 0.7941, Recall: 0.8100, F1_score: 0.8020
Model performance on Happy speech (in training): 
	Precision: 0.7612, Recall: 0.6375, F1_score: 0.6939
Model performance on Neutral speech (in training): 
	Precision: 0.6942, Recall: 0.7150, F1_score: 0.7044
Model performance on Sad speech (in training): 
	Precision: 0.7708, Recall: 0.8575, F1_score: 0.8118

Eval Phase: 
Validation loss: 171.7134, Validation accuracy: 0.6500
Macro F1-score: 0.6331
Model performance on Angry speech (in validation): 
	Precision: 0.7800, Recall: 0.7800, F1_score: 0.7800
Model performance on Happy speech (in validation): 
	Precision: 0.7500, Recall: 0.3000, F1_score: 0.4286
Model performance on Neutral speech (in validation): 
	Precision: 0.5054, Recall: 0.9400, F1_score: 0.6573
Model performance on Sad speech (in validation): 
	Precision: 0.7838, Recall: 0.5800, F1_score: 0.6667
Epoch 7/100

Training Phase:
Training loss: 944.4852, Training accuracy: 0.7588
Macro F1-score: 0.7561
Model performance on Angry speech (in training): 
	Precision: 0.8024, Recall: 0.8225, F1_score: 0.8123
Model performance on Happy speech (in training): 
	Precision: 0.7575, Recall: 0.6325, F1_score: 0.6894
Model performance on Neutral speech (in training): 
	Precision: 0.6990, Recall: 0.7025, F1_score: 0.7007
Model performance on Sad speech (in training): 
	Precision: 0.7731, Recall: 0.8775, F1_score: 0.8220

Eval Phase: 
Validation loss: 167.7783, Validation accuracy: 0.6850
Macro F1-score: 0.6712
Model performance on Angry speech (in validation): 
	Precision: 0.7414, Recall: 0.8600, F1_score: 0.7963
Model performance on Happy speech (in validation): 
	Precision: 0.6786, Recall: 0.3800, F1_score: 0.4872
Model performance on Neutral speech (in validation): 
	Precision: 0.6545, Recall: 0.7200, F1_score: 0.6857
Model performance on Sad speech (in validation): 
	Precision: 0.6610, Recall: 0.7800, F1_score: 0.7156
Epoch 8/100

Training Phase:
                               Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|â–ˆâ–Œ        | 256/1600 [00:10<00:52, 25.57it/s]Training:  32%|â–ˆâ–ˆâ–ˆâ–      | 512/1600 [00:20<00:43, 24.75it/s]Training:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 769/1600 [00:30<00:33, 25.16it/s]Training:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1026/1600 [00:41<00:23, 24.78it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1288/1600 [00:51<00:12, 25.27it/s]Training:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1550/1600 [01:01<00:01, 25.15it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–Œ        | 241/1600 [00:10<00:56, 23.92it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 481/1600 [00:23<00:56, 19.65it/s]Training:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 725/16Training loss: 858.5974, Training accuracy: 0.7913
Macro F1-score: 0.7899
Model performance on Angry speech (in training): 
	Precision: 0.8441, Recall: 0.8525, F1_score: 0.8483
Model performance on Happy speech (in training): 
	Precision: 0.7989, Recall: 0.6950, F1_score: 0.7433
Model performance on Neutral speech (in training): 
	Precision: 0.7277, Recall: 0.7350, F1_score: 0.7313
Model performance on Sad speech (in training): 
	Precision: 0.7950, Recall: 0.8825, F1_score: 0.8365

Eval Phase: 
Validation loss: 255.8421, Validation accuracy: 0.6050
Macro F1-score: 0.5768
Model performance on Angry speech (in validation): 
	Precision: 0.8718, Recall: 0.6800, F1_score: 0.7640
Model performance on Happy speech (in validation): 
	Precision: 0.8000, Recall: 0.1600, F1_score: 0.2667
Model performance on Neutral speech (in validation): 
	Precision: 0.4396, Recall: 0.8000, F1_score: 0.5674
Model performance on Sad speech (in validation): 
	Precision: 0.6500, Recall: 0.7800, F1_score: 0.7091
Epoch 9/100

Training Phase:
00 [00:33<00:40, 21.56it/s]Training:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 975/1600 [00:43<00:27, 22.79it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1228/1600 [00:53<00:15, 23.61it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1228/1600 [01:08<00:15, 23.61it/s]Training:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1460/1600 [01:08<00:06, 20.43it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|â–ˆâ–Ž        | 203/1600 [00:10<01:09, 20.24it/s]Training:  26%|â–ˆâ–ˆâ–Œ       | 410/1600 [00:20<00:58, 20.49it/s]Training:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 623/1600 [00:30<00:46, 20.84it/s]Training:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 623/1600 [00:40<00:46, 20.84it/s]Training:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 836/1600 [00:40<00:36, 20.70it/s]Training:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1049/1600 [00:50<00:26, 20.89it/s]Training:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1271Training loss: 780.1893, Training accuracy: 0.8113
Macro F1-score: 0.8102
Model performance on Angry speech (in training): 
	Precision: 0.8561, Recall: 0.8625, F1_score: 0.8593
Model performance on Happy speech (in training): 
	Precision: 0.8110, Recall: 0.7400, F1_score: 0.7739
Model performance on Neutral speech (in training): 
	Precision: 0.7614, Recall: 0.7500, F1_score: 0.7557
Model performance on Sad speech (in training): 
	Precision: 0.8151, Recall: 0.8925, F1_score: 0.8520

Eval Phase: 
Validation loss: 221.5922, Validation accuracy: 0.6350
Macro F1-score: 0.6228
Model performance on Angry speech (in validation): 
	Precision: 0.6949, Recall: 0.8200, F1_score: 0.7523
Model performance on Happy speech (in validation): 
	Precision: 0.7826, Recall: 0.3600, F1_score: 0.4932
Model performance on Neutral speech (in validation): 
	Precision: 0.5000, Recall: 0.8400, F1_score: 0.6269
Model performance on Sad speech (in validation): 
	Precision: 0.7647, Recall: 0.5200, F1_score: 0.6190
Epoch 10/100

Training Phase:
Training loss: 757.4612, Training accuracy: 0.8163
Macro F1-score: 0.8158
Model performance on Angry speech (in training): 
	Precision: 0.8728, Recall: 0.8575, F1_score: 0.8651
Model performance on Happy speech (in training): 
	Precision: 0.8237, Recall: 0.7475, F1_score: 0.7837
Model performance on Neutral speech (in training): 
	Precision: 0.7610, Recall: 0.7800, F1_score: 0.7704
Model performance on Sad speech (in training): 
	Precision: 0.8111, Recall: 0.8800, F1_score: 0.8441

Eval Phase: 
Validation loss: 217.1551, Validation accuracy: 0.6250
Macro F1-score: 0.6217
Model performance on Angry speech (in validation): 
	Precision: 0.8049, Recall: 0.6600, F1_score: 0.7253
Model performance on Happy speech (in validation): 
	Precision: 0.6176, Recall: 0.4200, F1_score: 0.5000
Model performance on Neutral speech (in validation): 
	Precision: 0.5342, Recall: 0.7800, F1_score: 0.6341
Model performance on Sad speech (in validation): 
	Precision: 0.6154, Recall: 0.6400, F1_score: 0.6275
Epoch 11/100

Training Phase:
/1600 [01:00<00:15, 21.32it/s]Training:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1502/1600 [01:10<00:04, 21.90it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|â–ˆâ–Œ        | 252/1600 [00:10<00:53, 25.16it/s]Training:  32%|â–ˆâ–ˆâ–ˆâ–      | 504/1600 [00:20<00:43, 25.07it/s]Training:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 755/1600 [00:30<00:34, 24.77it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1007/1600 [00:40<00:23, 24.92it/s]Training:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1259/1600 [00:51<00:14, 24.26it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1491/1600 [01:01<00:04, 23.62it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–Œ        | 2Training loss: 674.1491, Training accuracy: 0.8406
Macro F1-score: 0.8404
Model performance on Angry speech (in training): 
	Precision: 0.8900, Recall: 0.8900, F1_score: 0.8900
Model performance on Happy speech (in training): 
	Precision: 0.8698, Recall: 0.7850, F1_score: 0.8252
Model performance on Neutral speech (in training): 
	Precision: 0.7780, Recall: 0.7975, F1_score: 0.7877
Model performance on Sad speech (in training): 
	Precision: 0.8298, Recall: 0.8900, F1_score: 0.8589

Eval Phase: 
Validation loss: 209.8622, Validation accuracy: 0.6700
Macro F1-score: 0.6719
Model performance on Angry speech (in validation): 
	Precision: 0.8750, Recall: 0.7000, F1_score: 0.7778
Model performance on Happy speech (in validation): 
	Precision: 0.6000, Recall: 0.6000, F1_score: 0.6000
Model performance on Neutral speech (in validation): 
	Precision: 0.5797, Recall: 0.8000, F1_score: 0.6723
Model performance on Sad speech (in validation): 
	Precision: 0.7073, Recall: 0.5800, F1_score: 0.6374
Epoch 12/100

Training Phase:
43/1600 [00:10<00:56, 24.22it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 486/1600 [00:20<00:47, 23.66it/s]Training:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 719/1600 [00:30<00:37, 23.35it/s]Training:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 949/1600 [00:40<00:28, 23.04it/s]Training:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1180/1600 [00:50<00:18, 23.04it/s]Training:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1411/1600 [01:01<00:08, 22.86it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–        | 225/1600 [00:10<01:01, 22.48it/s]Training:  28%|â–ˆâ–ˆâ–Š       | 450/1600 [00:20<00:51, 22.26it/s]Training:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 674/1600 [00:30<00:41, 22.31it/s]Training:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 899/1600 [00:40<00:31, 22.38it/s]Training:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1131/1600 [00:50<00:20, 22.67it/s]Training:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1372/1Training loss: 648.0262, Training accuracy: 0.8494
Macro F1-score: 0.8489
Model performance on Angry speech (in training): 
	Precision: 0.8914, Recall: 0.8825, F1_score: 0.8869
Model performance on Happy speech (in training): 
	Precision: 0.8443, Recall: 0.8000, F1_score: 0.8216
Model performance on Neutral speech (in training): 
	Precision: 0.8081, Recall: 0.8000, F1_score: 0.8040
Model performance on Sad speech (in training): 
	Precision: 0.8531, Recall: 0.9150, F1_score: 0.8830

Eval Phase: 
Validation loss: 206.6901, Validation accuracy: 0.6850
Macro F1-score: 0.6833
Model performance on Angry speech (in validation): 
	Precision: 0.8780, Recall: 0.7200, F1_score: 0.7912
Model performance on Happy speech (in validation): 
	Precision: 0.6098, Recall: 0.5000, F1_score: 0.5495
Model performance on Neutral speech (in validation): 
	Precision: 0.6406, Recall: 0.8200, F1_score: 0.7193
Model performance on Sad speech (in validation): 
	Precision: 0.6481, Recall: 0.7000, F1_score: 0.6731
Epoch 13/100

Training Phase:
Training loss: 607.7775, Training accuracy: 0.8431
Macro F1-score: 0.8423
Model performance on Angry speech (in training): 
	Precision: 0.8861, Recall: 0.8950, F1_score: 0.8905
Model performance on Happy speech (in training): 
	Precision: 0.8324, Recall: 0.7700, F1_score: 0.8000
Model performance on Neutral speech (in training): 
	Precision: 0.7850, Recall: 0.7850, F1_score: 0.7850
Model performance on Sad speech (in training): 
	Precision: 0.8662, Recall: 0.9225, F1_score: 0.8935

Eval Phase: 
Validation loss: 264.3156, Validation accuracy: 0.6100
Macro F1-score: 0.6102
Model performance on Angry speech (in validation): 
	Precision: 0.9394, Recall: 0.6200, F1_score: 0.7470
Model performance on Happy speech (in validation): 
	Precision: 0.4884, Recall: 0.4200, F1_score: 0.4516
Model performance on Neutral speech (in validation): 
	Precision: 0.5000, Recall: 0.8800, F1_score: 0.6377
Model performance on Sad speech (in validation): 
	Precision: 0.7222, Recall: 0.5200, F1_score: 0.6047
Epoch 14/100

Training Phase:
600 [01:00<00:09, 23.12it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–        | 231/1600 [00:10<00:59, 23.05it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 482/1600 [00:20<00:46, 24.21it/s]Training:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 733/1600 [00:30<00:36, 23.77it/s]Training:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 972/1600 [00:40<00:26, 23.80it/s]Training:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1214/1600 [00:50<00:16, 23.92it/s]Training:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1214/1600 [01:01<00:16, 23.92it/s]Training:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1451/1600 [01:01<00:06, 23.66it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–Œ        | 244/1600 [00:1Training loss: 536.1909, Training accuracy: 0.8694
Macro F1-score: 0.8691
Model performance on Angry speech (in training): 
	Precision: 0.9169, Recall: 0.9100, F1_score: 0.9134
Model performance on Happy speech (in training): 
	Precision: 0.8780, Recall: 0.8100, F1_score: 0.8427
Model performance on Neutral speech (in training): 
	Precision: 0.8195, Recall: 0.8400, F1_score: 0.8296
Model performance on Sad speech (in training): 
	Precision: 0.8656, Recall: 0.9175, F1_score: 0.8908

Eval Phase: 
Validation loss: 258.2240, Validation accuracy: 0.6300
Macro F1-score: 0.6225
Model performance on Angry speech (in validation): 
	Precision: 0.7755, Recall: 0.7600, F1_score: 0.7677
Model performance on Happy speech (in validation): 
	Precision: 0.4681, Recall: 0.4400, F1_score: 0.4536
Model performance on Neutral speech (in validation): 
	Precision: 0.5811, Recall: 0.8600, F1_score: 0.6935
Model performance on Sad speech (in validation): 
	Precision: 0.7667, Recall: 0.4600, F1_score: 0.5750
Validation loss does not decrease for 10 epochs. End training.
Model best accuracy on validation set: 0.7300

Test Phase: 
Test loss: 130.6508, Test accuracy: 0.7250
Macro F1-score: 0.7162
Model performance on Angry speech (in test): 
	Precision: 0.7636, Recall: 0.8400, F1_score: 0.8000
Model performance on Happy speech (in test): 
	Precision: 0.8519, Recall: 0.4600, F1_score: 0.5974
Model performance on Neutral speech (in test): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Sad speech (in test): 
	Precision: 0.7000, Recall: 0.8400, F1_score: 0.7636

cn, all folds accuracy: ['0.6550', '0.6400', '0.6450', '0.6500', '0.7250']
cn, all folds emo precision: {'Angry': ['0.8261', '0.6316', '0.7170', '0.6852', '0.7636'], 'Happy': ['0.5778', '0.6667', '0.8125', '0.6857', '0.8519'], 'Neutral': ['0.5472', '0.5323', '0.6182', '0.5818', '0.6552'], 'Sad': ['0.6786', '0.7593', '0.5789', '0.6607', '0.7000']}
cn, all folds emo recall: {'Angry': ['0.7600', '0.7200', '0.7600', '0.7400', '0.8400'], 'Happy': ['0.5200', '0.3600', '0.2600', '0.4800', '0.4600'], 'Neutral': ['0.5800', '0.6600', '0.6800', '0.6400', '0.7600'], 'Sad': ['0.7600', '0.8200', '0.8800', '0.7400', '0.8400']}
cn, all folds emo f1score: {'Angry': ['0.7917', '0.6729', '0.7379', '0.7115', '0.8000'], 'Happy': ['0.5474', '0.4675', '0.3939', '0.5647', '0.5974'], 'Neutral': ['0.5631', '0.5893', '0.6476', '0.6095', '0.7037'], 'Sad': ['0.7170', '0.7885', '0.6984', '0.6981', '0.7636']}
0<00:55, 24.36it/s]Training:  15%|â–ˆâ–Œ        | 244/1600 [00:20<00:55, 24.36it/s]Training:  30%|â–ˆâ–ˆâ–ˆ       | 483/1600 [00:20<00:47, 23.69it/s]Training:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 716/1600 [00:30<00:37, 23.44it/s]Training:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 955/1600 [00:40<00:27, 23.58it/s]Training:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1195/1600 [00:50<00:17, 23.71it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1435/1600 [01:00<00:06, 23.76it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]                                                ------------------NEXT SCRIPT: RUNNER_DE----------------------
/work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Matplotlib created a temporary cache directory at /dev/shm/zhan7721_5912054/matplotlib-9_0mj00p because the default path (/home/tc062/tc062/zhan7721/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Some weights of the model checkpoint at /work/tc062/tc062/zhan7721/saved_models/de were not used when initializing Wav2Vec2Model: ['encoder.layers.10.attention.k_proj.bias', 'encoder.layers.10.attention.k_proj.weight', 'encoder.layers.10.attention.out_proj.bias', 'encoder.layers.10.attention.out_proj.weight', 'encoder.layers.10.attention.q_proj.bias', 'encoder.layers.10.attention.q_proj.weight', 'encoder.layers.10.attention.v_proj.bias', 'encoder.layers.10.attention.v_proj.weight', 'encoder.layers.10.feed_forward.intermediate_dense.bias', 'encoder.layers.10.feed_forward.intermediate_dense.weight', 'encoder.layers.10.feed_forward.output_dense.bias', 'encoder.layers.10.feed_forward.output_dense.weight', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.10.layer_norm.bias', 'encoder.layers.10.layer_norm.weight', 'encoder.layers.11.attention.k_proj.bias', 'encoder.layers.11.attention.k_proj.weight', 'encoder.layers.11.attention.out_proj.bias', 'encoder.layers.11.attention.out_proj.weight', 'encoder.layers.11.attention.q_proj.bias', 'encoder.layers.11.attention.q_proj.weight', 'encoder.layers.11.attention.v_proj.bias', 'encoder.layers.11.attention.v_proj.weight', 'encoder.layers.11.feed_forward.intermediate_dense.bias', 'encoder.layers.11.feed_forward.intermediate_dense.weight', 'encoder.layers.11.feed_forward.output_dense.bias', 'encoder.layers.11.feed_forward.output_dense.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.11.layer_norm.bias', 'encoder.layers.11.layer_norm.weight', 'encoder.layers.6.attention.k_proj.bias', 'encoder.layers.6.attention.k_proj.weight', 'encoder.layers.6.attention.out_proj.bias', 'encoder.layers.6.attention.out_proj.weight', 'encoder.layers.6.attention.q_proj.bias', 'encoder.layers.6.attention.q_proj.weight', 'encoder.layers.6.attention.v_proj.bias', 'encoder.layers.6.attention.v_proj.weight', 'encoder.layers.6.feed_forward.intermediate_dense.bias', 'encoder.layers.6.feed_forward.intermediate_dense.weight', 'encoder.layers.6.feed_forward.output_dense.bias', 'encoder.layers.6.feed_forward.output_dense.weight', 'encoder.layers.6.final_layer_norm.bias', 'encoder.layers.6.final_layer_norm.weight', 'encoder.layers.6.layer_norm.bias', 'encoder.layers.6.layer_norm.weight', 'encoder.layers.7.attention.k_proj.bias', 'encoder.layers.7.attention.k_proj.weight', 'encoder.layers.7.attention.out_proj.bias', 'encoder.layers.7.attention.out_proj.weight', 'encoder.layers.7.attention.q_proj.bias', 'encoder.layers.7.attention.q_proj.weight', 'encoder.layers.7.attention.v_proj.bias', 'encoder.layers.7.attention.v_proj.weight', 'encoder.layers.7.feed_forward.intermediate_dense.bias', 'encoder.layers.7.feed_forward.intermediate_dense.weight', 'encoder.layers.7.feed_forward.output_dense.bias', 'encoder.layers.7.feed_forward.output_dense.weight', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.7.layer_norm.bias', 'encoder.layers.7.layer_norm.weight', 'encoder.layers.8.attention.k_proj.bias', 'encoder.layers.8.attention.k_proj.weight', 'encoder.layers.8.attention.out_proj.bias', 'encoder.layers.8.attention.out_proj.weight', 'encoder.layers.8.attention.q_proj.bias', 'encoder.layers.8.attention.q_proj.weight', 'encoder.layers.8.attention.v_proj.bias', 'encoder.layers.8.attention.v_proj.weight', 'encoder.layers.8.feed_forward.intermediate_dense.bias', 'encoder.layers.8.feed_forward.intermediate_dense.weight', 'encoder.layers.8.feed_forward.output_dense.bias', 'encoder.layers.8.feed_forward.output_dense.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.8.layer_norm.bias', 'encoder.layers.8.layer_norm.weight', 'encoder.layers.9.attention.k_proj.bias', 'encoder.layers.9.attention.k_proj.weight', 'encoder.layers.9.attention.out_proj.bias', 'encoder.layers.9.attention.out_proj.weight', 'encoder.layers.9.attention.q_proj.bias', 'encoder.layers.9.attention.q_proj.weight', 'encoder.layers.9.attention.v_proj.bias', 'encoder.layers.9.attention.v_proj.weight', 'encoder.layers.9.feed_forward.intermediate_dense.bias', 'encoder.layers.9.feed_forward.intermediate_dense.weight', 'encoder.layers.9.feed_forward.output_dense.bias', 'encoder.layers.9.feed_forward.output_dense.weight', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.layer_norm.bias', 'encoder.layers.9.layer_norm.weight']
- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).

======================= This is fold_0 on de =======================

Load dataset: 
Loading en train data: fold_0...
Preprocess en fold_0 data for de model
Loading en eval data: fold_0...
Preprocess en fold_0 data for de model
Loading en test data: fold_0...
Preprocess en fold_0 data for de model
Use de model to add lora
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:   0%|          | 1/1600 [00:53<23:34:46, 53.09s/it]Training:   8%|â–Š         | 125/1600 [01:03<09:18,  2.64it/s] Training:  17%|â–ˆâ–‹        | 270/1600 [01:13<04:06,  5.39it/s]Training:  28%|â–ˆâ–ˆâ–Š       | 445/1600 [01:23<02:17,  8.40it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 633/1600 [01:33<01:27, 11.11it/s]Training:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 822/1600 [01:43<00:58, 13.21it/s]Training:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1012/1600 [01:53<00:39, 14.82it/s]Training:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1205/1600 [02:03<00:24, 16.09it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1398/1600 [02:13<00:12, 16.75it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1596/1600 [02:23<00:00, 17.62it/s]                                                             /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Training loss: 2001.4359, Training accuracy: 0.4000
Macro F1-score: 0.3089
Model performance on Angry speech (in training): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Happy speech (in training): 
	Precision: 0.3090, Recall: 0.7500, F1_score: 0.4376
Model performance on Neutral speech (in training): 
	Precision: 0.3936, Recall: 0.0925, F1_score: 0.1498
Model performance on Sad speech (in training): 
	Precision: 0.5664, Recall: 0.7575, F1_score: 0.6481

Eval Phase: 
Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 235.6458, Validation accuracy: 0.4050
Macro F1-score: 0.3258
Model performance on Angry speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Happy speech (in validation): 
	Precision: 0.2308, Recall: 0.1800, F1_score: 0.2022
Model performance on Neutral speech (in validation): 
	Precision: 0.3544, Recall: 0.5600, F1_score: 0.4341
Model performance on Sad speech (in validation): 
	Precision: 0.5366, Recall: 0.8800, F1_score: 0.6667
New best accuracy for layer 5 on epoch 1: 0.4050. Model saved.
Epoch 2/100

Training Phase:
Training loss: 1764.2850, Training accuracy: 0.4850
Macro F1-score: 0.4783
Model performance on Angry speech (in training): 
	Precision: 0.5224, Recall: 0.3500, F1_score: 0.4192
Model performance on Happy speech (in training): 
	Precision: 0.3480, Recall: 0.3750, F1_score: 0.3610
Model performance on Neutral speech (in training): 
	Precision: 0.4133, Recall: 0.4350, F1_score: 0.4239
Model performance on Sad speech (in training): 
	Precision: 0.6500, Recall: 0.7800, F1_score: 0.7091

Eval Phase: 
Validation loss: 195.9933, Validation accuracy: 0.6350
Macro F1-score: 0.6132
Model performance on Angry speech (in validation): 
	Precision: 0.6364, Recall: 0.8400, F1_score: 0.7241
Model performance on Happy speech (in validation): 
	Precision: 0.6538, Recall: 0.3400, F1_score: 0.4474
Model performance on Neutral speech (in validation): 
	Precision: 0.5581, Recall: 0.4800, F1_score: 0.5161
Model performance on Sad speech (in validation): 
	Precision: 0.6769, Recall: 0.8800, F1_score: 0.7652
New best accuracy for layer 5 on epoch 2: 0.6350. Model saved.
Epoch 3/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–        | 220/1600 [00:10<01:02, 21.92it/s]Training:  14%|â–ˆâ–        | 220/1600 [00:20<01:02, 21.92it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 436/1600 [00:20<00:54, 21.42it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 647/1600 [00:30<00:45, 20.89it/s]Training:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 867/1600 [00:40<00:34, 21.30it/s]Training:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1087/1600 [00:51<00:24, 21.24it/s]Training:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1300/1600 [01:01<00:14, 21.25it/s]Training:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1525/1600 [01:11<00:03, 21.62it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|â–ˆâ–Ž        | 211/1600 [00:10<01:05, 21.06it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 428/1600 [00:20<00:54, 21.40it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 645/1600 Training loss: 1609.0890, Training accuracy: 0.5606
Macro F1-score: 0.5484
Model performance on Angry speech (in training): 
	Precision: 0.5990, Recall: 0.6200, F1_score: 0.6093
Model performance on Happy speech (in training): 
	Precision: 0.4798, Recall: 0.2975, F1_score: 0.3673
Model performance on Neutral speech (in training): 
	Precision: 0.4694, Recall: 0.5375, F1_score: 0.5012
Model performance on Sad speech (in training): 
	Precision: 0.6562, Recall: 0.7875, F1_score: 0.7159

Eval Phase: 
Validation loss: 194.9426, Validation accuracy: 0.6200
Macro F1-score: 0.5940
Model performance on Angry speech (in validation): 
	Precision: 0.9429, Recall: 0.6600, F1_score: 0.7765
Model performance on Happy speech (in validation): 
	Precision: 0.5645, Recall: 0.7000, F1_score: 0.6250
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.2000, F1_score: 0.3175
Model performance on Sad speech (in validation): 
	Precision: 0.5111, Recall: 0.9200, F1_score: 0.6571
Epoch 4/100

Training Phase:
[00:30<00:44, 21.30it/s]Training:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 860/1600 [00:40<00:34, 21.37it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1075/1600 [00:50<00:24, 21.14it/s]Training:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1293/1600 [01:00<00:14, 21.34it/s]Training:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1511/1600 [01:10<00:04, 21.39it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|â–ˆâ–Ž        | 211/1600 [00:10<01:05, 21.07it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 428/1600 [00:20<00:54, 21.43it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 645/1600 [00:30<00:44, 21.35it/s]Training:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 861/1600 [00:40<00:34, 21.44it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1078/1600 [00:50<00:24, 21.50it/s]Training:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1295/1600 [01:00<00:14, 21.34it/s]Training:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâTraining loss: 1437.3760, Training accuracy: 0.6375
Macro F1-score: 0.6322
Model performance on Angry speech (in training): 
	Precision: 0.6949, Recall: 0.6775, F1_score: 0.6861
Model performance on Happy speech (in training): 
	Precision: 0.5858, Recall: 0.4525, F1_score: 0.5106
Model performance on Neutral speech (in training): 
	Precision: 0.5638, Recall: 0.6075, F1_score: 0.5848
Model performance on Sad speech (in training): 
	Precision: 0.6915, Recall: 0.8125, F1_score: 0.7471

Eval Phase: 
Validation loss: 165.2028, Validation accuracy: 0.6900
Macro F1-score: 0.6929
Model performance on Angry speech (in validation): 
	Precision: 0.9706, Recall: 0.6600, F1_score: 0.7857
Model performance on Happy speech (in validation): 
	Precision: 0.5556, Recall: 0.7000, F1_score: 0.6195
Model performance on Neutral speech (in validation): 
	Precision: 0.5870, Recall: 0.5400, F1_score: 0.5625
Model performance on Sad speech (in validation): 
	Precision: 0.7544, Recall: 0.8600, F1_score: 0.8037
New best accuracy for layer 5 on epoch 4: 0.6900. Model saved.
Epoch 5/100

Training Phase:
Training loss: 1286.8499, Training accuracy: 0.6906
Macro F1-score: 0.6863
Model performance on Angry speech (in training): 
	Precision: 0.7468, Recall: 0.7375, F1_score: 0.7421
Model performance on Happy speech (in training): 
	Precision: 0.6494, Recall: 0.5000, F1_score: 0.5650
Model performance on Neutral speech (in training): 
	Precision: 0.6289, Recall: 0.7075, F1_score: 0.6659
Model performance on Sad speech (in training): 
	Precision: 0.7315, Recall: 0.8175, F1_score: 0.7721

Eval Phase: 
Validation loss: 181.9451, Validation accuracy: 0.6500
Macro F1-score: 0.6339
Model performance on Angry speech (in validation): 
	Precision: 0.8163, Recall: 0.8000, F1_score: 0.8081
Model performance on Happy speech (in validation): 
	Precision: 0.8621, Recall: 0.5000, F1_score: 0.6329
Model performance on Neutral speech (in validation): 
	Precision: 0.6667, Recall: 0.3200, F1_score: 0.4324
Model performance on Sad speech (in validation): 
	Precision: 0.5000, Recall: 0.9800, F1_score: 0.6622
Epoch 6/100

Training Phase:
–| 1513/1600 [01:10<00:04, 21.47it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|â–ˆâ–Ž        | 213/1600 [00:10<01:05, 21.20it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 425/1600 [00:20<00:55, 21.18it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 646/1600 [00:30<00:44, 21.56it/s]Training:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 867/1600 [00:40<00:33, 21.63it/s]Training:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1086/1600 [00:50<00:23, 21.72it/s]Training:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1305/1600 [01:00<00:13, 21.39it/s]Training:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1517/1600 [01:10<00:03, 21.29it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–Ž        | 218/Training loss: 1168.0380, Training accuracy: 0.7188
Macro F1-score: 0.7154
Model performance on Angry speech (in training): 
	Precision: 0.7959, Recall: 0.7800, F1_score: 0.7879
Model performance on Happy speech (in training): 
	Precision: 0.7129, Recall: 0.5400, F1_score: 0.6145
Model performance on Neutral speech (in training): 
	Precision: 0.6394, Recall: 0.7225, F1_score: 0.6784
Model performance on Sad speech (in training): 
	Precision: 0.7351, Recall: 0.8325, F1_score: 0.7808

Eval Phase: 
Validation loss: 169.7531, Validation accuracy: 0.6350
Macro F1-score: 0.6270
Model performance on Angry speech (in validation): 
	Precision: 0.8857, Recall: 0.6200, F1_score: 0.7294
Model performance on Happy speech (in validation): 
	Precision: 0.6562, Recall: 0.4200, F1_score: 0.5122
Model performance on Neutral speech (in validation): 
	Precision: 0.5385, Recall: 0.5600, F1_score: 0.5490
Model performance on Sad speech (in validation): 
	Precision: 0.5802, Recall: 0.9400, F1_score: 0.7176
Epoch 7/100

Training Phase:
1600 [00:10<01:03, 21.73it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 436/1600 [00:20<00:53, 21.77it/s]Training:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 654/1600 [00:30<00:44, 21.43it/s]Training:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 871/1600 [00:40<00:33, 21.50it/s]Training:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1088/1600 [00:50<00:23, 21.56it/s]Training:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1305/1600 [01:00<00:13, 21.58it/s]Training:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1522/1600 [01:10<00:03, 21.47it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–Ž        | 216/1600 [00:10<01:04, 21.58it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 432/1600 [00:20<00:54, 21.38it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 646/1600 [00:30<00:44, 21.37it/s]Training:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 860/1600 [00:40<00:34, 21.38it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1078/1600 [00Training loss: 1050.3047, Training accuracy: 0.7481
Macro F1-score: 0.7450
Model performance on Angry speech (in training): 
	Precision: 0.7970, Recall: 0.7950, F1_score: 0.7960
Model performance on Happy speech (in training): 
	Precision: 0.7516, Recall: 0.5900, F1_score: 0.6611
Model performance on Neutral speech (in training): 
	Precision: 0.6860, Recall: 0.7375, F1_score: 0.7108
Model performance on Sad speech (in training): 
	Precision: 0.7615, Recall: 0.8700, F1_score: 0.8121

Eval Phase: 
Validation loss: 180.9045, Validation accuracy: 0.6350
Macro F1-score: 0.6337
Model performance on Angry speech (in validation): 
	Precision: 0.9524, Recall: 0.4000, F1_score: 0.5634
Model performance on Happy speech (in validation): 
	Precision: 0.4925, Recall: 0.6600, F1_score: 0.5641
Model performance on Neutral speech (in validation): 
	Precision: 0.5556, Recall: 0.7000, F1_score: 0.6195
Model performance on Sad speech (in validation): 
	Precision: 0.7959, Recall: 0.7800, F1_score: 0.7879
Epoch 8/100

Training Phase:
Training loss: 972.9928, Training accuracy: 0.7719
Macro F1-score: 0.7692
Model performance on Angry speech (in training): 
	Precision: 0.8321, Recall: 0.8175, F1_score: 0.8247
Model performance on Happy speech (in training): 
	Precision: 0.7538, Recall: 0.6200, F1_score: 0.6804
Model performance on Neutral speech (in training): 
	Precision: 0.7187, Recall: 0.7600, F1_score: 0.7388
Model performance on Sad speech (in training): 
	Precision: 0.7824, Recall: 0.8900, F1_score: 0.8327

Eval Phase: 
Validation loss: 187.1381, Validation accuracy: 0.6600
Macro F1-score: 0.6452
Model performance on Angry speech (in validation): 
	Precision: 0.9231, Recall: 0.7200, F1_score: 0.8090
Model performance on Happy speech (in validation): 
	Precision: 0.6275, Recall: 0.6400, F1_score: 0.6337
Model performance on Neutral speech (in validation): 
	Precision: 0.6667, Recall: 0.3200, F1_score: 0.4324
Model performance on Sad speech (in validation): 
	Precision: 0.5581, Recall: 0.9600, F1_score: 0.7059
Epoch 9/100

Training Phase:
:50<00:24, 21.51it/s]Training:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1296/1600 [01:00<00:14, 21.45it/s]Training:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1511/1600 [01:10<00:04, 21.41it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–        | 221/1600 [00:10<01:02, 22.04it/s]Training:  28%|â–ˆâ–ˆâ–Š       | 452/1600 [00:20<00:50, 22.64it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 683/1600 [00:30<00:41, 22.32it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 912/1600 [00:40<00:30, 22.54it/s]Training:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1141/1600 [00:50<00:20, 22.66it/s]Training:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1377/1600 [01:00<00:09, 22.95it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|      Training loss: 885.9301, Training accuracy: 0.7944
Macro F1-score: 0.7933
Model performance on Angry speech (in training): 
	Precision: 0.8564, Recall: 0.8350, F1_score: 0.8456
Model performance on Happy speech (in training): 
	Precision: 0.7867, Recall: 0.6825, F1_score: 0.7309
Model performance on Neutral speech (in training): 
	Precision: 0.7220, Recall: 0.7725, F1_score: 0.7464
Model performance on Sad speech (in training): 
	Precision: 0.8161, Recall: 0.8875, F1_score: 0.8503

Eval Phase: 
Validation loss: 193.5988, Validation accuracy: 0.6600
Macro F1-score: 0.6495
Model performance on Angry speech (in validation): 
	Precision: 0.8235, Recall: 0.8400, F1_score: 0.8317
Model performance on Happy speech (in validation): 
	Precision: 0.8696, Recall: 0.4000, F1_score: 0.5479
Model performance on Neutral speech (in validation): 
	Precision: 0.5532, Recall: 0.5200, F1_score: 0.5361
Model performance on Sad speech (in validation): 
	Precision: 0.5570, Recall: 0.8800, F1_score: 0.6822
Epoch 10/100

Training Phase:
    | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–        | 229/1600 [00:10<00:59, 22.88it/s]Training:  29%|â–ˆâ–ˆâ–‰       | 461/1600 [00:20<00:49, 23.04it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 693/1600 [00:30<00:39, 23.00it/s]Training:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 923/1600 [00:40<00:29, 22.77it/s]Training:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1154/1600 [00:50<00:19, 22.87it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1385/1600 [01:00<00:09, 22.72it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–        | 235/1600 [00:10<00:58, 23.45it/s]Training:  29%|â–ˆâ–ˆâ–‰       | 470/1600 [00:20<00:48, 23.09it/s]Training:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 699/1600 [00:30<00:40, 22.35it/s]Training:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 925/1600 [00:40<00:30, 22.44it/s]Training:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1159/1600 [00:50<00:19Training loss: 781.9027, Training accuracy: 0.8163
Macro F1-score: 0.8151
Model performance on Angry speech (in training): 
	Precision: 0.8731, Recall: 0.8600, F1_score: 0.8665
Model performance on Happy speech (in training): 
	Precision: 0.8468, Recall: 0.7050, F1_score: 0.7694
Model performance on Neutral speech (in training): 
	Precision: 0.7500, Recall: 0.7950, F1_score: 0.7718
Model performance on Sad speech (in training): 
	Precision: 0.8062, Recall: 0.9050, F1_score: 0.8528

Eval Phase: 
Validation loss: 184.2138, Validation accuracy: 0.6950
Macro F1-score: 0.6946
Model performance on Angry speech (in validation): 
	Precision: 0.9697, Recall: 0.6400, F1_score: 0.7711
Model performance on Happy speech (in validation): 
	Precision: 0.5574, Recall: 0.6800, F1_score: 0.6126
Model performance on Neutral speech (in validation): 
	Precision: 0.6279, Recall: 0.5400, F1_score: 0.5806
Model performance on Sad speech (in validation): 
	Precision: 0.7302, Recall: 0.9200, F1_score: 0.8142
New best accuracy for layer 5 on epoch 10: 0.6950. Model saved.
Epoch 11/100

Training Phase:
Training loss: 697.9413, Training accuracy: 0.8337
Macro F1-score: 0.8323
Model performance on Angry speech (in training): 
	Precision: 0.8778, Recall: 0.8800, F1_score: 0.8789
Model performance on Happy speech (in training): 
	Precision: 0.8378, Recall: 0.7100, F1_score: 0.7686
Model performance on Neutral speech (in training): 
	Precision: 0.7775, Recall: 0.8300, F1_score: 0.8029
Model performance on Sad speech (in training): 
	Precision: 0.8453, Recall: 0.9150, F1_score: 0.8788

Eval Phase: 
Validation loss: 204.6055, Validation accuracy: 0.6400
Macro F1-score: 0.6366
Model performance on Angry speech (in validation): 
	Precision: 0.7018, Recall: 0.8000, F1_score: 0.7477
Model performance on Happy speech (in validation): 
	Precision: 0.5500, Recall: 0.6600, F1_score: 0.6000
Model performance on Neutral speech (in validation): 
	Precision: 0.5500, Recall: 0.4400, F1_score: 0.4889
Model performance on Sad speech (in validation): 
	Precision: 0.7674, Recall: 0.6600, F1_score: 0.7097
Epoch 12/100

Training Phase:
, 22.78it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1393/1600 [01:01<00:09, 22.77it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–        | 230/1600 [00:10<00:59, 22.97it/s]Training:  29%|â–ˆâ–ˆâ–‰       | 460/1600 [00:20<00:49, 22.82it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 688/1600 [00:30<00:40, 22.51it/s]Training:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 925/1600 [00:40<00:29, 22.95it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1163/1600 [00:50<00:18, 23.24it/s]Training:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1401/1600 [01:01<00:08, 22.69it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–        | 229/1600 [00:10<00:59, 22.88Training loss: 650.4442, Training accuracy: 0.8456
Macro F1-score: 0.8449
Model performance on Angry speech (in training): 
	Precision: 0.8861, Recall: 0.8950, F1_score: 0.8905
Model performance on Happy speech (in training): 
	Precision: 0.8649, Recall: 0.7525, F1_score: 0.8048
Model performance on Neutral speech (in training): 
	Precision: 0.7981, Recall: 0.8400, F1_score: 0.8185
Model performance on Sad speech (in training): 
	Precision: 0.8384, Recall: 0.8950, F1_score: 0.8658

Eval Phase: 
Validation loss: 228.5225, Validation accuracy: 0.6500
Macro F1-score: 0.6510
Model performance on Angry speech (in validation): 
	Precision: 0.9143, Recall: 0.6400, F1_score: 0.7529
Model performance on Happy speech (in validation): 
	Precision: 0.6226, Recall: 0.6600, F1_score: 0.6408
Model performance on Neutral speech (in validation): 
	Precision: 0.5952, Recall: 0.5000, F1_score: 0.5435
Model performance on Sad speech (in validation): 
	Precision: 0.5714, Recall: 0.8000, F1_score: 0.6667
Epoch 13/100

Training Phase:
it/s]Training:  29%|â–ˆâ–ˆâ–‰       | 461/1600 [00:20<00:49, 22.99it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 692/1600 [00:30<00:40, 22.61it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 920/1600 [00:40<00:29, 22.68it/s]Training:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1148/1600 [00:50<00:20, 22.38it/s]Training:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1384/1600 [01:00<00:09, 22.76it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–        | 223/1600 [00:10<01:01, 22.25it/s]Training:  28%|â–ˆâ–ˆâ–Š       | 448/1600 [00:20<00:51, 22.40it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 684/1600 [00:30<00:39, 22.91it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 920/1600 [00:40<00:30, 22.49it/s]Training:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1157/1600 [00:50<00:19, 22.89it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1394/1600 [01:01<00:09, 22.85itTraining loss: 518.9882, Training accuracy: 0.8894
Macro F1-score: 0.8890
Model performance on Angry speech (in training): 
	Precision: 0.9359, Recall: 0.9125, F1_score: 0.9241
Model performance on Happy speech (in training): 
	Precision: 0.9030, Recall: 0.8150, F1_score: 0.8568
Model performance on Neutral speech (in training): 
	Precision: 0.8429, Recall: 0.8850, F1_score: 0.8634
Model performance on Sad speech (in training): 
	Precision: 0.8811, Recall: 0.9450, F1_score: 0.9119

Eval Phase: 
Validation loss: 223.9895, Validation accuracy: 0.6900
Macro F1-score: 0.6967
Model performance on Angry speech (in validation): 
	Precision: 0.9487, Recall: 0.7400, F1_score: 0.8315
Model performance on Happy speech (in validation): 
	Precision: 0.5870, Recall: 0.5400, F1_score: 0.5625
Model performance on Neutral speech (in validation): 
	Precision: 0.5362, Recall: 0.7400, F1_score: 0.6218
Model performance on Sad speech (in validation): 
	Precision: 0.8043, Recall: 0.7400, F1_score: 0.7708
Epoch 14/100

Training Phase:
Training loss: 493.0784, Training accuracy: 0.8919
Macro F1-score: 0.8917
Model performance on Angry speech (in training): 
	Precision: 0.9291, Recall: 0.9175, F1_score: 0.9233
Model performance on Happy speech (in training): 
	Precision: 0.9044, Recall: 0.8275, F1_score: 0.8642
Model performance on Neutral speech (in training): 
	Precision: 0.8551, Recall: 0.9000, F1_score: 0.8770
Model performance on Sad speech (in training): 
	Precision: 0.8828, Recall: 0.9225, F1_score: 0.9022

Eval Phase: 
Validation loss: 197.3223, Validation accuracy: 0.7300
Macro F1-score: 0.7270
Model performance on Angry speech (in validation): 
	Precision: 0.8810, Recall: 0.7400, F1_score: 0.8043
Model performance on Happy speech (in validation): 
	Precision: 0.7209, Recall: 0.6200, F1_score: 0.6667
Model performance on Neutral speech (in validation): 
	Precision: 0.7209, Recall: 0.6200, F1_score: 0.6667
Model performance on Sad speech (in validation): 
	Precision: 0.6528, Recall: 0.9400, F1_score: 0.7705
New best accuracy for layer 5 on epoch 14: 0.7300. Model saved.
Validation loss does not decrease for 10 epochs. End training.
Model best accuracy on validation set: 0.7300

Test Phase: 
/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–        | 223/1600 [00:10<01:02, 22.16it/s]Training:  28%|â–ˆâ–ˆâ–Š       | 445/1600 [00:20<00:52, 22.14it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 681/1600 [00:30<00:40, 22.79it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 917/1600 [00:40<00:29, 22.79it/s]Training:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1146/1600 [00:50<00:20, 22.64it/s]Training:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1382/1600 [01:00<00:09, 22.93it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]                                                Some weights of the model checkpoint at /work/tc062/tc062/zhan7721/saved_models/de were not used when initializing Wav2Vec2Model: ['encoder.layers.10.attention.k_proj.bias', 'encoder.layers.10.attention.k_proj.weight', 'encoder.layers.10.attention.out_proj.bias', 'encoder.layers.10.attention.out_proj.weight', 'encoder.layers.10.attention.q_proj.bias', 'encoder.layers.10.attention.q_proj.weight', 'encoder.layers.10.attention.v_proj.bias', 'encoder.layers.10.attention.v_proj.weight', 'encoder.layers.10.feed_forward.intermediate_dense.bias', 'encoder.layers.10.feed_forward.intermediate_dense.weight', 'encoder.layers.10.feed_forward.output_dense.bias', 'encoder.layers.10.feed_forward.output_dense.weight', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.10.layer_norm.bias', 'encoder.layers.10.layer_norm.weight', 'encoder.layers.11.attention.k_proj.bias', 'encoder.layers.11.attention.k_proj.weight', 'encoder.layers.11.attention.out_proj.bias', 'encoder.layers.11.attention.out_proj.weight', 'encoder.layers.11.attention.q_proj.bias', 'encoder.layers.11.attention.q_proj.weight', 'encoder.layers.11.attention.v_proj.bias', 'encoder.layers.11.attention.v_proj.weight', 'encoder.layers.11.feed_forward.intermediate_dense.bias', 'encoder.layers.11.feed_forward.intermediate_dense.weight', 'encoder.layers.11.feed_forward.output_dense.bias', 'encoder.layers.11.feed_forward.output_dense.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.11.layer_norm.bias', 'encoder.layers.11.layer_norm.weight', 'encoder.layers.6.attention.k_proj.bias', 'encoder.layers.6.attention.k_proj.weight', 'encoder.layers.6.attention.out_proj.bias', 'encoder.layers.6.attention.out_proj.weight', 'encoder.layers.6.attention.q_proj.bias', 'encoder.layers.6.attention.q_proj.weight', 'encoder.layers.6.attention.v_proj.bias', 'encoder.layers.6.attention.v_proj.weight', 'encoder.layers.6.feed_forward.intermediate_dense.bias', 'encoder.layers.6.feed_forward.intermediate_dense.weight', 'encoder.layers.6.feed_forward.output_dense.bias', 'encoder.layers.6.feed_forward.output_dense.weight', 'encoder.layers.6.final_layer_norm.bias', 'encoder.layers.6.final_layer_norm.weight', 'encoder.layers.6.layer_norm.bias', 'encoder.layers.6.layer_norm.weight', 'encoder.layers.7.attention.k_proj.bias', 'encoder.layers.7.attention.k_proj.weight', 'encoder.layers.7.attention.out_proj.bias', 'encoder.layers.7.attention.out_proj.weight', 'encoder.layers.7.attention.q_proj.bias', 'encoder.layers.7.attention.q_proj.weight', 'encoder.layers.7.attention.v_proj.bias', 'encoder.layers.7.attention.v_proj.weight', 'encoder.layers.7.feed_forward.intermediate_dense.bias', 'encoder.layers.7.feed_forward.intermediate_dense.weight', 'encoder.layers.7.feed_forward.output_dense.bias', 'encoder.layers.7.feed_forward.output_dense.weight', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.7.layer_norm.bias', 'encoder.layers.7.layer_norm.weight', 'encoder.layers.8.attention.k_proj.bias', 'encoder.layers.8.attention.k_proj.weight', 'encoder.layers.8.attention.out_proj.bias', 'encoder.layers.8.attention.out_proj.weight', 'encoder.layers.8.attention.q_proj.bias', 'encoder.layers.8.attention.q_proj.weight', 'encoder.layers.8.attention.v_proj.bias', 'encoder.layers.8.attention.v_proj.weight', 'encoder.layers.8.feed_forward.intermediate_dense.bias', 'encoder.layers.8.feed_forward.intermediate_dense.weight', 'encoder.layers.8.feed_forward.output_dense.bias', 'encoder.layers.8.feed_forward.output_dense.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.8.layer_norm.bias', 'encoder.layers.8.layer_norm.weight', 'encoder.layers.9.attention.k_proj.bias', 'encoder.layers.9.attention.k_proj.weight', 'encoder.layers.9.attention.out_proj.bias', 'encoder.layers.9.attention.out_proj.weight', 'encoder.layers.9.attention.q_proj.bias', 'encoder.layers.9.attention.q_proj.weight', 'encoder.layers.9.attention.v_proj.bias', 'encoder.layers.9.attention.v_proj.weight', 'encoder.layers.9.feed_forward.intermediate_dense.bias', 'encoder.layers.9.feed_forward.intermediate_dense.weight', 'encoder.layers.9.feed_forward.output_dense.bias', 'encoder.layers.9.feed_forward.output_dense.weight', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.layer_norm.bias', 'encoder.layers.9.layer_norm.weight']
- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Test loss: 253.5464, Test accuracy: 0.6150
Macro F1-score: 0.6049
Model performance on Angry speech (in test): 
	Precision: 0.8000, Recall: 0.7200, F1_score: 0.7579
Model performance on Happy speech (in test): 
	Precision: 0.5429, Recall: 0.3800, F1_score: 0.4471
Model performance on Neutral speech (in test): 
	Precision: 0.5814, Recall: 0.5000, F1_score: 0.5376
Model performance on Sad speech (in test): 
	Precision: 0.5584, Recall: 0.8600, F1_score: 0.6772

======================= This is fold_1 on de =======================

Load dataset: 
Loading en train data: fold_1...
Preprocess en fold_1 data for de model
Loading en eval data: fold_1...
Preprocess en fold_1 data for de model
Loading en test data: fold_1...
Preprocess en fold_1 data for de model
Use de model to add lora
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training loss: 1639.8565, Training accuracy: 0.5694
Macro F1-score: 0.5633
Model performance on Angry speech (in training): 
	Precision: 0.6036, Recall: 0.6700, F1_score: 0.6351
Model performance on Happy speech (in training): 
	Precision: 0.5162, Recall: 0.3975, F1_score: 0.4492
Model performance on Neutral speech (in training): 
	Precision: 0.4838, Recall: 0.4850, F1_score: 0.4844
Model performance on Sad speech (in training): 
	Precision: 0.6488, Recall: 0.7250, F1_score: 0.6848

Eval Phase: 
Validation loss: 182.3542, Validation accuracy: 0.6300
Macro F1-score: 0.5888
Model performance on Angry speech (in validation): 
	Precision: 0.5974, Recall: 0.9200, F1_score: 0.7244
Model performance on Happy speech (in validation): 
	Precision: 0.6429, Recall: 0.1800, F1_score: 0.2812
Model performance on Neutral speech (in validation): 
	Precision: 0.5294, Recall: 0.5400, F1_score: 0.5347
Model performance on Sad speech (in validation): 
	Precision: 0.7586, Recall: 0.8800, F1_score: 0.8148
New best accuracy for layer 5 on epoch 1: 0.6300. Model saved.
Epoch 2/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:   7%|â–‹         | 110/1600 [00:10<02:16, 10.95it/s]Training:  17%|â–ˆâ–‹        | 268/1600 [00:20<01:36, 13.78it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 439/1600 [00:30<01:16, 15.27it/s]Training:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 616/1600 [00:40<01:00, 16.20it/s]Training:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 802/1600 [00:50<00:47, 16.91it/s]Training:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 995/1600 [01:00<00:34, 17.70it/s]Training:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1188/1600 [01:10<00:22, 17.96it/s]Training:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1380/1600 [01:20<00:11, 18.34it/s]Training:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1572/1600 [01:30<00:01, 18.56it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|â–ˆâ–Ž        | 208/1600 [00:10<01:06, 20.80it/s]Training:  26%|â–ˆâ–ˆâ–‹       | 422/1Training loss: 1400.1252, Training accuracy: 0.6400
Macro F1-score: 0.6356
Model performance on Angry speech (in training): 
	Precision: 0.7125, Recall: 0.7125, F1_score: 0.7125
Model performance on Happy speech (in training): 
	Precision: 0.5892, Recall: 0.4625, F1_score: 0.5182
Model performance on Neutral speech (in training): 
	Precision: 0.5751, Recall: 0.6125, F1_score: 0.5932
Model performance on Sad speech (in training): 
	Precision: 0.6717, Recall: 0.7725, F1_score: 0.7186

Eval Phase: 
Validation loss: 185.7772, Validation accuracy: 0.6300
Macro F1-score: 0.6013
Model performance on Angry speech (in validation): 
	Precision: 0.5679, Recall: 0.9200, F1_score: 0.7023
Model performance on Happy speech (in validation): 
	Precision: 0.6667, Recall: 0.2000, F1_score: 0.3077
Model performance on Neutral speech (in validation): 
	Precision: 0.5385, Recall: 0.7000, F1_score: 0.6087
Model performance on Sad speech (in validation): 
	Precision: 0.8974, Recall: 0.7000, F1_score: 0.7865
Epoch 3/100

Training Phase:
600 [00:20<00:55, 21.14it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 636/1600 [00:30<00:45, 21.16it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 853/1600 [00:40<00:34, 21.37it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1070/1600 [00:50<00:24, 21.48it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1287/1600 [01:00<00:14, 21.31it/s]Training:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1505/1600 [01:10<00:04, 21.47it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|â–ˆâ–Ž        | 215/1600 [00:10<01:04, 21.44it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 430/1600 [00:20<00:55, 21.07it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 639/1600 [00:30<00:45, 20.99it/s]Training:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 861/1600 [00:40<00:34, 21.44it/s]Training:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1083/1600 [00:50<00:23, 21.61it/s]Training:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 130Training loss: 1267.4629, Training accuracy: 0.6856
Macro F1-score: 0.6847
Model performance on Angry speech (in training): 
	Precision: 0.7889, Recall: 0.7475, F1_score: 0.7677
Model performance on Happy speech (in training): 
	Precision: 0.6972, Recall: 0.5525, F1_score: 0.6165
Model performance on Neutral speech (in training): 
	Precision: 0.5784, Recall: 0.6550, F1_score: 0.6143
Model performance on Sad speech (in training): 
	Precision: 0.6984, Recall: 0.7875, F1_score: 0.7403

Eval Phase: 
Validation loss: 200.1950, Validation accuracy: 0.5700
Macro F1-score: 0.5267
Model performance on Angry speech (in validation): 
	Precision: 0.4900, Recall: 0.9800, F1_score: 0.6533
Model performance on Happy speech (in validation): 
	Precision: 0.4286, Recall: 0.1800, F1_score: 0.2535
Model performance on Neutral speech (in validation): 
	Precision: 0.5926, Recall: 0.3200, F1_score: 0.4156
Model performance on Sad speech (in validation): 
	Precision: 0.7692, Recall: 0.8000, F1_score: 0.7843
Epoch 4/100

Training Phase:
Training loss: 1146.0482, Training accuracy: 0.7238
Macro F1-score: 0.7216
Model performance on Angry speech (in training): 
	Precision: 0.7882, Recall: 0.8000, F1_score: 0.7940
Model performance on Happy speech (in training): 
	Precision: 0.7134, Recall: 0.5850, F1_score: 0.6429
Model performance on Neutral speech (in training): 
	Precision: 0.6612, Recall: 0.7025, F1_score: 0.6812
Model performance on Sad speech (in training): 
	Precision: 0.7324, Recall: 0.8075, F1_score: 0.7681

Eval Phase: 
Validation loss: 181.4000, Validation accuracy: 0.6250
Macro F1-score: 0.6006
Model performance on Angry speech (in validation): 
	Precision: 0.5610, Recall: 0.9200, F1_score: 0.6970
Model performance on Happy speech (in validation): 
	Precision: 0.6316, Recall: 0.2400, F1_score: 0.3478
Model performance on Neutral speech (in validation): 
	Precision: 0.5370, Recall: 0.5800, F1_score: 0.5577
Model performance on Sad speech (in validation): 
	Precision: 0.8444, Recall: 0.7600, F1_score: 0.8000
Epoch 5/100

Training Phase:
3/1600 [01:01<00:13, 21.40it/s]Training:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1515/1600 [01:11<00:03, 21.32it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|â–ˆâ–Ž        | 213/1600 [00:10<01:05, 21.27it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 427/1600 [00:20<00:54, 21.33it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 641/1600 [00:30<00:45, 21.14it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 854/1600 [00:40<00:35, 21.20it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1070/1600 [00:50<00:24, 21.32it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1286/1600 [01:00<00:14, 21.30it/s]Training:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1501/1600 [01:10<00:04, 21.35it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0Training loss: 1027.9462, Training accuracy: 0.7494
Macro F1-score: 0.7472
Model performance on Angry speech (in training): 
	Precision: 0.8177, Recall: 0.8300, F1_score: 0.8238
Model performance on Happy speech (in training): 
	Precision: 0.7756, Recall: 0.6050, F1_score: 0.6798
Model performance on Neutral speech (in training): 
	Precision: 0.6760, Recall: 0.7250, F1_score: 0.6996
Model performance on Sad speech (in training): 
	Precision: 0.7395, Recall: 0.8375, F1_score: 0.7855

Eval Phase: 
Validation loss: 195.1498, Validation accuracy: 0.5900
Macro F1-score: 0.5629
Model performance on Angry speech (in validation): 
	Precision: 0.5465, Recall: 0.9400, F1_score: 0.6912
Model performance on Happy speech (in validation): 
	Precision: 0.3871, Recall: 0.2400, F1_score: 0.2963
Model performance on Neutral speech (in validation): 
	Precision: 0.5882, Recall: 0.4000, F1_score: 0.4762
Model performance on Sad speech (in validation): 
	Precision: 0.7959, Recall: 0.7800, F1_score: 0.7879
Epoch 6/100

Training Phase:
%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|â–ˆâ–Ž        | 213/1600 [00:10<01:05, 21.27it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 427/1600 [00:20<00:55, 21.30it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 641/1600 [00:30<00:45, 21.29it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 854/1600 [00:40<00:35, 21.28it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1075/1600 [00:50<00:24, 21.55it/s]Training:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1296/1600 [01:00<00:14, 21.56it/s]Training:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1512/1600 [01:10<00:04, 21.33it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|â–ˆâ–Ž        | 212/1600 [00:10<01:05, 21.15it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 427/1600 [00:20<00:54, 21.35it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 642/1600 [00:30<00:45, 21.16it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 853/1600 [00:40<0Training loss: 899.6918, Training accuracy: 0.7712
Macro F1-score: 0.7700
Model performance on Angry speech (in training): 
	Precision: 0.8475, Recall: 0.8475, F1_score: 0.8475
Model performance on Happy speech (in training): 
	Precision: 0.8000, Recall: 0.6500, F1_score: 0.7172
Model performance on Neutral speech (in training): 
	Precision: 0.6988, Recall: 0.7425, F1_score: 0.7200
Model performance on Sad speech (in training): 
	Precision: 0.7511, Recall: 0.8450, F1_score: 0.7953

Eval Phase: 
Validation loss: 227.8543, Validation accuracy: 0.5800
Macro F1-score: 0.5478
Model performance on Angry speech (in validation): 
	Precision: 0.5595, Recall: 0.9400, F1_score: 0.7015
Model performance on Happy speech (in validation): 
	Precision: 0.4318, Recall: 0.3800, F1_score: 0.4043
Model performance on Neutral speech (in validation): 
	Precision: 0.5000, Recall: 0.2200, F1_score: 0.3056
Model performance on Sad speech (in validation): 
	Precision: 0.7800, Recall: 0.7800, F1_score: 0.7800
Epoch 7/100

Training Phase:
0:35, 21.13it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1071/1600 [00:50<00:24, 21.36it/s]Training:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1289/1600 [01:00<00:14, 21.30it/s]Training:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1508/1600 [01:10<00:04, 21.47it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–        | 220/1600 [00:10<01:02, 21.92it/s]Training:  28%|â–ˆâ–ˆâ–Š       | 440/1600 [00:20<00:54, 21.27it/s]Training:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 654/1600 [00:30<00:44, 21.31it/s]Training:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 874/1600 [00:40<00:33, 21.58it/s]Training:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1094/1600 [00:51<00:23, 21.27it/s]Training:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1307/1600 [01:01<00:13, 21.26it/s]Training:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1522/1600 [01:11<00:03, 21.32it/s]                                        Training loss: 821.5271, Training accuracy: 0.8013
Macro F1-score: 0.8008
Model performance on Angry speech (in training): 
	Precision: 0.8855, Recall: 0.8700, F1_score: 0.8777
Model performance on Happy speech (in training): 
	Precision: 0.7911, Recall: 0.7100, F1_score: 0.7484
Model performance on Neutral speech (in training): 
	Precision: 0.7640, Recall: 0.7850, F1_score: 0.7744
Model performance on Sad speech (in training): 
	Precision: 0.7689, Recall: 0.8400, F1_score: 0.8029

Eval Phase: 
Validation loss: 219.7463, Validation accuracy: 0.6100
Macro F1-score: 0.5831
Model performance on Angry speech (in validation): 
	Precision: 0.5867, Recall: 0.8800, F1_score: 0.7040
Model performance on Happy speech (in validation): 
	Precision: 0.5000, Recall: 0.2000, F1_score: 0.2857
Model performance on Neutral speech (in validation): 
	Precision: 0.5167, Recall: 0.6200, F1_score: 0.5636
Model performance on Sad speech (in validation): 
	Precision: 0.8222, Recall: 0.7400, F1_score: 0.7789
Epoch 8/100

Training Phase:
Training loss: 704.4036, Training accuracy: 0.8375
Macro F1-score: 0.8368
Model performance on Angry speech (in training): 
	Precision: 0.9040, Recall: 0.8950, F1_score: 0.8995
Model performance on Happy speech (in training): 
	Precision: 0.8278, Recall: 0.7450, F1_score: 0.7842
Model performance on Neutral speech (in training): 
	Precision: 0.8024, Recall: 0.8225, F1_score: 0.8123
Model performance on Sad speech (in training): 
	Precision: 0.8180, Recall: 0.8875, F1_score: 0.8513

Eval Phase: 
Validation loss: 256.8203, Validation accuracy: 0.5800
Macro F1-score: 0.5514
Model performance on Angry speech (in validation): 
	Precision: 0.5217, Recall: 0.9600, F1_score: 0.6761
Model performance on Happy speech (in validation): 
	Precision: 0.3889, Recall: 0.2800, F1_score: 0.3256
Model performance on Neutral speech (in validation): 
	Precision: 0.6000, Recall: 0.3000, F1_score: 0.4000
Model performance on Sad speech (in validation): 
	Precision: 0.8298, Recall: 0.7800, F1_score: 0.8041
Epoch 9/100

Training Phase:
                     Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–Ž        | 216/1600 [00:10<01:04, 21.58it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 433/1600 [00:20<00:53, 21.61it/s]Training:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 650/1600 [00:30<00:44, 21.31it/s]Training:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 865/1600 [00:40<00:34, 21.37it/s]Training:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1080/1600 [00:50<00:24, 21.30it/s]Training:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1294/1600 [01:00<00:14, 21.33it/s]Training:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1508/1600 [01:10<00:04, 21.25it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|â–ˆâ–Ž        | 212/1600 [00:10<01:05, 21.17it/s]Training:  26%|â–ˆâ–ˆâ–‹       | 424/1600 [00:20<00Training loss: 645.7128, Training accuracy: 0.8569
Macro F1-score: 0.8568
Model performance on Angry speech (in training): 
	Precision: 0.9201, Recall: 0.8925, F1_score: 0.9061
Model performance on Happy speech (in training): 
	Precision: 0.8598, Recall: 0.7975, F1_score: 0.8275
Model performance on Neutral speech (in training): 
	Precision: 0.8317, Recall: 0.8400, F1_score: 0.8358
Model performance on Sad speech (in training): 
	Precision: 0.8215, Recall: 0.8975, F1_score: 0.8578

Eval Phase: 
Validation loss: 304.0546, Validation accuracy: 0.5600
Macro F1-score: 0.5290
Model performance on Angry speech (in validation): 
	Precision: 0.4796, Recall: 0.9400, F1_score: 0.6351
Model performance on Happy speech (in validation): 
	Precision: 0.4500, Recall: 0.1800, F1_score: 0.2571
Model performance on Neutral speech (in validation): 
	Precision: 0.5128, Recall: 0.4000, F1_score: 0.4494
Model performance on Sad speech (in validation): 
	Precision: 0.8372, Recall: 0.7200, F1_score: 0.7742
Epoch 10/100

Training Phase:
:55, 21.14it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 639/1600 [00:30<00:45, 21.27it/s]Training:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 859/1600 [00:40<00:34, 21.55it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1079/1600 [00:50<00:24, 21.48it/s]Training:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1293/1600 [01:00<00:14, 21.34it/s]Training:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1505/1600 [01:10<00:04, 21.28it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|â–ˆâ–Ž        | 214/1600 [00:10<01:04, 21.37it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 432/1600 [00:20<00:54, 21.59it/s]Training:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 650/1600 [00:30<00:44, 21.15it/s]Training:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 869/1600 [00:40<00:34, 21.43it/s]Training:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1088/1600 [00:50<00:23, 21.52it/s]Training:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1305/1600 [01:01Training loss: 541.5371, Training accuracy: 0.8806
Macro F1-score: 0.8806
Model performance on Angry speech (in training): 
	Precision: 0.9333, Recall: 0.9100, F1_score: 0.9215
Model performance on Happy speech (in training): 
	Precision: 0.8916, Recall: 0.8225, F1_score: 0.8557
Model performance on Neutral speech (in training): 
	Precision: 0.8495, Recall: 0.8750, F1_score: 0.8621
Model performance on Sad speech (in training): 
	Precision: 0.8531, Recall: 0.9150, F1_score: 0.8830

Eval Phase: 
Validation loss: 345.2502, Validation accuracy: 0.5700
Macro F1-score: 0.5478
Model performance on Angry speech (in validation): 
	Precision: 0.5000, Recall: 0.9600, F1_score: 0.6575
Model performance on Happy speech (in validation): 
	Precision: 0.5000, Recall: 0.3000, F1_score: 0.3750
Model performance on Neutral speech (in validation): 
	Precision: 0.4706, Recall: 0.3200, F1_score: 0.3810
Model performance on Sad speech (in validation): 
	Precision: 0.8750, Recall: 0.7000, F1_score: 0.7778
Epoch 11/100

Training Phase:
Training loss: 458.5423, Training accuracy: 0.9050
Macro F1-score: 0.9050
Model performance on Angry speech (in training): 
	Precision: 0.9463, Recall: 0.9250, F1_score: 0.9355
Model performance on Happy speech (in training): 
	Precision: 0.9108, Recall: 0.8675, F1_score: 0.8886
Model performance on Neutral speech (in training): 
	Precision: 0.8829, Recall: 0.9050, F1_score: 0.8938
Model performance on Sad speech (in training): 
	Precision: 0.8828, Recall: 0.9225, F1_score: 0.9022

Eval Phase: 
<00:13, 21.32it/s]Training:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1516/1600 [01:11<00:03, 21.22it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|â–ˆâ–Ž        | 212/1600 [00:10<01:05, 21.18it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 430/1600 [00:20<00:54, 21.50it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 648/1600 [00:30<00:44, 21.49it/s]Training:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 868/1600 [00:40<00:33, 21.69it/s]Training:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1088/1600 [00:50<00:23, 21.61it/s]Training:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1088/1600 [01:00<00:23, 21.61it/s]Training:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1301/1600 [01:00<00:13, 21.47it/s]Training:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1513/1600 [01:10<00:04, 21.31it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s] Validation loss: 464.1340, Validation accuracy: 0.5000
Macro F1-score: 0.4510
Model performance on Angry speech (in validation): 
	Precision: 0.4118, Recall: 0.9800, F1_score: 0.5799
Model performance on Happy speech (in validation): 
	Precision: 0.5294, Recall: 0.1800, F1_score: 0.2687
Model performance on Neutral speech (in validation): 
	Precision: 0.3182, Recall: 0.1400, F1_score: 0.1944
Model performance on Sad speech (in validation): 
	Precision: 0.8333, Recall: 0.7000, F1_score: 0.7609
Epoch 12/100

Training Phase:
Training loss: 405.1581, Training accuracy: 0.9081
Macro F1-score: 0.9080
Model performance on Angry speech (in training): 
	Precision: 0.9332, Recall: 0.9425, F1_score: 0.9378
Model performance on Happy speech (in training): 
	Precision: 0.9399, Recall: 0.8600, F1_score: 0.8982
Model performance on Neutral speech (in training): 
	Precision: 0.8922, Recall: 0.8900, F1_score: 0.8911
Model performance on Sad speech (in training): 
	Precision: 0.8724, Recall: 0.9400, F1_score: 0.9049

Eval Phase: 
Validation loss: 288.3970, Validation accuracy: 0.5900
Macro F1-score: 0.5791
Model performance on Angry speech (in validation): 
	Precision: 0.6324, Recall: 0.8600, F1_score: 0.7288
Model performance on Happy speech (in validation): 
	Precision: 0.4375, Recall: 0.2800, F1_score: 0.3415
Model performance on Neutral speech (in validation): 
	Precision: 0.4407, Recall: 0.5200, F1_score: 0.4771
Model performance on Sad speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Epoch 13/100

Training Phase:
                                                  Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|â–ˆâ–Ž        | 214/1600 [00:10<01:04, 21.39it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 428/1600 [00:20<00:55, 21.23it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 640/1600 [00:30<00:45, 21.16it/s]Training:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 862/1600 [00:40<00:34, 21.55it/s]Training:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1084/1600 [00:50<00:24, 21.33it/s]Training:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1300/1600 [01:00<00:14, 21.39it/s]Training:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1516/1600 [01:11<00:03, 21.33it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|â–ˆâ–Ž        | 207/1600 [00:10<01:07, 20.69it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 434/1600 [00:20<00:53, 21.84it/s]Training:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 661/1600 [00:30<00:42Training loss: 373.5181, Training accuracy: 0.9137
Macro F1-score: 0.9138
Model performance on Angry speech (in training): 
	Precision: 0.9496, Recall: 0.9425, F1_score: 0.9460
Model performance on Happy speech (in training): 
	Precision: 0.9152, Recall: 0.8900, F1_score: 0.9024
Model performance on Neutral speech (in training): 
	Precision: 0.8916, Recall: 0.9050, F1_score: 0.8983
Model performance on Sad speech (in training): 
	Precision: 0.8995, Recall: 0.9175, F1_score: 0.9084

Eval Phase: 
Validation loss: 332.4264, Validation accuracy: 0.6050
Macro F1-score: 0.5887
Model performance on Angry speech (in validation): 
	Precision: 0.5341, Recall: 0.9400, F1_score: 0.6812
Model performance on Happy speech (in validation): 
	Precision: 0.5429, Recall: 0.3800, F1_score: 0.4471
Model performance on Neutral speech (in validation): 
	Precision: 0.5588, Recall: 0.3800, F1_score: 0.4524
Model performance on Sad speech (in validation): 
	Precision: 0.8372, Recall: 0.7200, F1_score: 0.7742
Epoch 14/100

Training Phase:
, 22.16it/s]Training:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 892/1600 [00:40<00:31, 22.52it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1123/1600 [00:50<00:21, 22.32it/s]Training:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1349/1600 [01:00<00:11, 22.40it/s]Training:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1585/1600 [01:10<00:00, 22.77it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–        | 224/1600 [00:10<01:01, 22.35it/s]Training:  28%|â–ˆâ–ˆâ–Š       | 453/1600 [00:20<00:50, 22.61it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 692/1600 [00:30<00:39, 23.15it/s]Training:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 930/1600 [00:40<00:29, 22.77it/s]Training:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1160/1600 [00:50<00:19, 22.84it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1390/1600 [01:01<00:09, 22.68it/s]                                               Training loss: 325.9987, Training accuracy: 0.9275
Macro F1-score: 0.9274
Model performance on Angry speech (in training): 
	Precision: 0.9524, Recall: 0.9500, F1_score: 0.9512
Model performance on Happy speech (in training): 
	Precision: 0.9319, Recall: 0.8900, F1_score: 0.9105
Model performance on Neutral speech (in training): 
	Precision: 0.9204, Recall: 0.9250, F1_score: 0.9227
Model performance on Sad speech (in training): 
	Precision: 0.9065, Recall: 0.9450, F1_score: 0.9253

Eval Phase: 
Validation loss: 333.9512, Validation accuracy: 0.5950
Macro F1-score: 0.5674
Model performance on Angry speech (in validation): 
	Precision: 0.5488, Recall: 0.9000, F1_score: 0.6818
Model performance on Happy speech (in validation): 
	Precision: 0.4400, Recall: 0.2200, F1_score: 0.2933
Model performance on Neutral speech (in validation): 
	Precision: 0.5349, Recall: 0.4600, F1_score: 0.4946
Model performance on Sad speech (in validation): 
	Precision: 0.8000, Recall: 0.8000, F1_score: 0.8000
Validation loss does not decrease for 10 epochs. End training.
Model best accuracy on validation set: 0.6300

Test Phase: 
              Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]                                                Some weights of the model checkpoint at /work/tc062/tc062/zhan7721/saved_models/de were not used when initializing Wav2Vec2Model: ['encoder.layers.10.attention.k_proj.bias', 'encoder.layers.10.attention.k_proj.weight', 'encoder.layers.10.attention.out_proj.bias', 'encoder.layers.10.attention.out_proj.weight', 'encoder.layers.10.attention.q_proj.bias', 'encoder.layers.10.attention.q_proj.weight', 'encoder.layers.10.attention.v_proj.bias', 'encoder.layers.10.attention.v_proj.weight', 'encoder.layers.10.feed_forward.intermediate_dense.bias', 'encoder.layers.10.feed_forward.intermediate_dense.weight', 'encoder.layers.10.feed_forward.output_dense.bias', 'encoder.layers.10.feed_forward.output_dense.weight', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.10.layer_norm.bias', 'encoder.layers.10.layer_norm.weight', 'encoder.layers.11.attention.k_proj.bias', 'encoder.layers.11.attention.k_proj.weight', 'encoder.layers.11.attention.out_proj.bias', 'encoder.layers.11.attention.out_proj.weight', 'encoder.layers.11.attention.q_proj.bias', 'encoder.layers.11.attention.q_proj.weight', 'encoder.layers.11.attention.v_proj.bias', 'encoder.layers.11.attention.v_proj.weight', 'encoder.layers.11.feed_forward.intermediate_dense.bias', 'encoder.layers.11.feed_forward.intermediate_dense.weight', 'encoder.layers.11.feed_forward.output_dense.bias', 'encoder.layers.11.feed_forward.output_dense.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.11.layer_norm.bias', 'encoder.layers.11.layer_norm.weight', 'encoder.layers.6.attention.k_proj.bias', 'encoder.layers.6.attention.k_proj.weight', 'encoder.layers.6.attention.out_proj.bias', 'encoder.layers.6.attention.out_proj.weight', 'encoder.layers.6.attention.q_proj.bias', 'encoder.layers.6.attention.q_proj.weight', 'encoder.layers.6.attention.v_proj.bias', 'encoder.layers.6.attention.v_proj.weight', 'encoder.layers.6.feed_forward.intermediate_dense.bias', 'encoder.layers.6.feed_forward.intermediate_dense.weight', 'encoder.layers.6.feed_forward.output_dense.bias', 'encoder.layers.6.feed_forward.output_dense.weight', 'encoder.layers.6.final_layer_norm.bias', 'encoder.layers.6.final_layer_norm.weight', 'encoder.layers.6.layer_norm.bias', 'encoder.layers.6.layer_norm.weight', 'encoder.layers.7.attention.k_proj.bias', 'encoder.layers.7.attention.k_proj.weight', 'encoder.layers.7.attention.out_proj.bias', 'encoder.layers.7.attention.out_proj.weight', 'encoder.layers.7.attention.q_proj.bias', 'encoder.layers.7.attention.q_proj.weight', 'encoder.layers.7.attention.v_proj.bias', 'encoder.layers.7.attention.v_proj.weight', 'encoder.layers.7.feed_forward.intermediate_dense.bias', 'encoder.layers.7.feed_forward.intermediate_dense.weight', 'encoder.layers.7.feed_forward.output_dense.bias', 'encoder.layers.7.feed_forward.output_dense.weight', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.7.layer_norm.bias', 'encoder.layers.7.layer_norm.weight', 'encoder.layers.8.attention.k_proj.bias', 'encoder.layers.8.attention.k_proj.weight', 'encoder.layers.8.attention.out_proj.bias', 'encoder.layers.8.attention.out_proj.weight', 'encoder.layers.8.attention.q_proj.bias', 'encoder.layers.8.attention.q_proj.weight', 'encoder.layers.8.attention.v_proj.bias', 'encoder.layers.8.attention.v_proj.weight', 'encoder.layers.8.feed_forward.intermediate_dense.bias', 'encoder.layers.8.feed_forward.intermediate_dense.weight', 'encoder.layers.8.feed_forward.output_dense.bias', 'encoder.layers.8.feed_forward.output_dense.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.8.layer_norm.bias', 'encoder.layers.8.layer_norm.weight', 'encoder.layers.9.attention.k_proj.bias', 'encoder.layers.9.attention.k_proj.weight', 'encoder.layers.9.attention.out_proj.bias', 'encoder.layers.9.attention.out_proj.weight', 'encoder.layers.9.attention.q_proj.bias', 'encoder.layers.9.attention.q_proj.weight', 'encoder.layers.9.attention.v_proj.bias', 'encoder.layers.9.attention.v_proj.weight', 'encoder.layers.9.feed_forward.intermediate_dense.bias', 'encoder.layers.9.feed_forward.intermediate_dense.weight', 'encoder.layers.9.feed_forward.output_dense.bias', 'encoder.layers.9.feed_forward.output_dense.weight', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.layer_norm.bias', 'encoder.layers.9.layer_norm.weight']
- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Test loss: 188.0572, Test accuracy: 0.5850
Macro F1-score: 0.5508
Model performance on Angry speech (in test): 
	Precision: 0.5541, Recall: 0.8200, F1_score: 0.6613
Model performance on Happy speech (in test): 
	Precision: 0.5714, Recall: 0.1600, F1_score: 0.2500
Model performance on Neutral speech (in test): 
	Precision: 0.4833, Recall: 0.5800, F1_score: 0.5273
Model performance on Sad speech (in test): 
	Precision: 0.7500, Recall: 0.7800, F1_score: 0.7647

======================= This is fold_2 on de =======================

Load dataset: 
Loading en train data: fold_2...
Preprocess en fold_2 data for de model
Loading en eval data: fold_2...
Preprocess en fold_2 data for de model
Loading en test data: fold_2...
Preprocess en fold_2 data for de model
Use de model to add lora
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training loss: 1529.2663, Training accuracy: 0.6125
Macro F1-score: 0.6086
Model performance on Angry speech (in training): 
	Precision: 0.6605, Recall: 0.7100, F1_score: 0.6843
Model performance on Happy speech (in training): 
	Precision: 0.5519, Recall: 0.4650, F1_score: 0.5047
Model performance on Neutral speech (in training): 
	Precision: 0.5338, Recall: 0.5325, F1_score: 0.5332
Model performance on Sad speech (in training): 
	Precision: 0.6843, Recall: 0.7425, F1_score: 0.7122

Eval Phase: 
Validation loss: 194.6983, Validation accuracy: 0.6100
Macro F1-score: 0.5913
Model performance on Angry speech (in validation): 
	Precision: 0.7333, Recall: 0.6600, F1_score: 0.6947
Model performance on Happy speech (in validation): 
	Precision: 0.6364, Recall: 0.2800, F1_score: 0.3889
Model performance on Neutral speech (in validation): 
	Precision: 0.6200, Recall: 0.6200, F1_score: 0.6200
Model performance on Sad speech (in validation): 
	Precision: 0.5301, Recall: 0.8800, F1_score: 0.6617
New best accuracy for layer 5 on epoch 1: 0.6100. Model saved.
Epoch 2/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:   8%|â–Š         | 129/1600 [00:10<01:54, 12.87it/s]Training:  18%|â–ˆâ–Š        | 295/1600 [00:20<01:26, 15.00it/s]Training:  30%|â–ˆâ–ˆâ–‰       | 475/1600 [00:30<01:08, 16.33it/s]Training:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 667/1600 [00:40<00:53, 17.42it/s]Training:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 867/1600 [00:50<00:39, 18.34it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1070/1600 [01:00<00:27, 18.98it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1275/1600 [01:10<00:16, 19.47it/s]Training:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1484/1600 [01:20<00:05, 19.92it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–Ž        | 218/1600 [00:10<01:03, 21.77it/s]Training:  28%|â–ˆâ–ˆâ–Š       | 446/1600 [00:20<00:51, 22.37it/s]Training:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 674/1600 Training loss: 1326.9057, Training accuracy: 0.6569
Macro F1-score: 0.6518
Model performance on Angry speech (in training): 
	Precision: 0.6946, Recall: 0.7675, F1_score: 0.7292
Model performance on Happy speech (in training): 
	Precision: 0.6127, Recall: 0.4825, F1_score: 0.5399
Model performance on Neutral speech (in training): 
	Precision: 0.5891, Recall: 0.5950, F1_score: 0.5920
Model performance on Sad speech (in training): 
	Precision: 0.7130, Recall: 0.7825, F1_score: 0.7461

Eval Phase: 
Validation loss: 184.0396, Validation accuracy: 0.6550
Macro F1-score: 0.6472
Model performance on Angry speech (in validation): 
	Precision: 0.8649, Recall: 0.6400, F1_score: 0.7356
Model performance on Happy speech (in validation): 
	Precision: 0.6061, Recall: 0.4000, F1_score: 0.4819
Model performance on Neutral speech (in validation): 
	Precision: 0.5902, Recall: 0.7200, F1_score: 0.6486
Model performance on Sad speech (in validation): 
	Precision: 0.6232, Recall: 0.8600, F1_score: 0.7227
New best accuracy for layer 5 on epoch 2: 0.6550. Model saved.
Epoch 3/100

Training Phase:
[00:30<00:41, 22.37it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 911/1600 [00:40<00:30, 22.87it/s]Training:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1148/1600 [00:50<00:19, 23.07it/s]Training:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1383/1600 [01:01<00:09, 22.63it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–        | 221/1600 [00:10<01:02, 22.03it/s]Training:  28%|â–ˆâ–ˆâ–Š       | 444/1600 [00:20<00:52, 22.17it/s]Training:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 672/1600 [00:30<00:41, 22.43it/s]Training:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 904/1600 [00:40<00:30, 22.70it/s]Training:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1137/1600 [00:50<00:20, 22.91it/s]Training:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1370/1600 [01:00<00:10, 22.88it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1599/1600 [01:10<00:00, 22.71it/s]                                   Training loss: 1188.9546, Training accuracy: 0.7169
Macro F1-score: 0.7147
Model performance on Angry speech (in training): 
	Precision: 0.7711, Recall: 0.8000, F1_score: 0.7853
Model performance on Happy speech (in training): 
	Precision: 0.6901, Recall: 0.5900, F1_score: 0.6361
Model performance on Neutral speech (in training): 
	Precision: 0.6496, Recall: 0.6675, F1_score: 0.6584
Model performance on Sad speech (in training): 
	Precision: 0.7500, Recall: 0.8100, F1_score: 0.7788

Eval Phase: 
Validation loss: 204.5835, Validation accuracy: 0.6100
Macro F1-score: 0.5973
Model performance on Angry speech (in validation): 
	Precision: 0.8250, Recall: 0.6600, F1_score: 0.7333
Model performance on Happy speech (in validation): 
	Precision: 0.6000, Recall: 0.3600, F1_score: 0.4500
Model performance on Neutral speech (in validation): 
	Precision: 0.6154, Recall: 0.4800, F1_score: 0.5393
Model performance on Sad speech (in validation): 
	Precision: 0.5165, Recall: 0.9400, F1_score: 0.6667
Epoch 4/100

Training Phase:
Training loss: 1051.6940, Training accuracy: 0.7369
Macro F1-score: 0.7359
Model performance on Angry speech (in training): 
	Precision: 0.7975, Recall: 0.7975, F1_score: 0.7975
Model performance on Happy speech (in training): 
	Precision: 0.7003, Recall: 0.6425, F1_score: 0.6701
Model performance on Neutral speech (in training): 
	Precision: 0.6781, Recall: 0.6900, F1_score: 0.6840
Model performance on Sad speech (in training): 
	Precision: 0.7676, Recall: 0.8175, F1_score: 0.7918

Eval Phase: 
Validation loss: 221.4275, Validation accuracy: 0.5850
Macro F1-score: 0.5513
Model performance on Angry speech (in validation): 
	Precision: 0.7442, Recall: 0.6400, F1_score: 0.6882
Model performance on Happy speech (in validation): 
	Precision: 0.8182, Recall: 0.1800, F1_score: 0.2951
Model performance on Neutral speech (in validation): 
	Precision: 0.5085, Recall: 0.6000, F1_score: 0.5505
Model performance on Sad speech (in validation): 
	Precision: 0.5287, Recall: 0.9200, F1_score: 0.6715
Epoch 5/100

Training Phase:
                          Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–        | 221/1600 [00:10<01:02, 22.03it/s]Training:  28%|â–ˆâ–ˆâ–Š       | 453/1600 [00:20<00:50, 22.71it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 685/1600 [00:30<00:40, 22.63it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 915/1600 [00:40<00:30, 22.77it/s]Training:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1145/1600 [00:50<00:20, 22.54it/s]Training:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1376/1600 [01:00<00:09, 22.70it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–        | 238/1600 [00:10<00:57, 23.76it/s]Training:  30%|â–ˆâ–ˆâ–‰       | 476/1600 [00:20<00:48, 23.20it/s]Training:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 705/1600 [00:30<00Training loss: 900.8299, Training accuracy: 0.7863
Macro F1-score: 0.7852
Model performance on Angry speech (in training): 
	Precision: 0.8415, Recall: 0.8625, F1_score: 0.8519
Model performance on Happy speech (in training): 
	Precision: 0.7759, Recall: 0.6925, F1_score: 0.7318
Model performance on Neutral speech (in training): 
	Precision: 0.7251, Recall: 0.7450, F1_score: 0.7349
Model performance on Sad speech (in training): 
	Precision: 0.8009, Recall: 0.8450, F1_score: 0.8224

Eval Phase: 
Validation loss: 208.4119, Validation accuracy: 0.6200
Macro F1-score: 0.6058
Model performance on Angry speech (in validation): 
	Precision: 0.7391, Recall: 0.6800, F1_score: 0.7083
Model performance on Happy speech (in validation): 
	Precision: 0.7273, Recall: 0.3200, F1_score: 0.4444
Model performance on Neutral speech (in validation): 
	Precision: 0.5333, Recall: 0.6400, F1_score: 0.5818
Model performance on Sad speech (in validation): 
	Precision: 0.5833, Recall: 0.8400, F1_score: 0.6885
Epoch 6/100

Training Phase:
:39, 22.91it/s]Training:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 934/1600 [00:40<00:29, 22.87it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1166/1600 [00:50<00:18, 22.97it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1398/1600 [01:01<00:09, 22.36it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–        | 223/1600 [00:10<01:01, 22.22it/s]Training:  28%|â–ˆâ–ˆâ–Š       | 450/1600 [00:20<00:51, 22.48it/s]Training:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 677/1600 [00:30<00:41, 22.46it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 905/1600 [00:40<00:30, 22.58it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 905/1600 [00:50<00:30, 22.58it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1127/1600 [00:50<00:21, 22.09it/s]Training:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1347/1600 [01:00<00:11, 22.05it/s]Training:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1567/1Training loss: 811.6603, Training accuracy: 0.8119
Macro F1-score: 0.8111
Model performance on Angry speech (in training): 
	Precision: 0.8771, Recall: 0.8925, F1_score: 0.8848
Model performance on Happy speech (in training): 
	Precision: 0.8125, Recall: 0.7150, F1_score: 0.7606
Model performance on Neutral speech (in training): 
	Precision: 0.7488, Recall: 0.7825, F1_score: 0.7653
Model performance on Sad speech (in training): 
	Precision: 0.8109, Recall: 0.8575, F1_score: 0.8335

Eval Phase: 
Validation loss: 235.0453, Validation accuracy: 0.5900
Macro F1-score: 0.5733
Model performance on Angry speech (in validation): 
	Precision: 0.7333, Recall: 0.6600, F1_score: 0.6947
Model performance on Happy speech (in validation): 
	Precision: 0.6087, Recall: 0.2800, F1_score: 0.3836
Model performance on Neutral speech (in validation): 
	Precision: 0.4915, Recall: 0.5800, F1_score: 0.5321
Model performance on Sad speech (in validation): 
	Precision: 0.5753, Recall: 0.8400, F1_score: 0.6829
Epoch 7/100

Training Phase:
Training loss: 720.7818, Training accuracy: 0.8337
Macro F1-score: 0.8333
Model performance on Angry speech (in training): 
	Precision: 0.8816, Recall: 0.8750, F1_score: 0.8783
Model performance on Happy speech (in training): 
	Precision: 0.8117, Recall: 0.7650, F1_score: 0.7876
Model performance on Neutral speech (in training): 
	Precision: 0.7887, Recall: 0.8025, F1_score: 0.7955
Model performance on Sad speech (in training): 
	Precision: 0.8520, Recall: 0.8925, F1_score: 0.8718

Eval Phase: 
Validation loss: 235.7575, Validation accuracy: 0.6250
Macro F1-score: 0.6147
Model performance on Angry speech (in validation): 
	Precision: 0.6957, Recall: 0.6400, F1_score: 0.6667
Model performance on Happy speech (in validation): 
	Precision: 0.6667, Recall: 0.4400, F1_score: 0.5301
Model performance on Neutral speech (in validation): 
	Precision: 0.5909, Recall: 0.5200, F1_score: 0.5532
Model performance on Sad speech (in validation): 
	Precision: 0.5844, Recall: 0.9000, F1_score: 0.7087
Epoch 8/100

Training Phase:
600 [01:10<00:01, 21.81it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|â–ˆâ–Ž        | 211/1600 [00:10<01:05, 21.05it/s]Training:  26%|â–ˆâ–ˆâ–‹       | 423/1600 [00:20<00:55, 21.14it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 638/1600 [00:30<00:45, 21.27it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 853/1600 [00:40<00:35, 21.18it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1068/1600 [00:50<00:24, 21.29it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1283/1600 [01:00<00:14, 21.24it/s]Training:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1503/1600 [01:10<00:04, 21.44it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|â–ˆâ–Ž        | 214/1600 [00:10<Training loss: 598.1836, Training accuracy: 0.8638
Macro F1-score: 0.8632
Model performance on Angry speech (in training): 
	Precision: 0.8960, Recall: 0.9050, F1_score: 0.9005
Model performance on Happy speech (in training): 
	Precision: 0.8495, Recall: 0.7900, F1_score: 0.8187
Model performance on Neutral speech (in training): 
	Precision: 0.8268, Recall: 0.8475, F1_score: 0.8370
Model performance on Sad speech (in training): 
	Precision: 0.8816, Recall: 0.9125, F1_score: 0.8968

Eval Phase: 
Validation loss: 291.8714, Validation accuracy: 0.6050
Macro F1-score: 0.5940
Model performance on Angry speech (in validation): 
	Precision: 0.8333, Recall: 0.6000, F1_score: 0.6977
Model performance on Happy speech (in validation): 
	Precision: 0.5333, Recall: 0.4800, F1_score: 0.5053
Model performance on Neutral speech (in validation): 
	Precision: 0.6061, Recall: 0.4000, F1_score: 0.4819
Model performance on Sad speech (in validation): 
	Precision: 0.5465, Recall: 0.9400, F1_score: 0.6912
Epoch 9/100

Training Phase:
01:04, 21.38it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 428/1600 [00:20<00:56, 20.92it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 638/1600 [00:30<00:45, 20.96it/s]Training:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 858/1600 [00:40<00:34, 21.34it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1078/1600 [00:50<00:24, 21.57it/s]Training:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1298/1600 [01:01<00:14, 21.30it/s]Training:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1517/1600 [01:11<00:03, 21.49it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|â–ˆâ–Ž        | 214/1600 [00:10<01:04, 21.34it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 431/1600 [00:20<00:54, 21.54it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 648/1600 [00:30<00:44, 21.48it/s]Training:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 863/1600 [00:40<00:34, 21.27it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1077/1600 [00:50<00:24, 21.Training loss: 483.9459, Training accuracy: 0.8931
Macro F1-score: 0.8927
Model performance on Angry speech (in training): 
	Precision: 0.9265, Recall: 0.9450, F1_score: 0.9356
Model performance on Happy speech (in training): 
	Precision: 0.9011, Recall: 0.8200, F1_score: 0.8586
Model performance on Neutral speech (in training): 
	Precision: 0.8575, Recall: 0.8875, F1_score: 0.8722
Model performance on Sad speech (in training): 
	Precision: 0.8889, Recall: 0.9200, F1_score: 0.9042

Eval Phase: 
Validation loss: 310.7473, Validation accuracy: 0.6100
Macro F1-score: 0.5990
Model performance on Angry speech (in validation): 
	Precision: 0.7561, Recall: 0.6200, F1_score: 0.6813
Model performance on Happy speech (in validation): 
	Precision: 0.6176, Recall: 0.4200, F1_score: 0.5000
Model performance on Neutral speech (in validation): 
	Precision: 0.6000, Recall: 0.4800, F1_score: 0.5333
Model performance on Sad speech (in validation): 
	Precision: 0.5412, Recall: 0.9200, F1_score: 0.6815
Epoch 10/100

Training Phase:
Training loss: 413.0733, Training accuracy: 0.9062
Macro F1-score: 0.9061
Model performance on Angry speech (in training): 
	Precision: 0.9171, Recall: 0.9400, F1_score: 0.9284
Model performance on Happy speech (in training): 
	Precision: 0.9108, Recall: 0.8675, F1_score: 0.8886
Model performance on Neutral speech (in training): 
	Precision: 0.8834, Recall: 0.8900, F1_score: 0.8867
Model performance on Sad speech (in training): 
	Precision: 0.9138, Recall: 0.9275, F1_score: 0.9206

Eval Phase: 
30it/s]Training:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1291/1600 [01:00<00:14, 21.09it/s]Training:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1511/1600 [01:10<00:04, 21.33it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–Ž        | 217/1600 [00:10<01:03, 21.61it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 434/1600 [00:20<00:54, 21.43it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 648/1600 [00:30<00:44, 21.30it/s]Training:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 865/1600 [00:40<00:34, 21.44it/s]Training:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1082/1600 [00:50<00:24, 21.17it/s]Training:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1296/1600 [01:00<00:14, 21.22it/s]Training:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1510/1600 [01:11<00:04, 21.12it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]            Validation loss: 349.5718, Validation accuracy: 0.6150
Macro F1-score: 0.6025
Model performance on Angry speech (in validation): 
	Precision: 0.7805, Recall: 0.6400, F1_score: 0.7033
Model performance on Happy speech (in validation): 
	Precision: 0.5476, Recall: 0.4600, F1_score: 0.5000
Model performance on Neutral speech (in validation): 
	Precision: 0.6176, Recall: 0.4200, F1_score: 0.5000
Model performance on Sad speech (in validation): 
	Precision: 0.5663, Recall: 0.9400, F1_score: 0.7068
Epoch 11/100

Training Phase:
Training loss: 353.6661, Training accuracy: 0.9231
Macro F1-score: 0.9231
Model performance on Angry speech (in training): 
	Precision: 0.9570, Recall: 0.9450, F1_score: 0.9509
Model performance on Happy speech (in training): 
	Precision: 0.9365, Recall: 0.8850, F1_score: 0.9100
Model performance on Neutral speech (in training): 
	Precision: 0.8878, Recall: 0.9100, F1_score: 0.8988
Model performance on Sad speech (in training): 
	Precision: 0.9137, Recall: 0.9525, F1_score: 0.9327

Eval Phase: 
Validation loss: 357.7946, Validation accuracy: 0.6050
Macro F1-score: 0.5931
Model performance on Angry speech (in validation): 
	Precision: 0.7857, Recall: 0.6600, F1_score: 0.7174
Model performance on Happy speech (in validation): 
	Precision: 0.6667, Recall: 0.4000, F1_score: 0.5000
Model performance on Neutral speech (in validation): 
	Precision: 0.5366, Recall: 0.4400, F1_score: 0.4835
Model performance on Sad speech (in validation): 
	Precision: 0.5287, Recall: 0.9200, F1_score: 0.6715
Epoch 12/100

Training Phase:
                                       Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–Ž        | 216/1600 [00:10<01:04, 21.58it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 432/1600 [00:20<00:54, 21.32it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 648/1600 [00:30<00:44, 21.44it/s]Training:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 864/1600 [00:40<00:34, 21.06it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1078/1600 [00:50<00:24, 21.15it/s]Training:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1298/1600 [01:00<00:14, 21.38it/s]Training:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1517/1600 [01:11<00:03, 21.36it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–        | 220/1600 [00:10<01:02, 21.92it/s]Training:  28%|â–ˆâ–ˆâ–Š       | 441/1600 [00:20<00:52, 22.01it/s]Training:  28%|â–ˆâ–ˆâ–Š       | 441/1600 [00:30<00:52, 22.01it/s]TraiTraining loss: 315.6972, Training accuracy: 0.9319
Macro F1-score: 0.9319
Model performance on Angry speech (in training): 
	Precision: 0.9494, Recall: 0.9375, F1_score: 0.9434
Model performance on Happy speech (in training): 
	Precision: 0.9306, Recall: 0.9050, F1_score: 0.9176
Model performance on Neutral speech (in training): 
	Precision: 0.9049, Recall: 0.9275, F1_score: 0.9160
Model performance on Sad speech (in training): 
	Precision: 0.9433, Recall: 0.9575, F1_score: 0.9504

Eval Phase: 
Validation loss: 343.6106, Validation accuracy: 0.6000
Macro F1-score: 0.5936
Model performance on Angry speech (in validation): 
	Precision: 0.7838, Recall: 0.5800, F1_score: 0.6667
Model performance on Happy speech (in validation): 
	Precision: 0.5789, Recall: 0.4400, F1_score: 0.5000
Model performance on Neutral speech (in validation): 
	Precision: 0.5306, Recall: 0.5200, F1_score: 0.5253
Model performance on Sad speech (in validation): 
	Precision: 0.5658, Recall: 0.8600, F1_score: 0.6825
Validation loss does not decrease for 10 epochs. End training.
Model best accuracy on validation set: 0.6550

Test Phase: 
ning:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 661/1600 [00:30<00:43, 21.78it/s]Training:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 877/1600 [00:40<00:33, 21.61it/s]Training:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1091/1600 [00:50<00:23, 21.54it/s]Training:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1305/1600 [01:00<00:13, 21.37it/s]Training:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1516/1600 [01:10<00:03, 21.18it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]                                                Some weights of the model checkpoint at /work/tc062/tc062/zhan7721/saved_models/de were not used when initializing Wav2Vec2Model: ['encoder.layers.10.attention.k_proj.bias', 'encoder.layers.10.attention.k_proj.weight', 'encoder.layers.10.attention.out_proj.bias', 'encoder.layers.10.attention.out_proj.weight', 'encoder.layers.10.attention.q_proj.bias', 'encoder.layers.10.attention.q_proj.weight', 'encoder.layers.10.attention.v_proj.bias', 'encoder.layers.10.attention.v_proj.weight', 'encoder.layers.10.feed_forward.intermediate_dense.bias', 'encoder.layers.10.feed_forward.intermediate_dense.weight', 'encoder.layers.10.feed_forward.output_dense.bias', 'encoder.layers.10.feed_forward.output_dense.weight', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.10.layer_norm.bias', 'encoder.layers.10.layer_norm.weight', 'encoder.layers.11.attention.k_proj.bias', 'encoder.layers.11.attention.k_proj.weight', 'encoder.layers.11.attention.out_proj.bias', 'encoder.layers.11.attention.out_proj.weight', 'encoder.layers.11.attention.q_proj.bias', 'encoder.layers.11.attention.q_proj.weight', 'encoder.layers.11.attention.v_proj.bias', 'encoder.layers.11.attention.v_proj.weight', 'encoder.layers.11.feed_forward.intermediate_dense.bias', 'encoder.layers.11.feed_forward.intermediate_dense.weight', 'encoder.layers.11.feed_forward.output_dense.bias', 'encoder.layers.11.feed_forward.output_dense.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.11.layer_norm.bias', 'encoder.layers.11.layer_norm.weight', 'encoder.layers.6.attention.k_proj.bias', 'encoder.layers.6.attention.k_proj.weight', 'encoder.layers.6.attention.out_proj.bias', 'encoder.layers.6.attention.out_proj.weight', 'encoder.layers.6.attention.q_proj.bias', 'encoder.layers.6.attention.q_proj.weight', 'encoder.layers.6.attention.v_proj.bias', 'encoder.layers.6.attention.v_proj.weight', 'encoder.layers.6.feed_forward.intermediate_dense.bias', 'encoder.layers.6.feed_forward.intermediate_dense.weight', 'encoder.layers.6.feed_forward.output_dense.bias', 'encoder.layers.6.feed_forward.output_dense.weight', 'encoder.layers.6.final_layer_norm.bias', 'encoder.layers.6.final_layer_norm.weight', 'encoder.layers.6.layer_norm.bias', 'encoder.layers.6.layer_norm.weight', 'encoder.layers.7.attention.k_proj.bias', 'encoder.layers.7.attention.k_proj.weight', 'encoder.layers.7.attention.out_proj.bias', 'encoder.layers.7.attention.out_proj.weight', 'encoder.layers.7.attention.q_proj.bias', 'encoder.layers.7.attention.q_proj.weight', 'encoder.layers.7.attention.v_proj.bias', 'encoder.layers.7.attention.v_proj.weight', 'encoder.layers.7.feed_forward.intermediate_dense.bias', 'encoder.layers.7.feed_forward.intermediate_dense.weight', 'encoder.layers.7.feed_forward.output_dense.bias', 'encoder.layers.7.feed_forward.output_dense.weight', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.7.layer_norm.bias', 'encoder.layers.7.layer_norm.weight', 'encoder.layers.8.attention.k_proj.bias', 'encoder.layers.8.attention.k_proj.weight', 'encoder.layers.8.attention.out_proj.bias', 'encoder.layers.8.attention.out_proj.weight', 'encoder.layers.8.attention.q_proj.bias', 'encoder.layers.8.attention.q_proj.weight', 'encoder.layers.8.attention.v_proj.bias', 'encoder.layers.8.attention.v_proj.weight', 'encoder.layers.8.feed_forward.intermediate_dense.bias', 'encoder.layers.8.feed_forward.intermediate_dense.weight', 'encoder.layers.8.feed_forward.output_dense.bias', 'encoder.layers.8.feed_forward.output_dense.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.8.layer_norm.bias', 'encoder.layers.8.layer_norm.weight', 'encoder.layers.9.attention.k_proj.bias', 'encoder.layers.9.attention.k_proj.weight', 'encoder.layers.9.attention.out_proj.bias', 'encoder.layers.9.attention.out_proj.weight', 'encoder.layers.9.attention.q_proj.bias', 'encoder.layers.9.attention.q_proj.weight', 'encoder.layers.9.attention.v_proj.bias', 'encoder.layers.9.attention.v_proj.weight', 'encoder.layers.9.feed_forward.intermediate_dense.bias', 'encoder.layers.9.feed_forward.intermediate_dense.weight', 'encoder.layers.9.feed_forward.output_dense.bias', 'encoder.layers.9.feed_forward.output_dense.weight', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.layer_norm.bias', 'encoder.layers.9.layer_norm.weight']
- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Test loss: 182.3590, Test accuracy: 0.6700
Macro F1-score: 0.6646
Model performance on Angry speech (in test): 
	Precision: 0.7561, Recall: 0.6200, F1_score: 0.6813
Model performance on Happy speech (in test): 
	Precision: 0.8214, Recall: 0.4600, F1_score: 0.5897
Model performance on Neutral speech (in test): 
	Precision: 0.5658, Recall: 0.8600, F1_score: 0.6825
Model performance on Sad speech (in test): 
	Precision: 0.6727, Recall: 0.7400, F1_score: 0.7048

======================= This is fold_3 on de =======================

Load dataset: 
Loading en train data: fold_3...
Preprocess en fold_3 data for de model
Loading en eval data: fold_3...
Preprocess en fold_3 data for de model
Loading en test data: fold_3...
Preprocess en fold_3 data for de model
Use de model to add lora
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training loss: 1505.1281, Training accuracy: 0.6169
Macro F1-score: 0.6121
Model performance on Angry speech (in training): 
	Precision: 0.6620, Recall: 0.7100, F1_score: 0.6852
Model performance on Happy speech (in training): 
	Precision: 0.5549, Recall: 0.4425, F1_score: 0.4924
Model performance on Neutral speech (in training): 
	Precision: 0.5537, Recall: 0.5675, F1_score: 0.5605
Model performance on Sad speech (in training): 
	Precision: 0.6765, Recall: 0.7475, F1_score: 0.7102

Eval Phase: 
Validation loss: 195.3058, Validation accuracy: 0.6300
Macro F1-score: 0.6285
Model performance on Angry speech (in validation): 
	Precision: 0.9355, Recall: 0.5800, F1_score: 0.7160
Model performance on Happy speech (in validation): 
	Precision: 0.8077, Recall: 0.4200, F1_score: 0.5526
Model performance on Neutral speech (in validation): 
	Precision: 0.4776, Recall: 0.6400, F1_score: 0.5470
Model performance on Sad speech (in validation): 
	Precision: 0.5789, Recall: 0.8800, F1_score: 0.6984
New best accuracy for layer 5 on epoch 1: 0.6300. Model saved.
Epoch 2/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:   8%|â–Š         | 135/1600 [00:10<01:49, 13.43it/s]Training:  18%|â–ˆâ–Š        | 296/1600 [00:20<01:27, 14.97it/s]Training:  30%|â–ˆâ–ˆâ–‰       | 475/1600 [00:30<01:09, 16.27it/s]Training:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 663/1600 [00:40<00:54, 17.26it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 855/1600 [00:50<00:41, 17.93it/s]Training:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1052/1600 [01:00<00:29, 18.52it/s]Training:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1249/1600 [01:10<00:18, 18.58it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1446/1600 [01:20<00:08, 18.93it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–        | 224/1600 [00:10<01:01, 22.33it/s]Training:  28%|â–ˆâ–ˆâ–Š       | 448/1600 [00:20<00:53, 21.62it/s]Training:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 667/1600 [0Training loss: 1301.0931, Training accuracy: 0.6731
Macro F1-score: 0.6683
Model performance on Angry speech (in training): 
	Precision: 0.7279, Recall: 0.7625, F1_score: 0.7448
Model performance on Happy speech (in training): 
	Precision: 0.6278, Recall: 0.4975, F1_score: 0.5551
Model performance on Neutral speech (in training): 
	Precision: 0.6064, Recall: 0.6200, F1_score: 0.6131
Model performance on Sad speech (in training): 
	Precision: 0.7143, Recall: 0.8125, F1_score: 0.7602

Eval Phase: 
Validation loss: 164.1271, Validation accuracy: 0.6700
Macro F1-score: 0.6703
Model performance on Angry speech (in validation): 
	Precision: 0.8605, Recall: 0.7400, F1_score: 0.7957
Model performance on Happy speech (in validation): 
	Precision: 0.7500, Recall: 0.4800, F1_score: 0.5854
Model performance on Neutral speech (in validation): 
	Precision: 0.5000, Recall: 0.6400, F1_score: 0.5614
Model performance on Sad speech (in validation): 
	Precision: 0.6721, Recall: 0.8200, F1_score: 0.7387
New best accuracy for layer 5 on epoch 2: 0.6700. Model saved.
Epoch 3/100

Training Phase:
0:30<00:43, 21.69it/s]Training:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 885/1600 [00:41<00:33, 21.35it/s]Training:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1101/1600 [00:51<00:23, 21.41it/s]Training:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1317/1600 [01:01<00:13, 21.46it/s]Training:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1533/1600 [01:11<00:03, 21.27it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|â–ˆâ–Ž        | 208/1600 [00:10<01:07, 20.76it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 425/1600 [00:20<00:55, 21.31it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 642/1600 [00:30<00:46, 20.80it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 855/1600 [00:40<00:35, 20.97it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1068/1600 [00:50<00:25, 20.99it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1284/1600 [01:00<00:14, 21.20it/s]Training:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâTraining loss: 1154.5012, Training accuracy: 0.7050
Macro F1-score: 0.7025
Model performance on Angry speech (in training): 
	Precision: 0.7621, Recall: 0.7850, F1_score: 0.7734
Model performance on Happy speech (in training): 
	Precision: 0.6825, Recall: 0.5750, F1_score: 0.6242
Model performance on Neutral speech (in training): 
	Precision: 0.6422, Recall: 0.6550, F1_score: 0.6485
Model performance on Sad speech (in training): 
	Precision: 0.7269, Recall: 0.8050, F1_score: 0.7639

Eval Phase: 
Validation loss: 177.3012, Validation accuracy: 0.6450
Macro F1-score: 0.6421
Model performance on Angry speech (in validation): 
	Precision: 0.8947, Recall: 0.6800, F1_score: 0.7727
Model performance on Happy speech (in validation): 
	Precision: 0.7500, Recall: 0.4200, F1_score: 0.5385
Model performance on Neutral speech (in validation): 
	Precision: 0.5167, Recall: 0.6200, F1_score: 0.5636
Model performance on Sad speech (in validation): 
	Precision: 0.5811, Recall: 0.8600, F1_score: 0.6935
Epoch 4/100

Training Phase:
Training loss: 1040.7109, Training accuracy: 0.7481
Macro F1-score: 0.7466
Model performance on Angry speech (in training): 
	Precision: 0.8161, Recall: 0.8100, F1_score: 0.8130
Model performance on Happy speech (in training): 
	Precision: 0.7299, Recall: 0.6350, F1_score: 0.6791
Model performance on Neutral speech (in training): 
	Precision: 0.6985, Recall: 0.7125, F1_score: 0.7054
Model performance on Sad speech (in training): 
	Precision: 0.7472, Recall: 0.8350, F1_score: 0.7887

Eval Phase: 
Validation loss: 176.1650, Validation accuracy: 0.6800
Macro F1-score: 0.6744
Model performance on Angry speech (in validation): 
	Precision: 0.7963, Recall: 0.8600, F1_score: 0.8269
Model performance on Happy speech (in validation): 
	Precision: 0.6316, Recall: 0.4800, F1_score: 0.5455
Model performance on Neutral speech (in validation): 
	Precision: 0.5660, Recall: 0.6000, F1_score: 0.5825
Model performance on Sad speech (in validation): 
	Precision: 0.7091, Recall: 0.7800, F1_score: 0.7429
New best accuracy for layer 5 on epoch 4: 0.6800. Model saved.
Epoch 5/100

Training Phase:
–| 1500/1600 [01:11<00:04, 21.25it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|â–ˆâ–        | 187/1600 [00:10<01:15, 18.68it/s]Training:  26%|â–ˆâ–ˆâ–‹       | 420/1600 [00:20<00:55, 21.36it/s]Training:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 653/1600 [00:30<00:42, 22.16it/s]Training:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 885/1600 [00:40<00:31, 22.57it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1121/1600 [00:50<00:20, 22.91it/s]Training:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1357/1600 [01:00<00:10, 22.85it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1593/1600 [01:10<00:00, 23.08it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–        | 228/Training loss: 892.5027, Training accuracy: 0.7762
Macro F1-score: 0.7745
Model performance on Angry speech (in training): 
	Precision: 0.8215, Recall: 0.8400, F1_score: 0.8307
Model performance on Happy speech (in training): 
	Precision: 0.7768, Recall: 0.6525, F1_score: 0.7092
Model performance on Neutral speech (in training): 
	Precision: 0.7225, Recall: 0.7550, F1_score: 0.7384
Model performance on Sad speech (in training): 
	Precision: 0.7849, Recall: 0.8575, F1_score: 0.8196

Eval Phase: 
Validation loss: 187.5583, Validation accuracy: 0.6700
Macro F1-score: 0.6656
Model performance on Angry speech (in validation): 
	Precision: 0.7959, Recall: 0.7800, F1_score: 0.7879
Model performance on Happy speech (in validation): 
	Precision: 0.6579, Recall: 0.5000, F1_score: 0.5682
Model performance on Neutral speech (in validation): 
	Precision: 0.5686, Recall: 0.5800, F1_score: 0.5743
Model performance on Sad speech (in validation): 
	Precision: 0.6613, Recall: 0.8200, F1_score: 0.7321
Epoch 6/100

Training Phase:
1600 [00:10<01:00, 22.77it/s]Training:  29%|â–ˆâ–ˆâ–Š       | 457/1600 [00:20<00:50, 22.83it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 689/1600 [00:30<00:39, 22.97it/s]Training:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 921/1600 [00:40<00:29, 22.90it/s]Training:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1150/1600 [00:50<00:19, 22.83it/s]Training:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1382/1600 [01:00<00:09, 22.94it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–        | 236/1600 [00:10<00:57, 23.57it/s]Training:  30%|â–ˆâ–ˆâ–‰       | 472/1600 [00:20<00:49, 23.02it/s]Training:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 708/1600 [00:30<00:38, 23.21it/s]Training:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 708/1600 [00:40<00:38, 23.21it/s]Training:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 940/1600 [00:41<00:29, 22.75it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1165/1600 [00:51Training loss: 782.5520, Training accuracy: 0.8144
Macro F1-score: 0.8139
Model performance on Angry speech (in training): 
	Precision: 0.8504, Recall: 0.8525, F1_score: 0.8514
Model performance on Happy speech (in training): 
	Precision: 0.8103, Recall: 0.7475, F1_score: 0.7776
Model performance on Neutral speech (in training): 
	Precision: 0.7896, Recall: 0.7975, F1_score: 0.7935
Model performance on Sad speech (in training): 
	Precision: 0.8075, Recall: 0.8600, F1_score: 0.8329

Eval Phase: 
Validation loss: 197.1181, Validation accuracy: 0.6400
Macro F1-score: 0.6454
Model performance on Angry speech (in validation): 
	Precision: 0.8974, Recall: 0.7000, F1_score: 0.7865
Model performance on Happy speech (in validation): 
	Precision: 0.5556, Recall: 0.5000, F1_score: 0.5263
Model performance on Neutral speech (in validation): 
	Precision: 0.5000, Recall: 0.6600, F1_score: 0.5690
Model performance on Sad speech (in validation): 
	Precision: 0.7000, Recall: 0.7000, F1_score: 0.7000
Epoch 7/100

Training Phase:
Training loss: 657.9233, Training accuracy: 0.8494
Macro F1-score: 0.8491
Model performance on Angry speech (in training): 
	Precision: 0.8995, Recall: 0.8950, F1_score: 0.8972
Model performance on Happy speech (in training): 
	Precision: 0.8289, Recall: 0.7875, F1_score: 0.8077
Model performance on Neutral speech (in training): 
	Precision: 0.8117, Recall: 0.8300, F1_score: 0.8208
Model performance on Sad speech (in training): 
	Precision: 0.8571, Recall: 0.8850, F1_score: 0.8708

Eval Phase: 
Validation loss: 217.5983, Validation accuracy: 0.6600
Macro F1-score: 0.6585
Model performance on Angry speech (in validation): 
	Precision: 0.8125, Recall: 0.7800, F1_score: 0.7959
Model performance on Happy speech (in validation): 
	Precision: 0.6136, Recall: 0.5400, F1_score: 0.5745
Model performance on Neutral speech (in validation): 
	Precision: 0.5600, Recall: 0.5600, F1_score: 0.5600
Model performance on Sad speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Epoch 8/100

Training Phase:
<00:19, 22.64it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1396/1600 [01:01<00:08, 22.78it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–        | 224/1600 [00:10<01:01, 22.31it/s]Training:  28%|â–ˆâ–ˆâ–Š       | 456/1600 [00:20<00:50, 22.78it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 689/1600 [00:30<00:39, 23.00it/s]Training:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 922/1600 [00:40<00:29, 22.79it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1165/1600 [00:50<00:18, 23.30it/s]Training:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1408/1600 [01:00<00:08, 23.41it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–        | 232/1600 [00:10<00:59,Training loss: 563.0425, Training accuracy: 0.8738
Macro F1-score: 0.8733
Model performance on Angry speech (in training): 
	Precision: 0.8988, Recall: 0.9100, F1_score: 0.9043
Model performance on Happy speech (in training): 
	Precision: 0.8686, Recall: 0.8100, F1_score: 0.8383
Model performance on Neutral speech (in training): 
	Precision: 0.8622, Recall: 0.8600, F1_score: 0.8611
Model performance on Sad speech (in training): 
	Precision: 0.8652, Recall: 0.9150, F1_score: 0.8894

Eval Phase: 
Validation loss: 226.3727, Validation accuracy: 0.6200
Macro F1-score: 0.6270
Model performance on Angry speech (in validation): 
	Precision: 0.8750, Recall: 0.7000, F1_score: 0.7778
Model performance on Happy speech (in validation): 
	Precision: 0.4902, Recall: 0.5000, F1_score: 0.4950
Model performance on Neutral speech (in validation): 
	Precision: 0.5000, Recall: 0.6400, F1_score: 0.5614
Model performance on Sad speech (in validation): 
	Precision: 0.7111, Recall: 0.6400, F1_score: 0.6737
Epoch 9/100

Training Phase:
 23.09it/s]Training:  29%|â–ˆâ–ˆâ–‰       | 463/1600 [00:20<00:49, 22.81it/s]Training:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 697/1600 [00:30<00:39, 23.05it/s]Training:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 933/1600 [00:40<00:28, 23.24it/s]Training:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1169/1600 [00:50<00:18, 23.09it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1398/1600 [01:00<00:08, 22.88it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–        | 230/1600 [00:10<00:59, 22.99it/s]Training:  29%|â–ˆâ–ˆâ–‰       | 460/1600 [00:20<00:50, 22.78it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 687/1600 [00:32<00:44, 20.66it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 914/1600 [00:42<00:32, 21.39it/s]Training:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1151/1600 [00:52<00:20, 22.16it/s]Training:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1388/1600 [01:02<00:09, 2Training loss: 456.2843, Training accuracy: 0.8975
Macro F1-score: 0.8976
Model performance on Angry speech (in training): 
	Precision: 0.9383, Recall: 0.9125, F1_score: 0.9252
Model performance on Happy speech (in training): 
	Precision: 0.9060, Recall: 0.8675, F1_score: 0.8863
Model performance on Neutral speech (in training): 
	Precision: 0.8655, Recall: 0.8850, F1_score: 0.8752
Model performance on Sad speech (in training): 
	Precision: 0.8831, Recall: 0.9250, F1_score: 0.9035

Eval Phase: 
Validation loss: 244.4535, Validation accuracy: 0.6500
Macro F1-score: 0.6496
Model performance on Angry speech (in validation): 
	Precision: 0.9000, Recall: 0.7200, F1_score: 0.8000
Model performance on Happy speech (in validation): 
	Precision: 0.5750, Recall: 0.4600, F1_score: 0.5111
Model performance on Neutral speech (in validation): 
	Precision: 0.5439, Recall: 0.6200, F1_score: 0.5794
Model performance on Sad speech (in validation): 
	Precision: 0.6349, Recall: 0.8000, F1_score: 0.7080
Epoch 10/100

Training Phase:
Training loss: 376.3313, Training accuracy: 0.9125
Macro F1-score: 0.9123
Model performance on Angry speech (in training): 
	Precision: 0.9367, Recall: 0.9250, F1_score: 0.9308
Model performance on Happy speech (in training): 
	Precision: 0.9060, Recall: 0.8675, F1_score: 0.8863
Model performance on Neutral speech (in training): 
	Precision: 0.8941, Recall: 0.9075, F1_score: 0.9007
Model performance on Sad speech (in training): 
	Precision: 0.9135, Recall: 0.9500, F1_score: 0.9314

Eval Phase: 
Validation loss: 280.4879, Validation accuracy: 0.6400
Macro F1-score: 0.6365
Model performance on Angry speech (in validation): 
	Precision: 0.8636, Recall: 0.7600, F1_score: 0.8085
Model performance on Happy speech (in validation): 
	Precision: 0.6562, Recall: 0.4200, F1_score: 0.5122
Model performance on Neutral speech (in validation): 
	Precision: 0.5179, Recall: 0.5800, F1_score: 0.5472
Model performance on Sad speech (in validation): 
	Precision: 0.5882, Recall: 0.8000, F1_score: 0.6780
Epoch 11/100

Training Phase:
2.45it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–Ž        | 218/1600 [00:10<01:03, 21.74it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 436/1600 [00:20<00:54, 21.40it/s]Training:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 670/1600 [00:30<00:41, 22.29it/s]Training:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 670/1600 [00:40<00:41, 22.29it/s]Training:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 892/1600 [00:40<00:32, 21.86it/s]Training:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1123/1600 [00:50<00:21, 22.30it/s]Training:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1354/1600 [01:01<00:11, 22.15it/s]Training:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 1576/1600 [01:11<00:01, 22.13it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?Training loss: 327.3294, Training accuracy: 0.9244
Macro F1-score: 0.9243
Model performance on Angry speech (in training): 
	Precision: 0.9309, Recall: 0.9425, F1_score: 0.9366
Model performance on Happy speech (in training): 
	Precision: 0.9135, Recall: 0.8975, F1_score: 0.9054
Model performance on Neutral speech (in training): 
	Precision: 0.9080, Recall: 0.9125, F1_score: 0.9102
Model performance on Sad speech (in training): 
	Precision: 0.9450, Recall: 0.9450, F1_score: 0.9450

Eval Phase: 
Validation loss: 281.2970, Validation accuracy: 0.6150
Macro F1-score: 0.6166
Model performance on Angry speech (in validation): 
	Precision: 0.8571, Recall: 0.7200, F1_score: 0.7826
Model performance on Happy speech (in validation): 
	Precision: 0.5833, Recall: 0.4200, F1_score: 0.4884
Model performance on Neutral speech (in validation): 
	Precision: 0.4783, Recall: 0.6600, F1_score: 0.5546
Model performance on Sad speech (in validation): 
	Precision: 0.6226, Recall: 0.6600, F1_score: 0.6408
Epoch 12/100

Training Phase:
, ?it/s]Training:  13%|â–ˆâ–Ž        | 215/1600 [00:10<01:04, 21.41it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 430/1600 [00:20<00:55, 21.20it/s]Training:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 650/1600 [00:30<00:44, 21.54it/s]Training:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 870/1600 [00:44<00:38, 18.95it/s]Training:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1085/1600 [00:54<00:26, 19.78it/s]Training:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1300/1600 [01:04<00:14, 20.32it/s]Training:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1515/1600 [01:14<00:04, 20.61it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–Ž        | 216/1600 [00:10<01:04, 21.56it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 435/1600 [00:20<00:53, 21.73it/s]Training:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 654/1600 [00:30<00:43, 21.68it/s]Training:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 871/1600 [00:40<00:33, 21.50it/s]Training: Training loss: 268.4303, Training accuracy: 0.9469
Macro F1-score: 0.9469
Model performance on Angry speech (in training): 
	Precision: 0.9696, Recall: 0.9575, F1_score: 0.9635
Model performance on Happy speech (in training): 
	Precision: 0.9540, Recall: 0.9325, F1_score: 0.9431
Model performance on Neutral speech (in training): 
	Precision: 0.9287, Recall: 0.9450, F1_score: 0.9368
Model performance on Sad speech (in training): 
	Precision: 0.9361, Recall: 0.9525, F1_score: 0.9442

Eval Phase: 
Validation loss: 298.0463, Validation accuracy: 0.6300
Macro F1-score: 0.6352
Model performance on Angry speech (in validation): 
	Precision: 0.8889, Recall: 0.8000, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 0.5745, Recall: 0.5400, F1_score: 0.5567
Model performance on Neutral speech (in validation): 
	Precision: 0.4576, Recall: 0.5400, F1_score: 0.4954
Model performance on Sad speech (in validation): 
	Precision: 0.6531, Recall: 0.6400, F1_score: 0.6465
Validation loss does not decrease for 10 epochs. End training.
Model best accuracy on validation set: 0.6800

Test Phase: 
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1090/1600 [00:50<00:23, 21.64it/s]Training:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1309/1600 [01:00<00:13, 21.66it/s]Training:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1540/1600 [01:10<00:02, 22.10it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]                                                Some weights of the model checkpoint at /work/tc062/tc062/zhan7721/saved_models/de were not used when initializing Wav2Vec2Model: ['encoder.layers.10.attention.k_proj.bias', 'encoder.layers.10.attention.k_proj.weight', 'encoder.layers.10.attention.out_proj.bias', 'encoder.layers.10.attention.out_proj.weight', 'encoder.layers.10.attention.q_proj.bias', 'encoder.layers.10.attention.q_proj.weight', 'encoder.layers.10.attention.v_proj.bias', 'encoder.layers.10.attention.v_proj.weight', 'encoder.layers.10.feed_forward.intermediate_dense.bias', 'encoder.layers.10.feed_forward.intermediate_dense.weight', 'encoder.layers.10.feed_forward.output_dense.bias', 'encoder.layers.10.feed_forward.output_dense.weight', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.10.layer_norm.bias', 'encoder.layers.10.layer_norm.weight', 'encoder.layers.11.attention.k_proj.bias', 'encoder.layers.11.attention.k_proj.weight', 'encoder.layers.11.attention.out_proj.bias', 'encoder.layers.11.attention.out_proj.weight', 'encoder.layers.11.attention.q_proj.bias', 'encoder.layers.11.attention.q_proj.weight', 'encoder.layers.11.attention.v_proj.bias', 'encoder.layers.11.attention.v_proj.weight', 'encoder.layers.11.feed_forward.intermediate_dense.bias', 'encoder.layers.11.feed_forward.intermediate_dense.weight', 'encoder.layers.11.feed_forward.output_dense.bias', 'encoder.layers.11.feed_forward.output_dense.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.11.layer_norm.bias', 'encoder.layers.11.layer_norm.weight', 'encoder.layers.6.attention.k_proj.bias', 'encoder.layers.6.attention.k_proj.weight', 'encoder.layers.6.attention.out_proj.bias', 'encoder.layers.6.attention.out_proj.weight', 'encoder.layers.6.attention.q_proj.bias', 'encoder.layers.6.attention.q_proj.weight', 'encoder.layers.6.attention.v_proj.bias', 'encoder.layers.6.attention.v_proj.weight', 'encoder.layers.6.feed_forward.intermediate_dense.bias', 'encoder.layers.6.feed_forward.intermediate_dense.weight', 'encoder.layers.6.feed_forward.output_dense.bias', 'encoder.layers.6.feed_forward.output_dense.weight', 'encoder.layers.6.final_layer_norm.bias', 'encoder.layers.6.final_layer_norm.weight', 'encoder.layers.6.layer_norm.bias', 'encoder.layers.6.layer_norm.weight', 'encoder.layers.7.attention.k_proj.bias', 'encoder.layers.7.attention.k_proj.weight', 'encoder.layers.7.attention.out_proj.bias', 'encoder.layers.7.attention.out_proj.weight', 'encoder.layers.7.attention.q_proj.bias', 'encoder.layers.7.attention.q_proj.weight', 'encoder.layers.7.attention.v_proj.bias', 'encoder.layers.7.attention.v_proj.weight', 'encoder.layers.7.feed_forward.intermediate_dense.bias', 'encoder.layers.7.feed_forward.intermediate_dense.weight', 'encoder.layers.7.feed_forward.output_dense.bias', 'encoder.layers.7.feed_forward.output_dense.weight', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.7.layer_norm.bias', 'encoder.layers.7.layer_norm.weight', 'encoder.layers.8.attention.k_proj.bias', 'encoder.layers.8.attention.k_proj.weight', 'encoder.layers.8.attention.out_proj.bias', 'encoder.layers.8.attention.out_proj.weight', 'encoder.layers.8.attention.q_proj.bias', 'encoder.layers.8.attention.q_proj.weight', 'encoder.layers.8.attention.v_proj.bias', 'encoder.layers.8.attention.v_proj.weight', 'encoder.layers.8.feed_forward.intermediate_dense.bias', 'encoder.layers.8.feed_forward.intermediate_dense.weight', 'encoder.layers.8.feed_forward.output_dense.bias', 'encoder.layers.8.feed_forward.output_dense.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.8.layer_norm.bias', 'encoder.layers.8.layer_norm.weight', 'encoder.layers.9.attention.k_proj.bias', 'encoder.layers.9.attention.k_proj.weight', 'encoder.layers.9.attention.out_proj.bias', 'encoder.layers.9.attention.out_proj.weight', 'encoder.layers.9.attention.q_proj.bias', 'encoder.layers.9.attention.q_proj.weight', 'encoder.layers.9.attention.v_proj.bias', 'encoder.layers.9.attention.v_proj.weight', 'encoder.layers.9.feed_forward.intermediate_dense.bias', 'encoder.layers.9.feed_forward.intermediate_dense.weight', 'encoder.layers.9.feed_forward.output_dense.bias', 'encoder.layers.9.feed_forward.output_dense.weight', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.layer_norm.bias', 'encoder.layers.9.layer_norm.weight']
- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Test loss: 177.3508, Test accuracy: 0.6700
Macro F1-score: 0.6625
Model performance on Angry speech (in test): 
	Precision: 0.6081, Recall: 0.9000, F1_score: 0.7258
Model performance on Happy speech (in test): 
	Precision: 0.7429, Recall: 0.5200, F1_score: 0.6118
Model performance on Neutral speech (in test): 
	Precision: 0.6923, Recall: 0.5400, F1_score: 0.6067
Model performance on Sad speech (in test): 
	Precision: 0.6923, Recall: 0.7200, F1_score: 0.7059

======================= This is fold_4 on de =======================

Load dataset: 
Loading en train data: fold_4...
Preprocess en fold_4 data for de model
Loading en eval data: fold_4...
Preprocess en fold_4 data for de model
Loading en test data: fold_4...
Preprocess en fold_4 data for de model
Use de model to add lora
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training loss: 1484.8692, Training accuracy: 0.6175
Macro F1-score: 0.6156
Model performance on Angry speech (in training): 
	Precision: 0.6795, Recall: 0.7050, F1_score: 0.6920
Model performance on Happy speech (in training): 
	Precision: 0.5625, Recall: 0.4950, F1_score: 0.5266
Model performance on Neutral speech (in training): 
	Precision: 0.5278, Recall: 0.5450, F1_score: 0.5363
Model performance on Sad speech (in training): 
	Precision: 0.6905, Recall: 0.7250, F1_score: 0.7073

Eval Phase: 
Validation loss: 170.0007, Validation accuracy: 0.6650
Macro F1-score: 0.6571
Model performance on Angry speech (in validation): 
	Precision: 0.7692, Recall: 0.8000, F1_score: 0.7843
Model performance on Happy speech (in validation): 
	Precision: 0.8000, Recall: 0.4000, F1_score: 0.5333
Model performance on Neutral speech (in validation): 
	Precision: 0.5588, Recall: 0.7600, F1_score: 0.6441
Model performance on Sad speech (in validation): 
	Precision: 0.6364, Recall: 0.7000, F1_score: 0.6667
New best accuracy for layer 5 on epoch 1: 0.6650. Model saved.
Epoch 2/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:   8%|â–Š         | 132/1600 [00:10<01:51, 13.18it/s]Training:  18%|â–ˆâ–Š        | 290/1600 [00:20<01:29, 14.68it/s]Training:  29%|â–ˆâ–ˆâ–‰       | 466/1600 [00:30<01:10, 16.00it/s]Training:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 650/1600 [00:40<00:56, 16.91it/s]Training:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 838/1600 [00:50<00:43, 17.59it/s]Training:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1036/1600 [01:00<00:30, 18.32it/s]Training:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1234/1600 [01:10<00:19, 18.69it/s]Training:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1435/1600 [01:20<00:08, 19.11it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|â–ˆâ–Ž        | 210/1600 [00:10<01:06, 20.97it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 425/1600 [00:20<00:55, 21.28it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 640/1600 [00:30Training loss: 1263.3899, Training accuracy: 0.6694
Macro F1-score: 0.6664
Model performance on Angry speech (in training): 
	Precision: 0.7233, Recall: 0.7450, F1_score: 0.7340
Model performance on Happy speech (in training): 
	Precision: 0.6822, Recall: 0.5475, F1_score: 0.6075
Model performance on Neutral speech (in training): 
	Precision: 0.5802, Recall: 0.5875, F1_score: 0.5839
Model performance on Sad speech (in training): 
	Precision: 0.6905, Recall: 0.7975, F1_score: 0.7401

Eval Phase: 
Validation loss: 211.5131, Validation accuracy: 0.6150
Macro F1-score: 0.5907
Model performance on Angry speech (in validation): 
	Precision: 0.5529, Recall: 0.9400, F1_score: 0.6963
Model performance on Happy speech (in validation): 
	Precision: 0.7419, Recall: 0.4600, F1_score: 0.5679
Model performance on Neutral speech (in validation): 
	Precision: 0.5588, Recall: 0.7600, F1_score: 0.6441
Model performance on Sad speech (in validation): 
	Precision: 0.9375, Recall: 0.3000, F1_score: 0.4545
Epoch 3/100

Training Phase:
<00:45, 21.19it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 853/1600 [00:40<00:35, 21.22it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1066/1600 [00:50<00:25, 21.23it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1287/1600 [01:00<00:14, 21.50it/s]Training:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1508/1600 [01:10<00:04, 21.42it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|â–ˆâ–Ž        | 214/1600 [00:10<01:04, 21.37it/s]Training:  27%|â–ˆâ–ˆâ–‹       | 428/1600 [00:20<00:54, 21.33it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 642/1600 [00:30<00:45, 21.17it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 852/1600 [00:40<00:35, 21.05it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1065/1600 [00:50<00:25, 21.11it/s]Training:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1278/1600 [01:00<00:15, 21.10it/s]Training:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 14Training loss: 1083.7911, Training accuracy: 0.7350
Macro F1-score: 0.7330
Model performance on Angry speech (in training): 
	Precision: 0.7762, Recall: 0.7975, F1_score: 0.7867
Model performance on Happy speech (in training): 
	Precision: 0.7251, Recall: 0.6200, F1_score: 0.6685
Model performance on Neutral speech (in training): 
	Precision: 0.6732, Recall: 0.6850, F1_score: 0.6791
Model performance on Sad speech (in training): 
	Precision: 0.7614, Recall: 0.8375, F1_score: 0.7976

Eval Phase: 
Validation loss: 173.1128, Validation accuracy: 0.6650
Macro F1-score: 0.6614
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 0.6286, Recall: 0.4400, F1_score: 0.5176
Model performance on Neutral speech (in validation): 
	Precision: 0.5366, Recall: 0.8800, F1_score: 0.6667
Model performance on Sad speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Epoch 4/100

Training Phase:
Training loss: 985.7232, Training accuracy: 0.7638
Macro F1-score: 0.7619
Model performance on Angry speech (in training): 
	Precision: 0.8246, Recall: 0.8225, F1_score: 0.8235
Model performance on Happy speech (in training): 
	Precision: 0.7486, Recall: 0.6550, F1_score: 0.6987
Model performance on Neutral speech (in training): 
	Precision: 0.7075, Recall: 0.7075, F1_score: 0.7075
Model performance on Sad speech (in training): 
	Precision: 0.7716, Recall: 0.8700, F1_score: 0.8179

Eval Phase: 
Validation loss: 200.2601, Validation accuracy: 0.6050
Macro F1-score: 0.5756
Model performance on Angry speech (in validation): 
	Precision: 0.6154, Recall: 0.8000, F1_score: 0.6957
Model performance on Happy speech (in validation): 
	Precision: 0.6471, Recall: 0.2200, F1_score: 0.3284
Model performance on Neutral speech (in validation): 
	Precision: 0.5541, Recall: 0.8200, F1_score: 0.6613
Model performance on Sad speech (in validation): 
	Precision: 0.6591, Recall: 0.5800, F1_score: 0.6170
Epoch 5/100

Training Phase:
99/1600 [01:10<00:04, 21.42it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|â–ˆâ–Ž        | 209/1600 [00:10<01:06, 20.86it/s]Training:  26%|â–ˆâ–ˆâ–‹       | 422/1600 [00:20<00:55, 21.08it/s]Training:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 635/1600 [00:30<00:46, 20.88it/s]Training:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 851/1600 [00:40<00:35, 21.15it/s]Training:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1075/1600 [00:50<00:24, 21.59it/s]Training:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 1299/1600 [01:00<00:13, 21.77it/s]Training:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 1531/1600 [01:10<00:03, 22.21it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|â–ˆâ–        | 234/1600 [00Training loss: 856.2550, Training accuracy: 0.7856
Macro F1-score: 0.7839
Model performance on Angry speech (in training): 
	Precision: 0.8338, Recall: 0.8275, F1_score: 0.8306
Model performance on Happy speech (in training): 
	Precision: 0.7778, Recall: 0.6650, F1_score: 0.7170
Model performance on Neutral speech (in training): 
	Precision: 0.7344, Recall: 0.7675, F1_score: 0.7506
Model performance on Sad speech (in training): 
	Precision: 0.7968, Recall: 0.8825, F1_score: 0.8375

Eval Phase: 
Validation loss: 204.3010, Validation accuracy: 0.6000
Macro F1-score: 0.5937
Model performance on Angry speech (in validation): 
	Precision: 0.7021, Recall: 0.6600, F1_score: 0.6804
Model performance on Happy speech (in validation): 
	Precision: 0.6129, Recall: 0.3800, F1_score: 0.4691
Model performance on Neutral speech (in validation): 
	Precision: 0.5246, Recall: 0.6400, F1_score: 0.5766
Model performance on Sad speech (in validation): 
	Precision: 0.5902, Recall: 0.7200, F1_score: 0.6486
Epoch 6/100

Training Phase:
:10<00:58, 23.39it/s]Training:  29%|â–ˆâ–ˆâ–‰       | 468/1600 [00:20<00:49, 22.94it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 695/1600 [00:30<00:40, 22.54it/s]Training:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 927/1600 [00:40<00:29, 22.79it/s]Training:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 927/1600 [00:50<00:29, 22.79it/s]Training:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1157/1600 [00:50<00:19, 22.68it/s]Training:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1383/1600 [01:00<00:09, 22.63it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–        | 228/1600 [00:10<01:00, 22.75it/s]Training:  29%|â–ˆâ–ˆâ–Š       | 457/1600 [00:20<00:50, 22.84it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 689/1600 [00:30<00:39, 22.99it/s]Training:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 921/1600 [00:40<00:29, 22.95it/s]Training:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1150/1600 [00:50<00:19Training loss: 767.1200, Training accuracy: 0.8169
Macro F1-score: 0.8162
Model performance on Angry speech (in training): 
	Precision: 0.8579, Recall: 0.8600, F1_score: 0.8589
Model performance on Happy speech (in training): 
	Precision: 0.8065, Recall: 0.7400, F1_score: 0.7718
Model performance on Neutral speech (in training): 
	Precision: 0.7734, Recall: 0.7850, F1_score: 0.7792
Model performance on Sad speech (in training): 
	Precision: 0.8286, Recall: 0.8825, F1_score: 0.8547

Eval Phase: 
Validation loss: 188.6010, Validation accuracy: 0.6550
Macro F1-score: 0.6331
Model performance on Angry speech (in validation): 
	Precision: 0.7321, Recall: 0.8200, F1_score: 0.7736
Model performance on Happy speech (in validation): 
	Precision: 0.6364, Recall: 0.2800, F1_score: 0.3889
Model performance on Neutral speech (in validation): 
	Precision: 0.5753, Recall: 0.8400, F1_score: 0.6829
Model performance on Sad speech (in validation): 
	Precision: 0.6939, Recall: 0.6800, F1_score: 0.6869
Epoch 7/100

Training Phase:
Training loss: 616.7387, Training accuracy: 0.8650
Macro F1-score: 0.8644
Model performance on Angry speech (in training): 
	Precision: 0.8897, Recall: 0.9075, F1_score: 0.8985
Model performance on Happy speech (in training): 
	Precision: 0.8753, Recall: 0.7900, F1_score: 0.8305
Model performance on Neutral speech (in training): 
	Precision: 0.8313, Recall: 0.8500, F1_score: 0.8405
Model performance on Sad speech (in training): 
	Precision: 0.8649, Recall: 0.9125, F1_score: 0.8881

Eval Phase: 
Validation loss: 221.6912, Validation accuracy: 0.6200
Macro F1-score: 0.6170
Model performance on Angry speech (in validation): 
	Precision: 0.8333, Recall: 0.6000, F1_score: 0.6977
Model performance on Happy speech (in validation): 
	Precision: 0.5250, Recall: 0.4200, F1_score: 0.4667
Model performance on Neutral speech (in validation): 
	Precision: 0.5902, Recall: 0.7200, F1_score: 0.6486
Model performance on Sad speech (in validation): 
	Precision: 0.5873, Recall: 0.7400, F1_score: 0.6549
Epoch 8/100

Training Phase:
, 22.88it/s]Training:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1378/1600 [01:00<00:09, 22.57it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1598/1600 [01:10<00:00, 22.35it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–        | 231/1600 [00:10<00:59, 23.01it/s]Training:  29%|â–ˆâ–ˆâ–‰       | 462/1600 [00:20<00:49, 22.92it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 692/1600 [00:30<00:39, 22.92it/s]Training:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 922/1600 [00:40<00:30, 22.56it/s]Training:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1149/1600 [00:50<00:19, 22.58it/s]Training:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1376/1600 [01:00<00:09, 22.44it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0Training loss: 539.1530, Training accuracy: 0.8688
Macro F1-score: 0.8685
Model performance on Angry speech (in training): 
	Precision: 0.9082, Recall: 0.8900, F1_score: 0.8990
Model performance on Happy speech (in training): 
	Precision: 0.8695, Recall: 0.8325, F1_score: 0.8506
Model performance on Neutral speech (in training): 
	Precision: 0.8317, Recall: 0.8275, F1_score: 0.8296
Model performance on Sad speech (in training): 
	Precision: 0.8665, Recall: 0.9250, F1_score: 0.8948

Eval Phase: 
Validation loss: 221.2486, Validation accuracy: 0.6650
Macro F1-score: 0.6564
Model performance on Angry speech (in validation): 
	Precision: 0.7193, Recall: 0.8200, F1_score: 0.7664
Model performance on Happy speech (in validation): 
	Precision: 0.5833, Recall: 0.4200, F1_score: 0.4884
Model performance on Neutral speech (in validation): 
	Precision: 0.6441, Recall: 0.7600, F1_score: 0.6972
Model performance on Sad speech (in validation): 
	Precision: 0.6875, Recall: 0.6600, F1_score: 0.6735
Epoch 9/100

Training Phase:
/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–        | 224/1600 [00:10<01:01, 22.37it/s]Training:  28%|â–ˆâ–ˆâ–Š       | 448/1600 [00:20<00:51, 22.30it/s]Training:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 675/1600 [00:30<00:41, 22.44it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 905/1600 [00:40<00:30, 22.66it/s]Training:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1140/1600 [00:50<00:20, 22.93it/s]Training:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1375/1600 [01:00<00:09, 22.89it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–        | 222/1600 [00:10<01:02, 22.19it/s]Training:  28%|â–ˆâ–ˆâ–Š       | 451/1600 [00:20<00:50, 22.60it/s]Training:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 680/1600 [00:30<00:40, 22.57it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 906/1600 [00:40<00:30, 22.55it/s]Training:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1132/1600 [00:50<00:20, 22.52itTraining loss: 427.9011, Training accuracy: 0.9000
Macro F1-score: 0.8999
Model performance on Angry speech (in training): 
	Precision: 0.9288, Recall: 0.9125, F1_score: 0.9206
Model performance on Happy speech (in training): 
	Precision: 0.9036, Recall: 0.8675, F1_score: 0.8852
Model performance on Neutral speech (in training): 
	Precision: 0.8741, Recall: 0.8850, F1_score: 0.8795
Model performance on Sad speech (in training): 
	Precision: 0.8947, Recall: 0.9350, F1_score: 0.9144

Eval Phase: 
Validation loss: 243.5632, Validation accuracy: 0.6350
Macro F1-score: 0.6234
Model performance on Angry speech (in validation): 
	Precision: 0.6667, Recall: 0.8400, F1_score: 0.7434
Model performance on Happy speech (in validation): 
	Precision: 0.5758, Recall: 0.3800, F1_score: 0.4578
Model performance on Neutral speech (in validation): 
	Precision: 0.5873, Recall: 0.7400, F1_score: 0.6549
Model performance on Sad speech (in validation): 
	Precision: 0.7073, Recall: 0.5800, F1_score: 0.6374
Epoch 10/100

Training Phase:
Training loss: 393.0989, Training accuracy: 0.9119
Macro F1-score: 0.9118
Model performance on Angry speech (in training): 
	Precision: 0.9422, Recall: 0.9375, F1_score: 0.9398
Model performance on Happy speech (in training): 
	Precision: 0.9056, Recall: 0.8875, F1_score: 0.8965
Model performance on Neutral speech (in training): 
	Precision: 0.8914, Recall: 0.8825, F1_score: 0.8869
Model performance on Sad speech (in training): 
	Precision: 0.9082, Recall: 0.9400, F1_score: 0.9238

Eval Phase: 
/s]Training:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1369/1600 [01:00<00:10, 22.90it/s]Training:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1369/1600 [01:10<00:10, 22.90it/s]Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1598/1600 [01:10<00:00, 22.74it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–        | 230/1600 [00:10<00:59, 22.98it/s]Training:  29%|â–ˆâ–ˆâ–‰       | 462/1600 [00:20<00:49, 23.09it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 694/1600 [00:30<00:39, 22.92it/s]Training:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 922/1600 [00:40<00:29, 22.84it/s]Training:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1150/1600 [00:50<00:20, 22.37it/s]Training:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 1384/1600 [01:00<00:09, 22.71it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]          Validation loss: 271.5869, Validation accuracy: 0.6000
Macro F1-score: 0.5776
Model performance on Angry speech (in validation): 
	Precision: 0.6143, Recall: 0.8600, F1_score: 0.7167
Model performance on Happy speech (in validation): 
	Precision: 0.5556, Recall: 0.3000, F1_score: 0.3896
Model performance on Neutral speech (in validation): 
	Precision: 0.5333, Recall: 0.8000, F1_score: 0.6400
Model performance on Sad speech (in validation): 
	Precision: 0.7857, Recall: 0.4400, F1_score: 0.5641
Epoch 11/100

Training Phase:
Training loss: 314.3426, Training accuracy: 0.9306
Macro F1-score: 0.9305
Model performance on Angry speech (in training): 
	Precision: 0.9454, Recall: 0.9525, F1_score: 0.9489
Model performance on Happy speech (in training): 
	Precision: 0.9280, Recall: 0.9025, F1_score: 0.9151
Model performance on Neutral speech (in training): 
	Precision: 0.9100, Recall: 0.9100, F1_score: 0.9100
Model performance on Sad speech (in training): 
	Precision: 0.9387, Recall: 0.9575, F1_score: 0.9480

Eval Phase: 
Validation loss: 232.2715, Validation accuracy: 0.6500
Macro F1-score: 0.6477
Model performance on Angry speech (in validation): 
	Precision: 0.8085, Recall: 0.7600, F1_score: 0.7835
Model performance on Happy speech (in validation): 
	Precision: 0.5192, Recall: 0.5400, F1_score: 0.5294
Model performance on Neutral speech (in validation): 
	Precision: 0.6061, Recall: 0.8000, F1_score: 0.6897
Model performance on Sad speech (in validation): 
	Precision: 0.7143, Recall: 0.5000, F1_score: 0.5882
Validation loss does not decrease for 10 epochs. End training.
Model best accuracy on validation set: 0.6650

Test Phase: 
Test loss: 149.0402, Test accuracy: 0.7100
Macro F1-score: 0.7007
Model performance on Angry speech (in test): 
	Precision: 0.7222, Recall: 0.7800, F1_score: 0.7500
Model performance on Happy speech (in test): 
	Precision: 0.8148, Recall: 0.4400, F1_score: 0.5714
Model performance on Neutral speech (in test): 
	Precision: 0.6406, Recall: 0.8200, F1_score: 0.7193
Model performance on Sad speech (in test): 
	Precision: 0.7273, Recall: 0.8000, F1_score: 0.7619

de, all folds accuracy: ['0.6150', '0.5850', '0.6700', '0.6700', '0.7100']
de, all folds emo precision: {'Angry': ['0.8000', '0.5541', '0.7561', '0.6081', '0.7222'], 'Happy': ['0.5429', '0.5714', '0.8214', '0.7429', '0.8148'], 'Neutral': ['0.5814', '0.4833', '0.5658', '0.6923', '0.6406'], 'Sad': ['0.5584', '0.7500', '0.6727', '0.6923', '0.7273']}
de, all folds emo recall: {'Angry': ['0.7200', '0.8200', '0.6200', '0.9000', '0.7800'], 'Happy': ['0.3800', '0.1600', '0.4600', '0.5200', '0.4400'], 'Neutral': ['0.5000', '0.5800', '0.8600', '0.5400', '0.8200'], 'Sad': ['0.8600', '0.7800', '0.7400', '0.7200', '0.8000']}
de, all folds emo f1score: {'Angry': ['0.7579', '0.6613', '0.6813', '0.7258', '0.7500'], 'Happy': ['0.4471', '0.2500', '0.5897', '0.6118', '0.5714'], 'Neutral': ['0.5376', '0.5273', '0.6825', '0.6067', '0.7193'], 'Sad': ['0.6772', '0.7647', '0.7048', '0.7059', '0.7619']}
                                         Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|â–ˆâ–        | 230/1600 [00:10<00:59, 23.00it/s]Training:  29%|â–ˆâ–ˆâ–‰       | 460/1600 [00:20<00:50, 22.63it/s]Training:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 689/1600 [00:30<00:40, 22.72it/s]Training:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 918/1600 [00:40<00:30, 22.67it/s]Training:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1145/1600 [00:50<00:20, 22.65it/s]Training:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 1372/1600 [01:00<00:10, 22.53it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]                                                