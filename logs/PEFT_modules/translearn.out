Loading python/3.10.8-gpu
  Loading requirement: nvidia/nvhpc-nompi/22.2 gcc/10.2.0
    openmpi/4.1.6-cuda-11.6
Loading pytorch/1.13.1-gpu
  Loading requirement: nvidia/cudnn/8.6.0-cuda-11.6 nvidia/tensorrt/8.4.3.1-u2
    libsndfile/1.0.28
------------------NEXT SCRIPT: RUNNER_DE, current setting----------------------
/work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Matplotlib created a temporary cache directory at /dev/shm/zhan7721_5912053/matplotlib-3d1ugwi4 because the default path (/home/tc062/tc062/zhan7721/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Some weights of the model checkpoint at /work/tc062/tc062/zhan7721/saved_models/de were not used when initializing Wav2Vec2Model: ['encoder.layers.10.attention.k_proj.bias', 'encoder.layers.10.attention.k_proj.weight', 'encoder.layers.10.attention.out_proj.bias', 'encoder.layers.10.attention.out_proj.weight', 'encoder.layers.10.attention.q_proj.bias', 'encoder.layers.10.attention.q_proj.weight', 'encoder.layers.10.attention.v_proj.bias', 'encoder.layers.10.attention.v_proj.weight', 'encoder.layers.10.feed_forward.intermediate_dense.bias', 'encoder.layers.10.feed_forward.intermediate_dense.weight', 'encoder.layers.10.feed_forward.output_dense.bias', 'encoder.layers.10.feed_forward.output_dense.weight', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.10.layer_norm.bias', 'encoder.layers.10.layer_norm.weight', 'encoder.layers.11.attention.k_proj.bias', 'encoder.layers.11.attention.k_proj.weight', 'encoder.layers.11.attention.out_proj.bias', 'encoder.layers.11.attention.out_proj.weight', 'encoder.layers.11.attention.q_proj.bias', 'encoder.layers.11.attention.q_proj.weight', 'encoder.layers.11.attention.v_proj.bias', 'encoder.layers.11.attention.v_proj.weight', 'encoder.layers.11.feed_forward.intermediate_dense.bias', 'encoder.layers.11.feed_forward.intermediate_dense.weight', 'encoder.layers.11.feed_forward.output_dense.bias', 'encoder.layers.11.feed_forward.output_dense.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.11.layer_norm.bias', 'encoder.layers.11.layer_norm.weight', 'encoder.layers.5.attention.k_proj.bias', 'encoder.layers.5.attention.k_proj.weight', 'encoder.layers.5.attention.out_proj.bias', 'encoder.layers.5.attention.out_proj.weight', 'encoder.layers.5.attention.q_proj.bias', 'encoder.layers.5.attention.q_proj.weight', 'encoder.layers.5.attention.v_proj.bias', 'encoder.layers.5.attention.v_proj.weight', 'encoder.layers.5.feed_forward.intermediate_dense.bias', 'encoder.layers.5.feed_forward.intermediate_dense.weight', 'encoder.layers.5.feed_forward.output_dense.bias', 'encoder.layers.5.feed_forward.output_dense.weight', 'encoder.layers.5.final_layer_norm.bias', 'encoder.layers.5.final_layer_norm.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.6.attention.k_proj.bias', 'encoder.layers.6.attention.k_proj.weight', 'encoder.layers.6.attention.out_proj.bias', 'encoder.layers.6.attention.out_proj.weight', 'encoder.layers.6.attention.q_proj.bias', 'encoder.layers.6.attention.q_proj.weight', 'encoder.layers.6.attention.v_proj.bias', 'encoder.layers.6.attention.v_proj.weight', 'encoder.layers.6.feed_forward.intermediate_dense.bias', 'encoder.layers.6.feed_forward.intermediate_dense.weight', 'encoder.layers.6.feed_forward.output_dense.bias', 'encoder.layers.6.feed_forward.output_dense.weight', 'encoder.layers.6.final_layer_norm.bias', 'encoder.layers.6.final_layer_norm.weight', 'encoder.layers.6.layer_norm.bias', 'encoder.layers.6.layer_norm.weight', 'encoder.layers.7.attention.k_proj.bias', 'encoder.layers.7.attention.k_proj.weight', 'encoder.layers.7.attention.out_proj.bias', 'encoder.layers.7.attention.out_proj.weight', 'encoder.layers.7.attention.q_proj.bias', 'encoder.layers.7.attention.q_proj.weight', 'encoder.layers.7.attention.v_proj.bias', 'encoder.layers.7.attention.v_proj.weight', 'encoder.layers.7.feed_forward.intermediate_dense.bias', 'encoder.layers.7.feed_forward.intermediate_dense.weight', 'encoder.layers.7.feed_forward.output_dense.bias', 'encoder.layers.7.feed_forward.output_dense.weight', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.7.layer_norm.bias', 'encoder.layers.7.layer_norm.weight', 'encoder.layers.8.attention.k_proj.bias', 'encoder.layers.8.attention.k_proj.weight', 'encoder.layers.8.attention.out_proj.bias', 'encoder.layers.8.attention.out_proj.weight', 'encoder.layers.8.attention.q_proj.bias', 'encoder.layers.8.attention.q_proj.weight', 'encoder.layers.8.attention.v_proj.bias', 'encoder.layers.8.attention.v_proj.weight', 'encoder.layers.8.feed_forward.intermediate_dense.bias', 'encoder.layers.8.feed_forward.intermediate_dense.weight', 'encoder.layers.8.feed_forward.output_dense.bias', 'encoder.layers.8.feed_forward.output_dense.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.8.layer_norm.bias', 'encoder.layers.8.layer_norm.weight', 'encoder.layers.9.attention.k_proj.bias', 'encoder.layers.9.attention.k_proj.weight', 'encoder.layers.9.attention.out_proj.bias', 'encoder.layers.9.attention.out_proj.weight', 'encoder.layers.9.attention.q_proj.bias', 'encoder.layers.9.attention.q_proj.weight', 'encoder.layers.9.attention.v_proj.bias', 'encoder.layers.9.attention.v_proj.weight', 'encoder.layers.9.feed_forward.intermediate_dense.bias', 'encoder.layers.9.feed_forward.intermediate_dense.weight', 'encoder.layers.9.feed_forward.output_dense.bias', 'encoder.layers.9.feed_forward.output_dense.weight', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.layer_norm.bias', 'encoder.layers.9.layer_norm.weight']
- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).

======================= This is fold_0 on de =======================

Load dataset: 
Loading cn train data: fold_0...
Preprocess cn fold_0 data for de model
Loading cn eval data: fold_0...
Preprocess cn fold_0 data for de model
Loading cn test data: fold_0...
Preprocess cn fold_0 data for de model
Use de model to add lora
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:   0%|          | 1/1600 [00:13<5:46:58, 13.02s/it]Training:  11%|█         | 176/1600 [00:23<02:34,  9.19it/s]Training:  25%|██▍       | 399/1600 [00:33<01:21, 14.79it/s]Training:  40%|███▉      | 635/1600 [00:43<00:53, 18.13it/s]Training:  56%|█████▌    | 888/1600 [00:53<00:34, 20.62it/s]Training:  71%|███████▏  | 1141/1600 [01:03<00:20, 22.08it/s]Training:  88%|████████▊ | 1401/1600 [01:13<00:08, 23.31it/s]                                                             /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Training loss: 1724.6418, Training accuracy: 0.4763
Macro F1-score: 0.3946
Model performance on Angry speech (in training): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Happy speech (in training): 
	Precision: 0.3822, Recall: 0.9125, F1_score: 0.5387
Model performance on Neutral speech (in training): 
	Precision: 0.6316, Recall: 0.2700, F1_score: 0.3783
Model performance on Sad speech (in training): 
	Precision: 0.6097, Recall: 0.7225, F1_score: 0.6613

Eval Phase: 
Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 242.3737, Validation accuracy: 0.4500
Macro F1-score: 0.3456
Model performance on Angry speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Happy speech (in validation): 
	Precision: 0.3521, Recall: 1.0000, F1_score: 0.5208
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.1000, F1_score: 0.1818
Model performance on Sad speech (in validation): 
	Precision: 0.6604, Recall: 0.7000, F1_score: 0.6796
New best accuracy for layer 4 on epoch 1: 0.4500. Model saved.
Epoch 2/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 272/1600 [00:10<00:48, 27.13it/s]Training:  34%|███▍      | 549/1600 [00:20<00:38, 27.45it/s]Training:  52%|█████▏    | 829/1600 [00:30<00:27, 27.70it/s]Training:  69%|██████▉   | 1109/1600 [00:40<00:17, 27.73it/s]Training:  87%|████████▋ | 1390/1600 [00:50<00:07, 27.85it/s]                                                             /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Training loss: 1039.4482, Training accuracy: 0.6887
Macro F1-score: 0.6107
Model performance on Angry speech (in training): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Happy speech (in training): 
	Precision: 0.4702, Recall: 0.9475, F1_score: 0.6285
Model performance on Neutral speech (in training): 
	Precision: 0.8911, Recall: 0.8800, F1_score: 0.8855
Model performance on Sad speech (in training): 
	Precision: 0.9298, Recall: 0.9275, F1_score: 0.9287

Eval Phase: 
Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 195.6396, Validation accuracy: 0.5500
Macro F1-score: 0.4784
Model performance on Angry speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Happy speech (in validation): 
	Precision: 0.3817, Recall: 1.0000, F1_score: 0.5525
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.3600, F1_score: 0.5294
Model performance on Sad speech (in validation): 
	Precision: 0.8235, Recall: 0.8400, F1_score: 0.8317
New best accuracy for layer 4 on epoch 2: 0.5500. Model saved.
Epoch 3/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 279/1600 [00:10<00:47, 27.87it/s]Training:  35%|███▍      | 558/1600 [00:20<00:37, 27.72it/s]Training:  52%|█████▏    | 836/1600 [00:30<00:27, 27.72it/s]Training:  70%|██████▉   | 1114/1600 [00:40<00:17, 27.55it/s]Training:  87%|████████▋ | 1387/1600 [00:50<00:07, 27.45it/s]                                                             /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Training loss: 774.5018, Training accuracy: 0.7200
Macro F1-score: 0.6397
Model performance on Angry speech (in training): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Happy speech (in training): 
	Precision: 0.4812, Recall: 0.9600, F1_score: 0.6411
Model performance on Neutral speech (in training): 
	Precision: 0.9406, Recall: 0.9500, F1_score: 0.9453
Model performance on Sad speech (in training): 
	Precision: 0.9749, Recall: 0.9700, F1_score: 0.9724

Eval Phase: 
Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 125.7953, Validation accuracy: 0.6800
Macro F1-score: 0.6103
Model performance on Angry speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Happy speech (in validation): 
	Precision: 0.4505, Recall: 1.0000, F1_score: 0.6211
Model performance on Neutral speech (in validation): 
	Precision: 0.9767, Recall: 0.8400, F1_score: 0.9032
Model performance on Sad speech (in validation): 
	Precision: 0.9565, Recall: 0.8800, F1_score: 0.9167
New best accuracy for layer 4 on epoch 3: 0.6800. Model saved.
Epoch 4/100

Training Phase:
Training loss: 554.2614, Training accuracy: 0.8237
Macro F1-score: 0.8203
Model performance on Angry speech (in training): 
	Precision: 0.7799, Recall: 0.5225, F1_score: 0.6257
Model performance on Happy speech (in training): 
	Precision: 0.6229, Recall: 0.8300, F1_score: 0.7117
Model performance on Neutral speech (in training): 
	Precision: 0.9600, Recall: 0.9600, F1_score: 0.9600
Model performance on Sad speech (in training): 
	Precision: 0.9850, Recall: 0.9825, F1_score: 0.9837

Eval Phase: 
Validation loss: 200.5657, Validation accuracy: 0.6000
Macro F1-score: 0.6269
Model performance on Angry speech (in validation): 
	Precision: 0.5385, Recall: 0.5600, F1_score: 0.5490
Model performance on Happy speech (in validation): 
	Precision: 0.3375, Recall: 0.5400, F1_score: 0.4154
Model performance on Neutral speech (in validation): 
	Precision: 0.9667, Recall: 0.5800, F1_score: 0.7250
Model performance on Sad speech (in validation): 
	Precision: 0.9474, Recall: 0.7200, F1_score: 0.8182
Epoch 5/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 270/1600 [00:10<00:49, 26.91it/s]Training:  34%|███▍      | 543/1600 [00:20<00:39, 27.10it/s]Training:  51%|█████     | 816/1600 [00:30<00:28, 27.04it/s]Training:  68%|██████▊   | 1086/1600 [00:40<00:19, 26.94it/s]Training:  85%|████████▍ | 1359/1600 [00:50<00:08, 27.04it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 278/1600 [00:10<00:47, 27.80it/s]Training:  35%|███▌      | 567/1600 [00:20<00:36, 28.43it/s]Training:  54%|█████▎    | 856/1600 [00:30<00:26, 28.61it/s]Training:  72%|███████▏  | 1145/1600 [00:40<00:15, 28.65it/s]Training:  90%|████████▉ | 1433/1600 [00:50<00:05, 28.60it/s]                           Training loss: 373.4069, Training accuracy: 0.9087
Macro F1-score: 0.9083
Model performance on Angry speech (in training): 
	Precision: 0.8080, Recall: 0.9050, F1_score: 0.8538
Model performance on Happy speech (in training): 
	Precision: 0.8778, Recall: 0.7725, F1_score: 0.8218
Model performance on Neutral speech (in training): 
	Precision: 0.9677, Recall: 0.9750, F1_score: 0.9714
Model performance on Sad speech (in training): 
	Precision: 0.9899, Recall: 0.9825, F1_score: 0.9862

Eval Phase: 
Validation loss: 312.6535, Validation accuracy: 0.6050
Macro F1-score: 0.5952
Model performance on Angry speech (in validation): 
	Precision: 0.5625, Recall: 0.3600, F1_score: 0.4390
Model performance on Happy speech (in validation): 
	Precision: 0.4304, Recall: 0.6800, F1_score: 0.5271
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.4400, F1_score: 0.6111
Model performance on Sad speech (in validation): 
	Precision: 0.7015, Recall: 0.9400, F1_score: 0.8034
Epoch 6/100

Training Phase:
Training loss: 283.3180, Training accuracy: 0.9275
Macro F1-score: 0.9270
Model performance on Angry speech (in training): 
	Precision: 0.8277, Recall: 0.9250, F1_score: 0.8737
Model performance on Happy speech (in training): 
	Precision: 0.9114, Recall: 0.7975, F1_score: 0.8507
Model performance on Neutral speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913
Model performance on Sad speech (in training): 
	Precision: 0.9900, Recall: 0.9950, F1_score: 0.9925

Eval Phase: 
Validation loss: 457.6552, Validation accuracy: 0.4800
Macro F1-score: 0.5101
Model performance on Angry speech (in validation): 
	Precision: 0.5385, Recall: 0.5600, F1_score: 0.5490
Model performance on Happy speech (in validation): 
	Precision: 0.2476, Recall: 0.5200, F1_score: 0.3355
Model performance on Neutral speech (in validation): 
	Precision: 0.9375, Recall: 0.3000, F1_score: 0.4545
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5400, F1_score: 0.7013
Epoch 7/100

Training Phase:
                                  Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  18%|█▊        | 290/1600 [00:10<00:45, 28.98it/s]Training:  36%|███▋      | 580/1600 [00:20<00:36, 27.90it/s]Training:  53%|█████▎    | 852/1600 [00:30<00:27, 27.45it/s]Training:  70%|███████   | 1123/1600 [00:40<00:17, 27.29it/s]Training:  87%|████████▋ | 1394/1600 [00:50<00:07, 27.18it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 269/1600 [00:10<00:49, 26.87it/s]Training:  34%|███▎      | 538/1600 [00:20<00:39, 26.84it/s]Training:  51%|█████     | 810/1600 [00:30<00:29, 26.97it/s]Training:  68%|██████▊   | 1089Training loss: 238.8171, Training accuracy: 0.9419
Macro F1-score: 0.9418
Model performance on Angry speech (in training): 
	Precision: 0.8923, Recall: 0.9325, F1_score: 0.9120
Model performance on Happy speech (in training): 
	Precision: 0.9167, Recall: 0.8800, F1_score: 0.8980
Model performance on Neutral speech (in training): 
	Precision: 0.9724, Recall: 0.9675, F1_score: 0.9699
Model performance on Sad speech (in training): 
	Precision: 0.9875, Recall: 0.9875, F1_score: 0.9875

Eval Phase: 
Validation loss: 171.0736, Validation accuracy: 0.6950
Macro F1-score: 0.6960
Model performance on Angry speech (in validation): 
	Precision: 0.5686, Recall: 0.5800, F1_score: 0.5743
Model performance on Happy speech (in validation): 
	Precision: 0.5094, Recall: 0.5400, F1_score: 0.5243
Model performance on Neutral speech (in validation): 
	Precision: 0.9459, Recall: 0.7000, F1_score: 0.8046
Model performance on Sad speech (in validation): 
	Precision: 0.8136, Recall: 0.9600, F1_score: 0.8807
New best accuracy for layer 4 on epoch 7: 0.6950. Model saved.
Epoch 8/100

Training Phase:
Training loss: 157.9117, Training accuracy: 0.9644
Macro F1-score: 0.9643
Model performance on Angry speech (in training): 
	Precision: 0.9207, Recall: 0.9575, F1_score: 0.9387
Model performance on Happy speech (in training): 
	Precision: 0.9528, Recall: 0.9075, F1_score: 0.9296
Model performance on Neutral speech (in training): 
	Precision: 0.9900, Recall: 0.9950, F1_score: 0.9925
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963

Eval Phase: 
Validation loss: 278.8733, Validation accuracy: 0.6650
Macro F1-score: 0.6729
Model performance on Angry speech (in validation): 
	Precision: 0.6744, Recall: 0.5800, F1_score: 0.6237
Model performance on Happy speech (in validation): 
	Precision: 0.4286, Recall: 0.7200, F1_score: 0.5373
Model performance on Neutral speech (in validation): 
	Precision: 0.9583, Recall: 0.4600, F1_score: 0.6216
Model performance on Sad speech (in validation): 
	Precision: 0.9184, Recall: 0.9000, F1_score: 0.9091
Epoch 9/100

Training Phase:
/1600 [00:40<00:18, 27.31it/s]Training:  86%|████████▌ | 1368/1600 [00:50<00:08, 27.48it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  18%|█▊        | 280/1600 [00:10<00:47, 27.92it/s]Training:  35%|███▌      | 560/1600 [00:20<00:37, 27.83it/s]Training:  52%|█████▏    | 838/1600 [00:30<00:27, 27.65it/s]Training:  70%|██████▉   | 1113/1600 [00:40<00:17, 27.52it/s]Training:  87%|████████▋ | 1387/1600 [00:50<00:07, 27.39it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 271/1600 [00:10<00:49, 27.05it/s]Training:  34%|███▍      | 550/1600 [00Training loss: 171.9834, Training accuracy: 0.9575
Macro F1-score: 0.9574
Model performance on Angry speech (in training): 
	Precision: 0.9220, Recall: 0.9450, F1_score: 0.9333
Model performance on Happy speech (in training): 
	Precision: 0.9282, Recall: 0.9050, F1_score: 0.9165
Model performance on Neutral speech (in training): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 219.5223, Validation accuracy: 0.7000
Macro F1-score: 0.6892
Model performance on Angry speech (in validation): 
	Precision: 0.5783, Recall: 0.9600, F1_score: 0.7218
Model performance on Happy speech (in validation): 
	Precision: 0.4474, Recall: 0.3400, F1_score: 0.3864
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.5600, F1_score: 0.7179
Model performance on Sad speech (in validation): 
	Precision: 0.9216, Recall: 0.9400, F1_score: 0.9307
New best accuracy for layer 4 on epoch 9: 0.7000. Model saved.
Epoch 10/100

Training Phase:
Training loss: 133.1259, Training accuracy: 0.9725
Macro F1-score: 0.9725
Model performance on Angry speech (in training): 
	Precision: 0.9457, Recall: 0.9575, F1_score: 0.9516
Model performance on Happy speech (in training): 
	Precision: 0.9596, Recall: 0.9500, F1_score: 0.9548
Model performance on Neutral speech (in training): 
	Precision: 0.9875, Recall: 0.9875, F1_score: 0.9875
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962

Eval Phase: 
Validation loss: 233.5556, Validation accuracy: 0.6400
Macro F1-score: 0.6619
Model performance on Angry speech (in validation): 
	Precision: 0.6667, Recall: 0.6800, F1_score: 0.6733
Model performance on Happy speech (in validation): 
	Precision: 0.3882, Recall: 0.6600, F1_score: 0.4889
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.5600, F1_score: 0.7179
Model performance on Sad speech (in validation): 
	Precision: 0.9167, Recall: 0.6600, F1_score: 0.7674
Epoch 11/100

Training Phase:
:20<00:38, 27.50it/s]Training:  52%|█████▏    | 829/1600 [00:30<00:27, 27.64it/s]Training:  69%|██████▉   | 1108/1600 [00:40<00:17, 27.60it/s]Training:  87%|████████▋ | 1387/1600 [00:50<00:07, 27.69it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 277/1600 [00:10<00:47, 27.68it/s]Training:  35%|███▍      | 556/1600 [00:20<00:37, 27.76it/s]Training:  52%|█████▏    | 835/1600 [00:30<00:27, 27.73it/s]Training:  70%|██████▉   | 1112/1600 [00:40<00:17, 27.61it/s]Training:  87%|████████▋ | 1387/1600 [00:50<00:07, 27.38it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|        Training loss: 69.6794, Training accuracy: 0.9831
Macro F1-score: 0.9831
Model performance on Angry speech (in training): 
	Precision: 0.9698, Recall: 0.9650, F1_score: 0.9674
Model performance on Happy speech (in training): 
	Precision: 0.9653, Recall: 0.9725, F1_score: 0.9689
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 243.8206, Validation accuracy: 0.7700
Macro F1-score: 0.7636
Model performance on Angry speech (in validation): 
	Precision: 0.7258, Recall: 0.9000, F1_score: 0.8036
Model performance on Happy speech (in validation): 
	Precision: 0.6275, Recall: 0.6400, F1_score: 0.6337
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.5600, F1_score: 0.7179
Model performance on Sad speech (in validation): 
	Precision: 0.8305, Recall: 0.9800, F1_score: 0.8991
New best accuracy for layer 4 on epoch 11: 0.7700. Model saved.
Epoch 12/100

Training Phase:
  | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 275/1600 [00:10<00:48, 27.41it/s]Training:  34%|███▍      | 552/1600 [00:20<00:38, 27.58it/s]Training:  52%|█████▏    | 829/1600 [00:30<00:27, 27.61it/s]Training:  69%|██████▉   | 1106/1600 [00:40<00:17, 27.60it/s]Training:  86%|████████▋ | 1384/1600 [00:50<00:07, 27.66it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 276/1600 [00:10<00:48, 27.54it/s]Training:  34%|███▍      | 552/1600 [00:20<00:38, 27.37it/s]Training:  52%|█████▏    | 835/1600 [00:30<00:27, 27.76it/s]Training:  70%|██████▉   | 1118/1600 [00:40<00:17, 27.78it/s]Training:  87%|████████▋ | 1396/1600 [00:50<00:07, 27.78it/s]                                                   Training loss: 115.7107, Training accuracy: 0.9762
Macro F1-score: 0.9763
Model performance on Angry speech (in training): 
	Precision: 0.9604, Recall: 0.9700, F1_score: 0.9652
Model performance on Happy speech (in training): 
	Precision: 0.9673, Recall: 0.9600, F1_score: 0.9636
Model performance on Neutral speech (in training): 
	Precision: 0.9900, Recall: 0.9875, F1_score: 0.9887
Model performance on Sad speech (in training): 
	Precision: 0.9875, Recall: 0.9875, F1_score: 0.9875

Eval Phase: 
Validation loss: 245.8157, Validation accuracy: 0.7350
Macro F1-score: 0.7214
Model performance on Angry speech (in validation): 
	Precision: 0.6923, Recall: 0.9000, F1_score: 0.7826
Model performance on Happy speech (in validation): 
	Precision: 0.6744, Recall: 0.5800, F1_score: 0.6237
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.4800, F1_score: 0.6486
Model performance on Sad speech (in validation): 
	Precision: 0.7206, Recall: 0.9800, F1_score: 0.8305
Epoch 13/100

Training Phase:
Training loss: 65.5853, Training accuracy: 0.9856
Macro F1-score: 0.9856
Model performance on Angry speech (in training): 
	Precision: 0.9655, Recall: 0.9800, F1_score: 0.9727
Model performance on Happy speech (in training): 
	Precision: 0.9796, Recall: 0.9625, F1_score: 0.9710
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 287.0350, Validation accuracy: 0.7000
Macro F1-score: 0.6962
Model performance on Angry speech (in validation): 
	Precision: 0.5833, Recall: 0.9800, F1_score: 0.7313
Model performance on Happy speech (in validation): 
	Precision: 0.4651, Recall: 0.4000, F1_score: 0.4301
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.5600, F1_score: 0.7179
Model performance on Sad speech (in validation): 
	Precision: 0.9556, Recall: 0.8600, F1_score: 0.9053
Validation loss does not decrease for 10 epochs. End training.
Model best accuracy on validation set: 0.7700

Test Phase: 
          Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 270/1600 [00:10<00:49, 26.98it/s]Training:  34%|███▍      | 540/1600 [00:20<00:39, 26.96it/s]Training:  51%|█████     | 811/1600 [00:30<00:29, 27.02it/s]Training:  68%|██████▊   | 1082/1600 [00:40<00:19, 27.05it/s]Training:  85%|████████▍ | 1355/1600 [00:50<00:09, 27.12it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]                                                Some weights of the model checkpoint at /work/tc062/tc062/zhan7721/saved_models/de were not used when initializing Wav2Vec2Model: ['encoder.layers.10.attention.k_proj.bias', 'encoder.layers.10.attention.k_proj.weight', 'encoder.layers.10.attention.out_proj.bias', 'encoder.layers.10.attention.out_proj.weight', 'encoder.layers.10.attention.q_proj.bias', 'encoder.layers.10.attention.q_proj.weight', 'encoder.layers.10.attention.v_proj.bias', 'encoder.layers.10.attention.v_proj.weight', 'encoder.layers.10.feed_forward.intermediate_dense.bias', 'encoder.layers.10.feed_forward.intermediate_dense.weight', 'encoder.layers.10.feed_forward.output_dense.bias', 'encoder.layers.10.feed_forward.output_dense.weight', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.10.layer_norm.bias', 'encoder.layers.10.layer_norm.weight', 'encoder.layers.11.attention.k_proj.bias', 'encoder.layers.11.attention.k_proj.weight', 'encoder.layers.11.attention.out_proj.bias', 'encoder.layers.11.attention.out_proj.weight', 'encoder.layers.11.attention.q_proj.bias', 'encoder.layers.11.attention.q_proj.weight', 'encoder.layers.11.attention.v_proj.bias', 'encoder.layers.11.attention.v_proj.weight', 'encoder.layers.11.feed_forward.intermediate_dense.bias', 'encoder.layers.11.feed_forward.intermediate_dense.weight', 'encoder.layers.11.feed_forward.output_dense.bias', 'encoder.layers.11.feed_forward.output_dense.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.11.layer_norm.bias', 'encoder.layers.11.layer_norm.weight', 'encoder.layers.5.attention.k_proj.bias', 'encoder.layers.5.attention.k_proj.weight', 'encoder.layers.5.attention.out_proj.bias', 'encoder.layers.5.attention.out_proj.weight', 'encoder.layers.5.attention.q_proj.bias', 'encoder.layers.5.attention.q_proj.weight', 'encoder.layers.5.attention.v_proj.bias', 'encoder.layers.5.attention.v_proj.weight', 'encoder.layers.5.feed_forward.intermediate_dense.bias', 'encoder.layers.5.feed_forward.intermediate_dense.weight', 'encoder.layers.5.feed_forward.output_dense.bias', 'encoder.layers.5.feed_forward.output_dense.weight', 'encoder.layers.5.final_layer_norm.bias', 'encoder.layers.5.final_layer_norm.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.6.attention.k_proj.bias', 'encoder.layers.6.attention.k_proj.weight', 'encoder.layers.6.attention.out_proj.bias', 'encoder.layers.6.attention.out_proj.weight', 'encoder.layers.6.attention.q_proj.bias', 'encoder.layers.6.attention.q_proj.weight', 'encoder.layers.6.attention.v_proj.bias', 'encoder.layers.6.attention.v_proj.weight', 'encoder.layers.6.feed_forward.intermediate_dense.bias', 'encoder.layers.6.feed_forward.intermediate_dense.weight', 'encoder.layers.6.feed_forward.output_dense.bias', 'encoder.layers.6.feed_forward.output_dense.weight', 'encoder.layers.6.final_layer_norm.bias', 'encoder.layers.6.final_layer_norm.weight', 'encoder.layers.6.layer_norm.bias', 'encoder.layers.6.layer_norm.weight', 'encoder.layers.7.attention.k_proj.bias', 'encoder.layers.7.attention.k_proj.weight', 'encoder.layers.7.attention.out_proj.bias', 'encoder.layers.7.attention.out_proj.weight', 'encoder.layers.7.attention.q_proj.bias', 'encoder.layers.7.attention.q_proj.weight', 'encoder.layers.7.attention.v_proj.bias', 'encoder.layers.7.attention.v_proj.weight', 'encoder.layers.7.feed_forward.intermediate_dense.bias', 'encoder.layers.7.feed_forward.intermediate_dense.weight', 'encoder.layers.7.feed_forward.output_dense.bias', 'encoder.layers.7.feed_forward.output_dense.weight', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.7.layer_norm.bias', 'encoder.layers.7.layer_norm.weight', 'encoder.layers.8.attention.k_proj.bias', 'encoder.layers.8.attention.k_proj.weight', 'encoder.layers.8.attention.out_proj.bias', 'encoder.layers.8.attention.out_proj.weight', 'encoder.layers.8.attention.q_proj.bias', 'encoder.layers.8.attention.q_proj.weight', 'encoder.layers.8.attention.v_proj.bias', 'encoder.layers.8.attention.v_proj.weight', 'encoder.layers.8.feed_forward.intermediate_dense.bias', 'encoder.layers.8.feed_forward.intermediate_dense.weight', 'encoder.layers.8.feed_forward.output_dense.bias', 'encoder.layers.8.feed_forward.output_dense.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.8.layer_norm.bias', 'encoder.layers.8.layer_norm.weight', 'encoder.layers.9.attention.k_proj.bias', 'encoder.layers.9.attention.k_proj.weight', 'encoder.layers.9.attention.out_proj.bias', 'encoder.layers.9.attention.out_proj.weight', 'encoder.layers.9.attention.q_proj.bias', 'encoder.layers.9.attention.q_proj.weight', 'encoder.layers.9.attention.v_proj.bias', 'encoder.layers.9.attention.v_proj.weight', 'encoder.layers.9.feed_forward.intermediate_dense.bias', 'encoder.layers.9.feed_forward.intermediate_dense.weight', 'encoder.layers.9.feed_forward.output_dense.bias', 'encoder.layers.9.feed_forward.output_dense.weight', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.layer_norm.bias', 'encoder.layers.9.layer_norm.weight']
- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Test loss: 286.5257, Test accuracy: 0.7100
Macro F1-score: 0.7054
Model performance on Angry speech (in test): 
	Precision: 0.6949, Recall: 0.8200, F1_score: 0.7523
Model performance on Happy speech (in test): 
	Precision: 0.5424, Recall: 0.6400, F1_score: 0.5872
Model performance on Neutral speech (in test): 
	Precision: 1.0000, Recall: 0.4800, F1_score: 0.6486
Model performance on Sad speech (in test): 
	Precision: 0.7759, Recall: 0.9000, F1_score: 0.8333

======================= This is fold_1 on de =======================

Load dataset: 
Loading cn train data: fold_1...
Preprocess cn fold_1 data for de model
Loading cn eval data: fold_1...
Preprocess cn fold_1 data for de model
Loading cn test data: fold_1...
Preprocess cn fold_1 data for de model
Use de model to add lora
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training loss: 872.7292, Training accuracy: 0.7756
Macro F1-score: 0.7754
Model performance on Angry speech (in training): 
	Precision: 0.7266, Recall: 0.6975, F1_score: 0.7117
Model performance on Happy speech (in training): 
	Precision: 0.6838, Recall: 0.6975, F1_score: 0.6906
Model performance on Neutral speech (in training): 
	Precision: 0.8175, Recall: 0.8400, F1_score: 0.8286
Model performance on Sad speech (in training): 
	Precision: 0.8741, Recall: 0.8675, F1_score: 0.8708

Eval Phase: 
Validation loss: 152.8658, Validation accuracy: 0.7750
Macro F1-score: 0.7362
Model performance on Angry speech (in validation): 
	Precision: 0.9057, Recall: 0.9600, F1_score: 0.9320
Model performance on Happy speech (in validation): 
	Precision: 0.9091, Recall: 0.2000, F1_score: 0.3279
Model performance on Neutral speech (in validation): 
	Precision: 0.5632, Recall: 0.9800, F1_score: 0.7153
Model performance on Sad speech (in validation): 
	Precision: 0.9796, Recall: 0.9600, F1_score: 0.9697
New best accuracy for layer 4 on epoch 1: 0.7750. Model saved.
Epoch 2/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  11%|█▏        | 183/1600 [00:10<01:17, 18.28it/s]Training:  26%|██▌       | 411/1600 [00:20<00:56, 20.90it/s]Training:  40%|████      | 648/1600 [00:30<00:42, 22.17it/s]Training:  55%|█████▌    | 886/1600 [00:40<00:31, 22.79it/s]Training:  70%|███████   | 1124/1600 [00:50<00:20, 23.13it/s]Training:  86%|████████▌ | 1377/1600 [01:00<00:09, 23.84it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 268/1600 [00:10<00:49, 26.71it/s]Training:  34%|███▎      | 536/1600 [00:20<00:39, 26.71it/s]Training:  50%|█████     | 808/1600 [00:30<00:29, 26.90it/s]Training:  68%|██████▊   | 1080/1600 [00:40<00:19, 26.77it/s]Training:  84%|████████▍Training loss: 403.5512, Training accuracy: 0.9144
Macro F1-score: 0.9140
Model performance on Angry speech (in training): 
	Precision: 0.8467, Recall: 0.8975, F1_score: 0.8714
Model performance on Happy speech (in training): 
	Precision: 0.8886, Recall: 0.8175, F1_score: 0.8516
Model performance on Neutral speech (in training): 
	Precision: 0.9487, Recall: 0.9700, F1_score: 0.9592
Model performance on Sad speech (in training): 
	Precision: 0.9749, Recall: 0.9725, F1_score: 0.9737

Eval Phase: 
Validation loss: 109.4767, Validation accuracy: 0.8150
Macro F1-score: 0.8065
Model performance on Angry speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in validation): 
	Precision: 0.8077, Recall: 0.4200, F1_score: 0.5526
Model performance on Neutral speech (in validation): 
	Precision: 0.5974, Recall: 0.9200, F1_score: 0.7244
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9400, F1_score: 0.9691
New best accuracy for layer 4 on epoch 2: 0.8150. Model saved.
Epoch 3/100

Training Phase:
Training loss: 253.1321, Training accuracy: 0.9394
Macro F1-score: 0.9394
Model performance on Angry speech (in training): 
	Precision: 0.8836, Recall: 0.9300, F1_score: 0.9062
Model performance on Happy speech (in training): 
	Precision: 0.9193, Recall: 0.8825, F1_score: 0.9005
Model performance on Neutral speech (in training): 
	Precision: 0.9746, Recall: 0.9600, F1_score: 0.9673
Model performance on Sad speech (in training): 
	Precision: 0.9825, Recall: 0.9850, F1_score: 0.9838

Eval Phase: 
Validation loss: 103.7985, Validation accuracy: 0.8050
Macro F1-score: 0.8031
Model performance on Angry speech (in validation): 
	Precision: 0.9792, Recall: 0.9400, F1_score: 0.9592
Model performance on Happy speech (in validation): 
	Precision: 0.8571, Recall: 0.4800, F1_score: 0.6154
Model performance on Neutral speech (in validation): 
	Precision: 0.5904, Recall: 0.9800, F1_score: 0.7368
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.8200, F1_score: 0.9011
Epoch 4/100

Training Phase:
 | 1348/1600 [00:50<00:09, 26.77it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 271/1600 [00:10<00:49, 27.02it/s]Training:  34%|███▍      | 542/1600 [00:20<00:39, 27.05it/s]Training:  51%|█████     | 813/1600 [00:30<00:29, 27.02it/s]Training:  68%|██████▊   | 1085/1600 [00:40<00:19, 27.07it/s]Training:  85%|████████▍ | 1357/1600 [00:50<00:09, 26.81it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 266/1600 [00:10<00:50, 26.54it/s]Training:  33%|███▎      | 534/1600 [00:20<00:39, 26.67it/s]Training:  50%|█████     | 802/1600 [00:30<Training loss: 188.2594, Training accuracy: 0.9537
Macro F1-score: 0.9537
Model performance on Angry speech (in training): 
	Precision: 0.9300, Recall: 0.9300, F1_score: 0.9300
Model performance on Happy speech (in training): 
	Precision: 0.9221, Recall: 0.9175, F1_score: 0.9198
Model performance on Neutral speech (in training): 
	Precision: 0.9751, Recall: 0.9800, F1_score: 0.9776
Model performance on Sad speech (in training): 
	Precision: 0.9875, Recall: 0.9875, F1_score: 0.9875

Eval Phase: 
Validation loss: 149.7743, Validation accuracy: 0.8200
Macro F1-score: 0.8117
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.8600, F1_score: 0.9247
Model performance on Happy speech (in validation): 
	Precision: 0.7586, Recall: 0.4400, F1_score: 0.5570
Model performance on Neutral speech (in validation): 
	Precision: 0.6329, Recall: 1.0000, F1_score: 0.7752
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
New best accuracy for layer 4 on epoch 4: 0.8200. Model saved.
Epoch 5/100

Training Phase:
Training loss: 155.8363, Training accuracy: 0.9637
Macro F1-score: 0.9637
Model performance on Angry speech (in training): 
	Precision: 0.9398, Recall: 0.9375, F1_score: 0.9387
Model performance on Happy speech (in training): 
	Precision: 0.9425, Recall: 0.9425, F1_score: 0.9425
Model performance on Neutral speech (in training): 
	Precision: 0.9825, Recall: 0.9850, F1_score: 0.9838
Model performance on Sad speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900

Eval Phase: 
Validation loss: 171.0508, Validation accuracy: 0.7100
Macro F1-score: 0.6999
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.4200, F1_score: 0.5915
Model performance on Happy speech (in validation): 
	Precision: 0.4630, Recall: 0.5000, F1_score: 0.4808
Model performance on Neutral speech (in validation): 
	Precision: 0.6447, Recall: 0.9800, F1_score: 0.7778
Model performance on Sad speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Epoch 6/100

Training Phase:
00:30, 26.57it/s]Training:  67%|██████▋   | 1069/1600 [00:40<00:19, 26.59it/s]Training:  84%|████████▎ | 1336/1600 [00:50<00:09, 26.62it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 270/1600 [00:10<00:49, 26.95it/s]Training:  34%|███▍      | 540/1600 [00:20<00:39, 26.61it/s]Training:  50%|█████     | 804/1600 [00:30<00:30, 26.45it/s]Training:  67%|██████▋   | 1068/1600 [00:40<00:20, 26.39it/s]Training:  83%|████████▎ | 1332/1600 [00:50<00:10, 26.21it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 274/1600 [00:10<00:4Training loss: 143.7029, Training accuracy: 0.9688
Macro F1-score: 0.9687
Model performance on Angry speech (in training): 
	Precision: 0.9572, Recall: 0.9500, F1_score: 0.9536
Model performance on Happy speech (in training): 
	Precision: 0.9425, Recall: 0.9425, F1_score: 0.9425
Model performance on Neutral speech (in training): 
	Precision: 0.9876, Recall: 0.9950, F1_score: 0.9913
Model performance on Sad speech (in training): 
	Precision: 0.9875, Recall: 0.9875, F1_score: 0.9875

Eval Phase: 
Validation loss: 130.9157, Validation accuracy: 0.7650
Macro F1-score: 0.7584
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.5600, F1_score: 0.7179
Model performance on Happy speech (in validation): 
	Precision: 0.5600, Recall: 0.5600, F1_score: 0.5600
Model performance on Neutral speech (in validation): 
	Precision: 0.7015, Recall: 0.9400, F1_score: 0.8034
Model performance on Sad speech (in validation): 
	Precision: 0.9091, Recall: 1.0000, F1_score: 0.9524
Epoch 7/100

Training Phase:
Training loss: 86.9958, Training accuracy: 0.9819
Macro F1-score: 0.9819
Model performance on Angry speech (in training): 
	Precision: 0.9700, Recall: 0.9700, F1_score: 0.9700
Model performance on Happy speech (in training): 
	Precision: 0.9675, Recall: 0.9675, F1_score: 0.9675
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963

Eval Phase: 
8, 27.36it/s]Training:  34%|███▍      | 548/1600 [00:20<00:38, 27.16it/s]Training:  51%|█████     | 819/1600 [00:30<00:28, 27.12it/s]Training:  68%|██████▊   | 1090/1600 [00:40<00:18, 27.06it/s]Training:  85%|████████▌ | 1360/1600 [00:50<00:08, 27.01it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 270/1600 [00:10<00:49, 26.95it/s]Training:  34%|███▍      | 541/1600 [00:20<00:39, 26.99it/s]Training:  51%|█████     | 812/1600 [00:30<00:29, 27.01it/s]Training:  68%|██████▊   | 1083/1600 [00:40<00:19, 27.04it/s]Training:  85%|████████▍ | 1354/1600 [00:50<00:09, 26.90it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                   Validation loss: 357.7678, Validation accuracy: 0.7350
Macro F1-score: 0.7239
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.8400, F1_score: 0.9130
Model performance on Happy speech (in validation): 
	Precision: 0.7368, Recall: 0.2800, F1_score: 0.4058
Model performance on Neutral speech (in validation): 
	Precision: 0.5102, Recall: 1.0000, F1_score: 0.6757
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.8200, F1_score: 0.9011
Epoch 8/100

Training Phase:
Training loss: 71.2552, Training accuracy: 0.9806
Macro F1-score: 0.9806
Model performance on Angry speech (in training): 
	Precision: 0.9701, Recall: 0.9725, F1_score: 0.9713
Model performance on Happy speech (in training): 
	Precision: 0.9749, Recall: 0.9700, F1_score: 0.9724
Model performance on Neutral speech (in training): 
	Precision: 0.9825, Recall: 0.9850, F1_score: 0.9838
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950

Eval Phase: 
Validation loss: 191.8864, Validation accuracy: 0.8000
Macro F1-score: 0.7814
Model performance on Angry speech (in validation): 
	Precision: 0.9796, Recall: 0.9600, F1_score: 0.9697
Model performance on Happy speech (in validation): 
	Precision: 0.9000, Recall: 0.3600, F1_score: 0.5143
Model performance on Neutral speech (in validation): 
	Precision: 0.6133, Recall: 0.9200, F1_score: 0.7360
Model performance on Sad speech (in validation): 
	Precision: 0.8571, Recall: 0.9600, F1_score: 0.9057
Epoch 9/100

Training Phase:
                                Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 270/1600 [00:10<00:49, 26.96it/s]Training:  34%|███▍      | 540/1600 [00:20<00:39, 26.77it/s]Training:  50%|█████     | 807/1600 [00:30<00:29, 26.67it/s]Training:  67%|██████▋   | 1073/1600 [00:40<00:19, 26.56it/s]Training:  84%|████████▍ | 1348/1600 [00:50<00:09, 26.89it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 279/1600 [00:10<00:47, 27.87it/s]Training:  35%|███▍      | 558/1600 [00:20<00:37, 27.67it/s]Training:  52%|█████▏    | 835/1600 [00:30<00:27, 27.66it/s]Training:  70%|██████▉   | 1112/1600 [00:40<00:17, 27.67it/s]Training:  87%|████████▋ | 1389/1600 [00:50<00:07, 27.65itTraining loss: 56.7313, Training accuracy: 0.9894
Macro F1-score: 0.9894
Model performance on Angry speech (in training): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in training): 
	Precision: 0.9776, Recall: 0.9825, F1_score: 0.9800
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 0.9950, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 170.8537, Validation accuracy: 0.7950
Macro F1-score: 0.7963
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.8000, F1_score: 0.8889
Model performance on Happy speech (in validation): 
	Precision: 0.7179, Recall: 0.5600, F1_score: 0.6292
Model performance on Neutral speech (in validation): 
	Precision: 0.6316, Recall: 0.9600, F1_score: 0.7619
Model performance on Sad speech (in validation): 
	Precision: 0.9556, Recall: 0.8600, F1_score: 0.9053
Epoch 10/100

Training Phase:
Training loss: 67.1218, Training accuracy: 0.9869
Macro F1-score: 0.9869
Model performance on Angry speech (in training): 
	Precision: 0.9776, Recall: 0.9825, F1_score: 0.9800
Model performance on Happy speech (in training): 
	Precision: 0.9850, Recall: 0.9825, F1_score: 0.9837
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925

Eval Phase: 
Validation loss: 517.0012, Validation accuracy: 0.5850
Macro F1-score: 0.5786
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.6600, F1_score: 0.7952
Model performance on Happy speech (in validation): 
	Precision: 0.4800, Recall: 0.2400, F1_score: 0.3200
Model performance on Neutral speech (in validation): 
	Precision: 0.4167, Recall: 1.0000, F1_score: 0.5882
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.4400, F1_score: 0.6111
Epoch 11/100

Training Phase:
/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 277/1600 [00:10<00:47, 27.67it/s]Training:  35%|███▍      | 554/1600 [00:20<00:37, 27.61it/s]Training:  52%|█████▏    | 832/1600 [00:30<00:27, 27.70it/s]Training:  69%|██████▉   | 1110/1600 [00:40<00:17, 27.53it/s]Training:  86%|████████▋ | 1383/1600 [00:50<00:07, 27.43it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 273/1600 [00:10<00:48, 27.23it/s]Training:  34%|███▍      | 546/1600 [00:20<00:38, 27.17it/s]Training:  51%|█████▏    | 822/1600 [00:30<00:28, 27.32it/s]Training:  6Training loss: 45.4637, Training accuracy: 0.9894
Macro F1-score: 0.9894
Model performance on Angry speech (in training): 
	Precision: 0.9825, Recall: 0.9800, F1_score: 0.9812
Model performance on Happy speech (in training): 
	Precision: 0.9825, Recall: 0.9825, F1_score: 0.9825
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Validation loss: 64.0831, Validation accuracy: 0.9150
Macro F1-score: 0.9162
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.8800, F1_score: 0.9362
Model performance on Happy speech (in validation): 
	Precision: 0.8214, Recall: 0.9200, F1_score: 0.8679
Model performance on Neutral speech (in validation): 
	Precision: 0.8824, Recall: 0.9000, F1_score: 0.8911
Model performance on Sad speech (in validation): 
	Precision: 0.9796, Recall: 0.9600, F1_score: 0.9697
New best accuracy for layer 4 on epoch 11: 0.9150. Model saved.
Epoch 12/100

Training Phase:
Training loss: 74.7667, Training accuracy: 0.9850
Macro F1-score: 0.9850
Model performance on Angry speech (in training): 
	Precision: 0.9797, Recall: 0.9675, F1_score: 0.9736
Model performance on Happy speech (in training): 
	Precision: 0.9728, Recall: 0.9825, F1_score: 0.9776
Model performance on Neutral speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Validation loss: 163.3916, Validation accuracy: 0.8000
Macro F1-score: 0.7974
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.8200, F1_score: 0.9011
Model performance on Happy speech (in validation): 
	Precision: 0.7576, Recall: 0.5000, F1_score: 0.6024
Model performance on Neutral speech (in validation): 
	Precision: 0.6250, Recall: 1.0000, F1_score: 0.7692
Model performance on Sad speech (in validation): 
	Precision: 0.9565, Recall: 0.8800, F1_score: 0.9167
Epoch 13/100

Training Phase:
9%|██████▊   | 1097/1600 [00:40<00:18, 27.27it/s]Training:  86%|████████▌ | 1370/1600 [00:50<00:08, 27.02it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▋        | 260/1600 [00:10<00:51, 25.94it/s]Training:  33%|███▎      | 533/1600 [00:20<00:39, 26.71it/s]Training:  50%|█████     | 806/1600 [00:30<00:29, 26.80it/s]Training:  67%|██████▋   | 1079/1600 [00:40<00:19, 26.96it/s]Training:  84%|████████▍ | 1352/1600 [00:50<00:09, 27.00it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 275/1600 [00:10<00:48, 27.48it/s]Training:  34%|Training loss: 42.7756, Training accuracy: 0.9931
Macro F1-score: 0.9931
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912
Model performance on Happy speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962

Eval Phase: 
Validation loss: 239.6482, Validation accuracy: 0.7650
Macro F1-score: 0.7513
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.7400, F1_score: 0.8506
Model performance on Happy speech (in validation): 
	Precision: 0.6000, Recall: 0.3600, F1_score: 0.4500
Model performance on Neutral speech (in validation): 
	Precision: 0.6173, Recall: 1.0000, F1_score: 0.7634
Model performance on Sad speech (in validation): 
	Precision: 0.9231, Recall: 0.9600, F1_score: 0.9412
Epoch 14/100

Training Phase:
Training loss: 46.1745, Training accuracy: 0.9881
Macro F1-score: 0.9881
Model performance on Angry speech (in training): 
	Precision: 0.9752, Recall: 0.9825, F1_score: 0.9788
Model performance on Happy speech (in training): 
	Precision: 0.9823, Recall: 0.9725, F1_score: 0.9774
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
██▍      | 550/1600 [00:20<00:38, 27.07it/s]Training:  51%|█████▏    | 820/1600 [00:30<00:28, 27.00it/s]Training:  68%|██████▊   | 1090/1600 [00:40<00:18, 26.97it/s]Training:  85%|████████▌ | 1360/1600 [00:50<00:08, 26.92it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 266/1600 [00:10<00:50, 26.55it/s]Training:  33%|███▎      | 532/1600 [00:20<00:40, 26.42it/s]Training:  50%|████▉     | 796/1600 [00:30<00:30, 26.34it/s]Training:  66%|██████▋   | 1060/1600 [00:40<00:20, 26.35it/s]Training:  83%|████████▎ | 1327/1600 [00:50<00:10, 26.45it/s]Training: 100%|██████████| 1600/1600 [01:00<00:00, 26.72it/s]                                                             Evaluating:   0%|Validation loss: 373.3937, Validation accuracy: 0.7300
Macro F1-score: 0.7293
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.8600, F1_score: 0.9247
Model performance on Happy speech (in validation): 
	Precision: 0.7692, Recall: 0.4000, F1_score: 0.5263
Model performance on Neutral speech (in validation): 
	Precision: 0.5155, Recall: 1.0000, F1_score: 0.6803
Model performance on Sad speech (in validation): 
	Precision: 0.9706, Recall: 0.6600, F1_score: 0.7857
Epoch 15/100

Training Phase:
Training loss: 58.3536, Training accuracy: 0.9869
Macro F1-score: 0.9869
Model performance on Angry speech (in training): 
	Precision: 0.9850, Recall: 0.9850, F1_score: 0.9850
Model performance on Happy speech (in training): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Neutral speech (in training): 
	Precision: 0.9899, Recall: 0.9850, F1_score: 0.9875
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9975, F1_score: 0.9950

Eval Phase: 
Validation loss: 202.1081, Validation accuracy: 0.7700
Macro F1-score: 0.7728
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.8800, F1_score: 0.9362
Model performance on Happy speech (in validation): 
	Precision: 0.8065, Recall: 0.5000, F1_score: 0.6173
Model performance on Neutral speech (in validation): 
	Precision: 0.5556, Recall: 1.0000, F1_score: 0.7143
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.7000, F1_score: 0.8235
Epoch 16/100

Training Phase:
          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 270/1600 [00:10<00:49, 26.98it/s]Training:  34%|███▍      | 540/1600 [00:20<00:39, 26.89it/s]Training:  51%|█████     | 809/1600 [00:30<00:29, 26.72it/s]Training:  68%|██████▊   | 1080/1600 [00:40<00:19, 26.85it/s]Training:  68%|██████▊   | 1080/1600 [00:50<00:19, 26.85it/s]Training:  84%|████████▍ | 1349/1600 [00:50<00:09, 26.83it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 272/1600 [00:10<00:48, 27.16it/s]Training:  34%|███▍      | 545/1600 [00:20<00:38, 27.22it/s]Training:  51%|█████     | 818/1600 [00:30<00:29, 26.80it/s]Training:  68%|███Training loss: 18.3135, Training accuracy: 0.9962
Macro F1-score: 0.9963
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 191.6393, Validation accuracy: 0.8150
Macro F1-score: 0.8147
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.8400, F1_score: 0.9130
Model performance on Happy speech (in validation): 
	Precision: 0.7778, Recall: 0.5600, F1_score: 0.6512
Model performance on Neutral speech (in validation): 
	Precision: 0.6447, Recall: 0.9800, F1_score: 0.7778
Model performance on Sad speech (in validation): 
	Precision: 0.9565, Recall: 0.8800, F1_score: 0.9167
Epoch 17/100

Training Phase:
Training loss: 59.9799, Training accuracy: 0.9875
Macro F1-score: 0.9875
Model performance on Angry speech (in training): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in training): 
	Precision: 0.9750, Recall: 0.9750, F1_score: 0.9750
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950

Eval Phase: 
Validation loss: 168.4426, Validation accuracy: 0.8250
Macro F1-score: 0.8211
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9400, F1_score: 0.9691
Model performance on Happy speech (in validation): 
	Precision: 0.8929, Recall: 0.5000, F1_score: 0.6410
Model performance on Neutral speech (in validation): 
	Precision: 0.6250, Recall: 1.0000, F1_score: 0.7692
Model performance on Sad speech (in validation): 
	Precision: 0.9556, Recall: 0.8600, F1_score: 0.9053
Epoch 18/100

Training Phase:
███▊   | 1082/1600 [00:40<00:19, 26.62it/s]Training:  84%|████████▍ | 1346/1600 [00:50<00:09, 26.47it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  18%|█▊        | 280/1600 [00:10<00:47, 27.93it/s]Training:  35%|███▌      | 560/1600 [00:20<00:37, 27.41it/s]Training:  52%|█████▏    | 831/1600 [00:30<00:28, 27.13it/s]Training:  69%|██████▉   | 1110/1600 [00:40<00:17, 27.42it/s]Training:  87%|████████▋ | 1389/1600 [00:50<00:07, 27.55it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 267/1600 [00:10<00:49, 26.67it/s]Training:  34%|███Training loss: 29.4300, Training accuracy: 0.9956
Macro F1-score: 0.9956
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Validation loss: 330.1643, Validation accuracy: 0.6300
Macro F1-score: 0.6283
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.4400, F1_score: 0.6111
Model performance on Happy speech (in validation): 
	Precision: 0.5000, Recall: 0.4600, F1_score: 0.4792
Model performance on Neutral speech (in validation): 
	Precision: 0.5000, Recall: 1.0000, F1_score: 0.6667
Model performance on Sad speech (in validation): 
	Precision: 0.9688, Recall: 0.6200, F1_score: 0.7561
Epoch 19/100

Training Phase:
Training loss: 14.9257, Training accuracy: 0.9988
Macro F1-score: 0.9988
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Happy speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
      | 538/1600 [00:20<00:39, 26.91it/s]Training:  51%|█████     | 813/1600 [00:30<00:28, 27.17it/s]Training:  68%|██████▊   | 1091/1600 [00:40<00:18, 27.40it/s]Training:  86%|████████▌ | 1369/1600 [00:50<00:08, 27.13it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 265/1600 [00:10<00:50, 26.42it/s]Training:  33%|███▎      | 535/1600 [00:20<00:39, 26.71it/s]Training:  50%|█████     | 805/1600 [00:30<00:30, 26.30it/s]Training:  67%|██████▋   | 1068/1600 [00:40<00:20, 26.27it/s]Training:  83%|████████▎ | 1334/1600 [00:50<00:10, 26.37it/s]Training: 100%|██████████| 1600/1600 [01:00<00:00, 26.36it/s]                                                             Evaluating:   0%|          | Validation loss: 373.5485, Validation accuracy: 0.7150
Macro F1-score: 0.7177
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.8400, F1_score: 0.9130
Model performance on Happy speech (in validation): 
	Precision: 0.7931, Recall: 0.4600, F1_score: 0.5823
Model performance on Neutral speech (in validation): 
	Precision: 0.5000, Recall: 1.0000, F1_score: 0.6667
Model performance on Sad speech (in validation): 
	Precision: 0.9655, Recall: 0.5600, F1_score: 0.7089
Epoch 20/100

Training Phase:
Training loss: 29.1180, Training accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938
Model performance on Happy speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Validation loss: 344.8912, Validation accuracy: 0.7600
Macro F1-score: 0.7597
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.8600, F1_score: 0.9247
Model performance on Happy speech (in validation): 
	Precision: 0.7857, Recall: 0.4400, F1_score: 0.5641
Model performance on Neutral speech (in validation): 
	Precision: 0.5495, Recall: 1.0000, F1_score: 0.7092
Model performance on Sad speech (in validation): 
	Precision: 0.9737, Recall: 0.7400, F1_score: 0.8409
Epoch 21/100

Training Phase:
0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▋        | 261/1600 [00:10<00:51, 26.06it/s]Training:  33%|███▎      | 524/1600 [00:20<00:41, 26.17it/s]Training:  50%|████▉     | 794/1600 [00:30<00:30, 26.51it/s]Training:  67%|██████▋   | 1068/1600 [00:40<00:19, 26.83it/s]Training:  84%|████████▍ | 1342/1600 [00:50<00:09, 26.91it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 270/1600 [00:10<00:49, 26.99it/s]Training:  34%|███▍      | 540/1600 [00:20<00:39, 26.84it/s]Training:  50%|█████     | 808/1600 [00:30<00:30, 26.38it/s]Training:  67%|██████▋   | 1077/1600 [00:40<00:19, 26.56it/s]Training:  84%|███████Training loss: 44.1329, Training accuracy: 0.9931
Macro F1-score: 0.9931
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9900, F1_score: 0.9925
Model performance on Happy speech (in training): 
	Precision: 0.9901, Recall: 0.9975, F1_score: 0.9938
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950

Eval Phase: 
Validation loss: 317.1897, Validation accuracy: 0.7450
Macro F1-score: 0.7491
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.8400, F1_score: 0.9130
Model performance on Happy speech (in validation): 
	Precision: 0.8125, Recall: 0.5200, F1_score: 0.6341
Model performance on Neutral speech (in validation): 
	Precision: 0.5393, Recall: 0.9600, F1_score: 0.6906
Model performance on Sad speech (in validation): 
	Precision: 0.8919, Recall: 0.6600, F1_score: 0.7586
Validation loss does not decrease for 10 epochs. End training.
Model best accuracy on validation set: 0.9150

Test Phase: 
█▍ | 1349/1600 [00:50<00:09, 26.76it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]                                                Some weights of the model checkpoint at /work/tc062/tc062/zhan7721/saved_models/de were not used when initializing Wav2Vec2Model: ['encoder.layers.10.attention.k_proj.bias', 'encoder.layers.10.attention.k_proj.weight', 'encoder.layers.10.attention.out_proj.bias', 'encoder.layers.10.attention.out_proj.weight', 'encoder.layers.10.attention.q_proj.bias', 'encoder.layers.10.attention.q_proj.weight', 'encoder.layers.10.attention.v_proj.bias', 'encoder.layers.10.attention.v_proj.weight', 'encoder.layers.10.feed_forward.intermediate_dense.bias', 'encoder.layers.10.feed_forward.intermediate_dense.weight', 'encoder.layers.10.feed_forward.output_dense.bias', 'encoder.layers.10.feed_forward.output_dense.weight', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.10.layer_norm.bias', 'encoder.layers.10.layer_norm.weight', 'encoder.layers.11.attention.k_proj.bias', 'encoder.layers.11.attention.k_proj.weight', 'encoder.layers.11.attention.out_proj.bias', 'encoder.layers.11.attention.out_proj.weight', 'encoder.layers.11.attention.q_proj.bias', 'encoder.layers.11.attention.q_proj.weight', 'encoder.layers.11.attention.v_proj.bias', 'encoder.layers.11.attention.v_proj.weight', 'encoder.layers.11.feed_forward.intermediate_dense.bias', 'encoder.layers.11.feed_forward.intermediate_dense.weight', 'encoder.layers.11.feed_forward.output_dense.bias', 'encoder.layers.11.feed_forward.output_dense.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.11.layer_norm.bias', 'encoder.layers.11.layer_norm.weight', 'encoder.layers.5.attention.k_proj.bias', 'encoder.layers.5.attention.k_proj.weight', 'encoder.layers.5.attention.out_proj.bias', 'encoder.layers.5.attention.out_proj.weight', 'encoder.layers.5.attention.q_proj.bias', 'encoder.layers.5.attention.q_proj.weight', 'encoder.layers.5.attention.v_proj.bias', 'encoder.layers.5.attention.v_proj.weight', 'encoder.layers.5.feed_forward.intermediate_dense.bias', 'encoder.layers.5.feed_forward.intermediate_dense.weight', 'encoder.layers.5.feed_forward.output_dense.bias', 'encoder.layers.5.feed_forward.output_dense.weight', 'encoder.layers.5.final_layer_norm.bias', 'encoder.layers.5.final_layer_norm.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.6.attention.k_proj.bias', 'encoder.layers.6.attention.k_proj.weight', 'encoder.layers.6.attention.out_proj.bias', 'encoder.layers.6.attention.out_proj.weight', 'encoder.layers.6.attention.q_proj.bias', 'encoder.layers.6.attention.q_proj.weight', 'encoder.layers.6.attention.v_proj.bias', 'encoder.layers.6.attention.v_proj.weight', 'encoder.layers.6.feed_forward.intermediate_dense.bias', 'encoder.layers.6.feed_forward.intermediate_dense.weight', 'encoder.layers.6.feed_forward.output_dense.bias', 'encoder.layers.6.feed_forward.output_dense.weight', 'encoder.layers.6.final_layer_norm.bias', 'encoder.layers.6.final_layer_norm.weight', 'encoder.layers.6.layer_norm.bias', 'encoder.layers.6.layer_norm.weight', 'encoder.layers.7.attention.k_proj.bias', 'encoder.layers.7.attention.k_proj.weight', 'encoder.layers.7.attention.out_proj.bias', 'encoder.layers.7.attention.out_proj.weight', 'encoder.layers.7.attention.q_proj.bias', 'encoder.layers.7.attention.q_proj.weight', 'encoder.layers.7.attention.v_proj.bias', 'encoder.layers.7.attention.v_proj.weight', 'encoder.layers.7.feed_forward.intermediate_dense.bias', 'encoder.layers.7.feed_forward.intermediate_dense.weight', 'encoder.layers.7.feed_forward.output_dense.bias', 'encoder.layers.7.feed_forward.output_dense.weight', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.7.layer_norm.bias', 'encoder.layers.7.layer_norm.weight', 'encoder.layers.8.attention.k_proj.bias', 'encoder.layers.8.attention.k_proj.weight', 'encoder.layers.8.attention.out_proj.bias', 'encoder.layers.8.attention.out_proj.weight', 'encoder.layers.8.attention.q_proj.bias', 'encoder.layers.8.attention.q_proj.weight', 'encoder.layers.8.attention.v_proj.bias', 'encoder.layers.8.attention.v_proj.weight', 'encoder.layers.8.feed_forward.intermediate_dense.bias', 'encoder.layers.8.feed_forward.intermediate_dense.weight', 'encoder.layers.8.feed_forward.output_dense.bias', 'encoder.layers.8.feed_forward.output_dense.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.8.layer_norm.bias', 'encoder.layers.8.layer_norm.weight', 'encoder.layers.9.attention.k_proj.bias', 'encoder.layers.9.attention.k_proj.weight', 'encoder.layers.9.attention.out_proj.bias', 'encoder.layers.9.attention.out_proj.weight', 'encoder.layers.9.attention.q_proj.bias', 'encoder.layers.9.attention.q_proj.weight', 'encoder.layers.9.attention.v_proj.bias', 'encoder.layers.9.attention.v_proj.weight', 'encoder.layers.9.feed_forward.intermediate_dense.bias', 'encoder.layers.9.feed_forward.intermediate_dense.weight', 'encoder.layers.9.feed_forward.output_dense.bias', 'encoder.layers.9.feed_forward.output_dense.weight', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.layer_norm.bias', 'encoder.layers.9.layer_norm.weight']
- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Test loss: 116.7412, Test accuracy: 0.8650
Macro F1-score: 0.8638
Model performance on Angry speech (in test): 
	Precision: 1.0000, Recall: 0.6800, F1_score: 0.8095
Model performance on Happy speech (in test): 
	Precision: 0.7460, Recall: 0.9400, F1_score: 0.8319
Model performance on Neutral speech (in test): 
	Precision: 0.8305, Recall: 0.9800, F1_score: 0.8991
Model performance on Sad speech (in test): 
	Precision: 0.9773, Recall: 0.8600, F1_score: 0.9149

======================= This is fold_2 on de =======================

Load dataset: 
Loading cn train data: fold_2...
Preprocess cn fold_2 data for de model
Loading cn eval data: fold_2...
Preprocess cn fold_2 data for de model
Loading cn test data: fold_2...
Preprocess cn fold_2 data for de model
Use de model to add lora
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training loss: 580.6473, Training accuracy: 0.8719
Macro F1-score: 0.8717
Model performance on Angry speech (in training): 
	Precision: 0.8730, Recall: 0.8075, F1_score: 0.8390
Model performance on Happy speech (in training): 
	Precision: 0.8030, Recall: 0.8050, F1_score: 0.8040
Model performance on Neutral speech (in training): 
	Precision: 0.8451, Recall: 0.9275, F1_score: 0.8844
Model performance on Sad speech (in training): 
	Precision: 0.9718, Recall: 0.9475, F1_score: 0.9595

Eval Phase: 
Validation loss: 263.3604, Validation accuracy: 0.6450
Macro F1-score: 0.5958
Model performance on Angry speech (in validation): 
	Precision: 0.5287, Recall: 0.9200, F1_score: 0.6715
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6250, Recall: 1.0000, F1_score: 0.7692
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
New best accuracy for layer 4 on epoch 1: 0.6450. Model saved.
Epoch 2/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  11%|█         | 177/1600 [00:10<01:20, 17.66it/s]Training:  25%|██▍       | 395/1600 [00:20<01:00, 20.05it/s]Training:  39%|███▉      | 630/1600 [00:30<00:44, 21.58it/s]Training:  55%|█████▍    | 874/1600 [00:40<00:32, 22.67it/s]Training:  70%|███████   | 1123/1600 [00:50<00:20, 23.47it/s]Training:  86%|████████▌ | 1378/1600 [01:00<00:09, 24.14it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 268/1600 [00:10<00:49, 26.77it/s]Training:  34%|███▎      | 537/1600 [00:20<00:39, 26.81it/s]Training:  50%|█████     | 808/1600 [00:30<00:29, 26.94it/s]Training:  67%|██████▋   | 1079/1600 [00:40<00:19, 26.62it/s]Training:  84%|████████▍ |Training loss: 202.6092, Training accuracy: 0.9525
Macro F1-score: 0.9524
Model performance on Angry speech (in training): 
	Precision: 0.9494, Recall: 0.9375, F1_score: 0.9434
Model performance on Happy speech (in training): 
	Precision: 0.9343, Recall: 0.9250, F1_score: 0.9296
Model performance on Neutral speech (in training): 
	Precision: 0.9487, Recall: 0.9700, F1_score: 0.9592
Model performance on Sad speech (in training): 
	Precision: 0.9775, Recall: 0.9775, F1_score: 0.9775

Eval Phase: 
Validation loss: 289.7069, Validation accuracy: 0.6250
Macro F1-score: 0.5662
Model performance on Angry speech (in validation): 
	Precision: 0.5165, Recall: 0.9400, F1_score: 0.6667
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1200, F1_score: 0.2143
Model performance on Neutral speech (in validation): 
	Precision: 0.6125, Recall: 0.9800, F1_score: 0.7538
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.4600, F1_score: 0.6301
Epoch 3/100

Training Phase:
Training loss: 106.6041, Training accuracy: 0.9781
Macro F1-score: 0.9781
Model performance on Angry speech (in training): 
	Precision: 0.9749, Recall: 0.9700, F1_score: 0.9724
Model performance on Happy speech (in training): 
	Precision: 0.9625, Recall: 0.9625, F1_score: 0.9625
Model performance on Neutral speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900
Model performance on Sad speech (in training): 
	Precision: 0.9851, Recall: 0.9900, F1_score: 0.9875

Eval Phase: 
Validation loss: 153.3020, Validation accuracy: 0.7700
Macro F1-score: 0.7611
Model performance on Angry speech (in validation): 
	Precision: 0.6351, Recall: 0.9400, F1_score: 0.7581
Model performance on Happy speech (in validation): 
	Precision: 0.9583, Recall: 0.4600, F1_score: 0.6216
Model performance on Neutral speech (in validation): 
	Precision: 0.7719, Recall: 0.8800, F1_score: 0.8224
Model performance on Sad speech (in validation): 
	Precision: 0.8889, Recall: 0.8000, F1_score: 0.8421
New best accuracy for layer 4 on epoch 3: 0.7700. Model saved.
Epoch 4/100

Training Phase:
 1341/1600 [00:50<00:09, 26.46it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▋        | 260/1600 [00:10<00:51, 25.99it/s]Training:  33%|███▎      | 522/1600 [00:20<00:41, 26.11it/s]Training:  49%|████▉     | 784/1600 [00:30<00:31, 26.02it/s]Training:  65%|██████▌   | 1044/1600 [00:40<00:21, 25.88it/s]Training:  82%|████████▏ | 1307/1600 [00:50<00:11, 26.01it/s]Training:  98%|█████████▊| 1571/1600 [01:00<00:01, 26.13it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 276/1600 [00:10<00:48, 27.53it/s]Training:  35%|███▍      | 556/160Training loss: 78.5642, Training accuracy: 0.9838
Macro F1-score: 0.9837
Model performance on Angry speech (in training): 
	Precision: 0.9727, Recall: 0.9800, F1_score: 0.9763
Model performance on Happy speech (in training): 
	Precision: 0.9773, Recall: 0.9675, F1_score: 0.9724
Model performance on Neutral speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963

Eval Phase: 
Validation loss: 243.8018, Validation accuracy: 0.7200
Macro F1-score: 0.7085
Model performance on Angry speech (in validation): 
	Precision: 0.6111, Recall: 0.8800, F1_score: 0.7213
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.4200, F1_score: 0.5915
Model performance on Neutral speech (in validation): 
	Precision: 0.6486, Recall: 0.9600, F1_score: 0.7742
Model performance on Sad speech (in validation): 
	Precision: 0.9394, Recall: 0.6200, F1_score: 0.7470
Epoch 5/100

Training Phase:
Training loss: 68.8529, Training accuracy: 0.9856
Macro F1-score: 0.9856
Model performance on Angry speech (in training): 
	Precision: 0.9826, Recall: 0.9900, F1_score: 0.9863
Model performance on Happy speech (in training): 
	Precision: 0.9824, Recall: 0.9750, F1_score: 0.9787
Model performance on Neutral speech (in training): 
	Precision: 0.9875, Recall: 0.9875, F1_score: 0.9875
Model performance on Sad speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900

Eval Phase: 
Validation loss: 272.2999, Validation accuracy: 0.7250
Macro F1-score: 0.7002
Model performance on Angry speech (in validation): 
	Precision: 0.5802, Recall: 0.9400, F1_score: 0.7176
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.3000, F1_score: 0.4615
Model performance on Neutral speech (in validation): 
	Precision: 0.7042, Recall: 1.0000, F1_score: 0.8264
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.6600, F1_score: 0.7952
Epoch 6/100

Training Phase:
0 [00:20<00:37, 27.80it/s]Training:  52%|█████▏    | 837/1600 [00:30<00:27, 27.93it/s]Training:  70%|██████▉   | 1118/1600 [00:40<00:17, 27.98it/s]Training:  88%|████████▊ | 1400/1600 [00:50<00:07, 28.03it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  18%|█▊        | 283/1600 [00:10<00:46, 28.24it/s]Training:  35%|███▌      | 566/1600 [00:20<00:37, 27.36it/s]Training:  52%|█████▏    | 834/1600 [00:30<00:28, 26.65it/s]Training:  68%|██████▊   | 1094/1600 [00:40<00:19, 26.37it/s]Training:  85%|████████▍ | 1356/1600 [00:51<00:09, 26.30it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|   Training loss: 74.6517, Training accuracy: 0.9856
Macro F1-score: 0.9856
Model performance on Angry speech (in training): 
	Precision: 0.9752, Recall: 0.9825, F1_score: 0.9788
Model performance on Happy speech (in training): 
	Precision: 0.9824, Recall: 0.9750, F1_score: 0.9787
Model performance on Neutral speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937

Eval Phase: 
Validation loss: 227.9981, Validation accuracy: 0.7600
Macro F1-score: 0.7516
Model performance on Angry speech (in validation): 
	Precision: 0.6479, Recall: 0.9200, F1_score: 0.7603
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.5200, F1_score: 0.6842
Model performance on Neutral speech (in validation): 
	Precision: 0.8421, Recall: 0.6400, F1_score: 0.7273
Model performance on Sad speech (in validation): 
	Precision: 0.7385, Recall: 0.9600, F1_score: 0.8348
Epoch 7/100

Training Phase:
       | 0/1600 [00:00<?, ?it/s]Training:  16%|█▋        | 261/1600 [00:10<00:51, 26.03it/s]Training:  33%|███▎      | 522/1600 [00:20<00:41, 25.78it/s]Training:  49%|████▉     | 783/1600 [00:30<00:31, 25.89it/s]Training:  65%|██████▌   | 1046/1600 [00:40<00:21, 26.01it/s]Training:  83%|████████▎ | 1321/1600 [00:50<00:10, 26.52it/s]Training: 100%|█████████▉| 1599/1600 [01:00<00:00, 26.93it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 279/1600 [00:10<00:47, 27.80it/s]Training:  35%|███▍      | 557/1600 [00:20<00:37, 27.79it/s]Training:  52%|█████▏    | 835/1600 [00:30<00:27, 27.75it/s]Training:  70%|██████▉   | 1112/1600 [00:40<00:17, 27.56it/s]Training:  87%|████████▋ | 1Training loss: 33.0272, Training accuracy: 0.9956
Macro F1-score: 0.9956
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9900, F1_score: 0.9925
Model performance on Happy speech (in training): 
	Precision: 0.9900, Recall: 0.9950, F1_score: 0.9925
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988

Eval Phase: 
Validation loss: 340.3856, Validation accuracy: 0.7000
Macro F1-score: 0.6735
Model performance on Angry speech (in validation): 
	Precision: 0.5529, Recall: 0.9400, F1_score: 0.6963
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.2600, F1_score: 0.4127
Model performance on Neutral speech (in validation): 
	Precision: 0.7455, Recall: 0.8200, F1_score: 0.7810
Model performance on Sad speech (in validation): 
	Precision: 0.8298, Recall: 0.7800, F1_score: 0.8041
Epoch 8/100

Training Phase:
Training loss: 52.0525, Training accuracy: 0.9912
Macro F1-score: 0.9913
Model performance on Angry speech (in training): 
	Precision: 0.9850, Recall: 0.9850, F1_score: 0.9850
Model performance on Happy speech (in training): 
	Precision: 0.9850, Recall: 0.9850, F1_score: 0.9850
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Validation loss: 450.5974, Validation accuracy: 0.6700
Macro F1-score: 0.5934
Model performance on Angry speech (in validation): 
	Precision: 0.5000, Recall: 1.0000, F1_score: 0.6667
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.8000, Recall: 0.8800, F1_score: 0.8381
Model performance on Sad speech (in validation): 
	Precision: 0.8864, Recall: 0.7800, F1_score: 0.8298
Epoch 9/100

Training Phase:
385/1600 [00:50<00:07, 27.04it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▋        | 264/1600 [00:10<00:50, 26.35it/s]Training:  33%|███▎      | 535/1600 [00:20<00:39, 26.76it/s]Training:  50%|█████     | 806/1600 [00:30<00:30, 26.34it/s]Training:  67%|██████▋   | 1071/1600 [00:40<00:20, 26.40it/s]Training:  84%|████████▎ | 1336/1600 [00:50<00:09, 26.43it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 269/1600 [00:10<00:49, 26.88it/s]Training:  34%|███▎      | 538/1600 [00:20<00:40, 26.42it/s]Training:  50%|█████     | 800/1600 [00:30<00:3Training loss: 21.1364, Training accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987

Eval Phase: 
Validation loss: 258.3029, Validation accuracy: 0.7600
Macro F1-score: 0.7492
Model performance on Angry speech (in validation): 
	Precision: 0.6410, Recall: 1.0000, F1_score: 0.7812
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.4600, F1_score: 0.6301
Model performance on Neutral speech (in validation): 
	Precision: 0.8372, Recall: 0.7200, F1_score: 0.7742
Model performance on Sad speech (in validation): 
	Precision: 0.7679, Recall: 0.8600, F1_score: 0.8113
Epoch 10/100

Training Phase:
Training loss: 43.0187, Training accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in training): 
	Precision: 0.9899, Recall: 0.9850, F1_score: 0.9875
Model performance on Happy speech (in training): 
	Precision: 0.9850, Recall: 0.9850, F1_score: 0.9850
Model performance on Neutral speech (in training): 
	Precision: 0.9876, Recall: 0.9925, F1_score: 0.9900
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Validation loss: 276.9765, Validation accuracy: 0.7500
Macro F1-score: 0.7283
Model performance on Angry speech (in validation): 
	Precision: 0.5882, Recall: 1.0000, F1_score: 0.7407
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.3200, F1_score: 0.4848
Model performance on Neutral speech (in validation): 
	Precision: 0.8036, Recall: 0.9000, F1_score: 0.8491
Model performance on Sad speech (in validation): 
	Precision: 0.9070, Recall: 0.7800, F1_score: 0.8387
Epoch 11/100

Training Phase:
0, 26.29it/s]Training:  66%|██████▋   | 1062/1600 [00:40<00:20, 26.05it/s]Training:  83%|████████▎ | 1323/1600 [00:50<00:10, 26.07it/s]Training: 100%|█████████▉| 1598/1600 [01:00<00:00, 26.52it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 268/1600 [00:10<00:49, 26.74it/s]Training:  34%|███▎      | 536/1600 [00:20<00:39, 26.68it/s]Training:  50%|█████     | 804/1600 [00:30<00:29, 26.69it/s]Training:  67%|██████▋   | 1073/1600 [00:40<00:19, 26.75it/s]Training:  84%|████████▍ | 1346/1600 [00:50<00:09, 26.93it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|         Training loss: 28.8230, Training accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 1.0000, F1_score: 0.9975
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925

Eval Phase: 
Validation loss: 270.8258, Validation accuracy: 0.7450
Macro F1-score: 0.7288
Model performance on Angry speech (in validation): 
	Precision: 0.5882, Recall: 1.0000, F1_score: 0.7407
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.3600, F1_score: 0.5294
Model performance on Neutral speech (in validation): 
	Precision: 0.8039, Recall: 0.8200, F1_score: 0.8119
Model performance on Sad speech (in validation): 
	Precision: 0.8696, Recall: 0.8000, F1_score: 0.8333
Epoch 12/100

Training Phase:
 | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 270/1600 [00:10<00:49, 26.99it/s]Training:  34%|███▍      | 540/1600 [00:20<00:39, 26.92it/s]Training:  51%|█████     | 810/1600 [00:30<00:29, 26.93it/s]Training:  68%|██████▊   | 1080/1600 [00:40<00:19, 26.82it/s]Training:  84%|████████▍ | 1351/1600 [00:50<00:09, 26.92it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 270/1600 [00:10<00:49, 26.90it/s]Training:  34%|███▍      | 540/1600 [00:20<00:39, 26.90it/s]Training:  51%|█████     | 810/1600 [00:30<00:29, 26.75it/s]Training:  68%|██████▊   | 1084/1600 [00:40<00:19, 26.97it/s]Training:  85%|████████▍ | 1358/1600 [00:50<00:08, 26.98it/s]                                                        Training loss: 30.6438, Training accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Happy speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 297.2789, Validation accuracy: 0.7650
Macro F1-score: 0.7432
Model performance on Angry speech (in validation): 
	Precision: 0.5904, Recall: 0.9800, F1_score: 0.7368
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.3200, F1_score: 0.4848
Model performance on Neutral speech (in validation): 
	Precision: 0.8776, Recall: 0.8600, F1_score: 0.8687
Model performance on Sad speech (in validation): 
	Precision: 0.8654, Recall: 0.9000, F1_score: 0.8824
Epoch 13/100

Training Phase:
Training loss: 20.0971, Training accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987
Model performance on Happy speech (in training): 
	Precision: 0.9876, Recall: 0.9925, F1_score: 0.9900
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987

Eval Phase: 
Validation loss: 358.3810, Validation accuracy: 0.7100
Macro F1-score: 0.6885
Model performance on Angry speech (in validation): 
	Precision: 0.5897, Recall: 0.9200, F1_score: 0.7188
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.3400, F1_score: 0.5075
Model performance on Neutral speech (in validation): 
	Precision: 0.6579, Recall: 1.0000, F1_score: 0.7937
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5800, F1_score: 0.7342
Validation loss does not decrease for 10 epochs. End training.
Model best accuracy on validation set: 0.7700

Test Phase: 
     Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 272/1600 [00:10<00:48, 27.18it/s]Training:  34%|███▍      | 544/1600 [00:20<00:38, 27.11it/s]Training:  51%|█████     | 818/1600 [00:30<00:28, 27.21it/s]Training:  68%|██████▊   | 1092/1600 [00:40<00:18, 26.93it/s]Training:  85%|████████▍ | 1358/1600 [00:50<00:09, 26.71it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]                                                Some weights of the model checkpoint at /work/tc062/tc062/zhan7721/saved_models/de were not used when initializing Wav2Vec2Model: ['encoder.layers.10.attention.k_proj.bias', 'encoder.layers.10.attention.k_proj.weight', 'encoder.layers.10.attention.out_proj.bias', 'encoder.layers.10.attention.out_proj.weight', 'encoder.layers.10.attention.q_proj.bias', 'encoder.layers.10.attention.q_proj.weight', 'encoder.layers.10.attention.v_proj.bias', 'encoder.layers.10.attention.v_proj.weight', 'encoder.layers.10.feed_forward.intermediate_dense.bias', 'encoder.layers.10.feed_forward.intermediate_dense.weight', 'encoder.layers.10.feed_forward.output_dense.bias', 'encoder.layers.10.feed_forward.output_dense.weight', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.10.layer_norm.bias', 'encoder.layers.10.layer_norm.weight', 'encoder.layers.11.attention.k_proj.bias', 'encoder.layers.11.attention.k_proj.weight', 'encoder.layers.11.attention.out_proj.bias', 'encoder.layers.11.attention.out_proj.weight', 'encoder.layers.11.attention.q_proj.bias', 'encoder.layers.11.attention.q_proj.weight', 'encoder.layers.11.attention.v_proj.bias', 'encoder.layers.11.attention.v_proj.weight', 'encoder.layers.11.feed_forward.intermediate_dense.bias', 'encoder.layers.11.feed_forward.intermediate_dense.weight', 'encoder.layers.11.feed_forward.output_dense.bias', 'encoder.layers.11.feed_forward.output_dense.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.11.layer_norm.bias', 'encoder.layers.11.layer_norm.weight', 'encoder.layers.5.attention.k_proj.bias', 'encoder.layers.5.attention.k_proj.weight', 'encoder.layers.5.attention.out_proj.bias', 'encoder.layers.5.attention.out_proj.weight', 'encoder.layers.5.attention.q_proj.bias', 'encoder.layers.5.attention.q_proj.weight', 'encoder.layers.5.attention.v_proj.bias', 'encoder.layers.5.attention.v_proj.weight', 'encoder.layers.5.feed_forward.intermediate_dense.bias', 'encoder.layers.5.feed_forward.intermediate_dense.weight', 'encoder.layers.5.feed_forward.output_dense.bias', 'encoder.layers.5.feed_forward.output_dense.weight', 'encoder.layers.5.final_layer_norm.bias', 'encoder.layers.5.final_layer_norm.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.6.attention.k_proj.bias', 'encoder.layers.6.attention.k_proj.weight', 'encoder.layers.6.attention.out_proj.bias', 'encoder.layers.6.attention.out_proj.weight', 'encoder.layers.6.attention.q_proj.bias', 'encoder.layers.6.attention.q_proj.weight', 'encoder.layers.6.attention.v_proj.bias', 'encoder.layers.6.attention.v_proj.weight', 'encoder.layers.6.feed_forward.intermediate_dense.bias', 'encoder.layers.6.feed_forward.intermediate_dense.weight', 'encoder.layers.6.feed_forward.output_dense.bias', 'encoder.layers.6.feed_forward.output_dense.weight', 'encoder.layers.6.final_layer_norm.bias', 'encoder.layers.6.final_layer_norm.weight', 'encoder.layers.6.layer_norm.bias', 'encoder.layers.6.layer_norm.weight', 'encoder.layers.7.attention.k_proj.bias', 'encoder.layers.7.attention.k_proj.weight', 'encoder.layers.7.attention.out_proj.bias', 'encoder.layers.7.attention.out_proj.weight', 'encoder.layers.7.attention.q_proj.bias', 'encoder.layers.7.attention.q_proj.weight', 'encoder.layers.7.attention.v_proj.bias', 'encoder.layers.7.attention.v_proj.weight', 'encoder.layers.7.feed_forward.intermediate_dense.bias', 'encoder.layers.7.feed_forward.intermediate_dense.weight', 'encoder.layers.7.feed_forward.output_dense.bias', 'encoder.layers.7.feed_forward.output_dense.weight', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.7.layer_norm.bias', 'encoder.layers.7.layer_norm.weight', 'encoder.layers.8.attention.k_proj.bias', 'encoder.layers.8.attention.k_proj.weight', 'encoder.layers.8.attention.out_proj.bias', 'encoder.layers.8.attention.out_proj.weight', 'encoder.layers.8.attention.q_proj.bias', 'encoder.layers.8.attention.q_proj.weight', 'encoder.layers.8.attention.v_proj.bias', 'encoder.layers.8.attention.v_proj.weight', 'encoder.layers.8.feed_forward.intermediate_dense.bias', 'encoder.layers.8.feed_forward.intermediate_dense.weight', 'encoder.layers.8.feed_forward.output_dense.bias', 'encoder.layers.8.feed_forward.output_dense.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.8.layer_norm.bias', 'encoder.layers.8.layer_norm.weight', 'encoder.layers.9.attention.k_proj.bias', 'encoder.layers.9.attention.k_proj.weight', 'encoder.layers.9.attention.out_proj.bias', 'encoder.layers.9.attention.out_proj.weight', 'encoder.layers.9.attention.q_proj.bias', 'encoder.layers.9.attention.q_proj.weight', 'encoder.layers.9.attention.v_proj.bias', 'encoder.layers.9.attention.v_proj.weight', 'encoder.layers.9.feed_forward.intermediate_dense.bias', 'encoder.layers.9.feed_forward.intermediate_dense.weight', 'encoder.layers.9.feed_forward.output_dense.bias', 'encoder.layers.9.feed_forward.output_dense.weight', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.layer_norm.bias', 'encoder.layers.9.layer_norm.weight']
- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Test loss: 176.0233, Test accuracy: 0.7450
Macro F1-score: 0.7215
Model performance on Angry speech (in test): 
	Precision: 0.5679, Recall: 0.9200, F1_score: 0.7023
Model performance on Happy speech (in test): 
	Precision: 0.8235, Recall: 0.2800, F1_score: 0.4179
Model performance on Neutral speech (in test): 
	Precision: 0.7966, Recall: 0.9400, F1_score: 0.8624
Model performance on Sad speech (in test): 
	Precision: 0.9767, Recall: 0.8400, F1_score: 0.9032

======================= This is fold_3 on de =======================

Load dataset: 
Loading cn train data: fold_3...
Preprocess cn fold_3 data for de model
Loading cn eval data: fold_3...
Preprocess cn fold_3 data for de model
Loading cn test data: fold_3...
Preprocess cn fold_3 data for de model
Use de model to add lora
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training loss: 674.8784, Training accuracy: 0.8313
Macro F1-score: 0.8306
Model performance on Angry speech (in training): 
	Precision: 0.7866, Recall: 0.7650, F1_score: 0.7757
Model performance on Happy speech (in training): 
	Precision: 0.7506, Recall: 0.7300, F1_score: 0.7402
Model performance on Neutral speech (in training): 
	Precision: 0.8449, Recall: 0.9125, F1_score: 0.8774
Model performance on Sad speech (in training): 
	Precision: 0.9410, Recall: 0.9175, F1_score: 0.9291

Eval Phase: 
Validation loss: 47.8123, Validation accuracy: 0.9350
Macro F1-score: 0.9350
Model performance on Angry speech (in validation): 
	Precision: 0.9792, Recall: 0.9400, F1_score: 0.9592
Model performance on Happy speech (in validation): 
	Precision: 0.8448, Recall: 0.9800, F1_score: 0.9074
Model performance on Neutral speech (in validation): 
	Precision: 0.9767, Recall: 0.8400, F1_score: 0.9032
Model performance on Sad speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
New best accuracy for layer 4 on epoch 1: 0.9350. Model saved.
Epoch 2/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  11%|█         | 177/1600 [00:10<01:20, 17.70it/s]Training:  25%|██▍       | 395/1600 [00:20<00:59, 20.11it/s]Training:  39%|███▉      | 625/1600 [00:30<00:45, 21.40it/s]Training:  54%|█████▍    | 864/1600 [00:40<00:32, 22.39it/s]Training:  70%|██████▉   | 1117/1600 [00:50<00:20, 23.42it/s]Training:  86%|████████▌ | 1372/1600 [01:00<00:09, 24.10it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 272/1600 [00:10<00:48, 27.19it/s]Training:  34%|███▍      | 544/1600 [00:20<00:39, 26.48it/s]Training:  51%|█████▏    | 820/1600 [00:30<00:28, 26.96it/s]Training:  68%|██████▊   | 1096/1600 [00:40<00:18, 26.99it/s]Training:  85%|████████▌Training loss: 303.3616, Training accuracy: 0.9263
Macro F1-score: 0.9259
Model performance on Angry speech (in training): 
	Precision: 0.8765, Recall: 0.8875, F1_score: 0.8820
Model performance on Happy speech (in training): 
	Precision: 0.8930, Recall: 0.8550, F1_score: 0.8736
Model performance on Neutral speech (in training): 
	Precision: 0.9420, Recall: 0.9750, F1_score: 0.9582
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9875, F1_score: 0.9900

Eval Phase: 
Validation loss: 65.4310, Validation accuracy: 0.9000
Macro F1-score: 0.8973
Model performance on Angry speech (in validation): 
	Precision: 0.9259, Recall: 1.0000, F1_score: 0.9615
Model performance on Happy speech (in validation): 
	Precision: 0.9574, Recall: 0.9000, F1_score: 0.9278
Model performance on Neutral speech (in validation): 
	Precision: 0.9231, Recall: 0.7200, F1_score: 0.8090
Model performance on Sad speech (in validation): 
	Precision: 0.8167, Recall: 0.9800, F1_score: 0.8909
Epoch 3/100

Training Phase:
Training loss: 178.9305, Training accuracy: 0.9600
Macro F1-score: 0.9599
Model performance on Angry speech (in training): 
	Precision: 0.9265, Recall: 0.9450, F1_score: 0.9356
Model performance on Happy speech (in training): 
	Precision: 0.9506, Recall: 0.9150, F1_score: 0.9325
Model performance on Neutral speech (in training): 
	Precision: 0.9729, Recall: 0.9875, F1_score: 0.9801
Model performance on Sad speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913

Eval Phase: 
Validation loss: 65.1506, Validation accuracy: 0.8750
Macro F1-score: 0.8735
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.8000, F1_score: 0.8889
Model performance on Happy speech (in validation): 
	Precision: 0.8033, Recall: 0.9800, F1_score: 0.8829
Model performance on Neutral speech (in validation): 
	Precision: 0.9487, Recall: 0.7400, F1_score: 0.8315
Model performance on Sad speech (in validation): 
	Precision: 0.8167, Recall: 0.9800, F1_score: 0.8909
Epoch 4/100

Training Phase:
 | 1367/1600 [00:50<00:08, 26.76it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▋        | 263/1600 [00:10<00:50, 26.28it/s]Training:  33%|███▎      | 528/1600 [00:20<00:40, 26.37it/s]Training:  50%|████▉     | 793/1600 [00:30<00:30, 26.25it/s]Training:  66%|██████▌   | 1057/1600 [00:40<00:20, 26.28it/s]Training:  83%|████████▎ | 1324/1600 [00:50<00:10, 26.42it/s]Training:  99%|█████████▉| 1591/1600 [01:00<00:00, 26.32it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 265/1600 [00:10<00:50, 26.46it/s]Training:  33%|███▎      | 530/1Training loss: 150.9783, Training accuracy: 0.9669
Macro F1-score: 0.9669
Model performance on Angry speech (in training): 
	Precision: 0.9412, Recall: 0.9600, F1_score: 0.9505
Model performance on Happy speech (in training): 
	Precision: 0.9541, Recall: 0.9350, F1_score: 0.9444
Model performance on Neutral speech (in training): 
	Precision: 0.9850, Recall: 0.9875, F1_score: 0.9863
Model performance on Sad speech (in training): 
	Precision: 0.9875, Recall: 0.9850, F1_score: 0.9862

Eval Phase: 
Validation loss: 77.0384, Validation accuracy: 0.8800
Macro F1-score: 0.8779
Model performance on Angry speech (in validation): 
	Precision: 0.9767, Recall: 0.8400, F1_score: 0.9032
Model performance on Happy speech (in validation): 
	Precision: 0.8033, Recall: 0.9800, F1_score: 0.8829
Model performance on Neutral speech (in validation): 
	Precision: 0.9474, Recall: 0.7200, F1_score: 0.8182
Model performance on Sad speech (in validation): 
	Precision: 0.8448, Recall: 0.9800, F1_score: 0.9074
Epoch 5/100

Training Phase:
600 [00:20<00:40, 26.23it/s]Training:  50%|████▉     | 795/1600 [00:30<00:30, 26.33it/s]Training:  66%|██████▋   | 1061/1600 [00:40<00:20, 26.42it/s]Training:  83%|████████▎ | 1327/1600 [00:50<00:10, 26.47it/s]Training: 100%|█████████▉| 1593/1600 [01:00<00:00, 26.40it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▋        | 263/1600 [00:10<00:50, 26.28it/s]Training:  33%|███▎      | 527/1600 [00:20<00:40, 26.34it/s]Training:  50%|████▉     | 794/1600 [00:30<00:30, 26.47it/s]Training:  66%|██████▋   | 1061/1600 [00:40<00:20, 26.47it/s]Training:  83%|████████▎ | 1326/1600 [00:50<00:10, 26.37it/s]Training:  99%|█████████▉| 1590/1600 [01:00<00:00, 26.36it/s]                        Training loss: 89.6277, Training accuracy: 0.9806
Macro F1-score: 0.9806
Model performance on Angry speech (in training): 
	Precision: 0.9698, Recall: 0.9625, F1_score: 0.9661
Model performance on Happy speech (in training): 
	Precision: 0.9651, Recall: 0.9675, F1_score: 0.9663
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963

Eval Phase: 
Validation loss: 72.9565, Validation accuracy: 0.8850
Macro F1-score: 0.8855
Model performance on Angry speech (in validation): 
	Precision: 0.9773, Recall: 0.8600, F1_score: 0.9149
Model performance on Happy speech (in validation): 
	Precision: 0.8033, Recall: 0.9800, F1_score: 0.8829
Model performance on Neutral speech (in validation): 
	Precision: 0.8600, Recall: 0.8600, F1_score: 0.8600
Model performance on Sad speech (in validation): 
	Precision: 0.9333, Recall: 0.8400, F1_score: 0.8842
Epoch 6/100

Training Phase:
Training loss: 103.3242, Training accuracy: 0.9788
Macro F1-score: 0.9788
Model performance on Angry speech (in training): 
	Precision: 0.9629, Recall: 0.9725, F1_score: 0.9677
Model performance on Happy speech (in training): 
	Precision: 0.9650, Recall: 0.9650, F1_score: 0.9650
Model performance on Neutral speech (in training): 
	Precision: 0.9949, Recall: 0.9825, F1_score: 0.9887
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938

Eval Phase: 
Validation loss: 83.9208, Validation accuracy: 0.9050
Macro F1-score: 0.9038
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8868, Recall: 0.9400, F1_score: 0.9126
Model performance on Neutral speech (in validation): 
	Precision: 0.9070, Recall: 0.7800, F1_score: 0.8387
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 7/100

Training Phase:
                                     Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 259/1600 [00:10<00:51, 25.88it/s]Training:  33%|███▎      | 526/1600 [00:20<00:40, 26.35it/s]Training:  50%|████▉     | 798/1600 [00:30<00:30, 26.73it/s]Training:  67%|██████▋   | 1075/1600 [00:40<00:19, 27.11it/s]Training:  84%|████████▍ | 1352/1600 [00:50<00:09, 27.14it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 270/1600 [00:10<00:49, 26.91it/s]Training:  34%|███▍      | 540/1600 [00:20<00:39, 26.95it/s]Training:  51%|█████     | 810/1600 [00:30<00:29, 26.94it/s]Training:  68%|██████▊   | 108Training loss: 50.8030, Training accuracy: 0.9875
Macro F1-score: 0.9875
Model performance on Angry speech (in training): 
	Precision: 0.9776, Recall: 0.9800, F1_score: 0.9788
Model performance on Happy speech (in training): 
	Precision: 0.9774, Recall: 0.9750, F1_score: 0.9762
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 80.4599, Validation accuracy: 0.8900
Macro F1-score: 0.8894
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.7400, F1_score: 0.8506
Model performance on Happy speech (in validation): 
	Precision: 0.7869, Recall: 0.9600, F1_score: 0.8649
Model performance on Neutral speech (in validation): 
	Precision: 0.8846, Recall: 0.9200, F1_score: 0.9020
Model performance on Sad speech (in validation): 
	Precision: 0.9400, Recall: 0.9400, F1_score: 0.9400
Epoch 8/100

Training Phase:
Training loss: 54.4986, Training accuracy: 0.9894
Macro F1-score: 0.9894
Model performance on Angry speech (in training): 
	Precision: 0.9850, Recall: 0.9875, F1_score: 0.9863
Model performance on Happy speech (in training): 
	Precision: 0.9850, Recall: 0.9850, F1_score: 0.9850
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9900, F1_score: 0.9925
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938

Eval Phase: 
Validation loss: 34.1262, Validation accuracy: 0.9650
Macro F1-score: 0.9649
Model performance on Angry speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Neutral speech (in validation): 
	Precision: 0.9583, Recall: 0.9200, F1_score: 0.9388
Model performance on Sad speech (in validation): 
	Precision: 0.9423, Recall: 0.9800, F1_score: 0.9608
New best accuracy for layer 4 on epoch 8: 0.9650. Model saved.
Epoch 9/100

Training Phase:
3/1600 [00:40<00:19, 27.08it/s]Training:  85%|████████▍ | 1356/1600 [00:50<00:09, 27.04it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▋        | 262/1600 [00:10<00:51, 26.11it/s]Training:  33%|███▎      | 533/1600 [00:20<00:40, 26.67it/s]Training:  50%|█████     | 804/1600 [00:30<00:29, 26.78it/s]Training:  67%|██████▋   | 1079/1600 [00:40<00:19, 27.06it/s]Training:  85%|████████▍ | 1357/1600 [00:50<00:08, 27.30it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 259/1600 [00:10<00:51, 25.84it/s]Training:  33%|███▎      | 527/1600 [00:Training loss: 42.0714, Training accuracy: 0.9912
Macro F1-score: 0.9912
Model performance on Angry speech (in training): 
	Precision: 0.9850, Recall: 0.9850, F1_score: 0.9850
Model performance on Happy speech (in training): 
	Precision: 0.9850, Recall: 0.9825, F1_score: 0.9837
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 1.0000, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987

Eval Phase: 
Validation loss: 76.1781, Validation accuracy: 0.8800
Macro F1-score: 0.8808
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9200, F1_score: 0.9583
Model performance on Happy speech (in validation): 
	Precision: 0.8136, Recall: 0.9600, F1_score: 0.8807
Model performance on Neutral speech (in validation): 
	Precision: 0.7857, Recall: 0.8800, F1_score: 0.8302
Model performance on Sad speech (in validation): 
	Precision: 0.9744, Recall: 0.7600, F1_score: 0.8539
Epoch 10/100

Training Phase:
Training loss: 41.0180, Training accuracy: 0.9919
Macro F1-score: 0.9919
Model performance on Angry speech (in training): 
	Precision: 0.9826, Recall: 0.9875, F1_score: 0.9850
Model performance on Happy speech (in training): 
	Precision: 0.9874, Recall: 0.9800, F1_score: 0.9837
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
20<00:40, 26.36it/s]Training:  50%|█████     | 800/1600 [00:30<00:29, 26.78it/s]Training:  67%|██████▋   | 1073/1600 [00:40<00:19, 26.88it/s]Training:  84%|████████▍ | 1344/1600 [00:50<00:09, 26.91it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 275/1600 [00:10<00:48, 27.41it/s]Training:  17%|█▋        | 275/1600 [00:20<00:48, 27.41it/s]Training:  34%|███▍      | 546/1600 [00:20<00:38, 27.20it/s]Training:  51%|█████     | 817/1600 [00:30<00:29, 26.98it/s]Training:  68%|██████▊   | 1085/1600 [00:40<00:19, 26.62it/s]Training:  84%|████████▍ | 1347/1600 [00:50<00:09, 26.45it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                Validation loss: 118.7932, Validation accuracy: 0.8450
Macro F1-score: 0.8457
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.6800, F1_score: 0.8095
Model performance on Happy speech (in validation): 
	Precision: 0.6714, Recall: 0.9400, F1_score: 0.7833
Model performance on Neutral speech (in validation): 
	Precision: 0.9286, Recall: 0.7800, F1_score: 0.8478
Model performance on Sad speech (in validation): 
	Precision: 0.9074, Recall: 0.9800, F1_score: 0.9423
Epoch 11/100

Training Phase:
Training loss: 44.1153, Training accuracy: 0.9919
Macro F1-score: 0.9919
Model performance on Angry speech (in training): 
	Precision: 0.9851, Recall: 0.9900, F1_score: 0.9875
Model performance on Happy speech (in training): 
	Precision: 0.9899, Recall: 0.9825, F1_score: 0.9862
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 68.9679, Validation accuracy: 0.9050
Macro F1-score: 0.9062
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.8400, F1_score: 0.9130
Model performance on Happy speech (in validation): 
	Precision: 0.7903, Recall: 0.9800, F1_score: 0.8750
Model performance on Neutral speech (in validation): 
	Precision: 0.9167, Recall: 0.8800, F1_score: 0.8980
Model performance on Sad speech (in validation): 
	Precision: 0.9583, Recall: 0.9200, F1_score: 0.9388
Epoch 12/100

Training Phase:
                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▋        | 263/1600 [00:10<00:50, 26.25it/s]Training:  33%|███▎      | 528/1600 [00:20<00:40, 26.35it/s]Training:  50%|████▉     | 793/1600 [00:30<00:30, 26.31it/s]Training:  66%|██████▌   | 1056/1600 [00:40<00:20, 26.08it/s]Training:  82%|████████▏ | 1316/1600 [00:50<00:10, 26.03it/s]Training:  99%|█████████▉| 1580/1600 [01:00<00:00, 26.15it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▋        | 262/1600 [00:10<00:51, 26.12it/s]Training:  33%|███▎      | 525/1600 [00:20<00:41, 26.22it/s]Training:  49%|████▉     | 789/1600 [00:30<00:30, 26.27it/s]Training:  66%|██████▌   | 1053/1600 [00:40<00:20, 26.3Training loss: 39.6884, Training accuracy: 0.9912
Macro F1-score: 0.9912
Model performance on Angry speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913
Model performance on Happy speech (in training): 
	Precision: 0.9874, Recall: 0.9825, F1_score: 0.9850
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950

Eval Phase: 
Validation loss: 66.5534, Validation accuracy: 0.9150
Macro F1-score: 0.9128
Model performance on Angry speech (in validation): 
	Precision: 0.9434, Recall: 1.0000, F1_score: 0.9709
Model performance on Happy speech (in validation): 
	Precision: 0.9388, Recall: 0.9200, F1_score: 0.9293
Model performance on Neutral speech (in validation): 
	Precision: 0.9268, Recall: 0.7600, F1_score: 0.8352
Model performance on Sad speech (in validation): 
	Precision: 0.8596, Recall: 0.9800, F1_score: 0.9159
Epoch 13/100

Training Phase:
Training loss: 38.0799, Training accuracy: 0.9912
Macro F1-score: 0.9912
Model performance on Angry speech (in training): 
	Precision: 0.9850, Recall: 0.9875, F1_score: 0.9863
Model performance on Happy speech (in training): 
	Precision: 0.9875, Recall: 0.9850, F1_score: 0.9862
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 85.7957, Validation accuracy: 0.9000
Macro F1-score: 0.9001
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.8200, F1_score: 0.9011
Model performance on Happy speech (in validation): 
	Precision: 0.8246, Recall: 0.9400, F1_score: 0.8785
Model performance on Neutral speech (in validation): 
	Precision: 0.8980, Recall: 0.8800, F1_score: 0.8889
Model performance on Sad speech (in validation): 
	Precision: 0.9057, Recall: 0.9600, F1_score: 0.9320
Epoch 14/100

Training Phase:
0it/s]Training:  82%|████████▎ | 1320/1600 [00:50<00:10, 26.44it/s]Training:  99%|█████████▉| 1591/1600 [01:00<00:00, 26.65it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 271/1600 [00:10<00:49, 27.08it/s]Training:  34%|███▍      | 542/1600 [00:20<00:39, 26.67it/s]Training:  50%|█████     | 806/1600 [00:30<00:30, 26.39it/s]Training:  67%|██████▋   | 1074/1600 [00:40<00:19, 26.55it/s]Training:  84%|████████▍ | 1342/1600 [00:50<00:09, 26.56it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 267/1600 [00:10<00:50, 26Training loss: 40.1749, Training accuracy: 0.9931
Macro F1-score: 0.9931
Model performance on Angry speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9900, F1_score: 0.9925
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963

Eval Phase: 
Validation loss: 69.6647, Validation accuracy: 0.8900
Macro F1-score: 0.8901
Model performance on Angry speech (in validation): 
	Precision: 0.9762, Recall: 0.8200, F1_score: 0.8913
Model performance on Happy speech (in validation): 
	Precision: 0.7869, Recall: 0.9600, F1_score: 0.8649
Model performance on Neutral speech (in validation): 
	Precision: 0.9111, Recall: 0.8200, F1_score: 0.8632
Model performance on Sad speech (in validation): 
	Precision: 0.9231, Recall: 0.9600, F1_score: 0.9412
Epoch 15/100

Training Phase:
Training loss: 35.3920, Training accuracy: 0.9925
Macro F1-score: 0.9925
Model performance on Angry speech (in training): 
	Precision: 0.9851, Recall: 0.9925, F1_score: 0.9888
Model performance on Happy speech (in training): 
	Precision: 0.9924, Recall: 0.9825, F1_score: 0.9874
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 1.0000, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962

Eval Phase: 
.62it/s]Training:  34%|███▎      | 538/1600 [00:20<00:39, 26.86it/s]Training:  51%|█████     | 810/1600 [00:30<00:29, 26.96it/s]Training:  51%|█████     | 810/1600 [00:40<00:29, 26.96it/s]Training:  67%|██████▋   | 1078/1600 [00:40<00:19, 26.84it/s]Training:  84%|████████▍ | 1345/1600 [00:50<00:09, 26.69it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 270/1600 [00:10<00:49, 26.93it/s]Training:  34%|███▍      | 544/1600 [00:20<00:38, 27.17it/s]Training:  51%|█████     | 818/1600 [00:30<00:28, 27.22it/s]Training:  68%|██████▊   | 1091/1600 [00:40<00:18, 27.18it/s]Training:  85%|████████▌ | 1363/1600 [00:50<00:08, 27.14it/s]                                                             EvaluValidation loss: 67.1304, Validation accuracy: 0.9200
Macro F1-score: 0.9187
Model performance on Angry speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in validation): 
	Precision: 0.9423, Recall: 0.9800, F1_score: 0.9608
Model performance on Neutral speech (in validation): 
	Precision: 0.9070, Recall: 0.7800, F1_score: 0.8387
Model performance on Sad speech (in validation): 
	Precision: 0.8545, Recall: 0.9400, F1_score: 0.8952
Epoch 16/100

Training Phase:
Training loss: 21.2722, Training accuracy: 0.9944
Macro F1-score: 0.9944
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 1.0000, F1_score: 0.9975
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9900, F1_score: 0.9925
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938

Eval Phase: 
Validation loss: 67.3148, Validation accuracy: 0.9200
Macro F1-score: 0.9202
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.8800, F1_score: 0.9362
Model performance on Happy speech (in validation): 
	Precision: 0.8596, Recall: 0.9800, F1_score: 0.9159
Model performance on Neutral speech (in validation): 
	Precision: 0.9167, Recall: 0.8800, F1_score: 0.8980
Model performance on Sad speech (in validation): 
	Precision: 0.9216, Recall: 0.9400, F1_score: 0.9307
Epoch 17/100

Training Phase:
ating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 274/1600 [00:10<00:48, 27.30it/s]Training:  34%|███▍      | 548/1600 [00:20<00:40, 26.08it/s]Training:  50%|█████     | 801/1600 [00:31<00:32, 24.64it/s]Training:  66%|██████▌   | 1056/1600 [00:42<00:21, 24.84it/s]Training:  82%|████████▏ | 1313/1600 [00:52<00:11, 25.12it/s]Training:  98%|█████████▊| 1575/1600 [01:02<00:00, 25.46it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 268/1600 [00:10<00:49, 26.71it/s]Training:  34%|███▎      | 536/1600 [00:20<00:39, 26.61it/s]Training:  50%|█████     | 802/1600 [00:30<00:30, 26.44it/s]TrainiTraining loss: 34.0349, Training accuracy: 0.9944
Macro F1-score: 0.9944
Model performance on Angry speech (in training): 
	Precision: 0.9875, Recall: 0.9900, F1_score: 0.9888
Model performance on Happy speech (in training): 
	Precision: 0.9900, Recall: 0.9875, F1_score: 0.9887
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 62.2112, Validation accuracy: 0.9200
Macro F1-score: 0.9202
Model performance on Angry speech (in validation): 
	Precision: 0.9767, Recall: 0.8400, F1_score: 0.9032
Model performance on Happy speech (in validation): 
	Precision: 0.8305, Recall: 0.9800, F1_score: 0.8991
Model performance on Neutral speech (in validation): 
	Precision: 0.9375, Recall: 0.9000, F1_score: 0.9184
Model performance on Sad speech (in validation): 
	Precision: 0.9600, Recall: 0.9600, F1_score: 0.9600
Epoch 18/100

Training Phase:
Training loss: 49.6715, Training accuracy: 0.9894
Macro F1-score: 0.9894
Model performance on Angry speech (in training): 
	Precision: 0.9849, Recall: 0.9800, F1_score: 0.9825
Model performance on Happy speech (in training): 
	Precision: 0.9850, Recall: 0.9875, F1_score: 0.9863
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938

Eval Phase: 
ng:  67%|██████▋   | 1067/1600 [00:40<00:20, 26.45it/s]Training:  83%|████████▎ | 1332/1600 [00:50<00:10, 26.25it/s]Training: 100%|█████████▉| 1592/1600 [01:00<00:00, 25.92it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 276/1600 [00:10<00:48, 27.51it/s]Training:  35%|███▍      | 555/1600 [00:20<00:37, 27.70it/s]Training:  35%|███▍      | 555/1600 [00:30<00:37, 27.70it/s]Training:  52%|█████▏    | 834/1600 [00:30<00:27, 27.55it/s]Training:  69%|██████▉   | 1109/1600 [00:40<00:17, 27.50it/s]Training:  87%|████████▋ | 1387/1600 [00:50<00:07, 27.58it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                          Validation loss: 51.3910, Validation accuracy: 0.9250
Macro F1-score: 0.9256
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.8400, F1_score: 0.9130
Model performance on Happy speech (in validation): 
	Precision: 0.8276, Recall: 0.9600, F1_score: 0.8889
Model performance on Neutral speech (in validation): 
	Precision: 0.9216, Recall: 0.9400, F1_score: 0.9307
Model performance on Sad speech (in validation): 
	Precision: 0.9796, Recall: 0.9600, F1_score: 0.9697
Validation loss does not decrease for 10 epochs. End training.
Model best accuracy on validation set: 0.9650

Test Phase: 
                         Testing:   0%|          | 0/200 [00:00<?, ?it/s]                                                Some weights of the model checkpoint at /work/tc062/tc062/zhan7721/saved_models/de were not used when initializing Wav2Vec2Model: ['encoder.layers.10.attention.k_proj.bias', 'encoder.layers.10.attention.k_proj.weight', 'encoder.layers.10.attention.out_proj.bias', 'encoder.layers.10.attention.out_proj.weight', 'encoder.layers.10.attention.q_proj.bias', 'encoder.layers.10.attention.q_proj.weight', 'encoder.layers.10.attention.v_proj.bias', 'encoder.layers.10.attention.v_proj.weight', 'encoder.layers.10.feed_forward.intermediate_dense.bias', 'encoder.layers.10.feed_forward.intermediate_dense.weight', 'encoder.layers.10.feed_forward.output_dense.bias', 'encoder.layers.10.feed_forward.output_dense.weight', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.10.layer_norm.bias', 'encoder.layers.10.layer_norm.weight', 'encoder.layers.11.attention.k_proj.bias', 'encoder.layers.11.attention.k_proj.weight', 'encoder.layers.11.attention.out_proj.bias', 'encoder.layers.11.attention.out_proj.weight', 'encoder.layers.11.attention.q_proj.bias', 'encoder.layers.11.attention.q_proj.weight', 'encoder.layers.11.attention.v_proj.bias', 'encoder.layers.11.attention.v_proj.weight', 'encoder.layers.11.feed_forward.intermediate_dense.bias', 'encoder.layers.11.feed_forward.intermediate_dense.weight', 'encoder.layers.11.feed_forward.output_dense.bias', 'encoder.layers.11.feed_forward.output_dense.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.11.layer_norm.bias', 'encoder.layers.11.layer_norm.weight', 'encoder.layers.5.attention.k_proj.bias', 'encoder.layers.5.attention.k_proj.weight', 'encoder.layers.5.attention.out_proj.bias', 'encoder.layers.5.attention.out_proj.weight', 'encoder.layers.5.attention.q_proj.bias', 'encoder.layers.5.attention.q_proj.weight', 'encoder.layers.5.attention.v_proj.bias', 'encoder.layers.5.attention.v_proj.weight', 'encoder.layers.5.feed_forward.intermediate_dense.bias', 'encoder.layers.5.feed_forward.intermediate_dense.weight', 'encoder.layers.5.feed_forward.output_dense.bias', 'encoder.layers.5.feed_forward.output_dense.weight', 'encoder.layers.5.final_layer_norm.bias', 'encoder.layers.5.final_layer_norm.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.6.attention.k_proj.bias', 'encoder.layers.6.attention.k_proj.weight', 'encoder.layers.6.attention.out_proj.bias', 'encoder.layers.6.attention.out_proj.weight', 'encoder.layers.6.attention.q_proj.bias', 'encoder.layers.6.attention.q_proj.weight', 'encoder.layers.6.attention.v_proj.bias', 'encoder.layers.6.attention.v_proj.weight', 'encoder.layers.6.feed_forward.intermediate_dense.bias', 'encoder.layers.6.feed_forward.intermediate_dense.weight', 'encoder.layers.6.feed_forward.output_dense.bias', 'encoder.layers.6.feed_forward.output_dense.weight', 'encoder.layers.6.final_layer_norm.bias', 'encoder.layers.6.final_layer_norm.weight', 'encoder.layers.6.layer_norm.bias', 'encoder.layers.6.layer_norm.weight', 'encoder.layers.7.attention.k_proj.bias', 'encoder.layers.7.attention.k_proj.weight', 'encoder.layers.7.attention.out_proj.bias', 'encoder.layers.7.attention.out_proj.weight', 'encoder.layers.7.attention.q_proj.bias', 'encoder.layers.7.attention.q_proj.weight', 'encoder.layers.7.attention.v_proj.bias', 'encoder.layers.7.attention.v_proj.weight', 'encoder.layers.7.feed_forward.intermediate_dense.bias', 'encoder.layers.7.feed_forward.intermediate_dense.weight', 'encoder.layers.7.feed_forward.output_dense.bias', 'encoder.layers.7.feed_forward.output_dense.weight', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.7.layer_norm.bias', 'encoder.layers.7.layer_norm.weight', 'encoder.layers.8.attention.k_proj.bias', 'encoder.layers.8.attention.k_proj.weight', 'encoder.layers.8.attention.out_proj.bias', 'encoder.layers.8.attention.out_proj.weight', 'encoder.layers.8.attention.q_proj.bias', 'encoder.layers.8.attention.q_proj.weight', 'encoder.layers.8.attention.v_proj.bias', 'encoder.layers.8.attention.v_proj.weight', 'encoder.layers.8.feed_forward.intermediate_dense.bias', 'encoder.layers.8.feed_forward.intermediate_dense.weight', 'encoder.layers.8.feed_forward.output_dense.bias', 'encoder.layers.8.feed_forward.output_dense.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.8.layer_norm.bias', 'encoder.layers.8.layer_norm.weight', 'encoder.layers.9.attention.k_proj.bias', 'encoder.layers.9.attention.k_proj.weight', 'encoder.layers.9.attention.out_proj.bias', 'encoder.layers.9.attention.out_proj.weight', 'encoder.layers.9.attention.q_proj.bias', 'encoder.layers.9.attention.q_proj.weight', 'encoder.layers.9.attention.v_proj.bias', 'encoder.layers.9.attention.v_proj.weight', 'encoder.layers.9.feed_forward.intermediate_dense.bias', 'encoder.layers.9.feed_forward.intermediate_dense.weight', 'encoder.layers.9.feed_forward.output_dense.bias', 'encoder.layers.9.feed_forward.output_dense.weight', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.layer_norm.bias', 'encoder.layers.9.layer_norm.weight']
- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Test loss: 39.1864, Test accuracy: 0.9400
Macro F1-score: 0.9402
Model performance on Angry speech (in test): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Happy speech (in test): 
	Precision: 0.9600, Recall: 0.9600, F1_score: 0.9600
Model performance on Neutral speech (in test): 
	Precision: 0.9167, Recall: 0.8800, F1_score: 0.8980
Model performance on Sad speech (in test): 
	Precision: 0.8889, Recall: 0.9600, F1_score: 0.9231

======================= This is fold_4 on de =======================

Load dataset: 
Loading cn train data: fold_4...
Preprocess cn fold_4 data for de model
Loading cn eval data: fold_4...
Preprocess cn fold_4 data for de model
Loading cn test data: fold_4...
Preprocess cn fold_4 data for de model
Use de model to add lora
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training loss: 510.8577, Training accuracy: 0.8762
Macro F1-score: 0.8761
Model performance on Angry speech (in training): 
	Precision: 0.8321, Recall: 0.8550, F1_score: 0.8434
Model performance on Happy speech (in training): 
	Precision: 0.8260, Recall: 0.7950, F1_score: 0.8102
Model performance on Neutral speech (in training): 
	Precision: 0.8966, Recall: 0.9325, F1_score: 0.9142
Model performance on Sad speech (in training): 
	Precision: 0.9510, Recall: 0.9225, F1_score: 0.9365

Eval Phase: 
Validation loss: 41.1755, Validation accuracy: 0.9100
Macro F1-score: 0.9085
Model performance on Angry speech (in validation): 
	Precision: 0.9250, Recall: 0.7400, F1_score: 0.8222
Model performance on Happy speech (in validation): 
	Precision: 0.8103, Recall: 0.9400, F1_score: 0.8704
Model performance on Neutral speech (in validation): 
	Precision: 0.9245, Recall: 0.9800, F1_score: 0.9515
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
New best accuracy for layer 4 on epoch 1: 0.9100. Model saved.
Epoch 2/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  10%|█         | 168/1600 [00:10<01:25, 16.65it/s]Training:  23%|██▎       | 375/1600 [00:20<01:04, 18.99it/s]Training:  38%|███▊      | 611/1600 [00:30<00:46, 21.06it/s]Training:  54%|█████▎    | 858/1600 [00:40<00:33, 22.47it/s]Training:  69%|██████▉   | 1105/1600 [00:50<00:21, 23.24it/s]Training:  85%|████████▍ | 1355/1600 [01:00<00:10, 23.78it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  18%|█▊        | 284/1600 [00:10<00:46, 28.33it/s]Training:  36%|███▌      | 568/1600 [00:20<00:38, 27.01it/s]Training:  53%|█████▎    | 844/1600 [00:30<00:27, 27.26it/s]Training:  70%|███████   | 1120/1600 [00:41<00:17, 27.02it/s]Training:  87%|████████▋Training loss: 218.8863, Training accuracy: 0.9506
Macro F1-score: 0.9506
Model performance on Angry speech (in training): 
	Precision: 0.9193, Recall: 0.9400, F1_score: 0.9295
Model performance on Happy speech (in training): 
	Precision: 0.9404, Recall: 0.9075, F1_score: 0.9237
Model performance on Neutral speech (in training): 
	Precision: 0.9563, Recall: 0.9850, F1_score: 0.9704
Model performance on Sad speech (in training): 
	Precision: 0.9873, Recall: 0.9700, F1_score: 0.9786

Eval Phase: 
Validation loss: 94.5630, Validation accuracy: 0.8100
Macro F1-score: 0.8113
Model performance on Angry speech (in validation): 
	Precision: 0.8810, Recall: 0.7400, F1_score: 0.8043
Model performance on Happy speech (in validation): 
	Precision: 0.5875, Recall: 0.9400, F1_score: 0.7231
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.5600, F1_score: 0.7179
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 3/100

Training Phase:
Training loss: 140.5392, Training accuracy: 0.9694
Macro F1-score: 0.9694
Model performance on Angry speech (in training): 
	Precision: 0.9386, Recall: 0.9550, F1_score: 0.9467
Model performance on Happy speech (in training): 
	Precision: 0.9517, Recall: 0.9350, F1_score: 0.9433
Model performance on Neutral speech (in training): 
	Precision: 0.9900, Recall: 0.9950, F1_score: 0.9925
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9925, F1_score: 0.9950

Eval Phase: 
Validation loss: 56.9216, Validation accuracy: 0.9150
Macro F1-score: 0.9114
Model performance on Angry speech (in validation): 
	Precision: 0.9722, Recall: 0.7000, F1_score: 0.8140
Model performance on Happy speech (in validation): 
	Precision: 0.8596, Recall: 0.9800, F1_score: 0.9159
Model performance on Neutral speech (in validation): 
	Precision: 0.8621, Recall: 1.0000, F1_score: 0.9259
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
New best accuracy for layer 4 on epoch 3: 0.9150. Model saved.
Epoch 4/100

Training Phase:
 | 1398/1600 [00:51<00:07, 27.28it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 267/1600 [00:10<00:50, 26.64it/s]Training:  34%|███▎      | 536/1600 [00:20<00:39, 26.78it/s]Training:  51%|█████     | 816/1600 [00:30<00:28, 27.31it/s]Training:  68%|██████▊   | 1096/1600 [00:40<00:18, 27.27it/s]Training:  86%|████████▌ | 1369/1600 [00:50<00:08, 26.83it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 268/1600 [00:10<00:49, 26.72it/s]Training:  34%|███▍      | 542/1600 [00:20<00:39, 27.12it/s]Training:  51%|█████▏    | 822/1600 [00:3Training loss: 79.6501, Training accuracy: 0.9856
Macro F1-score: 0.9856
Model performance on Angry speech (in training): 
	Precision: 0.9751, Recall: 0.9775, F1_score: 0.9763
Model performance on Happy speech (in training): 
	Precision: 0.9774, Recall: 0.9725, F1_score: 0.9749
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9975, F1_score: 0.9950

Eval Phase: 
Validation loss: 52.6129, Validation accuracy: 0.8950
Macro F1-score: 0.8956
Model performance on Angry speech (in validation): 
	Precision: 0.9286, Recall: 0.7800, F1_score: 0.8478
Model performance on Happy speech (in validation): 
	Precision: 0.7833, Recall: 0.9400, F1_score: 0.8545
Model performance on Neutral speech (in validation): 
	Precision: 0.9020, Recall: 0.9200, F1_score: 0.9109
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9400, F1_score: 0.9691
Epoch 5/100

Training Phase:
Training loss: 80.2858, Training accuracy: 0.9838
Macro F1-score: 0.9837
Model performance on Angry speech (in training): 
	Precision: 0.9776, Recall: 0.9800, F1_score: 0.9788
Model performance on Happy speech (in training): 
	Precision: 0.9799, Recall: 0.9750, F1_score: 0.9774
Model performance on Neutral speech (in training): 
	Precision: 0.9875, Recall: 0.9875, F1_score: 0.9875
Model performance on Sad speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913

Eval Phase: 
Validation loss: 60.3386, Validation accuracy: 0.8800
Macro F1-score: 0.8813
Model performance on Angry speech (in validation): 
	Precision: 0.9211, Recall: 0.7000, F1_score: 0.7955
Model performance on Happy speech (in validation): 
	Precision: 0.7015, Recall: 0.9400, F1_score: 0.8034
Model performance on Neutral speech (in validation): 
	Precision: 0.9778, Recall: 0.8800, F1_score: 0.9263
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 6/100

Training Phase:
0<00:28, 27.51it/s]Training:  69%|██████▉   | 1102/1600 [00:40<00:18, 27.44it/s]Training:  86%|████████▌ | 1376/1600 [00:50<00:08, 26.92it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 269/1600 [00:10<00:49, 26.82it/s]Training:  34%|███▍      | 545/1600 [00:20<00:38, 27.23it/s]Training:  51%|█████▏    | 821/1600 [00:30<00:28, 27.36it/s]Training:  69%|██████▊   | 1099/1600 [00:40<00:18, 27.53it/s]Training:  69%|██████▊   | 1099/1600 [00:50<00:18, 27.53it/s]Training:  86%|████████▌ | 1368/1600 [00:50<00:08, 27.10it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|       Training loss: 56.7069, Training accuracy: 0.9894
Macro F1-score: 0.9894
Model performance on Angry speech (in training): 
	Precision: 0.9777, Recall: 0.9850, F1_score: 0.9813
Model performance on Happy speech (in training): 
	Precision: 0.9874, Recall: 0.9800, F1_score: 0.9837
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Validation loss: 58.1972, Validation accuracy: 0.8950
Macro F1-score: 0.8932
Model performance on Angry speech (in validation): 
	Precision: 0.9706, Recall: 0.6600, F1_score: 0.7857
Model performance on Happy speech (in validation): 
	Precision: 0.7313, Recall: 0.9800, F1_score: 0.8376
Model performance on Neutral speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 7/100

Training Phase:
   | 0/1600 [00:00<?, ?it/s]Training:  16%|█▋        | 263/1600 [00:10<00:50, 26.27it/s]Training:  33%|███▎      | 526/1600 [00:20<00:40, 26.28it/s]Training:  49%|████▉     | 789/1600 [00:30<00:31, 26.16it/s]Training:  66%|██████▌   | 1050/1600 [00:40<00:21, 26.13it/s]Training:  82%|████████▏ | 1313/1600 [00:50<00:10, 26.16it/s]Training:  98%|█████████▊| 1576/1600 [01:00<00:00, 26.08it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▋        | 261/1600 [00:10<00:51, 25.99it/s]Training:  33%|███▎      | 523/1600 [00:20<00:41, 26.06it/s]Training:  49%|████▉     | 789/1600 [00:30<00:30, 26.30it/s]Training:  66%|██████▌   | 1055/1600 [00:40<00:20, 26.33it/s]Training:  82%|████████▏ | 1319/16Training loss: 40.7178, Training accuracy: 0.9881
Macro F1-score: 0.9881
Model performance on Angry speech (in training): 
	Precision: 0.9774, Recall: 0.9750, F1_score: 0.9762
Model performance on Happy speech (in training): 
	Precision: 0.9751, Recall: 0.9775, F1_score: 0.9763
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 50.9621, Validation accuracy: 0.9050
Macro F1-score: 0.9057
Model performance on Angry speech (in validation): 
	Precision: 0.9744, Recall: 0.7600, F1_score: 0.8539
Model performance on Happy speech (in validation): 
	Precision: 0.7538, Recall: 0.9800, F1_score: 0.8522
Model performance on Neutral speech (in validation): 
	Precision: 0.9565, Recall: 0.8800, F1_score: 0.9167
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 8/100

Training Phase:
Training loss: 46.6773, Training accuracy: 0.9888
Macro F1-score: 0.9887
Model performance on Angry speech (in training): 
	Precision: 0.9775, Recall: 0.9775, F1_score: 0.9775
Model performance on Happy speech (in training): 
	Precision: 0.9799, Recall: 0.9775, F1_score: 0.9787
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 42.5274, Validation accuracy: 0.9250
Macro F1-score: 0.9262
Model performance on Angry speech (in validation): 
	Precision: 0.9333, Recall: 0.8400, F1_score: 0.8842
Model performance on Happy speech (in validation): 
	Precision: 0.7966, Recall: 0.9400, F1_score: 0.8624
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.9200, F1_score: 0.9583
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
New best accuracy for layer 4 on epoch 8: 0.9250. Model saved.
Epoch 9/100

Training Phase:
00 [00:50<00:10, 26.33it/s]Training:  99%|█████████▉| 1589/1600 [01:00<00:00, 26.54it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 268/1600 [00:10<00:49, 26.76it/s]Training:  34%|███▎      | 536/1600 [00:20<00:40, 26.51it/s]Training:  50%|█████     | 802/1600 [00:30<00:30, 26.50it/s]Training:  67%|██████▋   | 1072/1600 [00:40<00:19, 26.67it/s]Training:  84%|████████▍ | 1342/1600 [00:51<00:09, 26.01it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 268/1600 [00:10<00:49, 26.72it/s]Training:  34%|███▎      | 536/1600 [00:20Training loss: 48.1883, Training accuracy: 0.9906
Macro F1-score: 0.9906
Model performance on Angry speech (in training): 
	Precision: 0.9900, Recall: 0.9875, F1_score: 0.9887
Model performance on Happy speech (in training): 
	Precision: 0.9851, Recall: 0.9900, F1_score: 0.9875
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9900, F1_score: 0.9925

Eval Phase: 
Validation loss: 42.7472, Validation accuracy: 0.9400
Macro F1-score: 0.9400
Model performance on Angry speech (in validation): 
	Precision: 0.9767, Recall: 0.8400, F1_score: 0.9032
Model performance on Happy speech (in validation): 
	Precision: 0.8448, Recall: 0.9800, F1_score: 0.9074
Model performance on Neutral speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
New best accuracy for layer 4 on epoch 9: 0.9400. Model saved.
Epoch 10/100

Training Phase:
<00:39, 26.61it/s]Training:  50%|█████     | 808/1600 [00:30<00:29, 26.84it/s]Training:  68%|██████▊   | 1080/1600 [00:40<00:19, 26.92it/s]Training:  68%|██████▊   | 1080/1600 [00:50<00:19, 26.92it/s]Training:  84%|████████▍ | 1347/1600 [00:50<00:09, 26.80it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▋        | 261/1600 [00:10<00:51, 26.07it/s]Training:  33%|███▎      | 522/1600 [00:20<00:41, 26.05it/s]Training:  49%|████▉     | 785/1600 [00:30<00:31, 26.13it/s]Training:  66%|██████▌   | 1049/1600 [00:40<00:21, 26.23it/s]Training:  82%|████████▏ | 1313/1600 [00:50<00:10, 26.23it/s]Training:  98%|█████████▊| 1576/1600 [01:00<00:00, 26.13it/s]                                        Training loss: 26.3241, Training accuracy: 0.9944
Macro F1-score: 0.9944
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925

Eval Phase: 
Validation loss: 260.2245, Validation accuracy: 0.6950
Macro F1-score: 0.6801
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.3000, F1_score: 0.4615
Model performance on Happy speech (in validation): 
	Precision: 0.4587, Recall: 1.0000, F1_score: 0.6289
Model performance on Neutral speech (in validation): 
	Precision: 0.9600, Recall: 0.4800, F1_score: 0.6400
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 11/100

Training Phase:
Training loss: 34.6518, Training accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 1.0000, F1_score: 0.9975

Eval Phase: 
Validation loss: 112.9529, Validation accuracy: 0.8650
Macro F1-score: 0.8667
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.6800, F1_score: 0.8095
Model performance on Happy speech (in validation): 
	Precision: 0.6667, Recall: 1.0000, F1_score: 0.8000
Model performance on Neutral speech (in validation): 
	Precision: 0.9512, Recall: 0.7800, F1_score: 0.8571
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Validation loss does not decrease for 10 epochs. End training.
Model best accuracy on validation set: 0.9400

Test Phase: 
Test loss: 51.9879, Test accuracy: 0.9200
Macro F1-score: 0.9192
Model performance on Angry speech (in test): 
	Precision: 0.9750, Recall: 0.7800, F1_score: 0.8667
Model performance on Happy speech (in test): 
	Precision: 0.8167, Recall: 0.9800, F1_score: 0.8909
Model performance on Neutral speech (in test): 
	Precision: 0.9388, Recall: 0.9200, F1_score: 0.9293
Model performance on Sad speech (in test): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901

de, all folds accuracy: ['0.7100', '0.8650', '0.7450', '0.9400', '0.9200']
de, all folds emo precision: {'Angry': ['0.6949', '1.0000', '0.5679', '1.0000', '0.9750'], 'Happy': ['0.5424', '0.7460', '0.8235', '0.9600', '0.8167'], 'Neutral': ['1.0000', '0.8305', '0.7966', '0.9167', '0.9388'], 'Sad': ['0.7759', '0.9773', '0.9767', '0.8889', '0.9804']}
de, all folds emo recall: {'Angry': ['0.8200', '0.6800', '0.9200', '0.9600', '0.7800'], 'Happy': ['0.6400', '0.9400', '0.2800', '0.9600', '0.9800'], 'Neutral': ['0.4800', '0.9800', '0.9400', '0.8800', '0.9200'], 'Sad': ['0.9000', '0.8600', '0.8400', '0.9600', '1.0000']}
de, all folds emo f1score: {'Angry': ['0.7523', '0.8095', '0.7023', '0.9796', '0.8667'], 'Happy': ['0.5872', '0.8319', '0.4179', '0.9600', '0.8909'], 'Neutral': ['0.6486', '0.8991', '0.8624', '0.8980', '0.9293'], 'Sad': ['0.8333', '0.9149', '0.9032', '0.9231', '0.9901']}
                     Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▋        | 261/1600 [00:10<00:51, 26.09it/s]Training:  33%|███▎      | 527/1600 [00:20<00:40, 26.34it/s]Training:  50%|████▉     | 793/1600 [00:30<00:30, 26.32it/s]Training:  67%|██████▋   | 1069/1600 [00:40<00:19, 26.81it/s]Training:  84%|████████▍ | 1345/1600 [00:50<00:09, 26.39it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]                                                ------------------NEXT SCRIPT: RUNNER_CN, current setting----------------------
/work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Matplotlib created a temporary cache directory at /dev/shm/zhan7721_5912053/matplotlib-z60s42zd because the default path (/home/tc062/tc062/zhan7721/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Some weights of the model checkpoint at /work/tc062/tc062/zhan7721/saved_models/de were not used when initializing Wav2Vec2Model: ['encoder.layers.10.attention.k_proj.bias', 'encoder.layers.10.attention.k_proj.weight', 'encoder.layers.10.attention.out_proj.bias', 'encoder.layers.10.attention.out_proj.weight', 'encoder.layers.10.attention.q_proj.bias', 'encoder.layers.10.attention.q_proj.weight', 'encoder.layers.10.attention.v_proj.bias', 'encoder.layers.10.attention.v_proj.weight', 'encoder.layers.10.feed_forward.intermediate_dense.bias', 'encoder.layers.10.feed_forward.intermediate_dense.weight', 'encoder.layers.10.feed_forward.output_dense.bias', 'encoder.layers.10.feed_forward.output_dense.weight', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.10.layer_norm.bias', 'encoder.layers.10.layer_norm.weight', 'encoder.layers.11.attention.k_proj.bias', 'encoder.layers.11.attention.k_proj.weight', 'encoder.layers.11.attention.out_proj.bias', 'encoder.layers.11.attention.out_proj.weight', 'encoder.layers.11.attention.q_proj.bias', 'encoder.layers.11.attention.q_proj.weight', 'encoder.layers.11.attention.v_proj.bias', 'encoder.layers.11.attention.v_proj.weight', 'encoder.layers.11.feed_forward.intermediate_dense.bias', 'encoder.layers.11.feed_forward.intermediate_dense.weight', 'encoder.layers.11.feed_forward.output_dense.bias', 'encoder.layers.11.feed_forward.output_dense.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.11.layer_norm.bias', 'encoder.layers.11.layer_norm.weight', 'encoder.layers.5.attention.k_proj.bias', 'encoder.layers.5.attention.k_proj.weight', 'encoder.layers.5.attention.out_proj.bias', 'encoder.layers.5.attention.out_proj.weight', 'encoder.layers.5.attention.q_proj.bias', 'encoder.layers.5.attention.q_proj.weight', 'encoder.layers.5.attention.v_proj.bias', 'encoder.layers.5.attention.v_proj.weight', 'encoder.layers.5.feed_forward.intermediate_dense.bias', 'encoder.layers.5.feed_forward.intermediate_dense.weight', 'encoder.layers.5.feed_forward.output_dense.bias', 'encoder.layers.5.feed_forward.output_dense.weight', 'encoder.layers.5.final_layer_norm.bias', 'encoder.layers.5.final_layer_norm.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.6.attention.k_proj.bias', 'encoder.layers.6.attention.k_proj.weight', 'encoder.layers.6.attention.out_proj.bias', 'encoder.layers.6.attention.out_proj.weight', 'encoder.layers.6.attention.q_proj.bias', 'encoder.layers.6.attention.q_proj.weight', 'encoder.layers.6.attention.v_proj.bias', 'encoder.layers.6.attention.v_proj.weight', 'encoder.layers.6.feed_forward.intermediate_dense.bias', 'encoder.layers.6.feed_forward.intermediate_dense.weight', 'encoder.layers.6.feed_forward.output_dense.bias', 'encoder.layers.6.feed_forward.output_dense.weight', 'encoder.layers.6.final_layer_norm.bias', 'encoder.layers.6.final_layer_norm.weight', 'encoder.layers.6.layer_norm.bias', 'encoder.layers.6.layer_norm.weight', 'encoder.layers.7.attention.k_proj.bias', 'encoder.layers.7.attention.k_proj.weight', 'encoder.layers.7.attention.out_proj.bias', 'encoder.layers.7.attention.out_proj.weight', 'encoder.layers.7.attention.q_proj.bias', 'encoder.layers.7.attention.q_proj.weight', 'encoder.layers.7.attention.v_proj.bias', 'encoder.layers.7.attention.v_proj.weight', 'encoder.layers.7.feed_forward.intermediate_dense.bias', 'encoder.layers.7.feed_forward.intermediate_dense.weight', 'encoder.layers.7.feed_forward.output_dense.bias', 'encoder.layers.7.feed_forward.output_dense.weight', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.7.layer_norm.bias', 'encoder.layers.7.layer_norm.weight', 'encoder.layers.8.attention.k_proj.bias', 'encoder.layers.8.attention.k_proj.weight', 'encoder.layers.8.attention.out_proj.bias', 'encoder.layers.8.attention.out_proj.weight', 'encoder.layers.8.attention.q_proj.bias', 'encoder.layers.8.attention.q_proj.weight', 'encoder.layers.8.attention.v_proj.bias', 'encoder.layers.8.attention.v_proj.weight', 'encoder.layers.8.feed_forward.intermediate_dense.bias', 'encoder.layers.8.feed_forward.intermediate_dense.weight', 'encoder.layers.8.feed_forward.output_dense.bias', 'encoder.layers.8.feed_forward.output_dense.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.8.layer_norm.bias', 'encoder.layers.8.layer_norm.weight', 'encoder.layers.9.attention.k_proj.bias', 'encoder.layers.9.attention.k_proj.weight', 'encoder.layers.9.attention.out_proj.bias', 'encoder.layers.9.attention.out_proj.weight', 'encoder.layers.9.attention.q_proj.bias', 'encoder.layers.9.attention.q_proj.weight', 'encoder.layers.9.attention.v_proj.bias', 'encoder.layers.9.attention.v_proj.weight', 'encoder.layers.9.feed_forward.intermediate_dense.bias', 'encoder.layers.9.feed_forward.intermediate_dense.weight', 'encoder.layers.9.feed_forward.output_dense.bias', 'encoder.layers.9.feed_forward.output_dense.weight', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.layer_norm.bias', 'encoder.layers.9.layer_norm.weight']
- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).

======================= This is fold_0 on cn =======================

Load dataset: 
Loading de train data: fold_0...
Preprocess de fold_0 data for cn model
Loading de eval data: fold_0...
Preprocess de fold_0 data for cn model
Loading de test data: fold_0...
Preprocess de fold_0 data for cn model
Use cn model to add lora
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training loss: 1501.2177, Training accuracy: 0.5375
Macro F1-score: 0.4791
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 0.0175, F1_score: 0.0344
Model performance on Happy speech (in training): 
	Precision: 0.3837, Recall: 0.8250, F1_score: 0.5238
Model performance on Neutral speech (in training): 
	Precision: 0.7267, Recall: 0.5650, F1_score: 0.6357
Model performance on Sad speech (in training): 
	Precision: 0.7038, Recall: 0.7425, F1_score: 0.7226

Eval Phase: 
Validation loss: 105.2045, Validation accuracy: 0.6500
Macro F1-score: 0.5803
Model performance on Angry speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Happy speech (in validation): 
	Precision: 0.7719, Recall: 0.8800, F1_score: 0.8224
Model performance on Neutral speech (in validation): 
	Precision: 0.9737, Recall: 0.7400, F1_score: 0.8409
Model performance on Sad speech (in validation): 
	Precision: 0.4949, Recall: 0.9800, F1_score: 0.6577
New best accuracy for layer 4 on epoch 1: 0.6500. Model saved.
Epoch 2/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:   0%|          | 1/1600 [00:37<16:52:07, 37.98s/it]Training:   8%|▊         | 134/1600 [00:48<06:41,  3.65it/s] Training:  18%|█▊        | 293/1600 [00:58<03:04,  7.08it/s]Training:  29%|██▉       | 466/1600 [01:08<01:53, 10.00it/s]Training:  41%|████      | 659/1600 [01:18<01:14, 12.69it/s]Training:  54%|█████▍    | 862/1600 [01:28<00:49, 14.91it/s]Training:  67%|██████▋   | 1068/1600 [01:38<00:32, 16.58it/s]Training:  80%|███████▉  | 1275/1600 [01:48<00:18, 17.78it/s]Training:  93%|█████████▎| 1486/1600 [01:58<00:06, 18.74it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 233/1600 [00:10<00:58, 23.21it/s]Training:  29%|██▉       | 466/1600 [00:20<00:Training loss: 432.0087, Training accuracy: 0.9231
Macro F1-score: 0.9231
Model performance on Angry speech (in training): 
	Precision: 0.9369, Recall: 0.9275, F1_score: 0.9322
Model performance on Happy speech (in training): 
	Precision: 0.8824, Recall: 0.9000, F1_score: 0.8911
Model performance on Neutral speech (in training): 
	Precision: 0.9205, Recall: 0.8975, F1_score: 0.9089
Model performance on Sad speech (in training): 
	Precision: 0.9532, Recall: 0.9675, F1_score: 0.9603

Eval Phase: 
Validation loss: 13.4705, Validation accuracy: 0.9850
Macro F1-score: 0.9850
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Neutral speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Sad speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
New best accuracy for layer 4 on epoch 2: 0.9850. Model saved.
Epoch 3/100

Training Phase:
49, 22.86it/s]Training:  43%|████▎     | 694/1600 [00:30<00:39, 22.81it/s]Training:  58%|█████▊    | 922/1600 [00:40<00:30, 22.54it/s]Training:  72%|███████▏  | 1152/1600 [00:50<00:19, 22.68it/s]Training:  72%|███████▏  | 1152/1600 [01:00<00:19, 22.68it/s]Training:  86%|████████▋ | 1381/1600 [01:01<00:09, 22.51it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 225/1600 [00:10<01:01, 22.48it/s]Training:  28%|██▊       | 451/1600 [00:20<00:50, 22.54it/s]Training:  42%|████▏     | 677/1600 [00:30<00:41, 22.33it/s]Training:  57%|█████▋    | 907/1600 [00:40<00:30, 22.56it/s]Training:  71%|███████   | 1137/1600 [00:50<00:20, 22.52it/s]Training:  85%|████████▌ | 1363/1600 [01Training loss: 228.0187, Training accuracy: 0.9519
Macro F1-score: 0.9519
Model performance on Angry speech (in training): 
	Precision: 0.9644, Recall: 0.9475, F1_score: 0.9559
Model performance on Happy speech (in training): 
	Precision: 0.9216, Recall: 0.9400, F1_score: 0.9307
Model performance on Neutral speech (in training): 
	Precision: 0.9496, Recall: 0.9425, F1_score: 0.9460
Model performance on Sad speech (in training): 
	Precision: 0.9726, Recall: 0.9775, F1_score: 0.9751

Eval Phase: 
Validation loss: 25.2950, Validation accuracy: 0.9650
Macro F1-score: 0.9649
Model performance on Angry speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.8800, F1_score: 0.9362
Model performance on Neutral speech (in validation): 
	Precision: 0.8929, Recall: 1.0000, F1_score: 0.9434
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Epoch 4/100

Training Phase:
Training loss: 173.8025, Training accuracy: 0.9675
Macro F1-score: 0.9675
Model performance on Angry speech (in training): 
	Precision: 0.9750, Recall: 0.9750, F1_score: 0.9750
Model performance on Happy speech (in training): 
	Precision: 0.9576, Recall: 0.9600, F1_score: 0.9588
Model performance on Neutral speech (in training): 
	Precision: 0.9621, Recall: 0.9525, F1_score: 0.9573
Model performance on Sad speech (in training): 
	Precision: 0.9752, Recall: 0.9825, F1_score: 0.9788

Eval Phase: 
Validation loss: 10.0908, Validation accuracy: 0.9850
Macro F1-score: 0.9850
Model performance on Angry speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Neutral speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Epoch 5/100

Training Phase:
:00<00:10, 22.50it/s]Training:  99%|█████████▉| 1591/1600 [01:10<00:00, 22.59it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 228/1600 [00:10<01:00, 22.73it/s]Training:  28%|██▊       | 456/1600 [00:20<00:50, 22.65it/s]Training:  43%|████▎     | 687/1600 [00:30<00:40, 22.82it/s]Training:  57%|█████▋    | 919/1600 [00:40<00:29, 22.96it/s]Training:  72%|███████▏  | 1151/1600 [00:50<00:19, 22.86it/s]Training:  86%|████████▌ | 1378/1600 [01:00<00:09, 22.77it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 226/1600 [00:10<0Training loss: 167.8743, Training accuracy: 0.9700
Macro F1-score: 0.9700
Model performance on Angry speech (in training): 
	Precision: 0.9825, Recall: 0.9825, F1_score: 0.9825
Model performance on Happy speech (in training): 
	Precision: 0.9627, Recall: 0.9675, F1_score: 0.9651
Model performance on Neutral speech (in training): 
	Precision: 0.9645, Recall: 0.9500, F1_score: 0.9572
Model performance on Sad speech (in training): 
	Precision: 0.9703, Recall: 0.9800, F1_score: 0.9751

Eval Phase: 
Validation loss: 6.7085, Validation accuracy: 0.9900
Macro F1-score: 0.9899
Model performance on Angry speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Neutral speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
New best accuracy for layer 4 on epoch 5: 0.9900. Model saved.
Epoch 6/100

Training Phase:
1:00, 22.55it/s]Training:  28%|██▊       | 454/1600 [00:20<00:50, 22.66it/s]Training:  43%|████▎     | 682/1600 [00:30<00:40, 22.61it/s]Training:  57%|█████▋    | 914/1600 [00:40<00:30, 22.83it/s]Training:  72%|███████▏  | 1148/1600 [00:50<00:19, 23.01it/s]Training:  86%|████████▋ | 1382/1600 [01:00<00:09, 22.90it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 225/1600 [00:10<01:01, 22.43it/s]Training:  28%|██▊       | 456/1600 [00:20<00:50, 22.76it/s]Training:  43%|████▎     | 691/1600 [00:30<00:39, 23.06it/s]Training:  58%|█████▊    | 926/1600 [00:40<00:29, 23.00it/s]Training:  72%|███████▏  | 1155/1600 [00:50<00:19, 22.79it/s]Training:  72%|███████▏  | 1155/1600 [01:00<00:19Training loss: 122.6572, Training accuracy: 0.9769
Macro F1-score: 0.9769
Model performance on Angry speech (in training): 
	Precision: 0.9801, Recall: 0.9875, F1_score: 0.9838
Model performance on Happy speech (in training): 
	Precision: 0.9696, Recall: 0.9575, F1_score: 0.9635
Model performance on Neutral speech (in training): 
	Precision: 0.9677, Recall: 0.9725, F1_score: 0.9701
Model performance on Sad speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900

Eval Phase: 
Validation loss: 5.9640, Validation accuracy: 0.9800
Macro F1-score: 0.9800
Model performance on Angry speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9400, F1_score: 0.9691
Model performance on Neutral speech (in validation): 
	Precision: 0.9434, Recall: 1.0000, F1_score: 0.9709
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Epoch 7/100

Training Phase:
Training loss: 116.7476, Training accuracy: 0.9719
Macro F1-score: 0.9719
Model performance on Angry speech (in training): 
	Precision: 0.9751, Recall: 0.9775, F1_score: 0.9763
Model performance on Happy speech (in training): 
	Precision: 0.9722, Recall: 0.9625, F1_score: 0.9673
Model performance on Neutral speech (in training): 
	Precision: 0.9627, Recall: 0.9675, F1_score: 0.9651
Model performance on Sad speech (in training): 
	Precision: 0.9776, Recall: 0.9800, F1_score: 0.9788

Eval Phase: 
, 22.79it/s]Training:  86%|████████▌ | 1373/1600 [01:00<00:10, 22.39it/s]Training: 100%|█████████▉| 1599/1600 [01:10<00:00, 22.44it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 223/1600 [00:10<01:01, 22.29it/s]Training:  28%|██▊       | 446/1600 [00:20<00:51, 22.27it/s]Training:  42%|████▏     | 669/1600 [00:30<00:41, 22.25it/s]Training:  56%|█████▌    | 892/1600 [00:40<00:31, 22.22it/s]Training:  70%|██████▉   | 1114/1600 [00:50<00:22, 22.03it/s]Training:  84%|████████▎ | 1337/1600 [01:00<00:11, 22.10it/s]Training:  98%|█████████▊| 1562/1600 [01:10<00:01, 22.21it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s] Validation loss: 21.4163, Validation accuracy: 0.9650
Macro F1-score: 0.9650
Model performance on Angry speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9400, F1_score: 0.9691
Model performance on Neutral speech (in validation): 
	Precision: 0.9091, Recall: 1.0000, F1_score: 0.9524
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9200, F1_score: 0.9583
Epoch 8/100

Training Phase:
Training loss: 62.0921, Training accuracy: 0.9862
Macro F1-score: 0.9862
Model performance on Angry speech (in training): 
	Precision: 0.9825, Recall: 0.9850, F1_score: 0.9838
Model performance on Happy speech (in training): 
	Precision: 0.9799, Recall: 0.9750, F1_score: 0.9774
Model performance on Neutral speech (in training): 
	Precision: 0.9875, Recall: 0.9875, F1_score: 0.9875
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963

Eval Phase: 
Validation loss: 8.9150, Validation accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Neutral speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 9/100

Training Phase:
                                                  Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 232/1600 [00:10<00:59, 23.13it/s]Training:  29%|██▉       | 464/1600 [00:20<00:50, 22.69it/s]Training:  43%|████▎     | 694/1600 [00:30<00:39, 22.82it/s]Training:  58%|█████▊    | 927/1600 [00:40<00:29, 23.00it/s]Training:  72%|███████▎  | 1160/1600 [00:50<00:19, 23.07it/s]Training:  87%|████████▋ | 1393/1600 [01:00<00:08, 23.12it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 234/1600 [00:10<00:58, 23.33it/s]Training:  29%|██▉       | 468/1600 [00:20<00:49, 22.92it/s]Training:  44%|████▍     | 702/1600 [00:30<00:38, 23.13it/s]Training:  58%|█████▊    | 936/1600 [00:40<00:28, 23.Training loss: 88.6219, Training accuracy: 0.9844
Macro F1-score: 0.9844
Model performance on Angry speech (in training): 
	Precision: 0.9826, Recall: 0.9875, F1_score: 0.9850
Model performance on Happy speech (in training): 
	Precision: 0.9874, Recall: 0.9800, F1_score: 0.9837
Model performance on Neutral speech (in training): 
	Precision: 0.9801, Recall: 0.9850, F1_score: 0.9825
Model performance on Sad speech (in training): 
	Precision: 0.9875, Recall: 0.9850, F1_score: 0.9862

Eval Phase: 
Validation loss: 5.9468, Validation accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Neutral speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
New best accuracy for layer 4 on epoch 9: 0.9950. Model saved.
Epoch 10/100

Training Phase:
Training loss: 93.7166, Training accuracy: 0.9794
Macro F1-score: 0.9794
Model performance on Angry speech (in training): 
	Precision: 0.9825, Recall: 0.9800, F1_score: 0.9812
Model performance on Happy speech (in training): 
	Precision: 0.9675, Recall: 0.9675, F1_score: 0.9675
Model performance on Neutral speech (in training): 
	Precision: 0.9775, Recall: 0.9775, F1_score: 0.9775
Model performance on Sad speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913

Eval Phase: 
16it/s]Training:  73%|███████▎  | 1169/1600 [00:50<00:18, 22.92it/s]Training:  73%|███████▎  | 1169/1600 [01:01<00:18, 22.92it/s]Training:  87%|████████▋ | 1394/1600 [01:01<00:09, 22.54it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 223/1600 [00:10<01:01, 22.25it/s]Training:  29%|██▉       | 461/1600 [00:20<00:49, 23.15it/s]Training:  44%|████▎     | 699/1600 [00:30<00:39, 22.97it/s]Training:  58%|█████▊    | 935/1600 [00:40<00:28, 23.19it/s]Training:  73%|███████▎  | 1171/1600 [00:51<00:18, 22.62it/s]Training:  87%|████████▋ | 1391/1600 [01:01<00:09, 22.38it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]            Validation loss: 4.7166, Validation accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Neutral speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Epoch 11/100

Training Phase:
Training loss: 56.9498, Training accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in training): 
	Precision: 0.9875, Recall: 0.9900, F1_score: 0.9888
Model performance on Happy speech (in training): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9900, F1_score: 0.9925
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988

Eval Phase: 
Validation loss: 17.0758, Validation accuracy: 0.9800
Macro F1-score: 0.9798
Model performance on Angry speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9200, F1_score: 0.9583
Model performance on Neutral speech (in validation): 
	Precision: 0.9434, Recall: 1.0000, F1_score: 0.9709
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 12/100

Training Phase:
                                       Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 229/1600 [00:10<00:59, 22.86it/s]Training:  29%|██▊       | 458/1600 [00:20<00:50, 22.61it/s]Training:  43%|████▎     | 687/1600 [00:30<00:40, 22.71it/s]Training:  58%|█████▊    | 923/1600 [00:40<00:29, 23.05it/s]Training:  72%|███████▏  | 1159/1600 [00:50<00:19, 22.93it/s]Training:  87%|████████▋ | 1388/1600 [01:00<00:09, 22.90it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 217/1600 [00:10<01:03, 21.66it/s]Training:  27%|██▋       | 434/1600 [00:20<00:54, 21.59it/s]Training:  41%|████      | 650/1600 [00:30<00:44, 21.43it/s]Training:  54%|█████▍    | 865/1600 [00:40<00:34, 21.44it/s]TrainTraining loss: 60.0727, Training accuracy: 0.9850
Macro F1-score: 0.9850
Model performance on Angry speech (in training): 
	Precision: 0.9850, Recall: 0.9875, F1_score: 0.9863
Model performance on Happy speech (in training): 
	Precision: 0.9799, Recall: 0.9775, F1_score: 0.9787
Model performance on Neutral speech (in training): 
	Precision: 0.9850, Recall: 0.9825, F1_score: 0.9837
Model performance on Sad speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913

Eval Phase: 
Validation loss: 20.1909, Validation accuracy: 0.9800
Macro F1-score: 0.9798
Model performance on Angry speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9200, F1_score: 0.9583
Model performance on Neutral speech (in validation): 
	Precision: 0.9434, Recall: 1.0000, F1_score: 0.9709
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 13/100

Training Phase:
ing:  68%|██████▊   | 1084/1600 [00:50<00:23, 21.57it/s]Training:  81%|████████▏ | 1303/1600 [01:00<00:13, 21.62it/s]Training:  96%|█████████▌| 1528/1600 [01:10<00:03, 21.89it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 223/1600 [00:10<01:01, 22.25it/s]Training:  28%|██▊       | 446/1600 [00:20<00:52, 22.19it/s]Training:  42%|████▏     | 668/1600 [00:30<00:42, 22.03it/s]Training:  55%|█████▌    | 887/1600 [00:40<00:32, 21.80it/s]Training:  69%|██████▉   | 1106/1600 [00:50<00:22, 21.83it/s]Training:  84%|████████▎ | 1338/1600 [01:00<00:11, 22.28it/s]Training:  98%|█████████▊| 1575/1600 [01:10<00:01, 22.72it/s]                                                          Training loss: 78.5235, Training accuracy: 0.9838
Macro F1-score: 0.9838
Model performance on Angry speech (in training): 
	Precision: 0.9875, Recall: 0.9875, F1_score: 0.9875
Model performance on Happy speech (in training): 
	Precision: 0.9679, Recall: 0.9800, F1_score: 0.9739
Model performance on Neutral speech (in training): 
	Precision: 0.9873, Recall: 0.9750, F1_score: 0.9811
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925

Eval Phase: 
Validation loss: 8.4898, Validation accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Neutral speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Epoch 14/100

Training Phase:
Training loss: 53.5438, Training accuracy: 0.9875
Macro F1-score: 0.9875
Model performance on Angry speech (in training): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in training): 
	Precision: 0.9751, Recall: 0.9775, F1_score: 0.9763
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 3.9551, Validation accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Neutral speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Epoch 15/100

Training Phase:
   Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 227/1600 [00:10<01:00, 22.65it/s]Training:  29%|██▊       | 458/1600 [00:20<00:49, 22.88it/s]Training:  43%|████▎     | 689/1600 [00:30<00:40, 22.63it/s]Training:  57%|█████▋    | 918/1600 [00:40<00:30, 22.73it/s]Training:  72%|███████▏  | 1150/1600 [00:50<00:19, 22.89it/s]Training:  86%|████████▋ | 1382/1600 [01:00<00:09, 22.88it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 220/1600 [00:10<01:02, 21.99it/s]Training:  28%|██▊       | 440/1600 [00:20<00:53, 21.86it/s]Training:  41%|████▏     | 662/1600 [00:30<00:42, 22.01it/s]TraininTraining loss: 71.1638, Training accuracy: 0.9875
Macro F1-score: 0.9875
Model performance on Angry speech (in training): 
	Precision: 0.9900, Recall: 0.9875, F1_score: 0.9887
Model performance on Happy speech (in training): 
	Precision: 0.9800, Recall: 0.9825, F1_score: 0.9813
Model performance on Neutral speech (in training): 
	Precision: 0.9826, Recall: 0.9875, F1_score: 0.9850
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9925, F1_score: 0.9950

Eval Phase: 
Validation loss: 8.8689, Validation accuracy: 0.9800
Macro F1-score: 0.9800
Model performance on Angry speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9400, F1_score: 0.9691
Model performance on Neutral speech (in validation): 
	Precision: 0.9434, Recall: 1.0000, F1_score: 0.9709
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Epoch 16/100

Training Phase:
g:  56%|█████▌    | 888/1600 [00:40<00:32, 22.20it/s]Training:  70%|██████▉   | 1113/1600 [00:50<00:22, 22.06it/s]Training:  83%|████████▎ | 1332/1600 [01:00<00:12, 21.88it/s]Training:  97%|█████████▋| 1554/1600 [01:10<00:02, 21.98it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 222/1600 [00:10<01:02, 22.19it/s]Training:  28%|██▊       | 447/1600 [00:20<00:51, 22.33it/s]Training:  42%|████▏     | 672/1600 [00:30<00:41, 22.40it/s]Training:  56%|█████▋    | 902/1600 [00:40<00:30, 22.60it/s]Training:  71%|███████   | 1132/1600 [00:50<00:20, 22.59it/s]Training:  85%|████████▌ | 1363/1600 [01:00<00:10, 22.75it/s]Training: 100%|█████████▉| 1596/1600 [01:10<00:00Training loss: 71.7721, Training accuracy: 0.9831
Macro F1-score: 0.9831
Model performance on Angry speech (in training): 
	Precision: 0.9875, Recall: 0.9875, F1_score: 0.9875
Model performance on Happy speech (in training): 
	Precision: 0.9701, Recall: 0.9725, F1_score: 0.9713
Model performance on Neutral speech (in training): 
	Precision: 0.9776, Recall: 0.9800, F1_score: 0.9788
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9925, F1_score: 0.9950

Eval Phase: 
Validation loss: 0.3420, Validation accuracy: 1.0000
Macro F1-score: 1.0000
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
New best accuracy for layer 4 on epoch 16: 1.0000. Model saved.
Epoch 17/100

Training Phase:
Training loss: 34.4396, Training accuracy: 0.9912
Macro F1-score: 0.9913
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 0.9925, F1_score: 0.9962
Model performance on Happy speech (in training): 
	Precision: 0.9875, Recall: 0.9900, F1_score: 0.9888
Model performance on Neutral speech (in training): 
	Precision: 0.9826, Recall: 0.9900, F1_score: 0.9863
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937

Eval Phase: 
Validation loss: 8.1230, Validation accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 18/100

Training Phase:
, 22.93it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 231/1600 [00:10<00:59, 23.05it/s]Training:  29%|██▉       | 462/1600 [00:20<00:50, 22.74it/s]Training:  43%|████▎     | 690/1600 [00:30<00:40, 22.74it/s]Training:  57%|█████▋    | 918/1600 [00:40<00:29, 22.74it/s]Training:  72%|███████▏  | 1146/1600 [00:50<00:20, 22.68it/s]Training:  86%|████████▌ | 1372/1600 [01:00<00:10, 22.64it/s]Training: 100%|█████████▉| 1598/1600 [01:10<00:00, 22.36it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 224/1600 [00:10<01:01, 22.Training loss: 43.0074, Training accuracy: 0.9925
Macro F1-score: 0.9925
Model performance on Angry speech (in training): 
	Precision: 0.9851, Recall: 0.9950, F1_score: 0.9900
Model performance on Happy speech (in training): 
	Precision: 0.9924, Recall: 0.9800, F1_score: 0.9862
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9975, F1_score: 0.9950
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987

Eval Phase: 
Validation loss: 0.9115, Validation accuracy: 1.0000
Macro F1-score: 1.0000
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 19/100

Training Phase:
34it/s]Training:  28%|██▊       | 452/1600 [00:20<00:50, 22.57it/s]Training:  43%|████▎     | 686/1600 [00:30<00:39, 22.93it/s]Training:  57%|█████▊    | 920/1600 [00:40<00:29, 22.73it/s]Training:  72%|███████▏  | 1145/1600 [00:50<00:20, 22.45it/s]Training:  86%|████████▌ | 1376/1600 [01:00<00:09, 22.65it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 219/1600 [00:10<01:03, 21.84it/s]Training:  28%|██▊       | 442/1600 [00:20<00:52, 22.10it/s]Training:  42%|████▏     | 665/1600 [00:30<00:42, 22.09it/s]Training:  55%|█████▌    | 886/1600 [00:40<00:32, 22.01it/s]Training:  69%|██████▉   | 1110/1600 [00:50<00:22, 22.11it/s]Training:  83%|████████▎ | 1333/1600 [01:00<00:12, 22.06itTraining loss: 54.1520, Training accuracy: 0.9888
Macro F1-score: 0.9887
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937
Model performance on Happy speech (in training): 
	Precision: 0.9851, Recall: 0.9950, F1_score: 0.9900
Model performance on Neutral speech (in training): 
	Precision: 0.9825, Recall: 0.9825, F1_score: 0.9825
Model performance on Sad speech (in training): 
	Precision: 0.9924, Recall: 0.9850, F1_score: 0.9887

Eval Phase: 
Validation loss: 1.2267, Validation accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Epoch 20/100

Training Phase:
Training loss: 34.2318, Training accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in training): 
	Precision: 0.9901, Recall: 0.9975, F1_score: 0.9938
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9875, F1_score: 0.9912
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987

Eval Phase: 
Validation loss: 5.5064, Validation accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Neutral speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 21/100

Training Phase:
/s]Training:  97%|█████████▋| 1553/1600 [01:10<00:02, 22.03it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 219/1600 [00:10<01:03, 21.85it/s]Training:  27%|██▋       | 438/1600 [00:20<00:53, 21.85it/s]Training:  41%|████▏     | 660/1600 [00:30<00:42, 21.97it/s]Training:  55%|█████▌    | 882/1600 [00:40<00:32, 22.01it/s]Training:  69%|██████▉   | 1103/1600 [00:50<00:22, 21.96it/s]Training:  83%|████████▎ | 1326/1600 [01:00<00:12, 22.07it/s]Training:  97%|█████████▋| 1557/1600 [01:10<00:01, 22.37it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00Training loss: 55.7848, Training accuracy: 0.9894
Macro F1-score: 0.9894
Model performance on Angry speech (in training): 
	Precision: 0.9850, Recall: 0.9850, F1_score: 0.9850
Model performance on Happy speech (in training): 
	Precision: 0.9875, Recall: 0.9875, F1_score: 0.9875
Model performance on Neutral speech (in training): 
	Precision: 0.9900, Recall: 0.9950, F1_score: 0.9925
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9900, F1_score: 0.9925

Eval Phase: 
Validation loss: 2.3479, Validation accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Neutral speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 22/100

Training Phase:
:00<?, ?it/s]Training:  15%|█▍        | 233/1600 [00:10<00:58, 23.23it/s]Training:  29%|██▉       | 466/1600 [00:20<00:49, 23.03it/s]Training:  43%|████▎     | 695/1600 [00:30<00:39, 22.92it/s]Training:  58%|█████▊    | 923/1600 [00:40<00:30, 22.48it/s]Training:  71%|███████▏  | 1142/1600 [00:50<00:20, 22.27it/s]Training:  85%|████████▌ | 1366/1600 [01:00<00:10, 22.29it/s]Training:  99%|█████████▉| 1591/1600 [01:10<00:00, 22.36it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 224/1600 [00:10<01:01, 22.31it/s]Training:  28%|██▊       | 448/1600 [00:20<00:51, 22.21it/s]Training:  42%|████▏     | 670/1600 [00:30<00:41, 22.19it/s]Training:  56%|█████▌    | 892/1600 [00:40<00:32, 22.08it/s]Training loss: 44.9560, Training accuracy: 0.9925
Macro F1-score: 0.9925
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Happy speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913
Model performance on Neutral speech (in training): 
	Precision: 0.9875, Recall: 0.9875, F1_score: 0.9875
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937

Eval Phase: 
Validation loss: 2.6828, Validation accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Neutral speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 23/100

Training Phase:
Training loss: 21.4957, Training accuracy: 0.9962
Macro F1-score: 0.9962
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9925, F1_score: 0.9950
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9975, F1_score: 0.9950
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Training:  70%|██████▉   | 1112/1600 [00:50<00:22, 22.02it/s]Training:  83%|████████▎ | 1332/1600 [01:00<00:12, 21.95it/s]Training:  97%|█████████▋| 1556/1600 [01:10<00:01, 22.09it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 235/1600 [00:10<00:58, 23.41it/s]Training:  29%|██▉       | 470/1600 [00:20<00:49, 22.91it/s]Training:  44%|████▍     | 701/1600 [00:30<00:39, 22.98it/s]Training:  58%|█████▊    | 932/1600 [00:40<00:29, 22.93it/s]Training:  73%|███████▎  | 1161/1600 [00:50<00:19, 22.92it/s]Training:  87%|████████▋ | 1394/1600 [01:00<00:08, 23.01it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                 Validation loss: 1.5361, Validation accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Neutral speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 24/100

Training Phase:
Training loss: 50.0662, Training accuracy: 0.9919
Macro F1-score: 0.9919
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Neutral speech (in training): 
	Precision: 0.9875, Recall: 0.9850, F1_score: 0.9862
Model performance on Sad speech (in training): 
	Precision: 0.9900, Recall: 0.9950, F1_score: 0.9925

Eval Phase: 
Validation loss: 2.8204, Validation accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Neutral speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Epoch 25/100

Training Phase:
                                  Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 224/1600 [00:10<01:01, 22.34it/s]Training:  28%|██▊       | 448/1600 [00:20<00:51, 22.27it/s]Training:  42%|████▏     | 673/1600 [00:30<00:41, 22.36it/s]Training:  57%|█████▋    | 905/1600 [00:40<00:30, 22.67it/s]Training:  57%|█████▋    | 905/1600 [00:50<00:30, 22.67it/s]Training:  71%|███████   | 1137/1600 [00:50<00:20, 22.78it/s]Training:  85%|████████▌ | 1367/1600 [01:00<00:10, 22.69it/s]Training: 100%|█████████▉| 1593/1600 [01:10<00:00, 22.52it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 225/1600 [00:10<01:01, 22.46it/s]Training:  28%|██▊       | 452/1600 [00:20<00:50, 22.56it/s]Training loss: 22.9869, Training accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Happy speech (in training): 
	Precision: 0.9900, Recall: 0.9950, F1_score: 0.9925
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987

Eval Phase: 
Validation loss: 14.9690, Validation accuracy: 0.9850
Macro F1-score: 0.9850
Model performance on Angry speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Neutral speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Epoch 26/100

Training Phase:
Training:  42%|████▏     | 679/1600 [00:30<00:40, 22.51it/s]Training:  57%|█████▋    | 907/1600 [00:40<00:30, 22.59it/s]Training:  71%|███████   | 1135/1600 [00:50<00:20, 22.61it/s]Training:  85%|████████▌ | 1362/1600 [01:00<00:10, 22.37it/s]Training:  99%|█████████▉| 1586/1600 [01:10<00:00, 22.37it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 221/1600 [00:10<01:02, 22.01it/s]Training:  28%|██▊       | 443/1600 [00:20<00:52, 22.11it/s]Training:  42%|████▏     | 666/1600 [00:30<00:42, 22.18it/s]Training:  56%|█████▌    | 890/1600 [00:40<00:31, 22.25it/s]Training:  70%|██████▉   | 1115/1600 [00:50<00:21, 22.31it/s]Training:  84%|████████▍ | 1343/1600 [01:00<00:11, 2Training loss: 37.3547, Training accuracy: 0.9925
Macro F1-score: 0.9925
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Happy speech (in training): 
	Precision: 0.9850, Recall: 0.9850, F1_score: 0.9850
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 8.0982, Validation accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Neutral speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Validation loss does not decrease for 10 epochs. End training.
Model best accuracy on validation set: 1.0000

Test Phase: 
2.47it/s]Training:  98%|█████████▊| 1571/1600 [01:10<00:01, 22.42it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]                                                Some weights of the model checkpoint at /work/tc062/tc062/zhan7721/saved_models/de were not used when initializing Wav2Vec2Model: ['encoder.layers.10.attention.k_proj.bias', 'encoder.layers.10.attention.k_proj.weight', 'encoder.layers.10.attention.out_proj.bias', 'encoder.layers.10.attention.out_proj.weight', 'encoder.layers.10.attention.q_proj.bias', 'encoder.layers.10.attention.q_proj.weight', 'encoder.layers.10.attention.v_proj.bias', 'encoder.layers.10.attention.v_proj.weight', 'encoder.layers.10.feed_forward.intermediate_dense.bias', 'encoder.layers.10.feed_forward.intermediate_dense.weight', 'encoder.layers.10.feed_forward.output_dense.bias', 'encoder.layers.10.feed_forward.output_dense.weight', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.10.layer_norm.bias', 'encoder.layers.10.layer_norm.weight', 'encoder.layers.11.attention.k_proj.bias', 'encoder.layers.11.attention.k_proj.weight', 'encoder.layers.11.attention.out_proj.bias', 'encoder.layers.11.attention.out_proj.weight', 'encoder.layers.11.attention.q_proj.bias', 'encoder.layers.11.attention.q_proj.weight', 'encoder.layers.11.attention.v_proj.bias', 'encoder.layers.11.attention.v_proj.weight', 'encoder.layers.11.feed_forward.intermediate_dense.bias', 'encoder.layers.11.feed_forward.intermediate_dense.weight', 'encoder.layers.11.feed_forward.output_dense.bias', 'encoder.layers.11.feed_forward.output_dense.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.11.layer_norm.bias', 'encoder.layers.11.layer_norm.weight', 'encoder.layers.5.attention.k_proj.bias', 'encoder.layers.5.attention.k_proj.weight', 'encoder.layers.5.attention.out_proj.bias', 'encoder.layers.5.attention.out_proj.weight', 'encoder.layers.5.attention.q_proj.bias', 'encoder.layers.5.attention.q_proj.weight', 'encoder.layers.5.attention.v_proj.bias', 'encoder.layers.5.attention.v_proj.weight', 'encoder.layers.5.feed_forward.intermediate_dense.bias', 'encoder.layers.5.feed_forward.intermediate_dense.weight', 'encoder.layers.5.feed_forward.output_dense.bias', 'encoder.layers.5.feed_forward.output_dense.weight', 'encoder.layers.5.final_layer_norm.bias', 'encoder.layers.5.final_layer_norm.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.6.attention.k_proj.bias', 'encoder.layers.6.attention.k_proj.weight', 'encoder.layers.6.attention.out_proj.bias', 'encoder.layers.6.attention.out_proj.weight', 'encoder.layers.6.attention.q_proj.bias', 'encoder.layers.6.attention.q_proj.weight', 'encoder.layers.6.attention.v_proj.bias', 'encoder.layers.6.attention.v_proj.weight', 'encoder.layers.6.feed_forward.intermediate_dense.bias', 'encoder.layers.6.feed_forward.intermediate_dense.weight', 'encoder.layers.6.feed_forward.output_dense.bias', 'encoder.layers.6.feed_forward.output_dense.weight', 'encoder.layers.6.final_layer_norm.bias', 'encoder.layers.6.final_layer_norm.weight', 'encoder.layers.6.layer_norm.bias', 'encoder.layers.6.layer_norm.weight', 'encoder.layers.7.attention.k_proj.bias', 'encoder.layers.7.attention.k_proj.weight', 'encoder.layers.7.attention.out_proj.bias', 'encoder.layers.7.attention.out_proj.weight', 'encoder.layers.7.attention.q_proj.bias', 'encoder.layers.7.attention.q_proj.weight', 'encoder.layers.7.attention.v_proj.bias', 'encoder.layers.7.attention.v_proj.weight', 'encoder.layers.7.feed_forward.intermediate_dense.bias', 'encoder.layers.7.feed_forward.intermediate_dense.weight', 'encoder.layers.7.feed_forward.output_dense.bias', 'encoder.layers.7.feed_forward.output_dense.weight', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.7.layer_norm.bias', 'encoder.layers.7.layer_norm.weight', 'encoder.layers.8.attention.k_proj.bias', 'encoder.layers.8.attention.k_proj.weight', 'encoder.layers.8.attention.out_proj.bias', 'encoder.layers.8.attention.out_proj.weight', 'encoder.layers.8.attention.q_proj.bias', 'encoder.layers.8.attention.q_proj.weight', 'encoder.layers.8.attention.v_proj.bias', 'encoder.layers.8.attention.v_proj.weight', 'encoder.layers.8.feed_forward.intermediate_dense.bias', 'encoder.layers.8.feed_forward.intermediate_dense.weight', 'encoder.layers.8.feed_forward.output_dense.bias', 'encoder.layers.8.feed_forward.output_dense.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.8.layer_norm.bias', 'encoder.layers.8.layer_norm.weight', 'encoder.layers.9.attention.k_proj.bias', 'encoder.layers.9.attention.k_proj.weight', 'encoder.layers.9.attention.out_proj.bias', 'encoder.layers.9.attention.out_proj.weight', 'encoder.layers.9.attention.q_proj.bias', 'encoder.layers.9.attention.q_proj.weight', 'encoder.layers.9.attention.v_proj.bias', 'encoder.layers.9.attention.v_proj.weight', 'encoder.layers.9.feed_forward.intermediate_dense.bias', 'encoder.layers.9.feed_forward.intermediate_dense.weight', 'encoder.layers.9.feed_forward.output_dense.bias', 'encoder.layers.9.feed_forward.output_dense.weight', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.layer_norm.bias', 'encoder.layers.9.layer_norm.weight']
- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Test loss: 8.8687, Test accuracy: 0.9800
Macro F1-score: 0.9799
Model performance on Angry speech (in test): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in test): 
	Precision: 0.9792, Recall: 0.9400, F1_score: 0.9592
Model performance on Neutral speech (in test): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Sad speech (in test): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

======================= This is fold_1 on cn =======================

Load dataset: 
Loading de train data: fold_1...
Preprocess de fold_1 data for cn model
Loading de eval data: fold_1...
Preprocess de fold_1 data for cn model
Loading de test data: fold_1...
Preprocess de fold_1 data for cn model
Use cn model to add lora
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training loss: 636.1727, Training accuracy: 0.8594
Macro F1-score: 0.8602
Model performance on Angry speech (in training): 
	Precision: 0.8974, Recall: 0.8525, F1_score: 0.8744
Model performance on Happy speech (in training): 
	Precision: 0.7938, Recall: 0.8275, F1_score: 0.8103
Model performance on Neutral speech (in training): 
	Precision: 0.8101, Recall: 0.8425, F1_score: 0.8260
Model performance on Sad speech (in training): 
	Precision: 0.9457, Recall: 0.9150, F1_score: 0.9301

Eval Phase: 
Validation loss: 26.7478, Validation accuracy: 0.9400
Macro F1-score: 0.9395
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Happy speech (in validation): 
	Precision: 0.9756, Recall: 0.8000, F1_score: 0.8791
Model performance on Neutral speech (in validation): 
	Precision: 0.8333, Recall: 1.0000, F1_score: 0.9091
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
New best accuracy for layer 4 on epoch 1: 0.9400. Model saved.
Epoch 2/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:   8%|▊         | 133/1600 [00:10<01:50, 13.22it/s]Training:  19%|█▉        | 306/1600 [00:20<01:22, 15.61it/s]Training:  31%|███       | 494/1600 [00:30<01:04, 17.06it/s]Training:  43%|████▎     | 694/1600 [00:40<00:49, 18.19it/s]Training:  56%|█████▌    | 894/1600 [00:50<00:37, 18.68it/s]Training:  69%|██████▊   | 1099/1600 [01:00<00:25, 19.29it/s]Training:  82%|████████▏ | 1314/1600 [01:10<00:14, 19.99it/s]Training:  96%|█████████▌| 1529/1600 [01:20<00:03, 20.22it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 216/1600 [00:10<01:04, 21.55it/s]Training:  27%|██▋       | 434/1600 [00:20<00:53, 21.69it/s]Training:  41%|████      | 654/1600 Training loss: 184.4094, Training accuracy: 0.9637
Macro F1-score: 0.9638
Model performance on Angry speech (in training): 
	Precision: 0.9772, Recall: 0.9625, F1_score: 0.9698
Model performance on Happy speech (in training): 
	Precision: 0.9454, Recall: 0.9525, F1_score: 0.9489
Model performance on Neutral speech (in training): 
	Precision: 0.9529, Recall: 0.9600, F1_score: 0.9564
Model performance on Sad speech (in training): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800

Eval Phase: 
Validation loss: 19.9008, Validation accuracy: 0.9750
Macro F1-score: 0.9750
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Happy speech (in validation): 
	Precision: 0.9796, Recall: 0.9600, F1_score: 0.9697
Model performance on Neutral speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Sad speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
New best accuracy for layer 4 on epoch 2: 0.9750. Model saved.
Epoch 3/100

Training Phase:
[00:30<00:43, 21.83it/s]Training:  55%|█████▍    | 878/1600 [00:40<00:32, 22.05it/s]Training:  69%|██████▉   | 1102/1600 [00:50<00:22, 22.01it/s]Training:  83%|████████▎ | 1322/1600 [01:00<00:12, 21.98it/s]Training:  96%|█████████▋| 1543/1600 [01:10<00:02, 22.00it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 223/1600 [00:10<01:01, 22.21it/s]Training:  28%|██▊       | 446/1600 [00:20<00:52, 22.18it/s]Training:  42%|████▏     | 668/1600 [00:30<00:42, 22.09it/s]Training:  56%|█████▌    | 888/1600 [00:40<00:32, 22.05it/s]Training:  70%|██████▉   | 1116/1600 [00:50<00:21, 22.31it/s]Training:  84%|████████▍ | 1344/1600 [01:00<00:11, 22.05it/s]Training:  98%|███████Training loss: 155.0831, Training accuracy: 0.9644
Macro F1-score: 0.9643
Model performance on Angry speech (in training): 
	Precision: 0.9701, Recall: 0.9750, F1_score: 0.9726
Model performance on Happy speech (in training): 
	Precision: 0.9591, Recall: 0.9375, F1_score: 0.9482
Model performance on Neutral speech (in training): 
	Precision: 0.9480, Recall: 0.9575, F1_score: 0.9527
Model performance on Sad speech (in training): 
	Precision: 0.9801, Recall: 0.9875, F1_score: 0.9838

Eval Phase: 
Validation loss: 8.1119, Validation accuracy: 0.9850
Macro F1-score: 0.9850
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Happy speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Neutral speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
New best accuracy for layer 4 on epoch 3: 0.9850. Model saved.
Epoch 4/100

Training Phase:
Training loss: 118.6275, Training accuracy: 0.9775
Macro F1-score: 0.9775
Model performance on Angry speech (in training): 
	Precision: 0.9799, Recall: 0.9750, F1_score: 0.9774
Model performance on Happy speech (in training): 
	Precision: 0.9602, Recall: 0.9650, F1_score: 0.9626
Model performance on Neutral speech (in training): 
	Precision: 0.9774, Recall: 0.9750, F1_score: 0.9762
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938

Eval Phase: 
Validation loss: 17.9807, Validation accuracy: 0.9700
Macro F1-score: 0.9700
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9400, F1_score: 0.9691
Model performance on Happy speech (in validation): 
	Precision: 0.9412, Recall: 0.9600, F1_score: 0.9505
Model performance on Neutral speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 5/100

Training Phase:
█▊| 1567/1600 [01:10<00:01, 22.10it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 219/1600 [00:10<01:03, 21.83it/s]Training:  28%|██▊       | 440/1600 [00:20<00:52, 21.98it/s]Training:  41%|████▏     | 661/1600 [00:30<00:42, 21.85it/s]Training:  55%|█████▌    | 885/1600 [00:40<00:32, 22.02it/s]Training:  69%|██████▉   | 1108/1600 [00:50<00:22, 22.02it/s]Training:  83%|████████▎ | 1333/1600 [01:00<00:12, 22.18it/s]Training:  97%|█████████▋| 1558/1600 [01:10<00:01, 21.99it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎      Training loss: 102.4210, Training accuracy: 0.9800
Macro F1-score: 0.9800
Model performance on Angry speech (in training): 
	Precision: 0.9799, Recall: 0.9775, F1_score: 0.9787
Model performance on Happy speech (in training): 
	Precision: 0.9724, Recall: 0.9700, F1_score: 0.9712
Model performance on Neutral speech (in training): 
	Precision: 0.9752, Recall: 0.9825, F1_score: 0.9788
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912

Eval Phase: 
Validation loss: 19.2708, Validation accuracy: 0.9750
Macro F1-score: 0.9750
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Happy speech (in validation): 
	Precision: 0.9796, Recall: 0.9600, F1_score: 0.9697
Model performance on Neutral speech (in validation): 
	Precision: 0.9423, Recall: 0.9800, F1_score: 0.9608
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 6/100

Training Phase:
  | 216/1600 [00:10<01:04, 21.58it/s]Training:  27%|██▋       | 436/1600 [00:20<00:53, 21.81it/s]Training:  41%|████      | 658/1600 [00:30<00:42, 21.96it/s]Training:  55%|█████▌    | 880/1600 [00:40<00:32, 21.85it/s]Training:  69%|██████▉   | 1102/1600 [00:50<00:22, 21.97it/s]Training:  83%|████████▎ | 1324/1600 [01:00<00:12, 22.03it/s]Training:  97%|█████████▋| 1546/1600 [01:10<00:02, 21.97it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 221/1600 [00:10<01:02, 22.07it/s]Training:  28%|██▊       | 442/1600 [00:20<00:52, 21.93it/s]Training:  42%|████▏     | 666/1600 [00:30<00:42, 22.12it/s]Training:  56%|█████▌    | 890/1600 [00:40<00:32, 22.14it/s]Training:  70%|██████▉   | 111Training loss: 106.7143, Training accuracy: 0.9775
Macro F1-score: 0.9775
Model performance on Angry speech (in training): 
	Precision: 0.9776, Recall: 0.9800, F1_score: 0.9788
Model performance on Happy speech (in training): 
	Precision: 0.9723, Recall: 0.9650, F1_score: 0.9686
Model performance on Neutral speech (in training): 
	Precision: 0.9703, Recall: 0.9800, F1_score: 0.9751
Model performance on Sad speech (in training): 
	Precision: 0.9899, Recall: 0.9850, F1_score: 0.9875

Eval Phase: 
Validation loss: 5.1432, Validation accuracy: 0.9850
Macro F1-score: 0.9850
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Happy speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Neutral speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 7/100

Training Phase:
Training loss: 93.1171, Training accuracy: 0.9856
Macro F1-score: 0.9856
Model performance on Angry speech (in training): 
	Precision: 0.9850, Recall: 0.9850, F1_score: 0.9850
Model performance on Happy speech (in training): 
	Precision: 0.9849, Recall: 0.9775, F1_score: 0.9812
Model performance on Neutral speech (in training): 
	Precision: 0.9802, Recall: 0.9900, F1_score: 0.9851
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912

Eval Phase: 
3/1600 [00:50<00:21, 22.18it/s]Training:  84%|████████▎ | 1336/1600 [01:00<00:11, 22.16it/s]Training:  98%|█████████▊| 1563/1600 [01:10<00:01, 22.32it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 220/1600 [00:10<01:02, 21.98it/s]Training:  28%|██▊       | 440/1600 [00:20<00:53, 21.82it/s]Training:  41%|████▏     | 660/1600 [00:30<00:42, 21.86it/s]Training:  55%|█████▌    | 880/1600 [00:40<00:32, 21.89it/s]Training:  69%|██████▉   | 1102/1600 [00:50<00:22, 21.99it/s]Training:  83%|████████▎ | 1324/1600 [01:00<00:12, 22.01it/s]Training:  97%|█████████▋| 1549/1600 [01:10<00:02, 22.12it/s]                                                             Evaluating:   0%|          | 0/200Validation loss: 10.5720, Validation accuracy: 0.9800
Macro F1-score: 0.9799
Model performance on Angry speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in validation): 
	Precision: 0.9792, Recall: 0.9400, F1_score: 0.9592
Model performance on Neutral speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 8/100

Training Phase:
Training loss: 69.2624, Training accuracy: 0.9856
Macro F1-score: 0.9856
Model performance on Angry speech (in training): 
	Precision: 0.9826, Recall: 0.9875, F1_score: 0.9850
Model performance on Happy speech (in training): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Neutral speech (in training): 
	Precision: 0.9899, Recall: 0.9800, F1_score: 0.9849
Model performance on Sad speech (in training): 
	Precision: 0.9900, Recall: 0.9950, F1_score: 0.9925

Eval Phase: 
Validation loss: 50.4159, Validation accuracy: 0.9350
Macro F1-score: 0.9344
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Happy speech (in validation): 
	Precision: 0.9750, Recall: 0.7800, F1_score: 0.8667
Model performance on Neutral speech (in validation): 
	Precision: 0.8167, Recall: 0.9800, F1_score: 0.8909
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 9/100

Training Phase:
 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 225/1600 [00:10<01:01, 22.40it/s]Training:  28%|██▊       | 456/1600 [00:20<00:50, 22.77it/s]Training:  43%|████▎     | 689/1600 [00:30<00:39, 23.01it/s]Training:  58%|█████▊    | 922/1600 [00:40<00:29, 22.97it/s]Training:  72%|███████▏  | 1155/1600 [00:50<00:19, 23.08it/s]Training:  87%|████████▋ | 1388/1600 [01:00<00:09, 22.82it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 226/1600 [00:10<01:00, 22.53it/s]Training:  14%|█▍        | 226/1600 [00:20<01:00, 22.53it/s]Training:  28%|██▊       | 452/1600 [00:20<00:51, 22.30it/s]Training:  42%|████▏     | 674/1600 [00:30Training loss: 68.0004, Training accuracy: 0.9881
Macro F1-score: 0.9881
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9875, F1_score: 0.9900
Model performance on Happy speech (in training): 
	Precision: 0.9850, Recall: 0.9875, F1_score: 0.9863
Model performance on Neutral speech (in training): 
	Precision: 0.9850, Recall: 0.9825, F1_score: 0.9837
Model performance on Sad speech (in training): 
	Precision: 0.9900, Recall: 0.9950, F1_score: 0.9925

Eval Phase: 
Validation loss: 14.6112, Validation accuracy: 0.9800
Macro F1-score: 0.9800
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Neutral speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Sad speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Epoch 10/100

Training Phase:
<00:41, 22.09it/s]Training:  56%|█████▌    | 896/1600 [00:40<00:31, 22.11it/s]Training:  70%|███████   | 1122/1600 [00:50<00:21, 22.26it/s]Training:  84%|████████▍ | 1351/1600 [01:00<00:11, 22.46it/s]Training:  99%|█████████▉| 1580/1600 [01:10<00:00, 22.43it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 222/1600 [00:10<01:02, 22.18it/s]Training:  28%|██▊       | 444/1600 [00:20<00:52, 22.01it/s]Training:  41%|████▏     | 663/1600 [00:30<00:42, 21.83it/s]Training:  55%|█████▌    | 884/1600 [00:40<00:32, 21.93it/s]Training:  69%|██████▉   | 1109/1600 [00:50<00:22, 22.13it/s]Training:  83%|████████▎ | 1334/1600 [01:00<00:11, 22.18it/s]Training:  97%|█████████Training loss: 74.0637, Training accuracy: 0.9850
Macro F1-score: 0.9850
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912
Model performance on Happy speech (in training): 
	Precision: 0.9776, Recall: 0.9825, F1_score: 0.9800
Model performance on Neutral speech (in training): 
	Precision: 0.9799, Recall: 0.9775, F1_score: 0.9787
Model performance on Sad speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900

Eval Phase: 
Validation loss: 13.9299, Validation accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Neutral speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
New best accuracy for layer 4 on epoch 10: 0.9900. Model saved.
Epoch 11/100

Training Phase:
Training loss: 57.4140, Training accuracy: 0.9888
Macro F1-score: 0.9888
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9900, F1_score: 0.9925
Model performance on Happy speech (in training): 
	Precision: 0.9800, Recall: 0.9825, F1_score: 0.9813
Model performance on Neutral speech (in training): 
	Precision: 0.9850, Recall: 0.9850, F1_score: 0.9850
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963

Eval Phase: 
Validation loss: 7.4881, Validation accuracy: 0.9850
Macro F1-score: 0.9850
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Happy speech (in validation): 
	Precision: 0.9796, Recall: 0.9600, F1_score: 0.9697
Model performance on Neutral speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 12/100

Training Phase:
| 1557/1600 [01:10<00:01, 22.08it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 220/1600 [00:10<01:02, 21.91it/s]Training:  28%|██▊       | 440/1600 [00:20<00:52, 21.96it/s]Training:  42%|████▏     | 665/1600 [00:30<00:42, 22.19it/s]Training:  56%|█████▌    | 890/1600 [00:40<00:32, 22.03it/s]Training:  69%|██████▉   | 1108/1600 [00:50<00:22, 21.80it/s]Training:  83%|████████▎ | 1328/1600 [01:00<00:12, 21.85it/s]Training:  97%|█████████▋| 1549/1600 [01:10<00:02, 21.91it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 21Training loss: 33.4836, Training accuracy: 0.9931
Macro F1-score: 0.9931
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9925, F1_score: 0.9950
Model performance on Happy speech (in training): 
	Precision: 0.9876, Recall: 0.9925, F1_score: 0.9900
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963

Eval Phase: 
Validation loss: 9.4640, Validation accuracy: 0.9850
Macro F1-score: 0.9851
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Neutral speech (in validation): 
	Precision: 0.9434, Recall: 1.0000, F1_score: 0.9709
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 13/100

Training Phase:
9/1600 [00:10<01:03, 21.86it/s]Training:  27%|██▋       | 439/1600 [00:20<00:53, 21.90it/s]Training:  41%|████▏     | 662/1600 [00:30<00:42, 22.05it/s]Training:  55%|█████▌    | 885/1600 [00:40<00:32, 21.87it/s]Training:  69%|██████▉   | 1103/1600 [00:50<00:22, 21.83it/s]Training:  84%|████████▎ | 1337/1600 [01:00<00:11, 22.36it/s]Training:  98%|█████████▊| 1571/1600 [01:10<00:01, 22.46it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 223/1600 [00:10<01:01, 22.23it/s]Training:  28%|██▊       | 446/1600 [00:20<00:51, 22.26it/s]Training:  42%|████▏     | 679/1600 [00:30<00:40, 22.71it/s]Training:  57%|█████▋    | 912/1600 [00:40<00:30, 22.66it/s]Training:  71%|███████▏  | 1142/Training loss: 55.3119, Training accuracy: 0.9894
Macro F1-score: 0.9894
Model performance on Angry speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900
Model performance on Happy speech (in training): 
	Precision: 0.9850, Recall: 0.9850, F1_score: 0.9850
Model performance on Neutral speech (in training): 
	Precision: 0.9899, Recall: 0.9850, F1_score: 0.9875
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9975, F1_score: 0.9950

Eval Phase: 
Validation loss: 23.5574, Validation accuracy: 0.9750
Macro F1-score: 0.9750
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Happy speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Neutral speech (in validation): 
	Precision: 0.9434, Recall: 1.0000, F1_score: 0.9709
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 14/100

Training Phase:
1600 [00:50<00:20, 22.75it/s]Training:  86%|████████▌ | 1372/1600 [01:00<00:10, 22.43it/s]Training:  99%|█████████▉| 1591/1600 [01:10<00:00, 22.23it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 219/1600 [00:10<01:03, 21.85it/s]Training:  27%|██▋       | 438/1600 [00:20<00:53, 21.76it/s]Training:  41%|████      | 657/1600 [00:30<00:43, 21.77it/s]Training:  55%|█████▍    | 876/1600 [00:40<00:33, 21.80it/s]Training:  69%|██████▉   | 1106/1600 [00:50<00:22, 22.20it/s]Training:  69%|██████▉   | 1106/1600 [01:00<00:22, 22.20it/s]Training:  84%|████████▎ | 1336/1600 [01:00<00:11, 22.42it/s]Training:  98%|█████████▊| 1566/1600 [01:10<00:01, 22.59it/s]                         Training loss: 40.9120, Training accuracy: 0.9944
Macro F1-score: 0.9944
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Happy speech (in training): 
	Precision: 0.9900, Recall: 0.9950, F1_score: 0.9925
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9875, F1_score: 0.9900
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Validation loss: 17.8247, Validation accuracy: 0.9850
Macro F1-score: 0.9851
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Neutral speech (in validation): 
	Precision: 0.9434, Recall: 1.0000, F1_score: 0.9709
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 15/100

Training Phase:
Training loss: 37.2722, Training accuracy: 0.9919
Macro F1-score: 0.9919
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912
Model performance on Happy speech (in training): 
	Precision: 0.9875, Recall: 0.9900, F1_score: 0.9888
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950

Eval Phase: 
Validation loss: 23.5683, Validation accuracy: 0.9800
Macro F1-score: 0.9801
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Neutral speech (in validation): 
	Precision: 0.9423, Recall: 0.9800, F1_score: 0.9608
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 16/100

Training Phase:
                                    Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 219/1600 [00:10<01:03, 21.80it/s]Training:  28%|██▊       | 442/1600 [00:20<00:52, 22.06it/s]Training:  42%|████▏     | 665/1600 [00:30<00:42, 21.94it/s]Training:  56%|█████▌    | 893/1600 [00:40<00:31, 22.25it/s]Training:  70%|███████   | 1122/1600 [00:50<00:21, 22.47it/s]Training:  84%|████████▍ | 1351/1600 [01:00<00:11, 22.36it/s]Training:  98%|█████████▊| 1574/1600 [01:10<00:01, 22.34it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 229/1600 [00:10<01:00, 22.83it/s]Training:  29%|██▊       |Training loss: 63.8122, Training accuracy: 0.9856
Macro F1-score: 0.9856
Model performance on Angry speech (in training): 
	Precision: 0.9875, Recall: 0.9875, F1_score: 0.9875
Model performance on Happy speech (in training): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Neutral speech (in training): 
	Precision: 0.9825, Recall: 0.9850, F1_score: 0.9838
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912

Eval Phase: 
Validation loss: 9.9754, Validation accuracy: 0.9850
Macro F1-score: 0.9851
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Neutral speech (in validation): 
	Precision: 0.9434, Recall: 1.0000, F1_score: 0.9709
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Validation loss does not decrease for 10 epochs. End training.
Model best accuracy on validation set: 0.9900

Test Phase: 
 458/1600 [00:20<00:51, 22.21it/s]Training:  42%|████▏     | 677/1600 [00:30<00:42, 21.81it/s]Training:  56%|█████▌    | 899/1600 [00:40<00:31, 21.95it/s]Training:  70%|███████   | 1121/1600 [00:50<00:21, 21.91it/s]Training:  84%|████████▍ | 1342/1600 [01:01<00:11, 21.94it/s]Training:  84%|████████▍ | 1342/1600 [01:11<00:11, 21.94it/s]Training:  98%|█████████▊| 1560/1600 [01:11<00:01, 21.71it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]                                                Some weights of the model checkpoint at /work/tc062/tc062/zhan7721/saved_models/de were not used when initializing Wav2Vec2Model: ['encoder.layers.10.attention.k_proj.bias', 'encoder.layers.10.attention.k_proj.weight', 'encoder.layers.10.attention.out_proj.bias', 'encoder.layers.10.attention.out_proj.weight', 'encoder.layers.10.attention.q_proj.bias', 'encoder.layers.10.attention.q_proj.weight', 'encoder.layers.10.attention.v_proj.bias', 'encoder.layers.10.attention.v_proj.weight', 'encoder.layers.10.feed_forward.intermediate_dense.bias', 'encoder.layers.10.feed_forward.intermediate_dense.weight', 'encoder.layers.10.feed_forward.output_dense.bias', 'encoder.layers.10.feed_forward.output_dense.weight', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.10.layer_norm.bias', 'encoder.layers.10.layer_norm.weight', 'encoder.layers.11.attention.k_proj.bias', 'encoder.layers.11.attention.k_proj.weight', 'encoder.layers.11.attention.out_proj.bias', 'encoder.layers.11.attention.out_proj.weight', 'encoder.layers.11.attention.q_proj.bias', 'encoder.layers.11.attention.q_proj.weight', 'encoder.layers.11.attention.v_proj.bias', 'encoder.layers.11.attention.v_proj.weight', 'encoder.layers.11.feed_forward.intermediate_dense.bias', 'encoder.layers.11.feed_forward.intermediate_dense.weight', 'encoder.layers.11.feed_forward.output_dense.bias', 'encoder.layers.11.feed_forward.output_dense.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.11.layer_norm.bias', 'encoder.layers.11.layer_norm.weight', 'encoder.layers.5.attention.k_proj.bias', 'encoder.layers.5.attention.k_proj.weight', 'encoder.layers.5.attention.out_proj.bias', 'encoder.layers.5.attention.out_proj.weight', 'encoder.layers.5.attention.q_proj.bias', 'encoder.layers.5.attention.q_proj.weight', 'encoder.layers.5.attention.v_proj.bias', 'encoder.layers.5.attention.v_proj.weight', 'encoder.layers.5.feed_forward.intermediate_dense.bias', 'encoder.layers.5.feed_forward.intermediate_dense.weight', 'encoder.layers.5.feed_forward.output_dense.bias', 'encoder.layers.5.feed_forward.output_dense.weight', 'encoder.layers.5.final_layer_norm.bias', 'encoder.layers.5.final_layer_norm.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.6.attention.k_proj.bias', 'encoder.layers.6.attention.k_proj.weight', 'encoder.layers.6.attention.out_proj.bias', 'encoder.layers.6.attention.out_proj.weight', 'encoder.layers.6.attention.q_proj.bias', 'encoder.layers.6.attention.q_proj.weight', 'encoder.layers.6.attention.v_proj.bias', 'encoder.layers.6.attention.v_proj.weight', 'encoder.layers.6.feed_forward.intermediate_dense.bias', 'encoder.layers.6.feed_forward.intermediate_dense.weight', 'encoder.layers.6.feed_forward.output_dense.bias', 'encoder.layers.6.feed_forward.output_dense.weight', 'encoder.layers.6.final_layer_norm.bias', 'encoder.layers.6.final_layer_norm.weight', 'encoder.layers.6.layer_norm.bias', 'encoder.layers.6.layer_norm.weight', 'encoder.layers.7.attention.k_proj.bias', 'encoder.layers.7.attention.k_proj.weight', 'encoder.layers.7.attention.out_proj.bias', 'encoder.layers.7.attention.out_proj.weight', 'encoder.layers.7.attention.q_proj.bias', 'encoder.layers.7.attention.q_proj.weight', 'encoder.layers.7.attention.v_proj.bias', 'encoder.layers.7.attention.v_proj.weight', 'encoder.layers.7.feed_forward.intermediate_dense.bias', 'encoder.layers.7.feed_forward.intermediate_dense.weight', 'encoder.layers.7.feed_forward.output_dense.bias', 'encoder.layers.7.feed_forward.output_dense.weight', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.7.layer_norm.bias', 'encoder.layers.7.layer_norm.weight', 'encoder.layers.8.attention.k_proj.bias', 'encoder.layers.8.attention.k_proj.weight', 'encoder.layers.8.attention.out_proj.bias', 'encoder.layers.8.attention.out_proj.weight', 'encoder.layers.8.attention.q_proj.bias', 'encoder.layers.8.attention.q_proj.weight', 'encoder.layers.8.attention.v_proj.bias', 'encoder.layers.8.attention.v_proj.weight', 'encoder.layers.8.feed_forward.intermediate_dense.bias', 'encoder.layers.8.feed_forward.intermediate_dense.weight', 'encoder.layers.8.feed_forward.output_dense.bias', 'encoder.layers.8.feed_forward.output_dense.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.8.layer_norm.bias', 'encoder.layers.8.layer_norm.weight', 'encoder.layers.9.attention.k_proj.bias', 'encoder.layers.9.attention.k_proj.weight', 'encoder.layers.9.attention.out_proj.bias', 'encoder.layers.9.attention.out_proj.weight', 'encoder.layers.9.attention.q_proj.bias', 'encoder.layers.9.attention.q_proj.weight', 'encoder.layers.9.attention.v_proj.bias', 'encoder.layers.9.attention.v_proj.weight', 'encoder.layers.9.feed_forward.intermediate_dense.bias', 'encoder.layers.9.feed_forward.intermediate_dense.weight', 'encoder.layers.9.feed_forward.output_dense.bias', 'encoder.layers.9.feed_forward.output_dense.weight', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.layer_norm.bias', 'encoder.layers.9.layer_norm.weight']
- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Test loss: 1.7993, Test accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in test): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in test): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Neutral speech (in test): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Sad speech (in test): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

======================= This is fold_2 on cn =======================

Load dataset: 
Loading de train data: fold_2...
Preprocess de fold_2 data for cn model
Loading de eval data: fold_2...
Preprocess de fold_2 data for cn model
Loading de test data: fold_2...
Preprocess de fold_2 data for cn model
Use cn model to add lora
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training loss: 508.3189, Training accuracy: 0.8944
Macro F1-score: 0.8948
Model performance on Angry speech (in training): 
	Precision: 0.9175, Recall: 0.8900, F1_score: 0.9036
Model performance on Happy speech (in training): 
	Precision: 0.8258, Recall: 0.8650, F1_score: 0.8449
Model performance on Neutral speech (in training): 
	Precision: 0.8722, Recall: 0.8700, F1_score: 0.8711
Model performance on Sad speech (in training): 
	Precision: 0.9670, Recall: 0.9525, F1_score: 0.9597

Eval Phase: 
Validation loss: 37.9380, Validation accuracy: 0.9350
Macro F1-score: 0.9342
Model performance on Angry speech (in validation): 
	Precision: 0.9583, Recall: 0.9200, F1_score: 0.9388
Model performance on Happy speech (in validation): 
	Precision: 0.9333, Recall: 0.8400, F1_score: 0.8842
Model performance on Neutral speech (in validation): 
	Precision: 0.8909, Recall: 0.9800, F1_score: 0.9333
Model performance on Sad speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
New best accuracy for layer 4 on epoch 1: 0.9350. Model saved.
Epoch 2/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:   8%|▊         | 123/1600 [00:10<02:00, 12.30it/s]Training:  17%|█▋        | 276/1600 [00:20<01:34, 14.06it/s]Training:  29%|██▊       | 457/1600 [00:30<01:11, 15.88it/s]Training:  41%|████      | 649/1600 [00:40<00:55, 17.19it/s]Training:  53%|█████▎    | 848/1600 [00:50<00:41, 18.13it/s]Training:  65%|██████▌   | 1046/1600 [01:00<00:29, 18.59it/s]Training:  78%|███████▊  | 1247/1600 [01:10<00:18, 19.08it/s]Training:  90%|█████████ | 1448/1600 [01:20<00:07, 19.36it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 223/1600 [00:10<01:01, 22.29it/s]Training:  28%|██▊       | 449/1600 [00:20<00:51, 22.41it/s]Training:  42%|████▏     | 675/1600 [00:Training loss: 157.0115, Training accuracy: 0.9675
Macro F1-score: 0.9675
Model performance on Angry speech (in training): 
	Precision: 0.9773, Recall: 0.9675, F1_score: 0.9724
Model performance on Happy speech (in training): 
	Precision: 0.9573, Recall: 0.9525, F1_score: 0.9549
Model performance on Neutral speech (in training): 
	Precision: 0.9554, Recall: 0.9650, F1_score: 0.9602
Model performance on Sad speech (in training): 
	Precision: 0.9801, Recall: 0.9850, F1_score: 0.9825

Eval Phase: 
Validation loss: 23.9216, Validation accuracy: 0.9650
Macro F1-score: 0.9647
Model performance on Angry speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9000, F1_score: 0.9474
Model performance on Neutral speech (in validation): 
	Precision: 0.9423, Recall: 0.9800, F1_score: 0.9608
Model performance on Sad speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
New best accuracy for layer 4 on epoch 2: 0.9650. Model saved.
Epoch 3/100

Training Phase:
30<00:41, 22.48it/s]Training:  56%|█████▋    | 901/1600 [00:40<00:31, 22.53it/s]Training:  70%|███████   | 1128/1600 [00:50<00:20, 22.57it/s]Training:  85%|████████▍ | 1355/1600 [01:00<00:10, 22.55it/s]Training:  99%|█████████▉| 1584/1600 [01:10<00:00, 22.65it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 230/1600 [00:10<00:59, 22.98it/s]Training:  29%|██▉       | 460/1600 [00:20<00:50, 22.62it/s]Training:  43%|████▎     | 684/1600 [00:30<00:40, 22.47it/s]Training:  57%|█████▋    | 910/1600 [00:40<00:30, 22.51it/s]Training:  71%|███████   | 1138/1600 [00:50<00:20, 22.61it/s]Training:  85%|████████▌ | 1366/1600 [01:00<00:10, 22.54it/s]Training: 100%|████████Training loss: 121.0671, Training accuracy: 0.9781
Macro F1-score: 0.9781
Model performance on Angry speech (in training): 
	Precision: 0.9899, Recall: 0.9800, F1_score: 0.9849
Model performance on Happy speech (in training): 
	Precision: 0.9627, Recall: 0.9675, F1_score: 0.9651
Model performance on Neutral speech (in training): 
	Precision: 0.9701, Recall: 0.9750, F1_score: 0.9726
Model performance on Sad speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900

Eval Phase: 
Validation loss: 34.8422, Validation accuracy: 0.9500
Macro F1-score: 0.9490
Model performance on Angry speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.8200, F1_score: 0.9011
Model performance on Neutral speech (in validation): 
	Precision: 0.8750, Recall: 0.9800, F1_score: 0.9245
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 4/100

Training Phase:
Training loss: 106.3281, Training accuracy: 0.9769
Macro F1-score: 0.9769
Model performance on Angry speech (in training): 
	Precision: 0.9850, Recall: 0.9850, F1_score: 0.9850
Model performance on Happy speech (in training): 
	Precision: 0.9673, Recall: 0.9625, F1_score: 0.9649
Model performance on Neutral speech (in training): 
	Precision: 0.9676, Recall: 0.9700, F1_score: 0.9688
Model performance on Sad speech (in training): 
	Precision: 0.9875, Recall: 0.9900, F1_score: 0.9888

Eval Phase: 
Validation loss: 36.8766, Validation accuracy: 0.9600
Macro F1-score: 0.9598
Model performance on Angry speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9000, F1_score: 0.9474
Model performance on Neutral speech (in validation): 
	Precision: 0.9412, Recall: 0.9600, F1_score: 0.9505
Model performance on Sad speech (in validation): 
	Precision: 0.9434, Recall: 1.0000, F1_score: 0.9709
Epoch 5/100

Training Phase:
▉| 1592/1600 [01:10<00:00, 22.55it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 228/1600 [00:10<01:00, 22.71it/s]Training:  28%|██▊       | 456/1600 [00:20<00:51, 22.42it/s]Training:  43%|████▎     | 686/1600 [00:30<00:40, 22.65it/s]Training:  57%|█████▋    | 916/1600 [00:40<00:30, 22.73it/s]Training:  72%|███████▏  | 1145/1600 [00:50<00:20, 22.68it/s]Training:  86%|████████▌ | 1375/1600 [01:00<00:09, 22.79it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 230/1600 [00:10<00:59, 22.93it/s]Training:  29%|██▉       | 460/1600 [00:Training loss: 98.8158, Training accuracy: 0.9769
Macro F1-score: 0.9769
Model performance on Angry speech (in training): 
	Precision: 0.9825, Recall: 0.9825, F1_score: 0.9825
Model performance on Happy speech (in training): 
	Precision: 0.9673, Recall: 0.9625, F1_score: 0.9649
Model performance on Neutral speech (in training): 
	Precision: 0.9653, Recall: 0.9750, F1_score: 0.9701
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9875, F1_score: 0.9900

Eval Phase: 
Validation loss: 44.9410, Validation accuracy: 0.9700
Macro F1-score: 0.9698
Model performance on Angry speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9200, F1_score: 0.9583
Model performance on Neutral speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Sad speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
New best accuracy for layer 4 on epoch 5: 0.9700. Model saved.
Epoch 6/100

Training Phase:
20<00:49, 22.80it/s]Training:  43%|████▎     | 688/1600 [00:30<00:40, 22.79it/s]Training:  57%|█████▋    | 916/1600 [00:40<00:30, 22.69it/s]Training:  72%|███████▏  | 1146/1600 [00:50<00:19, 22.78it/s]Training:  86%|████████▌ | 1378/1600 [01:00<00:09, 22.92it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 218/1600 [00:10<01:03, 21.80it/s]Training:  28%|██▊       | 441/1600 [00:20<00:52, 22.09it/s]Training:  42%|████▏     | 670/1600 [00:30<00:41, 22.42it/s]Training:  56%|█████▌    | 899/1600 [00:40<00:31, 22.37it/s]Training:  70%|███████   | 1123/1600 [00:50<00:21, 22.38it/s]Training:  84%|████████▍ | 1348/1600 [01:00<00:11, 22.39it/s]Training:  98%|█████████▊| 157Training loss: 89.6078, Training accuracy: 0.9794
Macro F1-score: 0.9794
Model performance on Angry speech (in training): 
	Precision: 0.9850, Recall: 0.9825, F1_score: 0.9837
Model performance on Happy speech (in training): 
	Precision: 0.9774, Recall: 0.9725, F1_score: 0.9749
Model performance on Neutral speech (in training): 
	Precision: 0.9726, Recall: 0.9775, F1_score: 0.9751
Model performance on Sad speech (in training): 
	Precision: 0.9825, Recall: 0.9850, F1_score: 0.9838

Eval Phase: 
Validation loss: 28.9096, Validation accuracy: 0.9700
Macro F1-score: 0.9698
Model performance on Angry speech (in validation): 
	Precision: 0.9245, Recall: 0.9800, F1_score: 0.9515
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9000, F1_score: 0.9474
Model performance on Neutral speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 7/100

Training Phase:
Training loss: 63.2384, Training accuracy: 0.9881
Macro F1-score: 0.9881
Model performance on Angry speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900
Model performance on Happy speech (in training): 
	Precision: 0.9848, Recall: 0.9750, F1_score: 0.9799
Model performance on Neutral speech (in training): 
	Precision: 0.9802, Recall: 0.9900, F1_score: 0.9851
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Validation loss: 19.1650, Validation accuracy: 0.9800
Macro F1-score: 0.9800
Model performance on Angry speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Neutral speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Sad speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
New best accuracy for layer 4 on epoch 7: 0.9800. Model saved.
Epoch 8/100

Training Phase:
5/1600 [01:10<00:01, 22.48it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 227/1600 [00:10<01:00, 22.68it/s]Training:  28%|██▊       | 454/1600 [00:20<00:51, 22.09it/s]Training:  42%|████▎     | 680/1600 [00:30<00:41, 22.31it/s]Training:  57%|█████▋    | 907/1600 [00:40<00:30, 22.43it/s]Training:  71%|███████   | 1134/1600 [00:50<00:20, 22.42it/s]Training:  85%|████████▍ | 1359/1600 [01:00<00:10, 22.37it/s]Training:  99%|█████████▉| 1582/1600 [01:10<00:00, 22.23it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 226/1600 Training loss: 52.7560, Training accuracy: 0.9875
Macro F1-score: 0.9875
Model performance on Angry speech (in training): 
	Precision: 0.9875, Recall: 0.9900, F1_score: 0.9888
Model performance on Happy speech (in training): 
	Precision: 0.9800, Recall: 0.9825, F1_score: 0.9813
Model performance on Neutral speech (in training): 
	Precision: 0.9875, Recall: 0.9875, F1_score: 0.9875
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9900, F1_score: 0.9925

Eval Phase: 
Validation loss: 55.9298, Validation accuracy: 0.9550
Macro F1-score: 0.9544
Model performance on Angry speech (in validation): 
	Precision: 0.9245, Recall: 0.9800, F1_score: 0.9515
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.8600, F1_score: 0.9247
Model performance on Neutral speech (in validation): 
	Precision: 0.9245, Recall: 0.9800, F1_score: 0.9515
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 9/100

Training Phase:
[00:10<01:00, 22.57it/s]Training:  28%|██▊       | 455/1600 [00:20<00:50, 22.75it/s]Training:  43%|████▎     | 684/1600 [00:30<00:40, 22.60it/s]Training:  57%|█████▋    | 914/1600 [00:40<00:30, 22.75it/s]Training:  72%|███████▏  | 1144/1600 [00:50<00:20, 22.60it/s]Training:  86%|████████▌ | 1375/1600 [01:00<00:09, 22.76it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 227/1600 [00:10<01:00, 22.68it/s]Training:  28%|██▊       | 454/1600 [00:20<00:50, 22.56it/s]Training:  43%|████▎     | 682/1600 [00:30<00:40, 22.65it/s]Training:  57%|█████▋    | 912/1600 [00:40<00:30, 22.76it/s]Training:  71%|███████▏  | 1142/1600 [00:50<00:20, 22.69it/s]Training:  86%|████████▌ | 1369/1600 [0Training loss: 46.5569, Training accuracy: 0.9888
Macro F1-score: 0.9887
Model performance on Angry speech (in training): 
	Precision: 0.9900, Recall: 0.9875, F1_score: 0.9887
Model performance on Happy speech (in training): 
	Precision: 0.9850, Recall: 0.9825, F1_score: 0.9837
Model performance on Neutral speech (in training): 
	Precision: 0.9851, Recall: 0.9925, F1_score: 0.9888
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937

Eval Phase: 
Validation loss: 43.2093, Validation accuracy: 0.9700
Macro F1-score: 0.9698
Model performance on Angry speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9200, F1_score: 0.9583
Model performance on Neutral speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Sad speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Epoch 10/100

Training Phase:
Training loss: 36.0834, Training accuracy: 0.9925
Macro F1-score: 0.9925
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912
Model performance on Happy speech (in training): 
	Precision: 0.9850, Recall: 0.9875, F1_score: 0.9863
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987

Eval Phase: 
Validation loss: 26.6206, Validation accuracy: 0.9750
Macro F1-score: 0.9749
Model performance on Angry speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9400, F1_score: 0.9691
Model performance on Neutral speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 11/100

Training Phase:
1:00<00:10, 22.68it/s]Training: 100%|█████████▉| 1598/1600 [01:10<00:00, 22.73it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 224/1600 [00:10<01:01, 22.30it/s]Training:  28%|██▊       | 449/1600 [00:20<00:51, 22.40it/s]Training:  43%|████▎     | 681/1600 [00:30<00:40, 22.76it/s]Training:  57%|█████▋    | 913/1600 [00:40<00:30, 22.77it/s]Training:  72%|███████▏  | 1145/1600 [00:50<00:19, 22.88it/s]Training:  86%|████████▌ | 1377/1600 [01:00<00:09, 22.97it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 229/1600 [00:10<Training loss: 70.0557, Training accuracy: 0.9881
Macro F1-score: 0.9881
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9975, F1_score: 0.9950
Model performance on Happy speech (in training): 
	Precision: 0.9924, Recall: 0.9850, F1_score: 0.9887
Model performance on Neutral speech (in training): 
	Precision: 0.9801, Recall: 0.9850, F1_score: 0.9825
Model performance on Sad speech (in training): 
	Precision: 0.9875, Recall: 0.9850, F1_score: 0.9862

Eval Phase: 
Validation loss: 21.9960, Validation accuracy: 0.9700
Macro F1-score: 0.9699
Model performance on Angry speech (in validation): 
	Precision: 0.9423, Recall: 0.9800, F1_score: 0.9608
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9200, F1_score: 0.9583
Model performance on Neutral speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 12/100

Training Phase:
01:00, 22.80it/s]Training:  29%|██▊       | 457/1600 [00:20<00:50, 22.70it/s]Training:  43%|████▎     | 684/1600 [00:30<00:40, 22.43it/s]Training:  57%|█████▋    | 906/1600 [00:40<00:31, 22.29it/s]Training:  71%|███████   | 1139/1600 [00:50<00:20, 22.65it/s]Training:  86%|████████▌ | 1372/1600 [01:00<00:10, 22.58it/s]Training: 100%|█████████▉| 1597/1600 [01:10<00:00, 22.52it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 224/1600 [00:10<01:01, 22.34it/s]Training:  28%|██▊       | 453/1600 [00:20<00:50, 22.63it/s]Training:  43%|████▎     | 682/1600 [00:30<00:40, 22.70it/s]Training:  57%|█████▋    | 910/1600 [00:40<00:30, 22.51it/s]Training:  71%|███████   | 1136/1600 [00:50<00:2Training loss: 41.9657, Training accuracy: 0.9906
Macro F1-score: 0.9906
Model performance on Angry speech (in training): 
	Precision: 0.9900, Recall: 0.9875, F1_score: 0.9887
Model performance on Happy speech (in training): 
	Precision: 0.9800, Recall: 0.9825, F1_score: 0.9813
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 18.9888, Validation accuracy: 0.9700
Macro F1-score: 0.9699
Model performance on Angry speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9200, F1_score: 0.9583
Model performance on Neutral speech (in validation): 
	Precision: 0.9423, Recall: 0.9800, F1_score: 0.9608
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 13/100

Training Phase:
Training loss: 53.8290, Training accuracy: 0.9906
Macro F1-score: 0.9906
Model performance on Angry speech (in training): 
	Precision: 0.9900, Recall: 0.9875, F1_score: 0.9887
Model performance on Happy speech (in training): 
	Precision: 0.9827, Recall: 0.9925, F1_score: 0.9876
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9900, F1_score: 0.9925
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937

Eval Phase: 
0, 22.51it/s]Training:  85%|████████▌ | 1362/1600 [01:00<00:10, 22.54it/s]Training:  99%|█████████▉| 1591/1600 [01:10<00:00, 22.65it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 228/1600 [00:10<01:00, 22.78it/s]Training:  28%|██▊       | 456/1600 [00:20<00:51, 22.41it/s]Training:  43%|████▎     | 682/1600 [00:30<00:40, 22.46it/s]Training:  57%|█████▋    | 908/1600 [00:40<00:31, 22.32it/s]Training:  71%|███████   | 1135/1600 [00:50<00:20, 22.45it/s]Training:  85%|████████▌ | 1362/1600 [01:00<00:10, 22.46it/s]Training: 100%|█████████▉| 1592/1600 [01:10<00:00, 22.60it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]Validation loss: 28.5740, Validation accuracy: 0.9700
Macro F1-score: 0.9698
Model performance on Angry speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9200, F1_score: 0.9583
Model performance on Neutral speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Sad speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Epoch 14/100

Training Phase:
Training loss: 31.6106, Training accuracy: 0.9944
Macro F1-score: 0.9944
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950

Eval Phase: 
Validation loss: 26.7959, Validation accuracy: 0.9800
Macro F1-score: 0.9800
Model performance on Angry speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Neutral speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 15/100

Training Phase:
                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 231/1600 [00:10<00:59, 23.03it/s]Training:  29%|██▉       | 462/1600 [00:20<00:50, 22.76it/s]Training:  43%|████▎     | 688/1600 [00:30<00:40, 22.57it/s]Training:  57%|█████▋    | 916/1600 [00:40<00:30, 22.63it/s]Training:  72%|███████▏  | 1144/1600 [00:50<00:20, 22.59it/s]Training:  86%|████████▌ | 1370/1600 [01:00<00:10, 22.39it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 218/1600 [00:10<01:03, 21.71it/s]Training:  27%|██▋       | 437/1600 [00:20<00:53, 21.79it/s]Training:  41%|████▏     | 661/1600 [00:30<00:42, 22.03it/s]Training:  56%|█████▌    | 895/1600 [00:40<00:31, 22Training loss: 46.1648, Training accuracy: 0.9881
Macro F1-score: 0.9881
Model performance on Angry speech (in training): 
	Precision: 0.9899, Recall: 0.9850, F1_score: 0.9875
Model performance on Happy speech (in training): 
	Precision: 0.9777, Recall: 0.9850, F1_score: 0.9813
Model performance on Neutral speech (in training): 
	Precision: 0.9924, Recall: 0.9850, F1_score: 0.9887
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9975, F1_score: 0.9950

Eval Phase: 
Validation loss: 37.7236, Validation accuracy: 0.9650
Macro F1-score: 0.9649
Model performance on Angry speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9200, F1_score: 0.9583
Model performance on Neutral speech (in validation): 
	Precision: 0.9412, Recall: 0.9600, F1_score: 0.9505
Model performance on Sad speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Epoch 16/100

Training Phase:
.56it/s]Training:  71%|███████   | 1129/1600 [00:50<00:20, 22.46it/s]Training:  84%|████████▍ | 1352/1600 [01:00<00:11, 22.39it/s]Training:  98%|█████████▊| 1575/1600 [01:10<00:01, 22.18it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 219/1600 [00:10<01:03, 21.88it/s]Training:  28%|██▊       | 444/1600 [00:20<00:52, 22.19it/s]Training:  42%|████▏     | 669/1600 [00:30<00:42, 22.01it/s]Training:  56%|█████▌    | 892/1600 [00:40<00:32, 22.12it/s]Training:  70%|███████   | 1125/1600 [00:50<00:21, 22.52it/s]Training:  85%|████████▍ | 1358/1600 [01:00<00:10, 22.77it/s]Training:  99%|█████████▉| 1591/1600 [01:10<00:00, 22.85it/s]                                            Training loss: 32.2076, Training accuracy: 0.9956
Macro F1-score: 0.9956
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Validation loss: 54.2519, Validation accuracy: 0.9550
Macro F1-score: 0.9546
Model performance on Angry speech (in validation): 
	Precision: 0.8929, Recall: 1.0000, F1_score: 0.9434
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.8600, F1_score: 0.9247
Model performance on Neutral speech (in validation): 
	Precision: 0.9796, Recall: 0.9600, F1_score: 0.9697
Model performance on Sad speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Epoch 17/100

Training Phase:
Training loss: 48.5005, Training accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in training): 
	Precision: 0.9926, Recall: 1.0000, F1_score: 0.9963
Model performance on Happy speech (in training): 
	Precision: 0.9874, Recall: 0.9825, F1_score: 0.9850
Model performance on Neutral speech (in training): 
	Precision: 0.9825, Recall: 0.9825, F1_score: 0.9825
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962

Eval Phase: 
Validation loss: 16.0900, Validation accuracy: 0.9800
Macro F1-score: 0.9799
Model performance on Angry speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9400, F1_score: 0.9691
Model performance on Neutral speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 18/100

Training Phase:
                 Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 232/1600 [00:10<00:58, 23.20it/s]Training:  29%|██▉       | 464/1600 [00:20<00:49, 22.96it/s]Training:  43%|████▎     | 693/1600 [00:30<00:40, 22.35it/s]Training:  57%|█████▋    | 913/1600 [00:40<00:30, 22.19it/s]Training:  71%|███████   | 1135/1600 [00:50<00:20, 22.19it/s]Training:  85%|████████▍ | 1357/1600 [01:01<00:11, 21.97it/s]Training:  99%|█████████▉| 1586/1600 [01:11<00:00, 22.26it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 227/1600 [00:10<01:00, 22.64it/s]Training:  28%|██▊       | 454/1600 [00:20<00Training loss: 29.6457, Training accuracy: 0.9944
Macro F1-score: 0.9944
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950

Eval Phase: 
Validation loss: 34.5603, Validation accuracy: 0.9650
Macro F1-score: 0.9648
Model performance on Angry speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9000, F1_score: 0.9474
Model performance on Neutral speech (in validation): 
	Precision: 0.9245, Recall: 0.9800, F1_score: 0.9515
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 19/100

Training Phase:
:51, 22.18it/s]Training:  42%|████▏     | 673/1600 [00:30<00:42, 22.05it/s]Training:  56%|█████▌    | 895/1600 [00:40<00:31, 22.09it/s]Training:  70%|██████▉   | 1117/1600 [00:50<00:21, 22.07it/s]Training:  84%|████████▍ | 1345/1600 [01:00<00:11, 22.29it/s]Training:  98%|█████████▊| 1573/1600 [01:10<00:01, 22.26it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 230/1600 [00:10<00:59, 23.00it/s]Training:  14%|█▍        | 230/1600 [00:20<00:59, 23.00it/s]Training:  29%|██▊       | 459/1600 [00:20<00:51, 22.20it/s]Training:  43%|████▎     | 687/1600 [00:30<00:40, 22.43it/s]Training:  57%|█████▋    | 915/1600 [00:40<00:30, 22.40it/s]Training:  71%|███████▏  | 1141/1600 [00:50<00:20,Training loss: 52.1866, Training accuracy: 0.9912
Macro F1-score: 0.9913
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9900, F1_score: 0.9925
Model performance on Happy speech (in training): 
	Precision: 0.9851, Recall: 0.9900, F1_score: 0.9875
Model performance on Neutral speech (in training): 
	Precision: 0.9900, Recall: 0.9875, F1_score: 0.9887
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963

Eval Phase: 
Validation loss: 21.1714, Validation accuracy: 0.9750
Macro F1-score: 0.9748
Model performance on Angry speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9200, F1_score: 0.9583
Model performance on Neutral speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 20/100

Training Phase:
Training loss: 22.2490, Training accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962

Eval Phase: 
Validation loss: 25.1262, Validation accuracy: 0.9750
Macro F1-score: 0.9749
Model performance on Angry speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9200, F1_score: 0.9583
Model performance on Neutral speech (in validation): 
	Precision: 0.9434, Recall: 1.0000, F1_score: 0.9709
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 21/100

Training Phase:
 22.45it/s]Training:  85%|████████▌ | 1367/1600 [01:00<00:10, 22.44it/s]Training: 100%|█████████▉| 1594/1600 [01:10<00:00, 22.51it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 229/1600 [00:10<01:00, 22.81it/s]Training:  29%|██▊       | 458/1600 [00:20<00:50, 22.51it/s]Training:  43%|████▎     | 681/1600 [00:30<00:41, 22.18it/s]Training:  57%|█████▋    | 910/1600 [00:40<00:30, 22.44it/s]Training:  72%|███████▏  | 1144/1600 [00:50<00:20, 22.78it/s]Training:  86%|████████▋ | 1383/1600 [01:00<00:09, 23.13it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/Training loss: 44.2374, Training accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912
Model performance on Happy speech (in training): 
	Precision: 0.9850, Recall: 0.9825, F1_score: 0.9837
Model performance on Neutral speech (in training): 
	Precision: 0.9875, Recall: 0.9900, F1_score: 0.9888
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963

Eval Phase: 
Validation loss: 20.2050, Validation accuracy: 0.9850
Macro F1-score: 0.9849
Model performance on Angry speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9400, F1_score: 0.9691
Model performance on Neutral speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
New best accuracy for layer 4 on epoch 21: 0.9850. Model saved.
Epoch 22/100

Training Phase:
1600 [00:00<?, ?it/s]Training:  15%|█▍        | 236/1600 [00:10<00:57, 23.57it/s]Training:  30%|██▉       | 472/1600 [00:20<00:48, 23.45it/s]Training:  44%|████▍     | 707/1600 [00:30<00:38, 23.44it/s]Training:  59%|█████▉    | 942/1600 [00:40<00:28, 23.17it/s]Training:  74%|███████▍  | 1184/1600 [00:50<00:17, 23.50it/s]Training:  89%|████████▉ | 1425/1600 [01:00<00:07, 23.45it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 237/1600 [00:10<00:57, 23.66it/s]Training:  30%|██▉       | 474/1600 [00:20<00:47, 23.53it/s]Training:  44%|████▍     | 710/1600 [00:30<00:37, 23.51it/s]Training:  59%|█████▉    | 945/1600 [00:40<00:28, 23.08it/s]Training:  73%|███████▎  | 1170/1600 [00:50<00:18, 22.87iTraining loss: 35.1986, Training accuracy: 0.9938
Macro F1-score: 0.9938
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Neutral speech (in training): 
	Precision: 0.9876, Recall: 0.9925, F1_score: 0.9900
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9900, F1_score: 0.9937

Eval Phase: 
Validation loss: 21.5959, Validation accuracy: 0.9850
Macro F1-score: 0.9849
Model performance on Angry speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9400, F1_score: 0.9691
Model performance on Neutral speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 23/100

Training Phase:
Training loss: 26.7534, Training accuracy: 0.9931
Macro F1-score: 0.9931
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9900, F1_score: 0.9925
Model performance on Neutral speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938

Eval Phase: 
Validation loss: 75.8491, Validation accuracy: 0.9450
Macro F1-score: 0.9448
Model performance on Angry speech (in validation): 
	Precision: 0.9245, Recall: 0.9800, F1_score: 0.9515
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9000, F1_score: 0.9474
Model performance on Neutral speech (in validation): 
	Precision: 0.9574, Recall: 0.9000, F1_score: 0.9278
Model performance on Sad speech (in validation): 
	Precision: 0.9091, Recall: 1.0000, F1_score: 0.9524
Epoch 24/100

Training Phase:
t/s]Training:  88%|████████▊ | 1400/1600 [01:00<00:08, 22.91it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 230/1600 [00:10<00:59, 22.94it/s]Training:  29%|██▉       | 460/1600 [00:20<00:49, 22.94it/s]Training:  44%|████▎     | 697/1600 [00:30<00:38, 23.24it/s]Training:  58%|█████▊    | 933/1600 [00:40<00:28, 23.27it/s]Training:  73%|███████▎  | 1167/1600 [00:50<00:18, 23.21it/s]Training:  88%|████████▊ | 1401/1600 [01:00<00:08, 23.25it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 233/1600 [00:10<00:58, 23.23it/s]TrTraining loss: 32.3502, Training accuracy: 0.9931
Macro F1-score: 0.9931
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9975, F1_score: 0.9950
Model performance on Neutral speech (in training): 
	Precision: 0.9899, Recall: 0.9850, F1_score: 0.9875
Model performance on Sad speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913

Eval Phase: 
Validation loss: 21.9895, Validation accuracy: 0.9800
Macro F1-score: 0.9799
Model performance on Angry speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9400, F1_score: 0.9691
Model performance on Neutral speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 25/100

Training Phase:
aining:  29%|██▉       | 466/1600 [00:20<00:48, 23.17it/s]Training:  44%|████▎     | 699/1600 [00:30<00:38, 23.19it/s]Training:  58%|█████▊    | 932/1600 [00:40<00:28, 23.06it/s]Training:  73%|███████▎  | 1165/1600 [00:50<00:18, 23.12it/s]Training:  88%|████████▊ | 1402/1600 [01:00<00:08, 23.31it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 231/1600 [00:10<00:59, 23.07it/s]Training:  29%|██▉       | 463/1600 [00:20<00:49, 23.12it/s]Training:  43%|████▎     | 695/1600 [00:30<00:39, 23.08it/s]Training:  58%|█████▊    | 930/1600 [00:40<00:28, 23.24it/s]Training:  73%|███████▎  | 1167/1600 [00:50<00:18, 23.39it/s]Training:  88%|████████▊ | 1404/1600 [01:00<00:08, 23.37it/s]    Training loss: 41.7394, Training accuracy: 0.9931
Macro F1-score: 0.9931
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Happy speech (in training): 
	Precision: 0.9850, Recall: 0.9875, F1_score: 0.9863
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 17.9453, Validation accuracy: 0.9800
Macro F1-score: 0.9799
Model performance on Angry speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9400, F1_score: 0.9691
Model performance on Neutral speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 26/100

Training Phase:
Training loss: 15.6011, Training accuracy: 0.9975
Macro F1-score: 0.9975
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 23.9754, Validation accuracy: 0.9800
Macro F1-score: 0.9799
Model performance on Angry speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9400, F1_score: 0.9691
Model performance on Neutral speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 27/100

Training Phase:
                                                         Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 236/1600 [00:10<00:57, 23.54it/s]Training:  30%|██▉       | 472/1600 [00:20<00:48, 23.31it/s]Training:  44%|████▍     | 704/1600 [00:30<00:38, 23.25it/s]Training:  58%|█████▊    | 936/1600 [00:40<00:28, 23.20it/s]Training:  73%|███████▎  | 1168/1600 [00:50<00:18, 23.15it/s]Training:  88%|████████▊ | 1400/1600 [01:00<00:08, 23.14it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 234/1600 [00:10<00:58, 23.40it/s]Training:  29%|██▉       | 468/1600 [00:20<00:48, 23.38it/s]Training:  44%|███Training loss: 26.3679, Training accuracy: 0.9944
Macro F1-score: 0.9944
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9875, F1_score: 0.9912
Model performance on Neutral speech (in training): 
	Precision: 0.9851, Recall: 0.9925, F1_score: 0.9888
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Validation loss: 27.4528, Validation accuracy: 0.9850
Macro F1-score: 0.9850
Model performance on Angry speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Neutral speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Validation loss does not decrease for 10 epochs. End training.
Model best accuracy on validation set: 0.9850

Test Phase: 
█▍     | 703/1600 [00:30<00:38, 23.43it/s]Training:  59%|█████▊    | 938/1600 [00:40<00:28, 23.36it/s]Training:  73%|███████▎  | 1173/1600 [00:50<00:18, 23.40it/s]Training:  73%|███████▎  | 1173/1600 [01:00<00:18, 23.40it/s]Training:  88%|████████▊ | 1407/1600 [01:00<00:08, 23.05it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]                                                Some weights of the model checkpoint at /work/tc062/tc062/zhan7721/saved_models/de were not used when initializing Wav2Vec2Model: ['encoder.layers.10.attention.k_proj.bias', 'encoder.layers.10.attention.k_proj.weight', 'encoder.layers.10.attention.out_proj.bias', 'encoder.layers.10.attention.out_proj.weight', 'encoder.layers.10.attention.q_proj.bias', 'encoder.layers.10.attention.q_proj.weight', 'encoder.layers.10.attention.v_proj.bias', 'encoder.layers.10.attention.v_proj.weight', 'encoder.layers.10.feed_forward.intermediate_dense.bias', 'encoder.layers.10.feed_forward.intermediate_dense.weight', 'encoder.layers.10.feed_forward.output_dense.bias', 'encoder.layers.10.feed_forward.output_dense.weight', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.10.layer_norm.bias', 'encoder.layers.10.layer_norm.weight', 'encoder.layers.11.attention.k_proj.bias', 'encoder.layers.11.attention.k_proj.weight', 'encoder.layers.11.attention.out_proj.bias', 'encoder.layers.11.attention.out_proj.weight', 'encoder.layers.11.attention.q_proj.bias', 'encoder.layers.11.attention.q_proj.weight', 'encoder.layers.11.attention.v_proj.bias', 'encoder.layers.11.attention.v_proj.weight', 'encoder.layers.11.feed_forward.intermediate_dense.bias', 'encoder.layers.11.feed_forward.intermediate_dense.weight', 'encoder.layers.11.feed_forward.output_dense.bias', 'encoder.layers.11.feed_forward.output_dense.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.11.layer_norm.bias', 'encoder.layers.11.layer_norm.weight', 'encoder.layers.5.attention.k_proj.bias', 'encoder.layers.5.attention.k_proj.weight', 'encoder.layers.5.attention.out_proj.bias', 'encoder.layers.5.attention.out_proj.weight', 'encoder.layers.5.attention.q_proj.bias', 'encoder.layers.5.attention.q_proj.weight', 'encoder.layers.5.attention.v_proj.bias', 'encoder.layers.5.attention.v_proj.weight', 'encoder.layers.5.feed_forward.intermediate_dense.bias', 'encoder.layers.5.feed_forward.intermediate_dense.weight', 'encoder.layers.5.feed_forward.output_dense.bias', 'encoder.layers.5.feed_forward.output_dense.weight', 'encoder.layers.5.final_layer_norm.bias', 'encoder.layers.5.final_layer_norm.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.6.attention.k_proj.bias', 'encoder.layers.6.attention.k_proj.weight', 'encoder.layers.6.attention.out_proj.bias', 'encoder.layers.6.attention.out_proj.weight', 'encoder.layers.6.attention.q_proj.bias', 'encoder.layers.6.attention.q_proj.weight', 'encoder.layers.6.attention.v_proj.bias', 'encoder.layers.6.attention.v_proj.weight', 'encoder.layers.6.feed_forward.intermediate_dense.bias', 'encoder.layers.6.feed_forward.intermediate_dense.weight', 'encoder.layers.6.feed_forward.output_dense.bias', 'encoder.layers.6.feed_forward.output_dense.weight', 'encoder.layers.6.final_layer_norm.bias', 'encoder.layers.6.final_layer_norm.weight', 'encoder.layers.6.layer_norm.bias', 'encoder.layers.6.layer_norm.weight', 'encoder.layers.7.attention.k_proj.bias', 'encoder.layers.7.attention.k_proj.weight', 'encoder.layers.7.attention.out_proj.bias', 'encoder.layers.7.attention.out_proj.weight', 'encoder.layers.7.attention.q_proj.bias', 'encoder.layers.7.attention.q_proj.weight', 'encoder.layers.7.attention.v_proj.bias', 'encoder.layers.7.attention.v_proj.weight', 'encoder.layers.7.feed_forward.intermediate_dense.bias', 'encoder.layers.7.feed_forward.intermediate_dense.weight', 'encoder.layers.7.feed_forward.output_dense.bias', 'encoder.layers.7.feed_forward.output_dense.weight', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.7.layer_norm.bias', 'encoder.layers.7.layer_norm.weight', 'encoder.layers.8.attention.k_proj.bias', 'encoder.layers.8.attention.k_proj.weight', 'encoder.layers.8.attention.out_proj.bias', 'encoder.layers.8.attention.out_proj.weight', 'encoder.layers.8.attention.q_proj.bias', 'encoder.layers.8.attention.q_proj.weight', 'encoder.layers.8.attention.v_proj.bias', 'encoder.layers.8.attention.v_proj.weight', 'encoder.layers.8.feed_forward.intermediate_dense.bias', 'encoder.layers.8.feed_forward.intermediate_dense.weight', 'encoder.layers.8.feed_forward.output_dense.bias', 'encoder.layers.8.feed_forward.output_dense.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.8.layer_norm.bias', 'encoder.layers.8.layer_norm.weight', 'encoder.layers.9.attention.k_proj.bias', 'encoder.layers.9.attention.k_proj.weight', 'encoder.layers.9.attention.out_proj.bias', 'encoder.layers.9.attention.out_proj.weight', 'encoder.layers.9.attention.q_proj.bias', 'encoder.layers.9.attention.q_proj.weight', 'encoder.layers.9.attention.v_proj.bias', 'encoder.layers.9.attention.v_proj.weight', 'encoder.layers.9.feed_forward.intermediate_dense.bias', 'encoder.layers.9.feed_forward.intermediate_dense.weight', 'encoder.layers.9.feed_forward.output_dense.bias', 'encoder.layers.9.feed_forward.output_dense.weight', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.layer_norm.bias', 'encoder.layers.9.layer_norm.weight']
- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Test loss: 15.4408, Test accuracy: 0.9800
Macro F1-score: 0.9800
Model performance on Angry speech (in test): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in test): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Neutral speech (in test): 
	Precision: 0.9792, Recall: 0.9400, F1_score: 0.9592
Model performance on Sad speech (in test): 
	Precision: 0.9434, Recall: 1.0000, F1_score: 0.9709

======================= This is fold_3 on cn =======================

Load dataset: 
Loading de train data: fold_3...
Preprocess de fold_3 data for cn model
Loading de eval data: fold_3...
Preprocess de fold_3 data for cn model
Loading de test data: fold_3...
Preprocess de fold_3 data for cn model
Use cn model to add lora
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training loss: 455.1809, Training accuracy: 0.9019
Macro F1-score: 0.9022
Model performance on Angry speech (in training): 
	Precision: 0.9323, Recall: 0.8950, F1_score: 0.9133
Model performance on Happy speech (in training): 
	Precision: 0.8762, Recall: 0.9025, F1_score: 0.8892
Model performance on Neutral speech (in training): 
	Precision: 0.8554, Recall: 0.8875, F1_score: 0.8712
Model performance on Sad speech (in training): 
	Precision: 0.9486, Recall: 0.9225, F1_score: 0.9354

Eval Phase: 
Validation loss: 8.7410, Validation accuracy: 0.9800
Macro F1-score: 0.9800
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Happy speech (in validation): 
	Precision: 0.9792, Recall: 0.9400, F1_score: 0.9592
Model performance on Neutral speech (in validation): 
	Precision: 0.9434, Recall: 1.0000, F1_score: 0.9709
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
New best accuracy for layer 4 on epoch 1: 0.9800. Model saved.
Epoch 2/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  10%|▉         | 155/1600 [00:10<01:33, 15.47it/s]Training:  21%|██        | 333/1600 [00:20<01:15, 16.81it/s]Training:  33%|███▎      | 523/1600 [00:30<01:00, 17.80it/s]Training:  46%|████▌     | 734/1600 [00:40<00:45, 19.08it/s]Training:  59%|█████▉    | 945/1600 [00:50<00:33, 19.73it/s]Training:  72%|███████▏  | 1158/1600 [01:00<00:21, 20.25it/s]Training:  86%|████████▌ | 1375/1600 [01:10<00:10, 20.68it/s]Training: 100%|█████████▉| 1593/1600 [01:20<00:00, 21.02it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 229/1600 [00:10<01:00, 22.80it/s]Training:  29%|██▉       | 465/1600 [00:20<00:48, 23.26it/s]Training:  44%|████▍     | 704Training loss: 167.8311, Training accuracy: 0.9631
Macro F1-score: 0.9631
Model performance on Angry speech (in training): 
	Precision: 0.9677, Recall: 0.9750, F1_score: 0.9714
Model performance on Happy speech (in training): 
	Precision: 0.9520, Recall: 0.9425, F1_score: 0.9472
Model performance on Neutral speech (in training): 
	Precision: 0.9480, Recall: 0.9575, F1_score: 0.9527
Model performance on Sad speech (in training): 
	Precision: 0.9849, Recall: 0.9775, F1_score: 0.9812

Eval Phase: 
Validation loss: 21.6597, Validation accuracy: 0.9650
Macro F1-score: 0.9647
Model performance on Angry speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in validation): 
	Precision: 0.9778, Recall: 0.8800, F1_score: 0.9263
Model performance on Neutral speech (in validation): 
	Precision: 0.9091, Recall: 1.0000, F1_score: 0.9524
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 3/100

Training Phase:
/1600 [00:30<00:38, 23.51it/s]Training:  59%|█████▉    | 943/1600 [00:40<00:27, 23.58it/s]Training:  74%|███████▍  | 1180/1600 [00:50<00:17, 23.47it/s]Training:  88%|████████▊ | 1413/1600 [01:00<00:07, 23.38it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 224/1600 [00:10<01:01, 22.35it/s]Training:  28%|██▊       | 449/1600 [00:20<00:51, 22.39it/s]Training:  42%|████▏     | 674/1600 [00:30<00:41, 22.40it/s]Training:  56%|█████▌    | 899/1600 [00:40<00:31, 22.44it/s]Training:  70%|███████   | 1124/1600 [00:50<00:21, 22.45it/s]Training:  84%|████████▍ | 1350/1600 [01:00<00:11, 22.48it/s]Training:  98%|█████████▊| 1576/1600 [01:10<00:01, 22.50it/s]                             Training loss: 103.8195, Training accuracy: 0.9725
Macro F1-score: 0.9725
Model performance on Angry speech (in training): 
	Precision: 0.9748, Recall: 0.9675, F1_score: 0.9711
Model performance on Happy speech (in training): 
	Precision: 0.9505, Recall: 0.9600, F1_score: 0.9552
Model performance on Neutral speech (in training): 
	Precision: 0.9726, Recall: 0.9750, F1_score: 0.9738
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9875, F1_score: 0.9900

Eval Phase: 
Validation loss: 20.8798, Validation accuracy: 0.9700
Macro F1-score: 0.9698
Model performance on Angry speech (in validation): 
	Precision: 0.9245, Recall: 0.9800, F1_score: 0.9515
Model performance on Happy speech (in validation): 
	Precision: 0.9783, Recall: 0.9000, F1_score: 0.9375
Model performance on Neutral speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 4/100

Training Phase:
Training loss: 111.8360, Training accuracy: 0.9762
Macro F1-score: 0.9762
Model performance on Angry speech (in training): 
	Precision: 0.9749, Recall: 0.9700, F1_score: 0.9724
Model performance on Happy speech (in training): 
	Precision: 0.9602, Recall: 0.9650, F1_score: 0.9626
Model performance on Neutral speech (in training): 
	Precision: 0.9799, Recall: 0.9750, F1_score: 0.9774
Model performance on Sad speech (in training): 
	Precision: 0.9900, Recall: 0.9950, F1_score: 0.9925

Eval Phase: 
Validation loss: 8.9415, Validation accuracy: 0.9800
Macro F1-score: 0.9799
Model performance on Angry speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Happy speech (in validation): 
	Precision: 0.9792, Recall: 0.9400, F1_score: 0.9592
Model performance on Neutral speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 5/100

Training Phase:
                                Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 223/1600 [00:10<01:01, 22.21it/s]Training:  28%|██▊       | 450/1600 [00:20<00:51, 22.43it/s]Training:  42%|████▏     | 676/1600 [00:30<00:41, 22.46it/s]Training:  56%|█████▋    | 904/1600 [00:40<00:30, 22.57it/s]Training:  71%|███████   | 1132/1600 [00:50<00:20, 22.40it/s]Training:  85%|████████▍ | 1355/1600 [01:00<00:10, 22.35it/s]Training:  99%|█████████▉| 1582/1600 [01:10<00:00, 22.44it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 240/1600 [00:10<00:56, 23.98it/s]Training:  30%|███       | 480Training loss: 74.0143, Training accuracy: 0.9825
Macro F1-score: 0.9825
Model performance on Angry speech (in training): 
	Precision: 0.9850, Recall: 0.9825, F1_score: 0.9837
Model performance on Happy speech (in training): 
	Precision: 0.9799, Recall: 0.9775, F1_score: 0.9787
Model performance on Neutral speech (in training): 
	Precision: 0.9728, Recall: 0.9850, F1_score: 0.9789
Model performance on Sad speech (in training): 
	Precision: 0.9924, Recall: 0.9850, F1_score: 0.9887

Eval Phase: 
Validation loss: 16.3982, Validation accuracy: 0.9750
Macro F1-score: 0.9748
Model performance on Angry speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Happy speech (in validation): 
	Precision: 0.9787, Recall: 0.9200, F1_score: 0.9485
Model performance on Neutral speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 6/100

Training Phase:
/1600 [00:20<00:47, 23.67it/s]Training:  45%|████▍     | 716/1600 [00:30<00:37, 23.62it/s]Training:  60%|█████▉    | 953/1600 [00:40<00:27, 23.64it/s]Training:  74%|███████▍  | 1190/1600 [00:50<00:17, 23.53it/s]Training:  89%|████████▉ | 1424/1600 [01:00<00:07, 23.44it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 238/1600 [00:10<00:57, 23.76it/s]Training:  30%|██▉       | 476/1600 [00:20<00:48, 23.24it/s]Training:  44%|████▍     | 711/1600 [00:30<00:38, 23.33it/s]Training:  59%|█████▉    | 946/1600 [00:40<00:28, 23.30it/s]Training:  74%|███████▍  | 1180/1600 [00:50<00:18, 23.31it/s]Training:  88%|████████▊ | 1415/1600 [01:00<00:07, 23.37it/s]                                      Training loss: 76.5699, Training accuracy: 0.9856
Macro F1-score: 0.9856
Model performance on Angry speech (in training): 
	Precision: 0.9900, Recall: 0.9875, F1_score: 0.9887
Model performance on Happy speech (in training): 
	Precision: 0.9776, Recall: 0.9825, F1_score: 0.9800
Model performance on Neutral speech (in training): 
	Precision: 0.9825, Recall: 0.9800, F1_score: 0.9812
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925

Eval Phase: 
Validation loss: 9.9336, Validation accuracy: 0.9850
Macro F1-score: 0.9849
Model performance on Angry speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in validation): 
	Precision: 0.9796, Recall: 0.9600, F1_score: 0.9697
Model performance on Neutral speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
New best accuracy for layer 4 on epoch 6: 0.9850. Model saved.
Epoch 7/100

Training Phase:
Training loss: 94.3083, Training accuracy: 0.9794
Macro F1-score: 0.9794
Model performance on Angry speech (in training): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Happy speech (in training): 
	Precision: 0.9725, Recall: 0.9725, F1_score: 0.9725
Model performance on Neutral speech (in training): 
	Precision: 0.9725, Recall: 0.9725, F1_score: 0.9725
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925

Eval Phase: 
Validation loss: 22.8614, Validation accuracy: 0.9750
Macro F1-score: 0.9749
Model performance on Angry speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Happy speech (in validation): 
	Precision: 0.9792, Recall: 0.9400, F1_score: 0.9592
Model performance on Neutral speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 8/100

Training Phase:
                       Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 230/1600 [00:10<00:59, 22.93it/s]Training:  29%|██▉       | 469/1600 [00:20<00:48, 23.42it/s]Training:  44%|████▍     | 707/1600 [00:30<00:38, 23.34it/s]Training:  59%|█████▉    | 942/1600 [00:40<00:28, 23.38it/s]Training:  74%|███████▎  | 1177/1600 [00:50<00:18, 23.38it/s]Training:  88%|████████▊ | 1411/1600 [01:00<00:08, 23.37it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 234/1600 [00:10<00:58, 23.39it/s]Training:  29%|██▉       | 471/1600 [00:20<00:47, 23.56it/s]Training:  44%|████▍     | 708/1600 [00:30<00:38Training loss: 51.2607, Training accuracy: 0.9862
Macro F1-score: 0.9862
Model performance on Angry speech (in training): 
	Precision: 0.9851, Recall: 0.9900, F1_score: 0.9875
Model performance on Happy speech (in training): 
	Precision: 0.9849, Recall: 0.9775, F1_score: 0.9812
Model performance on Neutral speech (in training): 
	Precision: 0.9825, Recall: 0.9825, F1_score: 0.9825
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938

Eval Phase: 
Validation loss: 23.7738, Validation accuracy: 0.9800
Macro F1-score: 0.9800
Model performance on Angry speech (in validation): 
	Precision: 0.9259, Recall: 1.0000, F1_score: 0.9615
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9200, F1_score: 0.9583
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 9/100

Training Phase:
Training loss: 60.8474, Training accuracy: 0.9881
Macro F1-score: 0.9881
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9875, F1_score: 0.9912
Model performance on Happy speech (in training): 
	Precision: 0.9800, Recall: 0.9825, F1_score: 0.9813
Model performance on Neutral speech (in training): 
	Precision: 0.9850, Recall: 0.9850, F1_score: 0.9850
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9975, F1_score: 0.9950

Eval Phase: 
, 23.22it/s]Training:  59%|█████▉    | 943/1600 [00:40<00:28, 23.32it/s]Training:  74%|███████▎  | 1178/1600 [00:50<00:18, 23.35it/s]Training:  88%|████████▊ | 1413/1600 [01:00<00:08, 23.35it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 236/1600 [00:10<00:57, 23.57it/s]Training:  30%|██▉       | 472/1600 [00:20<00:48, 23.45it/s]Training:  44%|████▍     | 710/1600 [00:30<00:37, 23.58it/s]Training:  59%|█████▉    | 948/1600 [00:40<00:27, 23.55it/s]Training:  74%|███████▍  | 1184/1600 [00:50<00:17, 23.34it/s]Training:  88%|████████▊ | 1414/1600 [01:00<00:08, 23.01it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]            Validation loss: 28.0272, Validation accuracy: 0.9750
Macro F1-score: 0.9749
Model performance on Angry speech (in validation): 
	Precision: 0.9091, Recall: 1.0000, F1_score: 0.9524
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9000, F1_score: 0.9474
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 10/100

Training Phase:
Training loss: 45.5423, Training accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in training): 
	Precision: 0.9850, Recall: 0.9825, F1_score: 0.9837
Model performance on Happy speech (in training): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 14.4563, Validation accuracy: 0.9850
Macro F1-score: 0.9850
Model performance on Angry speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Happy speech (in validation): 
	Precision: 0.9796, Recall: 0.9600, F1_score: 0.9697
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 11/100

Training Phase:
                                       Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 223/1600 [00:10<01:01, 22.27it/s]Training:  28%|██▊       | 449/1600 [00:20<00:51, 22.43it/s]Training:  42%|████▏     | 675/1600 [00:30<00:41, 22.46it/s]Training:  56%|█████▋    | 900/1600 [00:40<00:31, 22.47it/s]Training:  70%|███████   | 1126/1600 [00:50<00:21, 22.51it/s]Training:  84%|████████▍ | 1352/1600 [01:00<00:11, 22.43it/s]Training:  98%|█████████▊| 1575/1600 [01:10<00:01, 22.37it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 233/1600 [00:10<00:58, 23.19it/s]Training:  29%|██▉       | 471/1600 [00:20<00:47, 23.52it/s]Training:  44%|████▍     | 709/1600 [00:30<00:37, 23.55itTraining loss: 65.7279, Training accuracy: 0.9869
Macro F1-score: 0.9869
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912
Model performance on Happy speech (in training): 
	Precision: 0.9777, Recall: 0.9850, F1_score: 0.9813
Model performance on Neutral speech (in training): 
	Precision: 0.9874, Recall: 0.9775, F1_score: 0.9824
Model performance on Sad speech (in training): 
	Precision: 0.9900, Recall: 0.9950, F1_score: 0.9925

Eval Phase: 
Validation loss: 13.3946, Validation accuracy: 0.9800
Macro F1-score: 0.9800
Model performance on Angry speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Happy speech (in validation): 
	Precision: 0.9796, Recall: 0.9600, F1_score: 0.9697
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Validation loss does not decrease for 10 epochs. End training.
Model best accuracy on validation set: 0.9850

Test Phase: 
/s]Training:  59%|█████▉    | 945/1600 [00:40<00:27, 23.54it/s]Training:  74%|███████▍  | 1181/1600 [00:50<00:17, 23.54it/s]Training:  89%|████████▊ | 1417/1600 [01:00<00:07, 23.47it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]                                                Some weights of the model checkpoint at /work/tc062/tc062/zhan7721/saved_models/de were not used when initializing Wav2Vec2Model: ['encoder.layers.10.attention.k_proj.bias', 'encoder.layers.10.attention.k_proj.weight', 'encoder.layers.10.attention.out_proj.bias', 'encoder.layers.10.attention.out_proj.weight', 'encoder.layers.10.attention.q_proj.bias', 'encoder.layers.10.attention.q_proj.weight', 'encoder.layers.10.attention.v_proj.bias', 'encoder.layers.10.attention.v_proj.weight', 'encoder.layers.10.feed_forward.intermediate_dense.bias', 'encoder.layers.10.feed_forward.intermediate_dense.weight', 'encoder.layers.10.feed_forward.output_dense.bias', 'encoder.layers.10.feed_forward.output_dense.weight', 'encoder.layers.10.final_layer_norm.bias', 'encoder.layers.10.final_layer_norm.weight', 'encoder.layers.10.layer_norm.bias', 'encoder.layers.10.layer_norm.weight', 'encoder.layers.11.attention.k_proj.bias', 'encoder.layers.11.attention.k_proj.weight', 'encoder.layers.11.attention.out_proj.bias', 'encoder.layers.11.attention.out_proj.weight', 'encoder.layers.11.attention.q_proj.bias', 'encoder.layers.11.attention.q_proj.weight', 'encoder.layers.11.attention.v_proj.bias', 'encoder.layers.11.attention.v_proj.weight', 'encoder.layers.11.feed_forward.intermediate_dense.bias', 'encoder.layers.11.feed_forward.intermediate_dense.weight', 'encoder.layers.11.feed_forward.output_dense.bias', 'encoder.layers.11.feed_forward.output_dense.weight', 'encoder.layers.11.final_layer_norm.bias', 'encoder.layers.11.final_layer_norm.weight', 'encoder.layers.11.layer_norm.bias', 'encoder.layers.11.layer_norm.weight', 'encoder.layers.5.attention.k_proj.bias', 'encoder.layers.5.attention.k_proj.weight', 'encoder.layers.5.attention.out_proj.bias', 'encoder.layers.5.attention.out_proj.weight', 'encoder.layers.5.attention.q_proj.bias', 'encoder.layers.5.attention.q_proj.weight', 'encoder.layers.5.attention.v_proj.bias', 'encoder.layers.5.attention.v_proj.weight', 'encoder.layers.5.feed_forward.intermediate_dense.bias', 'encoder.layers.5.feed_forward.intermediate_dense.weight', 'encoder.layers.5.feed_forward.output_dense.bias', 'encoder.layers.5.feed_forward.output_dense.weight', 'encoder.layers.5.final_layer_norm.bias', 'encoder.layers.5.final_layer_norm.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.6.attention.k_proj.bias', 'encoder.layers.6.attention.k_proj.weight', 'encoder.layers.6.attention.out_proj.bias', 'encoder.layers.6.attention.out_proj.weight', 'encoder.layers.6.attention.q_proj.bias', 'encoder.layers.6.attention.q_proj.weight', 'encoder.layers.6.attention.v_proj.bias', 'encoder.layers.6.attention.v_proj.weight', 'encoder.layers.6.feed_forward.intermediate_dense.bias', 'encoder.layers.6.feed_forward.intermediate_dense.weight', 'encoder.layers.6.feed_forward.output_dense.bias', 'encoder.layers.6.feed_forward.output_dense.weight', 'encoder.layers.6.final_layer_norm.bias', 'encoder.layers.6.final_layer_norm.weight', 'encoder.layers.6.layer_norm.bias', 'encoder.layers.6.layer_norm.weight', 'encoder.layers.7.attention.k_proj.bias', 'encoder.layers.7.attention.k_proj.weight', 'encoder.layers.7.attention.out_proj.bias', 'encoder.layers.7.attention.out_proj.weight', 'encoder.layers.7.attention.q_proj.bias', 'encoder.layers.7.attention.q_proj.weight', 'encoder.layers.7.attention.v_proj.bias', 'encoder.layers.7.attention.v_proj.weight', 'encoder.layers.7.feed_forward.intermediate_dense.bias', 'encoder.layers.7.feed_forward.intermediate_dense.weight', 'encoder.layers.7.feed_forward.output_dense.bias', 'encoder.layers.7.feed_forward.output_dense.weight', 'encoder.layers.7.final_layer_norm.bias', 'encoder.layers.7.final_layer_norm.weight', 'encoder.layers.7.layer_norm.bias', 'encoder.layers.7.layer_norm.weight', 'encoder.layers.8.attention.k_proj.bias', 'encoder.layers.8.attention.k_proj.weight', 'encoder.layers.8.attention.out_proj.bias', 'encoder.layers.8.attention.out_proj.weight', 'encoder.layers.8.attention.q_proj.bias', 'encoder.layers.8.attention.q_proj.weight', 'encoder.layers.8.attention.v_proj.bias', 'encoder.layers.8.attention.v_proj.weight', 'encoder.layers.8.feed_forward.intermediate_dense.bias', 'encoder.layers.8.feed_forward.intermediate_dense.weight', 'encoder.layers.8.feed_forward.output_dense.bias', 'encoder.layers.8.feed_forward.output_dense.weight', 'encoder.layers.8.final_layer_norm.bias', 'encoder.layers.8.final_layer_norm.weight', 'encoder.layers.8.layer_norm.bias', 'encoder.layers.8.layer_norm.weight', 'encoder.layers.9.attention.k_proj.bias', 'encoder.layers.9.attention.k_proj.weight', 'encoder.layers.9.attention.out_proj.bias', 'encoder.layers.9.attention.out_proj.weight', 'encoder.layers.9.attention.q_proj.bias', 'encoder.layers.9.attention.q_proj.weight', 'encoder.layers.9.attention.v_proj.bias', 'encoder.layers.9.attention.v_proj.weight', 'encoder.layers.9.feed_forward.intermediate_dense.bias', 'encoder.layers.9.feed_forward.intermediate_dense.weight', 'encoder.layers.9.feed_forward.output_dense.bias', 'encoder.layers.9.feed_forward.output_dense.weight', 'encoder.layers.9.final_layer_norm.bias', 'encoder.layers.9.final_layer_norm.weight', 'encoder.layers.9.layer_norm.bias', 'encoder.layers.9.layer_norm.weight']
- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Test loss: 7.5702, Test accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in test): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Happy speech (in test): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Neutral speech (in test): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Sad speech (in test): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

======================= This is fold_4 on cn =======================

Load dataset: 
Loading de train data: fold_4...
Preprocess de fold_4 data for cn model
Loading de eval data: fold_4...
Preprocess de fold_4 data for cn model
Loading de test data: fold_4...
Preprocess de fold_4 data for cn model
Use cn model to add lora
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training loss: 400.2395, Training accuracy: 0.9137
Macro F1-score: 0.9141
Model performance on Angry speech (in training): 
	Precision: 0.9468, Recall: 0.8900, F1_score: 0.9175
Model performance on Happy speech (in training): 
	Precision: 0.8775, Recall: 0.8950, F1_score: 0.8861
Model performance on Neutral speech (in training): 
	Precision: 0.8709, Recall: 0.9275, F1_score: 0.8983
Model performance on Sad speech (in training): 
	Precision: 0.9667, Recall: 0.9425, F1_score: 0.9544

Eval Phase: 
Validation loss: 6.1046, Validation accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
New best accuracy for layer 4 on epoch 1: 0.9950. Model saved.
Epoch 2/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:   9%|▉         | 147/1600 [00:10<01:38, 14.70it/s]Training:  20%|██        | 324/1600 [00:20<01:17, 16.37it/s]Training:  33%|███▎      | 522/1600 [00:30<01:00, 17.93it/s]Training:  45%|████▌     | 721/1600 [00:40<00:47, 18.68it/s]Training:  58%|█████▊    | 926/1600 [00:50<00:34, 19.30it/s]Training:  71%|███████   | 1132/1600 [01:00<00:23, 19.73it/s]Training:  84%|████████▍ | 1348/1600 [01:10<00:12, 20.31it/s]Training:  98%|█████████▊| 1573/1600 [01:20<00:01, 21.00it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 224/1600 [00:10<01:01, 22.38it/s]Training:  28%|██▊       | 450/1600 [00:20<00:51, 22.49it/s]Training:  28%|██▊       | 450/1600 Training loss: 158.1633, Training accuracy: 0.9644
Macro F1-score: 0.9644
Model performance on Angry speech (in training): 
	Precision: 0.9770, Recall: 0.9575, F1_score: 0.9672
Model performance on Happy speech (in training): 
	Precision: 0.9403, Recall: 0.9450, F1_score: 0.9426
Model performance on Neutral speech (in training): 
	Precision: 0.9580, Recall: 0.9700, F1_score: 0.9640
Model performance on Sad speech (in training): 
	Precision: 0.9825, Recall: 0.9850, F1_score: 0.9838

Eval Phase: 
Validation loss: 10.2842, Validation accuracy: 0.9800
Macro F1-score: 0.9799
Model performance on Angry speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9400, F1_score: 0.9691
Model performance on Neutral speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 3/100

Training Phase:
[00:30<00:51, 22.49it/s]Training:  42%|████▏     | 675/1600 [00:30<00:41, 22.41it/s]Training:  56%|█████▋    | 904/1600 [00:40<00:30, 22.59it/s]Training:  71%|███████   | 1133/1600 [00:50<00:20, 22.51it/s]Training:  85%|████████▍ | 1357/1600 [01:00<00:10, 22.44it/s]Training:  99%|█████████▉| 1588/1600 [01:10<00:00, 22.66it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 224/1600 [00:10<01:01, 22.37it/s]Training:  28%|██▊       | 453/1600 [00:20<00:50, 22.64it/s]Training:  43%|████▎     | 685/1600 [00:30<00:39, 22.89it/s]Training:  58%|█████▊    | 922/1600 [00:40<00:29, 23.19it/s]Training:  73%|███████▎  | 1162/1600 [00:50<00:18, 23.47it/s]Training:  88%|████████▊ |Training loss: 93.6397, Training accuracy: 0.9788
Macro F1-score: 0.9787
Model performance on Angry speech (in training): 
	Precision: 0.9703, Recall: 0.9800, F1_score: 0.9751
Model performance on Happy speech (in training): 
	Precision: 0.9722, Recall: 0.9600, F1_score: 0.9660
Model performance on Neutral speech (in training): 
	Precision: 0.9777, Recall: 0.9875, F1_score: 0.9826
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9875, F1_score: 0.9912

Eval Phase: 
Validation loss: 9.5868, Validation accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 4/100

Training Phase:
Training loss: 82.8983, Training accuracy: 0.9869
Macro F1-score: 0.9869
Model performance on Angry speech (in training): 
	Precision: 0.9949, Recall: 0.9800, F1_score: 0.9874
Model performance on Happy speech (in training): 
	Precision: 0.9778, Recall: 0.9900, F1_score: 0.9839
Model performance on Neutral speech (in training): 
	Precision: 0.9850, Recall: 0.9875, F1_score: 0.9863
Model performance on Sad speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900

Eval Phase: 
Validation loss: 10.8454, Validation accuracy: 0.9850
Macro F1-score: 0.9849
Model performance on Angry speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Neutral speech (in validation): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 5/100

Training Phase:
 1402/1600 [01:00<00:08, 23.32it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 233/1600 [00:10<00:58, 23.20it/s]Training:  30%|██▉       | 474/1600 [00:20<00:47, 23.69it/s]Training:  45%|████▍     | 715/1600 [00:30<00:37, 23.65it/s]Training:  60%|█████▉    | 953/1600 [00:40<00:27, 23.67it/s]Training:  74%|███████▍  | 1191/1600 [00:50<00:17, 23.58it/s]Training:  89%|████████▉ | 1426/1600 [01:00<00:07, 23.43it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 232/1600 [00:10<00:59, 23.15it/s]Training:  29%|██▉       | 464/1600 [00:20<00Training loss: 68.0318, Training accuracy: 0.9812
Macro F1-score: 0.9813
Model performance on Angry speech (in training): 
	Precision: 0.9825, Recall: 0.9800, F1_score: 0.9812
Model performance on Happy speech (in training): 
	Precision: 0.9749, Recall: 0.9725, F1_score: 0.9737
Model performance on Neutral speech (in training): 
	Precision: 0.9728, Recall: 0.9825, F1_score: 0.9776
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9900, F1_score: 0.9925

Eval Phase: 
Validation loss: 31.6323, Validation accuracy: 0.9650
Macro F1-score: 0.9646
Model performance on Angry speech (in validation): 
	Precision: 0.8929, Recall: 1.0000, F1_score: 0.9434
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.8600, F1_score: 0.9247
Model performance on Neutral speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 6/100

Training Phase:
:49, 22.89it/s]Training:  43%|████▎     | 692/1600 [00:30<00:40, 22.58it/s]Training:  57%|█████▋    | 916/1600 [00:40<00:30, 22.47it/s]Training:  72%|███████▏  | 1145/1600 [00:50<00:20, 22.60it/s]Training:  86%|████████▌ | 1374/1600 [01:00<00:09, 22.61it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 228/1600 [00:10<01:00, 22.77it/s]Training:  28%|██▊       | 456/1600 [00:20<00:50, 22.64it/s]Training:  43%|████▎     | 686/1600 [00:30<00:40, 22.75it/s]Training:  57%|█████▋    | 918/1600 [00:40<00:29, 22.93it/s]Training:  72%|███████▏  | 1154/1600 [00:50<00:19, 23.16it/s]Training:  87%|████████▋ | 1390/1600 [01:00<00:09, 23.23it/s]                                                     Training loss: 67.2241, Training accuracy: 0.9838
Macro F1-score: 0.9838
Model performance on Angry speech (in training): 
	Precision: 0.9875, Recall: 0.9850, F1_score: 0.9862
Model performance on Happy speech (in training): 
	Precision: 0.9704, Recall: 0.9825, F1_score: 0.9764
Model performance on Neutral speech (in training): 
	Precision: 0.9825, Recall: 0.9800, F1_score: 0.9812
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9875, F1_score: 0.9912

Eval Phase: 
Validation loss: 5.1077, Validation accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 7/100

Training Phase:
Training loss: 55.3058, Training accuracy: 0.9881
Macro F1-score: 0.9881
Model performance on Angry speech (in training): 
	Precision: 0.9900, Recall: 0.9875, F1_score: 0.9887
Model performance on Happy speech (in training): 
	Precision: 0.9775, Recall: 0.9775, F1_score: 0.9775
Model performance on Neutral speech (in training): 
	Precision: 0.9875, Recall: 0.9875, F1_score: 0.9875
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988

Eval Phase: 
Validation loss: 12.4828, Validation accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Epoch 8/100

Training Phase:
        Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 224/1600 [00:10<01:01, 22.32it/s]Training:  28%|██▊       | 448/1600 [00:20<00:51, 22.35it/s]Training:  42%|████▏     | 674/1600 [00:30<00:41, 22.44it/s]Training:  57%|█████▋    | 906/1600 [00:40<00:30, 22.73it/s]Training:  71%|███████   | 1138/1600 [00:50<00:20, 22.61it/s]Training:  86%|████████▌ | 1371/1600 [01:00<00:10, 22.83it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 225/1600 [00:10<01:01, 22.39it/s]Training:  28%|██▊       | 455/1600 [00:20<00:50, 22.70it/s]Training:  28%|██▊       | 455/1600 [00:30<00:50, 22.70it/s]TrainingTraining loss: 58.9637, Training accuracy: 0.9856
Macro F1-score: 0.9856
Model performance on Angry speech (in training): 
	Precision: 0.9875, Recall: 0.9900, F1_score: 0.9888
Model performance on Happy speech (in training): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Neutral speech (in training): 
	Precision: 0.9825, Recall: 0.9800, F1_score: 0.9812
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925

Eval Phase: 
Validation loss: 10.4594, Validation accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 9/100

Training Phase:
Training loss: 52.3928, Training accuracy: 0.9850
Macro F1-score: 0.9850
Model performance on Angry speech (in training): 
	Precision: 0.9874, Recall: 0.9825, F1_score: 0.9850
Model performance on Happy speech (in training): 
	Precision: 0.9799, Recall: 0.9750, F1_score: 0.9774
Model performance on Neutral speech (in training): 
	Precision: 0.9777, Recall: 0.9875, F1_score: 0.9826
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950

Eval Phase: 
:  43%|████▎     | 685/1600 [00:30<00:40, 22.69it/s]Training:  57%|█████▋    | 918/1600 [00:40<00:29, 22.93it/s]Training:  72%|███████▏  | 1152/1600 [00:50<00:19, 23.09it/s]Training:  87%|████████▋ | 1386/1600 [01:00<00:09, 23.15it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 239/1600 [00:10<00:57, 23.85it/s]Training:  30%|██▉       | 479/1600 [00:20<00:46, 23.89it/s]Training:  45%|████▍     | 719/1600 [00:30<00:37, 23.47it/s]Training:  60%|█████▉    | 957/1600 [00:40<00:27, 23.57it/s]Training:  75%|███████▍  | 1195/1600 [00:50<00:17, 23.48it/s]Training:  89%|████████▉ | 1429/1600 [01:00<00:07, 23.45it/s]                                                             Evaluating:   Validation loss: 29.2794, Validation accuracy: 0.9850
Macro F1-score: 0.9850
Model performance on Angry speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 10/100

Training Phase:
Training loss: 33.6629, Training accuracy: 0.9938
Macro F1-score: 0.9938
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9925, F1_score: 0.9950
Model performance on Happy speech (in training): 
	Precision: 0.9851, Recall: 0.9925, F1_score: 0.9888
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987

Eval Phase: 
Validation loss: 25.3399, Validation accuracy: 0.9800
Macro F1-score: 0.9800
Model performance on Angry speech (in validation): 
	Precision: 0.9434, Recall: 1.0000, F1_score: 0.9709
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9400, F1_score: 0.9691
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 11/100

Training Phase:
0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 241/1600 [00:10<00:56, 24.09it/s]Training:  15%|█▌        | 241/1600 [00:20<00:56, 24.09it/s]Training:  30%|██▉       | 474/1600 [00:20<00:47, 23.60it/s]Training:  44%|████▍     | 707/1600 [00:30<00:38, 23.00it/s]Training:  58%|█████▊    | 931/1600 [00:40<00:29, 22.73it/s]Training:  72%|███████▏  | 1159/1600 [00:50<00:19, 22.73it/s]Training:  87%|████████▋ | 1387/1600 [01:00<00:09, 22.57it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 224/1600 [00:10<01:01, 22.38it/s]Training:  28%|██▊       | 456/1600 [00:20<00:50, 22.82it/s]Training:  43%|████▎  Training loss: 61.2008, Training accuracy: 0.9838
Macro F1-score: 0.9837
Model performance on Angry speech (in training): 
	Precision: 0.9900, Recall: 0.9875, F1_score: 0.9887
Model performance on Happy speech (in training): 
	Precision: 0.9824, Recall: 0.9775, F1_score: 0.9799
Model performance on Neutral speech (in training): 
	Precision: 0.9751, Recall: 0.9775, F1_score: 0.9763
Model performance on Sad speech (in training): 
	Precision: 0.9876, Recall: 0.9925, F1_score: 0.9900

Eval Phase: 
Validation loss: 24.4237, Validation accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 12/100

Training Phase:
Training loss: 39.3369, Training accuracy: 0.9912
Macro F1-score: 0.9912
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937
Model performance on Happy speech (in training): 
	Precision: 0.9850, Recall: 0.9875, F1_score: 0.9863
Model performance on Neutral speech (in training): 
	Precision: 0.9900, Recall: 0.9875, F1_score: 0.9887
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963

Eval Phase: 
   | 692/1600 [00:30<00:39, 23.14it/s]Training:  58%|█████▊    | 928/1600 [00:40<00:28, 23.22it/s]Training:  73%|███████▎  | 1162/1600 [00:50<00:18, 23.21it/s]Training:  87%|████████▋ | 1396/1600 [01:00<00:08, 23.26it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 241/1600 [00:10<00:56, 24.04it/s]Training:  30%|███       | 482/1600 [00:20<00:47, 23.75it/s]Training:  45%|████▍     | 718/1600 [00:30<00:37, 23.61it/s]Training:  60%|█████▉    | 955/1600 [00:40<00:27, 23.63it/s]Training:  74%|███████▍  | 1192/1600 [00:50<00:17, 23.55it/s]Training:  89%|████████▉ | 1427/1600 [01:00<00:07, 23.48it/s]                                                             Evaluating:   0%|          | 0/200 [00Validation loss: 19.3435, Validation accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 13/100

Training Phase:
Training loss: 42.5125, Training accuracy: 0.9925
Macro F1-score: 0.9925
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938
Model performance on Happy speech (in training): 
	Precision: 0.9900, Recall: 0.9875, F1_score: 0.9887
Model performance on Neutral speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962

Eval Phase: 
Validation loss: 23.9061, Validation accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 14/100

Training Phase:
:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 229/1600 [00:10<00:59, 22.89it/s]Training:  29%|██▉       | 460/1600 [00:20<00:49, 22.96it/s]Training:  43%|████▎     | 691/1600 [00:30<00:39, 22.75it/s]Training:  57%|█████▋    | 917/1600 [00:40<00:30, 22.67it/s]Training:  72%|███████▏  | 1144/1600 [00:50<00:20, 22.65it/s]Training:  86%|████████▌ | 1377/1600 [01:00<00:09, 22.85it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 240/1600 [00:10<00:56, 23.92it/s]Training:  30%|███       | 480/1600 [00:20<00:46, 23.86it/s]Training:  45%|████▍     | 719/1600 [00:30<00:37, 23.64it/s]Training:  60%|█████▉    | 953/1600 [0Training loss: 36.6395, Training accuracy: 0.9925
Macro F1-score: 0.9925
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Happy speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900
Model performance on Neutral speech (in training): 
	Precision: 0.9899, Recall: 0.9850, F1_score: 0.9875
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 1.0000, F1_score: 0.9975

Eval Phase: 
Validation loss: 18.7676, Validation accuracy: 0.9850
Macro F1-score: 0.9850
Model performance on Angry speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 15/100

Training Phase:
Training loss: 14.6381, Training accuracy: 0.9969
Macro F1-score: 0.9969
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
0:40<00:27, 23.36it/s]Training:  74%|███████▍  | 1183/1600 [00:50<00:18, 22.92it/s]Training:  88%|████████▊ | 1410/1600 [01:00<00:08, 22.82it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 228/1600 [00:10<01:00, 22.68it/s]Training:  28%|██▊       | 455/1600 [00:20<00:50, 22.56it/s]Training:  42%|████▎     | 680/1600 [00:30<00:40, 22.45it/s]Training:  57%|█████▋    | 908/1600 [00:40<00:30, 22.57it/s]Training:  71%|███████   | 1136/1600 [00:50<00:20, 22.61it/s]Training:  85%|████████▌ | 1363/1600 [01:02<00:11, 20.95it/s]Training:  99%|█████████▉| 1585/1600 [01:12<00:00, 21.33it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?iValidation loss: 17.5245, Validation accuracy: 0.9850
Macro F1-score: 0.9850
Model performance on Angry speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Sad speech (in validation): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Epoch 16/100

Training Phase:
Training loss: 48.7344, Training accuracy: 0.9888
Macro F1-score: 0.9888
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9900, F1_score: 0.9925
Model performance on Happy speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900
Model performance on Neutral speech (in training): 
	Precision: 0.9850, Recall: 0.9875, F1_score: 0.9863
Model performance on Sad speech (in training): 
	Precision: 0.9850, Recall: 0.9875, F1_score: 0.9863

Eval Phase: 
Validation loss: 15.0812, Validation accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in validation): 
	Precision: 0.9615, Recall: 1.0000, F1_score: 0.9804
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.9600, F1_score: 0.9796
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Validation loss does not decrease for 10 epochs. End training.
Model best accuracy on validation set: 0.9950

Test Phase: 
Test loss: 8.3588, Test accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in test): 
	Precision: 0.9804, Recall: 1.0000, F1_score: 0.9901
Model performance on Happy speech (in test): 
	Precision: 1.0000, Recall: 0.9800, F1_score: 0.9899
Model performance on Neutral speech (in test): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in test): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

cn, all folds accuracy: ['0.9800', '0.9950', '0.9800', '0.9900', '0.9950']
cn, all folds emo precision: {'Angry': ['0.9800', '1.0000', '1.0000', '1.0000', '0.9804'], 'Happy': ['0.9792', '0.9804', '1.0000', '0.9800', '1.0000'], 'Neutral': ['0.9615', '1.0000', '0.9792', '0.9804', '1.0000'], 'Sad': ['1.0000', '1.0000', '0.9434', '1.0000', '1.0000']}
cn, all folds emo recall: {'Angry': ['0.9800', '1.0000', '1.0000', '0.9800', '1.0000'], 'Happy': ['0.9400', '1.0000', '0.9800', '0.9800', '0.9800'], 'Neutral': ['1.0000', '0.9800', '0.9400', '1.0000', '1.0000'], 'Sad': ['1.0000', '1.0000', '1.0000', '1.0000', '1.0000']}
cn, all folds emo f1score: {'Angry': ['0.9800', '1.0000', '1.0000', '0.9899', '0.9901'], 'Happy': ['0.9592', '0.9901', '0.9899', '0.9800', '0.9899'], 'Neutral': ['0.9804', '0.9899', '0.9592', '0.9901', '1.0000'], 'Sad': ['1.0000', '1.0000', '0.9709', '1.0000', '1.0000']}
t/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 223/1600 [00:10<01:01, 22.27it/s]Training:  28%|██▊       | 449/1600 [00:20<00:51, 22.42it/s]Training:  42%|████▏     | 675/1600 [00:30<00:41, 22.28it/s]Training:  56%|█████▋    | 900/1600 [00:40<00:31, 22.35it/s]Training:  70%|███████   | 1125/1600 [00:50<00:21, 22.34it/s]Training:  84%|████████▍ | 1349/1600 [01:00<00:11, 22.31it/s]Training:  98%|█████████▊| 1572/1600 [01:11<00:01, 21.52it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]                                                