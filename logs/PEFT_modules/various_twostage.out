Loading python/3.10.8-gpu
  Loading requirement: nvidia/nvhpc-nompi/22.2 gcc/10.2.0
    openmpi/4.1.6-cuda-11.6
Loading pytorch/1.13.1-gpu
  Loading requirement: nvidia/cudnn/8.6.0-cuda-11.6 nvidia/tensorrt/8.4.3.1-u2
    libsndfile/1.0.28
------------------ NEXT SCRIPT: RUNNER_DE, former -> current ----------------------
/work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Matplotlib created a temporary cache directory at /dev/shm/zhan7721_5912030/matplotlib-7e48e9rn because the default path (/home/tc062/tc062/zhan7721/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.

======================= This is fold_0 on de =======================

Load dataset: 
Loading de train data: fold_0...
Preprocess de fold_0 data for de model
Loading cn eval data: fold_0...
Preprocess cn fold_0 data for de model
Loading cn test data: fold_0...
Preprocess cn fold_0 data for de model
Use de model to add lora
================== SET ALL PARAMS =====================
modified_wav2vec2.base_model.model.masked_spec_embed: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.0.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.0.layer_norm.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.0.layer_norm.bias: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.1.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.2.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.3.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.4.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.5.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.6.conv.weight: False
modified_wav2vec2.base_model.model.feature_projection.layer_norm.weight: False
modified_wav2vec2.base_model.model.feature_projection.layer_norm.bias: False
modified_wav2vec2.base_model.model.feature_projection.projection.weight: False
modified_wav2vec2.base_model.model.feature_projection.projection.bias: False
modified_wav2vec2.base_model.model.encoder.pos_conv_embed.conv.bias: False
modified_wav2vec2.base_model.model.encoder.pos_conv_embed.conv.weight_g: False
modified_wav2vec2.base_model.model.encoder.pos_conv_embed.conv.weight_v: False
modified_wav2vec2.base_model.model.encoder.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.up.bias: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.up.bias: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.up.bias: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.up.bias: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.4.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.4.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.bottleneck_adaptor.up.bias: True
normal_classifier.dense1.weight: True
normal_classifier.dense1.bias: True
normal_classifier.dense.weight: True
normal_classifier.dense.bias: True
normal_classifier.out.weight: True
normal_classifier.out.bias: True
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training loss: 1272.9351, Training accuracy: 0.6656
Macro F1-score: 0.6715
Model performance on Angry speech (in training): 
	Precision: 0.8960, Recall: 0.4525, F1_score: 0.6013
Model performance on Happy speech (in training): 
	Precision: 0.4367, Recall: 0.7325, F1_score: 0.5472
Model performance on Neutral speech (in training): 
	Precision: 0.6916, Recall: 0.5775, F1_score: 0.6294
Model performance on Sad speech (in training): 
	Precision: 0.9160, Recall: 0.9000, F1_score: 0.9079

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:   0%|          | 1/1600 [00:44<19:36:26, 44.14s/it]Training:   8%|▊         | 130/1600 [00:54<07:43,  3.17it/s] Training:  18%|█▊        | 282/1600 [01:04<03:29,  6.28it/s]Training:  28%|██▊       | 448/1600 [01:14<02:07,  9.06it/s]Training:  39%|███▉      | 625/1600 [01:24<01:25, 11.45it/s]Training:  50%|█████     | 802/1600 [01:34<01:00, 13.13it/s]Training:  61%|██████▏   | 980/1600 [01:44<00:42, 14.46it/s]Training:  73%|███████▎  | 1164/1600 [01:54<00:27, 15.60it/s]Training:  84%|████████▍ | 1352/1600 [02:04<00:15, 16.47it/s]Training:  96%|█████████▌| 1538/1600 [02:14<00:03, 17.01it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
New best accuracy for layer 4 on epoch 1: 0.3300. Model saved.
Epoch 2/100

Training Phase:
Training loss: 398.2102, Training accuracy: 0.9337
Macro F1-score: 0.9340
Model performance on Angry speech (in training): 
	Precision: 0.9564, Recall: 0.9325, F1_score: 0.9443
Model performance on Happy speech (in training): 
	Precision: 0.8810, Recall: 0.9250, F1_score: 0.9024
Model performance on Neutral speech (in training): 
	Precision: 0.9262, Recall: 0.9100, F1_score: 0.9180
Model performance on Sad speech (in training): 
	Precision: 0.9748, Recall: 0.9675, F1_score: 0.9711

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 195/1600 [00:10<01:12, 19.42it/s]Training:  24%|██▍       | 390/1600 [00:20<01:02, 19.42it/s]Training:  37%|███▋      | 585/1600 [00:30<00:52, 19.43it/s]Training:  49%|████▉     | 780/1600 [00:40<00:42, 19.35it/s]Training:  61%|██████    | 978/1600 [00:50<00:31, 19.48it/s]Training:  73%|███████▎  | 1175/1600 [01:00<00:21, 19.35it/s]Training:  86%|████████▌ | 1371/1600 [01:10<00:11, 19.42it/s]Training:  98%|█████████▊| 1567/1600 [01:20<00:01, 19.46it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 521.9607, Validation accuracy: 0.2950
Macro F1-score: 0.2238
Model performance on Angry speech (in validation): 
	Precision: 0.3833, Recall: 0.9200, F1_score: 0.5412
Model performance on Happy speech (in validation): 
	Precision: 0.0597, Recall: 0.0800, F1_score: 0.0684
Model performance on Neutral speech (in validation): 
	Precision: 0.6923, Recall: 0.1800, F1_score: 0.2857
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 3/100

Training Phase:
Training loss: 179.6773, Training accuracy: 0.9694
Macro F1-score: 0.9694
Model performance on Angry speech (in training): 
	Precision: 0.9725, Recall: 0.9725, F1_score: 0.9725
Model performance on Happy speech (in training): 
	Precision: 0.9504, Recall: 0.9575, F1_score: 0.9539
Model performance on Neutral speech (in training): 
	Precision: 0.9697, Recall: 0.9600, F1_score: 0.9648
Model performance on Sad speech (in training): 
	Precision: 0.9850, Recall: 0.9875, F1_score: 0.9863

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 197/1600 [00:10<01:11, 19.62it/s]Training:  25%|██▍       | 394/1600 [00:20<01:01, 19.54it/s]Training:  37%|███▋      | 590/1600 [00:30<00:51, 19.56it/s]Training:  49%|████▉     | 786/1600 [00:40<00:41, 19.47it/s]Training:  61%|██████▏   | 980/1600 [00:50<00:31, 19.40it/s]Training:  74%|███████▎  | 1178/1600 [01:00<00:21, 19.51it/s]Training:  86%|████████▌ | 1376/1600 [01:10<00:11, 19.56it/s]Training:  98%|█████████▊| 1573/1600 [01:20<00:01, 19.60it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 678.3624, Validation accuracy: 0.2500
Macro F1-score: 0.1806
Model performance on Angry speech (in validation): 
	Precision: 0.4265, Recall: 0.5800, F1_score: 0.4915
Model performance on Happy speech (in validation): 
	Precision: 0.1591, Recall: 0.4200, F1_score: 0.2308
Model performance on Neutral speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 4/100

Training Phase:
Training loss: 119.0237, Training accuracy: 0.9788
Macro F1-score: 0.9788
Model performance on Angry speech (in training): 
	Precision: 0.9798, Recall: 0.9725, F1_score: 0.9762
Model performance on Happy speech (in training): 
	Precision: 0.9556, Recall: 0.9675, F1_score: 0.9615
Model performance on Neutral speech (in training): 
	Precision: 0.9849, Recall: 0.9775, F1_score: 0.9812
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 195/1600 [00:10<01:12, 19.46it/s]Training:  24%|██▍       | 391/1600 [00:20<01:02, 19.49it/s]Training:  37%|███▋      | 587/1600 [00:30<00:51, 19.53it/s]Training:  49%|████▉     | 784/1600 [00:40<00:41, 19.57it/s]Training:  61%|██████▏   | 981/1600 [00:50<00:31, 19.52it/s]Training:  74%|███████▎  | 1178/1600 [01:00<00:21, 19.56it/s]Training:  86%|████████▌ | 1375/1600 [01:10<00:11, 19.55it/s]Training:  98%|█████████▊| 1573/1600 [01:20<00:01, 19.63it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 619.6008, Validation accuracy: 0.2150
Macro F1-score: 0.1192
Model performance on Angry speech (in validation): 
	Precision: 0.2941, Recall: 0.1000, F1_score: 0.1493
Model performance on Happy speech (in validation): 
	Precision: 0.2088, Recall: 0.7600, F1_score: 0.3276
Model performance on Neutral speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 5/100

Training Phase:
Training loss: 121.0541, Training accuracy: 0.9769
Macro F1-score: 0.9769
Model performance on Angry speech (in training): 
	Precision: 0.9873, Recall: 0.9700, F1_score: 0.9786
Model performance on Happy speech (in training): 
	Precision: 0.9558, Recall: 0.9725, F1_score: 0.9641
Model performance on Neutral speech (in training): 
	Precision: 0.9750, Recall: 0.9750, F1_score: 0.9750
Model performance on Sad speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 194/1600 [00:10<01:12, 19.38it/s]Training:  24%|██▍       | 388/1600 [00:20<01:02, 19.34it/s]Training:  37%|███▋      | 586/1600 [00:30<00:51, 19.54it/s]Training:  49%|████▉     | 785/1600 [00:40<00:41, 19.65it/s]Training:  62%|██████▏   | 984/1600 [00:50<00:31, 19.64it/s]Training:  74%|███████▍  | 1182/1600 [01:00<00:21, 19.68it/s]Training:  86%|████████▋ | 1380/1600 [01:10<00:11, 19.58it/s]Training:  98%|█████████▊| 1575/1600 [01:20<00:01, 19.53it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 889.6910, Validation accuracy: 0.2000
Macro F1-score: 0.1436
Model performance on Angry speech (in validation): 
	Precision: 0.3735, Recall: 0.6200, F1_score: 0.4662
Model performance on Happy speech (in validation): 
	Precision: 0.0776, Recall: 0.1800, F1_score: 0.1084
Model performance on Neutral speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 6/100

Training Phase:
Training loss: 97.1997, Training accuracy: 0.9806
Macro F1-score: 0.9807
Model performance on Angry speech (in training): 
	Precision: 0.9924, Recall: 0.9775, F1_score: 0.9849
Model performance on Happy speech (in training): 
	Precision: 0.9606, Recall: 0.9750, F1_score: 0.9677
Model performance on Neutral speech (in training): 
	Precision: 0.9751, Recall: 0.9775, F1_score: 0.9763
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 196/1600 [00:10<01:11, 19.56it/s]Training:  25%|██▍       | 394/1600 [00:20<01:01, 19.67it/s]Training:  25%|██▍       | 394/1600 [00:30<01:01, 19.67it/s]Training:  37%|███▋      | 591/1600 [00:30<00:51, 19.58it/s]Training:  49%|████▉     | 786/1600 [00:40<00:41, 19.39it/s]Training:  61%|██████▏   | 982/1600 [00:50<00:31, 19.46it/s]Training:  74%|███████▍  | 1180/1600 [01:00<00:21, 19.56it/s]Training:  86%|████████▌ | 1378/1600 [01:10<00:11, 19.61it/s]Training:  98%|█████████▊| 1576/1600 [01:20<00:01, 19.59it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 792.9871, Validation accuracy: 0.2050
Macro F1-score: 0.1400
Model performance on Angry speech (in validation): 
	Precision: 0.3579, Recall: 0.6800, F1_score: 0.4690
Model performance on Happy speech (in validation): 
	Precision: 0.0673, Recall: 0.1400, F1_score: 0.0909
Model performance on Neutral speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 7/100

Training Phase:
Training loss: 67.3532, Training accuracy: 0.9844
Macro F1-score: 0.9844
Model performance on Angry speech (in training): 
	Precision: 0.9825, Recall: 0.9850, F1_score: 0.9838
Model performance on Happy speech (in training): 
	Precision: 0.9798, Recall: 0.9725, F1_score: 0.9762
Model performance on Neutral speech (in training): 
	Precision: 0.9826, Recall: 0.9875, F1_score: 0.9850
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 198/1600 [00:10<01:11, 19.71it/s]Training:  25%|██▍       | 396/1600 [00:20<01:01, 19.69it/s]Training:  37%|███▋      | 593/1600 [00:30<00:51, 19.68it/s]Training:  49%|████▉     | 790/1600 [00:40<00:41, 19.59it/s]Training:  62%|██████▏   | 987/1600 [00:50<00:31, 19.63it/s]Training:  74%|███████▍  | 1184/1600 [01:00<00:21, 19.55it/s]Training:  86%|████████▋ | 1380/1600 [01:10<00:11, 19.54it/s]Training:  98%|█████████▊| 1576/1600 [01:20<00:01, 19.50it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 1033.8356, Validation accuracy: 0.2250
Macro F1-score: 0.1494
Model performance on Angry speech (in validation): 
	Precision: 0.3871, Recall: 0.2400, F1_score: 0.2963
Model performance on Happy speech (in validation): 
	Precision: 0.1953, Recall: 0.6600, F1_score: 0.3014
Model performance on Neutral speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 8/100

Training Phase:
Training loss: 76.6924, Training accuracy: 0.9800
Macro F1-score: 0.9800
Model performance on Angry speech (in training): 
	Precision: 0.9898, Recall: 0.9750, F1_score: 0.9824
Model performance on Happy speech (in training): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Neutral speech (in training): 
	Precision: 0.9799, Recall: 0.9750, F1_score: 0.9774
Model performance on Sad speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 196/1600 [00:10<01:11, 19.58it/s]Training:  25%|██▍       | 395/1600 [00:20<01:00, 19.76it/s]Training:  37%|███▋      | 594/1600 [00:30<00:51, 19.72it/s]Training:  49%|████▉     | 791/1600 [00:40<00:41, 19.63it/s]Training:  62%|██████▏   | 988/1600 [00:50<00:31, 19.64it/s]Training:  74%|███████▍  | 1187/1600 [01:00<00:20, 19.70it/s]Training:  87%|████████▋ | 1386/1600 [01:10<00:10, 19.60it/s]Training:  99%|█████████▉| 1581/1600 [01:20<00:00, 19.48it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 977.6966, Validation accuracy: 0.2250
Macro F1-score: 0.1593
Model performance on Angry speech (in validation): 
	Precision: 0.3830, Recall: 0.3600, F1_score: 0.3711
Model performance on Happy speech (in validation): 
	Precision: 0.1765, Recall: 0.5400, F1_score: 0.2660
Model performance on Neutral speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 9/100

Training Phase:
Training loss: 61.3104, Training accuracy: 0.9875
Macro F1-score: 0.9875
Model performance on Angry speech (in training): 
	Precision: 0.9900, Recall: 0.9875, F1_score: 0.9887
Model performance on Happy speech (in training): 
	Precision: 0.9800, Recall: 0.9800, F1_score: 0.9800
Model performance on Neutral speech (in training): 
	Precision: 0.9850, Recall: 0.9875, F1_score: 0.9863
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 193/1600 [00:10<01:13, 19.26it/s]Training:  24%|██▍       | 389/1600 [00:20<01:02, 19.44it/s]Training:  37%|███▋      | 585/1600 [00:30<00:52, 19.51it/s]Training:  49%|████▉     | 782/1600 [00:40<00:41, 19.57it/s]Training:  61%|██████▏   | 980/1600 [00:50<00:31, 19.64it/s]Training:  74%|███████▎  | 1178/1600 [01:00<00:21, 19.57it/s]Training:  86%|████████▌ | 1375/1600 [01:10<00:11, 19.60it/s]Training:  98%|█████████▊| 1576/1600 [01:20<00:01, 19.73it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 898.1256, Validation accuracy: 0.1650
Macro F1-score: 0.1176
Model performance on Angry speech (in validation): 
	Precision: 0.2200, Recall: 0.2200, F1_score: 0.2200
Model performance on Happy speech (in validation): 
	Precision: 0.1419, Recall: 0.4200, F1_score: 0.2121
Model performance on Neutral speech (in validation): 
	Precision: 0.5000, Recall: 0.0200, F1_score: 0.0385
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 10/100

Training Phase:
Training loss: 41.1999, Training accuracy: 0.9925
Macro F1-score: 0.9925
Model performance on Angry speech (in training): 
	Precision: 0.9875, Recall: 0.9900, F1_score: 0.9888
Model performance on Happy speech (in training): 
	Precision: 0.9875, Recall: 0.9850, F1_score: 0.9862
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 195/1600 [00:10<01:12, 19.42it/s]Training:  24%|██▍       | 390/1600 [00:20<01:02, 19.43it/s]Training:  37%|███▋      | 587/1600 [00:30<00:51, 19.53it/s]Training:  49%|████▉     | 784/1600 [00:40<00:41, 19.56it/s]Training:  61%|██████▏   | 981/1600 [00:50<00:31, 19.56it/s]Training:  74%|███████▎  | 1177/1600 [01:00<00:21, 19.53it/s]Training:  86%|████████▌ | 1375/1600 [01:10<00:11, 19.61it/s]Training:  98%|█████████▊| 1576/1600 [01:20<00:01, 19.74it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 1093.2247, Validation accuracy: 0.1950
Macro F1-score: 0.1088
Model performance on Angry speech (in validation): 
	Precision: 0.1923, Recall: 0.1000, F1_score: 0.1316
Model performance on Happy speech (in validation): 
	Precision: 0.1954, Recall: 0.6800, F1_score: 0.3036
Model performance on Neutral speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 11/100

Training Phase:
Training loss: 40.6717, Training accuracy: 0.9894
Macro F1-score: 0.9894
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Happy speech (in training): 
	Precision: 0.9850, Recall: 0.9875, F1_score: 0.9863
Model performance on Neutral speech (in training): 
	Precision: 0.9874, Recall: 0.9825, F1_score: 0.9850
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 196/1600 [00:10<01:11, 19.56it/s]Training:  24%|██▍       | 392/1600 [00:20<01:01, 19.51it/s]Training:  37%|███▋      | 590/1600 [00:30<00:51, 19.60it/s]Training:  49%|████▉     | 788/1600 [00:40<00:41, 19.65it/s]Training:  62%|██████▏   | 986/1600 [00:50<00:31, 19.65it/s]Training:  74%|███████▍  | 1183/1600 [01:00<00:21, 19.61it/s]Training:  86%|████████▋ | 1380/1600 [01:10<00:11, 19.62it/s]Training:  99%|█████████▊| 1577/1600 [01:20<00:01, 19.63it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
/work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 1013.8379, Validation accuracy: 0.1900
Macro F1-score: 0.1229
Model performance on Angry speech (in validation): 
	Precision: 0.2632, Recall: 0.2000, F1_score: 0.2273
Model performance on Happy speech (in validation): 
	Precision: 0.1728, Recall: 0.5600, F1_score: 0.2642
Model performance on Neutral speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Validation loss does not decrease for 10 epochs. End training.
Epoch 12/100

Entering 2ND training phase: change training data from de to CN
Loading cn train data: fold_0...
Preprocess cn fold_0 data for de model
Reload model and reset eval loss

Training Phase:
Training loss: 2111.1942, Training accuracy: 0.5669
Macro F1-score: 0.5673
Model performance on Angry speech (in training): 
	Precision: 0.6636, Recall: 0.7100, F1_score: 0.6860
Model performance on Happy speech (in training): 
	Precision: 0.4222, Recall: 0.5425, F1_score: 0.4748
Model performance on Neutral speech (in training): 
	Precision: 0.5520, Recall: 0.5975, F1_score: 0.5738
Model performance on Sad speech (in training): 
	Precision: 0.7422, Recall: 0.4175, F1_score: 0.5344

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  10%|▉         | 154/1600 [00:10<01:34, 15.37it/s]Training:  22%|██▏       | 357/1600 [00:20<01:08, 18.26it/s]Training:  36%|███▋      | 583/1600 [00:30<00:50, 20.23it/s]Training:  51%|█████     | 814/1600 [00:40<00:36, 21.33it/s]Training:  66%|██████▌   | 1055/1600 [00:50<00:24, 22.32it/s]Training:  81%|████████  | 1296/1600 [01:00<00:13, 22.82it/s]Training:  96%|█████████▌| 1538/1600 [01:10<00:02, 23.26it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 13/100

Training Phase:
Training loss: 2158.0069, Training accuracy: 0.5575
Macro F1-score: 0.5597
Model performance on Angry speech (in training): 
	Precision: 0.6538, Recall: 0.6800, F1_score: 0.6667
Model performance on Happy speech (in training): 
	Precision: 0.4076, Recall: 0.5350, F1_score: 0.4627
Model performance on Neutral speech (in training): 
	Precision: 0.5491, Recall: 0.5875, F1_score: 0.5676
Model performance on Sad speech (in training): 
	Precision: 0.7403, Recall: 0.4275, F1_score: 0.5420

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 273/1600 [00:10<00:48, 27.22it/s]Training:  34%|███▍      | 546/1600 [00:20<00:38, 27.11it/s]Training:  51%|█████     | 817/1600 [00:30<00:29, 26.98it/s]Training:  68%|██████▊   | 1087/1600 [00:40<00:19, 26.96it/s]Training:  85%|████████▍ | 1357/1600 [00:50<00:09, 26.93it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 14/100

Training Phase:
Training loss: 2140.8634, Training accuracy: 0.5550
Macro F1-score: 0.5557
Model performance on Angry speech (in training): 
	Precision: 0.6627, Recall: 0.6975, F1_score: 0.6797
Model performance on Happy speech (in training): 
	Precision: 0.4147, Recall: 0.5225, F1_score: 0.4624
Model performance on Neutral speech (in training): 
	Precision: 0.5222, Recall: 0.5875, F1_score: 0.5529
Model performance on Sad speech (in training): 
	Precision: 0.7333, Recall: 0.4125, F1_score: 0.5280

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 270/1600 [00:10<00:49, 26.99it/s]Training:  34%|███▍      | 540/1600 [00:20<00:39, 26.94it/s]Training:  51%|█████     | 810/1600 [00:30<00:29, 26.91it/s]Training:  68%|██████▊   | 1080/1600 [00:40<00:19, 26.91it/s]Training:  84%|████████▍ | 1350/1600 [00:50<00:09, 26.88it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 15/100

Training Phase:
Training loss: 2149.7704, Training accuracy: 0.5613
Macro F1-score: 0.5623
Model performance on Angry speech (in training): 
	Precision: 0.6667, Recall: 0.6950, F1_score: 0.6805
Model performance on Happy speech (in training): 
	Precision: 0.4146, Recall: 0.5400, F1_score: 0.4691
Model performance on Neutral speech (in training): 
	Precision: 0.5471, Recall: 0.5950, F1_score: 0.5701
Model performance on Sad speech (in training): 
	Precision: 0.7313, Recall: 0.4150, F1_score: 0.5295

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 270/1600 [00:10<00:49, 26.90it/s]Training:  34%|███▎      | 539/1600 [00:20<00:39, 26.66it/s]Training:  50%|█████     | 807/1600 [00:30<00:29, 26.68it/s]Training:  67%|██████▋   | 1079/1600 [00:40<00:19, 26.85it/s]Training:  84%|████████▍ | 1351/1600 [00:50<00:09, 26.89it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 16/100

Training Phase:
Training loss: 2149.0326, Training accuracy: 0.5613
Macro F1-score: 0.5632
Model performance on Angry speech (in training): 
	Precision: 0.6611, Recall: 0.6925, F1_score: 0.6764
Model performance on Happy speech (in training): 
	Precision: 0.4103, Recall: 0.5375, F1_score: 0.4654
Model performance on Neutral speech (in training): 
	Precision: 0.5529, Recall: 0.5875, F1_score: 0.5697
Model performance on Sad speech (in training): 
	Precision: 0.7371, Recall: 0.4275, F1_score: 0.5411

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 272/1600 [00:10<00:48, 27.13it/s]Training:  34%|███▍      | 544/1600 [00:20<00:39, 26.92it/s]Training:  51%|█████     | 815/1600 [00:30<00:29, 27.00it/s]Training:  68%|██████▊   | 1086/1600 [00:40<00:19, 26.95it/s]Training:  85%|████████▍ | 1357/1600 [00:50<00:09, 26.97it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 17/100

Training Phase:
Training loss: 2158.2551, Training accuracy: 0.5569
Macro F1-score: 0.5585
Model performance on Angry speech (in training): 
	Precision: 0.6603, Recall: 0.6900, F1_score: 0.6748
Model performance on Happy speech (in training): 
	Precision: 0.4077, Recall: 0.5300, F1_score: 0.4609
Model performance on Neutral speech (in training): 
	Precision: 0.5467, Recall: 0.5850, F1_score: 0.5652
Model performance on Sad speech (in training): 
	Precision: 0.7222, Recall: 0.4225, F1_score: 0.5331

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 270/1600 [00:10<00:49, 26.90it/s]Training:  34%|███▍      | 540/1600 [00:20<00:39, 26.94it/s]Training:  51%|█████     | 811/1600 [00:30<00:29, 26.96it/s]Training:  51%|█████     | 811/1600 [00:41<00:29, 26.96it/s]Training:  68%|██████▊   | 1081/1600 [00:41<00:19, 26.02it/s]Training:  68%|██████▊   | 1081/1600 [00:51<00:19, 26.02it/s]Training:  82%|████████▏ | 1307/1600 [00:51<00:11, 24.79it/s]Training:  96%|█████████▌| 1534/1600 [01:01<00:02, 24.08it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 18/100

Training Phase:
Training loss: 2170.1921, Training accuracy: 0.5513
Macro F1-score: 0.5532
Model performance on Angry speech (in training): 
	Precision: 0.6413, Recall: 0.6750, F1_score: 0.6577
Model performance on Happy speech (in training): 
	Precision: 0.3992, Recall: 0.5150, F1_score: 0.4498
Model performance on Neutral speech (in training): 
	Precision: 0.5471, Recall: 0.5950, F1_score: 0.5701
Model performance on Sad speech (in training): 
	Precision: 0.7368, Recall: 0.4200, F1_score: 0.5350

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 234/1600 [00:10<00:58, 23.30it/s]Training:  30%|███       | 483/1600 [00:20<00:46, 24.24it/s]Training:  46%|████▌     | 732/1600 [00:30<00:35, 24.11it/s]Training:  61%|██████▏   | 982/1600 [00:40<00:25, 24.45it/s]Training:  78%|███████▊  | 1248/1600 [00:50<00:13, 25.20it/s]Training:  95%|█████████▍| 1514/1600 [01:01<00:03, 25.04it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 19/100

Training Phase:
Training loss: 2132.5960, Training accuracy: 0.5513
Macro F1-score: 0.5528
Model performance on Angry speech (in training): 
	Precision: 0.6548, Recall: 0.6875, F1_score: 0.6707
Model performance on Happy speech (in training): 
	Precision: 0.4080, Recall: 0.5325, F1_score: 0.4620
Model performance on Neutral speech (in training): 
	Precision: 0.5330, Recall: 0.5650, F1_score: 0.5485
Model performance on Sad speech (in training): 
	Precision: 0.7179, Recall: 0.4200, F1_score: 0.5300

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 266/1600 [00:10<00:50, 26.59it/s]Training:  33%|███▎      | 532/1600 [00:20<00:40, 26.48it/s]Training:  50%|████▉     | 797/1600 [00:30<00:31, 25.58it/s]Training:  66%|██████▌   | 1048/1600 [00:40<00:21, 25.39it/s]Training:  82%|████████▏ | 1312/1600 [00:50<00:11, 25.72it/s]Training:  99%|█████████▊| 1579/1600 [01:00<00:00, 26.02it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 20/100

Training Phase:
Training loss: 2153.2123, Training accuracy: 0.5544
Macro F1-score: 0.5569
Model performance on Angry speech (in training): 
	Precision: 0.6610, Recall: 0.6825, F1_score: 0.6716
Model performance on Happy speech (in training): 
	Precision: 0.4041, Recall: 0.5425, F1_score: 0.4632
Model performance on Neutral speech (in training): 
	Precision: 0.5444, Recall: 0.5675, F1_score: 0.5557
Model performance on Sad speech (in training): 
	Precision: 0.7296, Recall: 0.4250, F1_score: 0.5371

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▋        | 263/1600 [00:10<00:50, 26.25it/s]Training:  33%|███▎      | 526/1600 [00:20<00:41, 26.11it/s]Training:  49%|████▉     | 787/1600 [00:30<00:31, 25.68it/s]Training:  65%|██████▌   | 1040/1600 [00:40<00:21, 25.52it/s]Training:  81%|████████  | 1293/1600 [00:50<00:12, 25.38it/s]Training:  97%|█████████▋| 1550/1600 [01:00<00:01, 25.49it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 21/100

Training Phase:
Training loss: 2120.4293, Training accuracy: 0.5656
Macro F1-score: 0.5658
Model performance on Angry speech (in training): 
	Precision: 0.6690, Recall: 0.7125, F1_score: 0.6901
Model performance on Happy speech (in training): 
	Precision: 0.4261, Recall: 0.5475, F1_score: 0.4792
Model performance on Neutral speech (in training): 
	Precision: 0.5427, Recall: 0.5875, F1_score: 0.5642
Model performance on Sad speech (in training): 
	Precision: 0.7313, Recall: 0.4150, F1_score: 0.5295

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▋        | 261/1600 [00:10<00:51, 26.00it/s]Training:  33%|███▎      | 521/1600 [00:20<00:42, 25.31it/s]Training:  48%|████▊     | 776/1600 [00:30<00:32, 25.35it/s]Training:  65%|██████▍   | 1035/1600 [00:40<00:22, 25.55it/s]Training:  81%|████████  | 1294/1600 [00:51<00:12, 25.24it/s]Training:  96%|█████████▋| 1542/1600 [01:01<00:02, 24.97it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 22/100

Training Phase:
Training loss: 2138.5358, Training accuracy: 0.5619
Macro F1-score: 0.5639
Model performance on Angry speech (in training): 
	Precision: 0.6740, Recall: 0.6925, F1_score: 0.6831
Model performance on Happy speech (in training): 
	Precision: 0.4144, Recall: 0.5450, F1_score: 0.4708
Model performance on Neutral speech (in training): 
	Precision: 0.5446, Recall: 0.5800, F1_score: 0.5617
Model performance on Sad speech (in training): 
	Precision: 0.7257, Recall: 0.4300, F1_score: 0.5400

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 231/1600 [00:10<00:59, 23.10it/s]Training:  29%|██▉       | 462/1600 [00:20<00:49, 22.89it/s]Training:  43%|████▎     | 692/1600 [00:30<00:39, 22.90it/s]Training:  58%|█████▊    | 922/1600 [00:40<00:29, 22.88it/s]Training:  72%|███████▎  | 1160/1600 [00:50<00:18, 23.20it/s]Training:  87%|████████▋ | 1398/1600 [01:00<00:08, 23.22it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 23/100

Training Phase:
Training loss: 2148.5375, Training accuracy: 0.5494
Macro F1-score: 0.5514
Model performance on Angry speech (in training): 
	Precision: 0.6447, Recall: 0.6850, F1_score: 0.6642
Model performance on Happy speech (in training): 
	Precision: 0.3968, Recall: 0.5000, F1_score: 0.4425
Model performance on Neutral speech (in training): 
	Precision: 0.5356, Recall: 0.5825, F1_score: 0.5581
Model performance on Sad speech (in training): 
	Precision: 0.7288, Recall: 0.4300, F1_score: 0.5409

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 231/1600 [00:10<00:59, 23.08it/s]Training:  29%|██▉       | 471/1600 [00:20<00:47, 23.62it/s]Training:  45%|████▍     | 718/1600 [00:30<00:36, 24.07it/s]Training:  60%|██████    | 965/1600 [00:40<00:26, 24.21it/s]Training:  76%|███████▌  | 1210/1600 [00:50<00:16, 24.15it/s]Training:  91%|█████████ | 1456/1600 [01:00<00:05, 24.28it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 24/100

Training Phase:
Training loss: 2145.3325, Training accuracy: 0.5656
Macro F1-score: 0.5663
Model performance on Angry speech (in training): 
	Precision: 0.6635, Recall: 0.7050, F1_score: 0.6836
Model performance on Happy speech (in training): 
	Precision: 0.4221, Recall: 0.5350, F1_score: 0.4719
Model performance on Neutral speech (in training): 
	Precision: 0.5455, Recall: 0.6000, F1_score: 0.5714
Model performance on Sad speech (in training): 
	Precision: 0.7412, Recall: 0.4225, F1_score: 0.5382

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 250/1600 [00:10<00:54, 24.97it/s]Training:  31%|███▏      | 502/1600 [00:20<00:43, 25.09it/s]Training:  48%|████▊     | 761/1600 [00:30<00:32, 25.45it/s]Training:  64%|██████▍   | 1030/1600 [00:40<00:21, 26.01it/s]Training:  81%|████████  | 1299/1600 [00:50<00:11, 25.81it/s]Training:  97%|█████████▋| 1554/1600 [01:00<00:01, 25.54it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 25/100

Training Phase:
Training loss: 2141.5910, Training accuracy: 0.5631
Macro F1-score: 0.5643
Model performance on Angry speech (in training): 
	Precision: 0.6565, Recall: 0.6975, F1_score: 0.6764
Model performance on Happy speech (in training): 
	Precision: 0.4160, Recall: 0.5325, F1_score: 0.4671
Model performance on Neutral speech (in training): 
	Precision: 0.5548, Recall: 0.5950, F1_score: 0.5742
Model performance on Sad speech (in training): 
	Precision: 0.7308, Recall: 0.4275, F1_score: 0.5394

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 251/1600 [00:10<00:53, 25.10it/s]Training:  31%|███▏      | 502/1600 [00:20<00:44, 24.74it/s]Training:  48%|████▊     | 765/1600 [00:30<00:32, 25.43it/s]Training:  64%|██████▍   | 1028/1600 [00:40<00:22, 25.77it/s]Training:  81%|████████  | 1294/1600 [00:50<00:11, 26.06it/s]Training:  81%|████████  | 1294/1600 [01:00<00:11, 26.06it/s]Training:  97%|█████████▋| 1548/1600 [01:00<00:02, 25.74it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 26/100

Training Phase:
Training loss: 2152.7920, Training accuracy: 0.5600
Macro F1-score: 0.5602
Model performance on Angry speech (in training): 
	Precision: 0.6636, Recall: 0.7100, F1_score: 0.6860
Model performance on Happy speech (in training): 
	Precision: 0.4176, Recall: 0.5325, F1_score: 0.4681
Model performance on Neutral speech (in training): 
	Precision: 0.5379, Recall: 0.5850, F1_score: 0.5605
Model performance on Sad speech (in training): 
	Precision: 0.7269, Recall: 0.4125, F1_score: 0.5263

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 249/1600 [00:10<00:54, 24.90it/s]Training:  32%|███▏      | 513/1600 [00:20<00:42, 25.76it/s]Training:  49%|████▊     | 777/1600 [00:30<00:32, 25.51it/s]Training:  64%|██████▍   | 1030/1600 [00:40<00:22, 25.27it/s]Training:  80%|████████  | 1281/1600 [00:50<00:12, 25.17it/s]Training:  96%|█████████▌| 1539/1600 [01:00<00:02, 25.35it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 27/100

Training Phase:
Training loss: 2130.4602, Training accuracy: 0.5625
Macro F1-score: 0.5641
Model performance on Angry speech (in training): 
	Precision: 0.6619, Recall: 0.7000, F1_score: 0.6804
Model performance on Happy speech (in training): 
	Precision: 0.4167, Recall: 0.5250, F1_score: 0.4646
Model performance on Neutral speech (in training): 
	Precision: 0.5415, Recall: 0.5875, F1_score: 0.5635
Model performance on Sad speech (in training): 
	Precision: 0.7322, Recall: 0.4375, F1_score: 0.5477

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 273/1600 [00:10<00:48, 27.19it/s]Training:  34%|███▍      | 545/1600 [00:20<00:39, 26.74it/s]Training:  34%|███▍      | 545/1600 [00:30<00:39, 26.74it/s]Training:  51%|█████     | 810/1600 [00:30<00:30, 26.03it/s]Training:  66%|██████▋   | 1063/1600 [00:40<00:20, 25.62it/s]Training:  83%|████████▎ | 1326/1600 [00:50<00:10, 25.84it/s]Training: 100%|█████████▉| 1595/1600 [01:01<00:00, 26.19it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 28/100

Training Phase:
Training loss: 2144.5108, Training accuracy: 0.5631
Macro F1-score: 0.5649
Model performance on Angry speech (in training): 
	Precision: 0.6749, Recall: 0.6850, F1_score: 0.6799
Model performance on Happy speech (in training): 
	Precision: 0.4204, Recall: 0.5675, F1_score: 0.4830
Model performance on Neutral speech (in training): 
	Precision: 0.5487, Recall: 0.5775, F1_score: 0.5627
Model performance on Sad speech (in training): 
	Precision: 0.7253, Recall: 0.4225, F1_score: 0.5340

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 270/1600 [00:10<00:49, 26.96it/s]Training:  34%|███▍      | 540/1600 [00:20<00:39, 26.98it/s]Training:  51%|█████     | 810/1600 [00:30<00:29, 26.67it/s]Training:  67%|██████▋   | 1074/1600 [00:40<00:19, 26.41it/s]Training:  84%|████████▍ | 1342/1600 [00:50<00:09, 26.54it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 29/100

Training Phase:
Training loss: 2134.0301, Training accuracy: 0.5619
Macro F1-score: 0.5638
Model performance on Angry speech (in training): 
	Precision: 0.6691, Recall: 0.6875, F1_score: 0.6782
Model performance on Happy speech (in training): 
	Precision: 0.4148, Recall: 0.5475, F1_score: 0.4720
Model performance on Neutral speech (in training): 
	Precision: 0.5465, Recall: 0.5875, F1_score: 0.5663
Model performance on Sad speech (in training): 
	Precision: 0.7359, Recall: 0.4250, F1_score: 0.5388

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 270/1600 [00:10<00:49, 26.91it/s]Training:  34%|███▍      | 540/1600 [00:20<00:39, 26.86it/s]Training:  51%|█████     | 809/1600 [00:30<00:29, 26.63it/s]Training:  67%|██████▋   | 1073/1600 [00:40<00:20, 26.23it/s]Training:  83%|████████▎ | 1330/1600 [00:50<00:10, 25.94it/s]Training:  99%|█████████▉| 1585/1600 [01:00<00:00, 25.57it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 30/100

Training Phase:
Training loss: 2127.9423, Training accuracy: 0.5606
Macro F1-score: 0.5606
Model performance on Angry speech (in training): 
	Precision: 0.6596, Recall: 0.6975, F1_score: 0.6780
Model performance on Happy speech (in training): 
	Precision: 0.4227, Recall: 0.5400, F1_score: 0.4742
Model performance on Neutral speech (in training): 
	Precision: 0.5446, Recall: 0.5950, F1_score: 0.5687
Model performance on Sad speech (in training): 
	Precision: 0.7162, Recall: 0.4100, F1_score: 0.5215

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 271/1600 [00:10<00:49, 27.01it/s]Training:  34%|███▍      | 542/1600 [00:21<00:41, 25.47it/s]Training:  49%|████▉     | 787/1600 [00:31<00:33, 24.41it/s]Training:  64%|██████▎   | 1019/1600 [00:41<00:24, 23.94it/s]Training:  78%|███████▊  | 1251/1600 [00:51<00:14, 23.61it/s]Training:  93%|█████████▎| 1482/1600 [01:01<00:05, 23.29it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 31/100

Training Phase:
Training loss: 2154.7838, Training accuracy: 0.5469
Macro F1-score: 0.5489
Model performance on Angry speech (in training): 
	Precision: 0.6490, Recall: 0.6750, F1_score: 0.6618
Model performance on Happy speech (in training): 
	Precision: 0.4054, Recall: 0.5300, F1_score: 0.4594
Model performance on Neutral speech (in training): 
	Precision: 0.5284, Recall: 0.5575, F1_score: 0.5426
Model performance on Sad speech (in training): 
	Precision: 0.7113, Recall: 0.4250, F1_score: 0.5321

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 237/1600 [00:10<00:57, 23.69it/s]Training:  30%|███       | 484/1600 [00:20<00:46, 24.23it/s]Training:  46%|████▌     | 731/1600 [00:30<00:36, 24.12it/s]Training:  61%|██████▏   | 983/1600 [00:40<00:25, 24.51it/s]Training:  77%|███████▋  | 1235/1600 [00:50<00:14, 24.67it/s]Training:  93%|█████████▎| 1485/1600 [01:00<00:04, 24.75it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 32/100

Training Phase:
Training loss: 2150.5443, Training accuracy: 0.5556
Macro F1-score: 0.5566
Model performance on Angry speech (in training): 
	Precision: 0.6534, Recall: 0.6975, F1_score: 0.6747
Model performance on Happy speech (in training): 
	Precision: 0.4115, Recall: 0.5350, F1_score: 0.4652
Model performance on Neutral speech (in training): 
	Precision: 0.5481, Recall: 0.5700, F1_score: 0.5588
Model performance on Sad speech (in training): 
	Precision: 0.7089, Recall: 0.4200, F1_score: 0.5275

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 248/1600 [00:10<00:54, 24.78it/s]Training:  31%|███       | 497/1600 [00:20<00:44, 24.82it/s]Training:  47%|████▋     | 747/1600 [00:30<00:34, 24.90it/s]Training:  64%|██████▎   | 1016/1600 [00:40<00:22, 25.66it/s]Training:  80%|████████  | 1286/1600 [00:50<00:12, 26.13it/s]Training:  97%|█████████▋| 1557/1600 [01:00<00:01, 26.44it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 33/100

Training Phase:
Training loss: 2127.2043, Training accuracy: 0.5606
Macro F1-score: 0.5618
Model performance on Angry speech (in training): 
	Precision: 0.6541, Recall: 0.6950, F1_score: 0.6739
Model performance on Happy speech (in training): 
	Precision: 0.4145, Recall: 0.5275, F1_score: 0.4642
Model performance on Neutral speech (in training): 
	Precision: 0.5499, Recall: 0.5925, F1_score: 0.5704
Model performance on Sad speech (in training): 
	Precision: 0.7277, Recall: 0.4275, F1_score: 0.5386

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 235/1600 [00:10<00:58, 23.48it/s]Training:  29%|██▉       | 470/1600 [00:20<00:48, 23.12it/s]Training:  44%|████▎     | 699/1600 [00:30<00:39, 22.83it/s]Training:  58%|█████▊    | 927/1600 [00:40<00:29, 22.81it/s]Training:  72%|███████▏  | 1157/1600 [00:50<00:19, 22.87it/s]Training:  87%|████████▋ | 1387/1600 [01:00<00:09, 22.79it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 34/100

Training Phase:
Training loss: 2152.6785, Training accuracy: 0.5569
Macro F1-score: 0.5579
Model performance on Angry speech (in training): 
	Precision: 0.6447, Recall: 0.6850, F1_score: 0.6642
Model performance on Happy speech (in training): 
	Precision: 0.4102, Recall: 0.5250, F1_score: 0.4605
Model performance on Neutral speech (in training): 
	Precision: 0.5517, Recall: 0.6000, F1_score: 0.5749
Model performance on Sad speech (in training): 
	Precision: 0.7325, Recall: 0.4175, F1_score: 0.5318

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 253/1600 [00:10<00:53, 25.22it/s]Training:  32%|███▏      | 506/1600 [00:20<00:43, 25.04it/s]Training:  47%|████▋     | 758/1600 [00:30<00:33, 25.10it/s]Training:  63%|██████▎   | 1013/1600 [00:40<00:23, 25.25it/s]Training:  63%|██████▎   | 1013/1600 [00:50<00:23, 25.25it/s]Training:  79%|███████▉  | 1266/1600 [00:50<00:13, 25.15it/s]Training:  95%|█████████▍| 1516/1600 [01:00<00:03, 24.95it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 35/100

Training Phase:
Training loss: 2146.2605, Training accuracy: 0.5544
Macro F1-score: 0.5553
Model performance on Angry speech (in training): 
	Precision: 0.6520, Recall: 0.7025, F1_score: 0.6763
Model performance on Happy speech (in training): 
	Precision: 0.4075, Recall: 0.5175, F1_score: 0.4559
Model performance on Neutral speech (in training): 
	Precision: 0.5397, Recall: 0.5775, F1_score: 0.5580
Model performance on Sad speech (in training): 
	Precision: 0.7210, Recall: 0.4200, F1_score: 0.5308

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 265/1600 [00:10<00:50, 26.46it/s]Training:  33%|███▎      | 532/1600 [00:20<00:40, 26.58it/s]Training:  50%|████▉     | 799/1600 [00:30<00:30, 26.40it/s]Training:  66%|██████▋   | 1061/1600 [00:40<00:20, 25.90it/s]Training:  82%|████████▎ | 1320/1600 [00:50<00:10, 25.90it/s]Training:  99%|█████████▊| 1579/1600 [01:00<00:00, 25.81it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 36/100

Training Phase:
Training loss: 2137.6632, Training accuracy: 0.5631
Macro F1-score: 0.5642
Model performance on Angry speech (in training): 
	Precision: 0.6620, Recall: 0.7050, F1_score: 0.6828
Model performance on Happy speech (in training): 
	Precision: 0.4137, Recall: 0.5275, F1_score: 0.4637
Model performance on Neutral speech (in training): 
	Precision: 0.5469, Recall: 0.5975, F1_score: 0.5711
Model performance on Sad speech (in training): 
	Precision: 0.7445, Recall: 0.4225, F1_score: 0.5391

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 272/1600 [00:10<00:48, 27.13it/s]Training:  34%|███▍      | 544/1600 [00:20<00:39, 26.82it/s]Training:  51%|█████     | 814/1600 [00:30<00:29, 26.90it/s]Training:  68%|██████▊   | 1084/1600 [00:40<00:19, 26.84it/s]Training:  84%|████████▍ | 1352/1600 [00:50<00:09, 26.42it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 37/100

Training Phase:
Training loss: 2144.4448, Training accuracy: 0.5569
Macro F1-score: 0.5577
Model performance on Angry speech (in training): 
	Precision: 0.6611, Recall: 0.6925, F1_score: 0.6764
Model performance on Happy speech (in training): 
	Precision: 0.4138, Recall: 0.5400, F1_score: 0.4685
Model performance on Neutral speech (in training): 
	Precision: 0.5444, Recall: 0.5825, F1_score: 0.5628
Model performance on Sad speech (in training): 
	Precision: 0.7143, Recall: 0.4125, F1_score: 0.5230

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 247/1600 [00:10<00:54, 24.62it/s]Training:  31%|███       | 494/1600 [00:20<00:44, 24.63it/s]Training:  46%|████▋     | 741/1600 [00:30<00:35, 24.40it/s]Training:  61%|██████▏   | 983/1600 [00:40<00:25, 24.30it/s]Training:  77%|███████▋  | 1225/1600 [00:50<00:15, 23.77it/s]Training:  91%|█████████ | 1454/1600 [01:00<00:06, 23.40it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 38/100

Training Phase:
Training loss: 2153.8138, Training accuracy: 0.5637
Macro F1-score: 0.5653
Model performance on Angry speech (in training): 
	Precision: 0.6667, Recall: 0.6950, F1_score: 0.6805
Model performance on Happy speech (in training): 
	Precision: 0.4184, Recall: 0.5450, F1_score: 0.4734
Model performance on Neutral speech (in training): 
	Precision: 0.5465, Recall: 0.5875, F1_score: 0.5663
Model performance on Sad speech (in training): 
	Precision: 0.7371, Recall: 0.4275, F1_score: 0.5411

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 231/1600 [00:10<00:59, 23.02it/s]Training:  29%|██▉       | 462/1600 [00:20<00:49, 22.97it/s]Training:  43%|████▎     | 693/1600 [00:30<00:39, 23.02it/s]Training:  58%|█████▊    | 924/1600 [00:40<00:29, 22.99it/s]Training:  73%|███████▎  | 1173/1600 [00:50<00:18, 23.65it/s]Training:  90%|████████▉ | 1433/1600 [01:00<00:06, 24.42it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 39/100

Training Phase:
Training loss: 2126.2592, Training accuracy: 0.5700
Macro F1-score: 0.5710
Model performance on Angry speech (in training): 
	Precision: 0.6731, Recall: 0.7000, F1_score: 0.6863
Model performance on Happy speech (in training): 
	Precision: 0.4253, Recall: 0.5550, F1_score: 0.4816
Model performance on Neutral speech (in training): 
	Precision: 0.5581, Recall: 0.6000, F1_score: 0.5783
Model performance on Sad speech (in training): 
	Precision: 0.7328, Recall: 0.4250, F1_score: 0.5380

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 265/1600 [00:10<00:50, 26.44it/s]Training:  33%|███▎      | 532/1600 [00:20<00:40, 26.55it/s]Training:  50%|████▉     | 799/1600 [00:30<00:30, 26.60it/s]Training:  67%|██████▋   | 1066/1600 [00:40<00:20, 26.37it/s]Training:  83%|████████▎ | 1327/1600 [00:50<00:10, 26.17it/s]Training:  99%|█████████▉| 1591/1600 [01:00<00:00, 26.24it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 40/100

Training Phase:
Training loss: 2137.3694, Training accuracy: 0.5644
Macro F1-score: 0.5648
Model performance on Angry speech (in training): 
	Precision: 0.6731, Recall: 0.6950, F1_score: 0.6839
Model performance on Happy speech (in training): 
	Precision: 0.4302, Recall: 0.5550, F1_score: 0.4847
Model performance on Neutral speech (in training): 
	Precision: 0.5362, Recall: 0.5925, F1_score: 0.5629
Model performance on Sad speech (in training): 
	Precision: 0.7249, Recall: 0.4150, F1_score: 0.5278

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 250/1600 [00:10<00:54, 24.96it/s]Training:  31%|███▏      | 501/1600 [00:20<00:43, 25.03it/s]Training:  47%|████▋     | 752/1600 [00:30<00:33, 24.95it/s]Training:  63%|██████▎   | 1003/1600 [00:40<00:23, 25.00it/s]Training:  79%|███████▊  | 1257/1600 [00:50<00:13, 25.14it/s]Training:  94%|█████████▍| 1511/1600 [01:00<00:03, 25.21it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 41/100

Training Phase:
Training loss: 2149.2526, Training accuracy: 0.5637
Macro F1-score: 0.5647
Model performance on Angry speech (in training): 
	Precision: 0.6731, Recall: 0.6950, F1_score: 0.6839
Model performance on Happy speech (in training): 
	Precision: 0.4214, Recall: 0.5425, F1_score: 0.4743
Model performance on Neutral speech (in training): 
	Precision: 0.5418, Recall: 0.6000, F1_score: 0.5694
Model performance on Sad speech (in training): 
	Precision: 0.7293, Recall: 0.4175, F1_score: 0.5310

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 258/1600 [00:10<00:52, 25.74it/s]Training:  32%|███▏      | 518/1600 [00:20<00:41, 25.88it/s]Training:  49%|████▊     | 778/1600 [00:30<00:31, 25.89it/s]Training:  65%|██████▍   | 1038/1600 [00:40<00:21, 25.82it/s]Training:  81%|████████  | 1298/1600 [00:50<00:11, 25.85it/s]Training:  97%|█████████▋| 1558/1600 [01:00<00:01, 25.71it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 42/100

Training Phase:
Training loss: 2119.0323, Training accuracy: 0.5713
Macro F1-score: 0.5732
Model performance on Angry speech (in training): 
	Precision: 0.6806, Recall: 0.6925, F1_score: 0.6865
Model performance on Happy speech (in training): 
	Precision: 0.4248, Recall: 0.5575, F1_score: 0.4822
Model performance on Neutral speech (in training): 
	Precision: 0.5556, Recall: 0.6000, F1_score: 0.5769
Model performance on Sad speech (in training): 
	Precision: 0.7373, Recall: 0.4350, F1_score: 0.5472

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 244/1600 [00:10<00:55, 24.31it/s]Training:  31%|███       | 491/1600 [00:20<00:45, 24.51it/s]Training:  46%|████▋     | 743/1600 [00:30<00:34, 24.81it/s]Training:  62%|██████▏   | 998/1600 [00:40<00:24, 25.04it/s]Training:  78%|███████▊  | 1253/1600 [00:50<00:13, 25.00it/s]Training:  95%|█████████▍| 1513/1600 [01:00<00:03, 25.34it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 43/100

Training Phase:
Training loss: 2143.3065, Training accuracy: 0.5581
Macro F1-score: 0.5597
Model performance on Angry speech (in training): 
	Precision: 0.6611, Recall: 0.6975, F1_score: 0.6788
Model performance on Happy speech (in training): 
	Precision: 0.4122, Recall: 0.5225, F1_score: 0.4609
Model performance on Neutral speech (in training): 
	Precision: 0.5370, Recall: 0.5800, F1_score: 0.5577
Model performance on Sad speech (in training): 
	Precision: 0.7238, Recall: 0.4325, F1_score: 0.5415

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 254/1600 [00:10<00:53, 25.32it/s]Training:  16%|█▌        | 254/1600 [00:20<00:53, 25.32it/s]Training:  31%|███▏      | 502/1600 [00:20<00:44, 24.94it/s]Training:  47%|████▋     | 749/1600 [00:30<00:34, 24.65it/s]Training:  62%|██████▏   | 999/1600 [00:40<00:24, 24.78it/s]Training:  78%|███████▊  | 1250/1600 [00:50<00:14, 24.86it/s]Training:  94%|█████████▍| 1508/1600 [01:00<00:03, 25.16it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 44/100

Training Phase:
Training loss: 2173.1281, Training accuracy: 0.5563
Macro F1-score: 0.5564
Model performance on Angry speech (in training): 
	Precision: 0.6618, Recall: 0.6850, F1_score: 0.6732
Model performance on Happy speech (in training): 
	Precision: 0.4218, Recall: 0.5525, F1_score: 0.4784
Model performance on Neutral speech (in training): 
	Precision: 0.5329, Recall: 0.5875, F1_score: 0.5589
Model performance on Sad speech (in training): 
	Precision: 0.7240, Recall: 0.4000, F1_score: 0.5153

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 267/1600 [00:10<00:50, 26.64it/s]Training:  33%|███▎      | 534/1600 [00:20<00:40, 26.11it/s]Training:  50%|████▉     | 792/1600 [00:30<00:31, 25.57it/s]Training:  66%|██████▌   | 1057/1600 [00:40<00:20, 25.92it/s]Training:  83%|████████▎ | 1324/1600 [00:50<00:10, 26.17it/s]Training:  99%|█████████▉| 1591/1600 [01:01<00:00, 25.48it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 45/100

Training Phase:
Training loss: 2153.5552, Training accuracy: 0.5606
Macro F1-score: 0.5626
Model performance on Angry speech (in training): 
	Precision: 0.6667, Recall: 0.6850, F1_score: 0.6757
Model performance on Happy speech (in training): 
	Precision: 0.4139, Recall: 0.5525, F1_score: 0.4732
Model performance on Neutral speech (in training): 
	Precision: 0.5482, Recall: 0.5825, F1_score: 0.5648
Model performance on Sad speech (in training): 
	Precision: 0.7348, Recall: 0.4225, F1_score: 0.5365

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 245/1600 [00:10<00:55, 24.50it/s]Training:  15%|█▌        | 245/1600 [00:20<00:55, 24.50it/s]Training:  30%|██▉       | 479/1600 [00:20<00:47, 23.65it/s]Training:  45%|████▍     | 718/1600 [00:30<00:37, 23.72it/s]Training:  60%|█████▉    | 958/1600 [00:40<00:26, 23.82it/s]Training:  76%|███████▌  | 1208/1600 [00:50<00:16, 24.23it/s]Training:  91%|█████████▏| 1462/1600 [01:00<00:05, 24.61it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 46/100

Training Phase:
Training loss: 2140.3455, Training accuracy: 0.5619
Macro F1-score: 0.5631
Model performance on Angry speech (in training): 
	Precision: 0.6597, Recall: 0.7075, F1_score: 0.6828
Model performance on Happy speech (in training): 
	Precision: 0.4115, Recall: 0.5350, F1_score: 0.4652
Model performance on Neutral speech (in training): 
	Precision: 0.5550, Recall: 0.5800, F1_score: 0.5672
Model performance on Sad speech (in training): 
	Precision: 0.7296, Recall: 0.4250, F1_score: 0.5371

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 258/1600 [00:10<00:52, 25.80it/s]Training:  32%|███▏      | 516/1600 [00:20<00:43, 25.15it/s]Training:  48%|████▊     | 764/1600 [00:30<00:33, 24.96it/s]Training:  63%|██████▎   | 1012/1600 [00:40<00:23, 24.54it/s]Training:  78%|███████▊  | 1252/1600 [00:51<00:14, 23.90it/s]Training:  94%|█████████▍| 1512/1600 [01:01<00:03, 24.59it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 47/100

Training Phase:
Training loss: 2145.6036, Training accuracy: 0.5650
Macro F1-score: 0.5646
Model performance on Angry speech (in training): 
	Precision: 0.6730, Recall: 0.7100, F1_score: 0.6910
Model performance on Happy speech (in training): 
	Precision: 0.4247, Recall: 0.5425, F1_score: 0.4764
Model performance on Neutral speech (in training): 
	Precision: 0.5428, Recall: 0.6025, F1_score: 0.5711
Model performance on Sad speech (in training): 
	Precision: 0.7265, Recall: 0.4050, F1_score: 0.5201

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 241/1600 [00:10<00:56, 24.08it/s]Training:  30%|███       | 482/1600 [00:20<00:47, 23.47it/s]Training:  45%|████▍     | 715/1600 [00:30<00:37, 23.36it/s]Training:  60%|█████▉    | 958/1600 [00:40<00:27, 23.72it/s]Training:  75%|███████▌  | 1201/1600 [00:50<00:16, 23.80it/s]Training:  90%|█████████ | 1441/1600 [01:00<00:06, 23.81it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 48/100

Training Phase:
Training loss: 2131.1459, Training accuracy: 0.5650
Macro F1-score: 0.5660
Model performance on Angry speech (in training): 
	Precision: 0.6635, Recall: 0.7000, F1_score: 0.6813
Model performance on Happy speech (in training): 
	Precision: 0.4235, Recall: 0.5400, F1_score: 0.4747
Model performance on Neutral speech (in training): 
	Precision: 0.5436, Recall: 0.5925, F1_score: 0.5670
Model performance on Sad speech (in training): 
	Precision: 0.7371, Recall: 0.4275, F1_score: 0.5411

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 244/1600 [00:10<00:55, 24.32it/s]Training:  31%|███       | 493/1600 [00:20<00:44, 24.62it/s]Training:  46%|████▋     | 742/1600 [00:30<00:35, 24.42it/s]Training:  62%|██████▏   | 987/1600 [00:40<00:25, 24.44it/s]Training:  77%|███████▋  | 1232/1600 [00:50<00:15, 24.18it/s]Training:  93%|█████████▎| 1483/1600 [01:00<00:04, 24.46it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 49/100

Training Phase:
Training loss: 2104.7251, Training accuracy: 0.5681
Macro F1-score: 0.5680
Model performance on Angry speech (in training): 
	Precision: 0.6744, Recall: 0.7250, F1_score: 0.6988
Model performance on Happy speech (in training): 
	Precision: 0.4243, Recall: 0.5325, F1_score: 0.4723
Model performance on Neutral speech (in training): 
	Precision: 0.5420, Recall: 0.5975, F1_score: 0.5684
Model performance on Sad speech (in training): 
	Precision: 0.7357, Recall: 0.4175, F1_score: 0.5327

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 250/1600 [00:10<00:54, 24.96it/s]Training:  31%|███▏      | 500/1600 [00:20<00:44, 24.88it/s]Training:  31%|███▏      | 500/1600 [00:30<00:44, 24.88it/s]Training:  42%|████▏     | 665/1600 [00:30<00:45, 20.54it/s]Training:  53%|█████▎    | 852/1600 [00:40<00:37, 19.77it/s]Training:  66%|██████▌   | 1048/1600 [00:50<00:28, 19.68it/s]Training:  79%|███████▉  | 1271/1600 [01:00<00:16, 20.55it/s]Training:  93%|█████████▎| 1494/1600 [01:11<00:05, 20.85it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 431.2556, Validation accuracy: 0.3300
Macro F1-score: 0.2759
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.9000, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.0976, Recall: 0.1600, F1_score: 0.1212
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.2600, F1_score: 0.3824
Model performance on Sad speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Epoch 50/100

Two-stage training complete.
Model best accuracy on validation set: 0.3300

Test Phase: 
Testing:   0%|          | 0/200 [00:00<?, ?it/s]Testing:   1%|          | 2/200 [00:00<00:10, 18.68it/s]Testing:   3%|▎         | 6/200 [00:00<00:07, 26.89it/s]Testing:   4%|▍         | 9/200 [00:00<00:07, 25.77it/s]Testing:   6%|▋         | 13/200 [00:00<00:06, 30.42it/s]Testing:   9%|▉         | 18/200 [00:00<00:05, 33.13it/s]Testing:  12%|█▏        | 23/200 [00:00<00:04, 38.11it/s]Testing:  14%|█▎        | 27/200 [00:00<00:05, 33.72it/s]Testing:  16%|█▌        | 32/200 [00:00<00:04, 38.03it/s]Testing:  19%|█▉        | 38/200 [00:01<00:03, 43.97it/s]Testing:  22%|██▎       | 45/200 [00:01<00:03, 48.42it/s]Testing:  26%|██▌       | 51/200 [00:01<00:03, 45.96it/s]Testing:  28%|██▊       | 56/200 [00:01<00:03, 45.22it/s]Testing:  32%|███▏      | 64/200 [00:01<00:02, 49.93it/s]Testing:  36%|███▌      | 72/200 [00:01<00:02, 56.44it/s]Testing:  39%|███▉      | 78/200 [00:01<00:02, 54.21it/s]Testing:  44%|████▎     | 87/200 [00:01<00:01, 60.28it/s]Testing:  48%|████▊     | 95/200 [00:02<00:01, 62.34it/s]Testing:  51%|█████     | 102/200 [00:02<00:01, 58.81it/s]Testing:  54%|█████▍    | 108/200 [00:02<00:01, 51.97it/s]Testing:  59%|█████▉    | 118/200 [00:02<00:01, 62.30it/s]Testing:  63%|██████▎   | 126/200 [00:02<00:01, 64.73it/s]Testing:  66%|██████▋   | 133/200 [00:02<00:01, 62.77it/s]Testing:  70%|███████   | 140/200 [00:02<00:00, 64.58it/s]Testing:  75%|███████▌  | 150/200 [00:02<00:00, 72.47it/s]Testing:  79%|███████▉  | 158/200 [00:02<00:00, 71.93it/s]Testing:  83%|████████▎ | 166/200 [00:03<00:00, 71.98it/s]Testing:  87%|████████▋ | 174/200 [00:03<00:00, 70.82it/s]Testing:  92%|█████████▏| 183/200 [00:03<00:00, 74.15it/s]Testing:  96%|█████████▌| 191/200 [00:03<00:00, 70.39it/s]Testing: 100%|█████████▉| 199/200 [00:03<00:00, 66.51it/s]                                                          /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Test loss: 432.1993, Test accuracy: 0.3300
Macro F1-score: 0.2748
Model performance on Angry speech (in test): 
	Precision: 0.4369, Recall: 0.9000, F1_score: 0.5882
Model performance on Happy speech (in test): 
	Precision: 0.1000, Recall: 0.1600, F1_score: 0.1231
Model performance on Neutral speech (in test): 
	Precision: 0.7647, Recall: 0.2600, F1_score: 0.3881
Model performance on Sad speech (in test): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000

======================= This is fold_1 on de =======================

Load dataset: 
Loading de train data: fold_1...
Preprocess de fold_1 data for de model
Loading cn eval data: fold_1...
Preprocess cn fold_1 data for de model
Loading cn test data: fold_1...
Preprocess cn fold_1 data for de model
Use de model to add lora
================== SET ALL PARAMS =====================
modified_wav2vec2.base_model.model.masked_spec_embed: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.0.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.0.layer_norm.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.0.layer_norm.bias: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.1.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.2.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.3.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.4.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.5.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.6.conv.weight: False
modified_wav2vec2.base_model.model.feature_projection.layer_norm.weight: False
modified_wav2vec2.base_model.model.feature_projection.layer_norm.bias: False
modified_wav2vec2.base_model.model.feature_projection.projection.weight: False
modified_wav2vec2.base_model.model.feature_projection.projection.bias: False
modified_wav2vec2.base_model.model.encoder.pos_conv_embed.conv.bias: False
modified_wav2vec2.base_model.model.encoder.pos_conv_embed.conv.weight_g: False
modified_wav2vec2.base_model.model.encoder.pos_conv_embed.conv.weight_v: False
modified_wav2vec2.base_model.model.encoder.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.up.bias: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.up.bias: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.up.bias: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.up.bias: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.4.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.4.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.bottleneck_adaptor.up.bias: True
normal_classifier.dense1.weight: True
normal_classifier.dense1.bias: True
normal_classifier.dense.weight: True
normal_classifier.dense.bias: True
normal_classifier.out.weight: True
normal_classifier.out.bias: True
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training loss: 470.7459, Training accuracy: 0.8994
Macro F1-score: 0.8993
Model performance on Angry speech (in training): 
	Precision: 0.9162, Recall: 0.9025, F1_score: 0.9093
Model performance on Happy speech (in training): 
	Precision: 0.8365, Recall: 0.8700, F1_score: 0.8529
Model performance on Neutral speech (in training): 
	Precision: 0.9026, Recall: 0.8575, F1_score: 0.8795
Model performance on Sad speech (in training): 
	Precision: 0.9439, Recall: 0.9675, F1_score: 0.9556

Eval Phase: 
Validation loss: 125.7075, Validation accuracy: 0.7400
Macro F1-score: 0.7353
Model performance on Angry speech (in validation): 
	Precision: 0.8448, Recall: 0.9800, F1_score: 0.9074
Model performance on Happy speech (in validation): 
	Precision: 0.7632, Recall: 0.5800, F1_score: 0.6591
Model performance on Neutral speech (in validation): 
	Precision: 0.5660, Recall: 0.6000, F1_score: 0.5825
Model performance on Sad speech (in validation): 
	Precision: 0.7843, Recall: 0.8000, F1_score: 0.7921
New best accuracy for layer 4 on epoch 1: 0.7400. Model saved.
Epoch 2/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:   8%|▊         | 126/1600 [00:10<01:57, 12.53it/s]Training:  17%|█▋        | 270/1600 [00:20<01:37, 13.63it/s]Training:  28%|██▊       | 443/1600 [00:30<01:15, 15.30it/s]Training:  39%|███▉      | 622/1600 [00:40<00:59, 16.32it/s]Training:  51%|█████     | 812/1600 [00:50<00:45, 17.25it/s]Training:  63%|██████▎   | 1002/1600 [01:00<00:33, 17.65it/s]Training:  75%|███████▍  | 1195/1600 [01:10<00:22, 18.16it/s]Training:  87%|████████▋ | 1388/1600 [01:20<00:11, 18.30it/s]Training:  99%|█████████▉| 1581/1600 [01:30<00:01, 18.59it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▎        | 200/1600 [00:10<01:10, 19.95it/s]Training:  25%|██▌       | 404/Training loss: 159.2208, Training accuracy: 0.9663
Macro F1-score: 0.9663
Model performance on Angry speech (in training): 
	Precision: 0.9623, Recall: 0.9575, F1_score: 0.9599
Model performance on Happy speech (in training): 
	Precision: 0.9429, Recall: 0.9500, F1_score: 0.9465
Model performance on Neutral speech (in training): 
	Precision: 0.9724, Recall: 0.9700, F1_score: 0.9712
Model performance on Sad speech (in training): 
	Precision: 0.9875, Recall: 0.9875, F1_score: 0.9875

Eval Phase: 
Validation loss: 187.5735, Validation accuracy: 0.6700
Macro F1-score: 0.6667
Model performance on Angry speech (in validation): 
	Precision: 0.9600, Recall: 0.4800, F1_score: 0.6400
Model performance on Happy speech (in validation): 
	Precision: 0.5574, Recall: 0.6800, F1_score: 0.6126
Model performance on Neutral speech (in validation): 
	Precision: 0.6038, Recall: 0.6400, F1_score: 0.6214
Model performance on Sad speech (in validation): 
	Precision: 0.7213, Recall: 0.8800, F1_score: 0.7928
Epoch 3/100

Training Phase:
1600 [00:20<00:59, 20.17it/s]Training:  38%|███▊      | 608/1600 [00:30<00:49, 20.07it/s]Training:  51%|█████     | 810/1600 [00:40<00:39, 20.10it/s]Training:  63%|██████▎   | 1012/1600 [00:50<00:29, 20.04it/s]Training:  76%|███████▌  | 1213/1600 [01:00<00:19, 20.05it/s]Training:  88%|████████▊ | 1414/1600 [01:10<00:09, 20.04it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 205/1600 [00:10<01:08, 20.42it/s]Training:  26%|██▌       | 410/1600 [00:20<00:59, 20.11it/s]Training:  38%|███▊      | 610/1600 [00:30<00:49, 20.02it/s]Training:  51%|█████     | 813/1600 [00:40<00:39, 20.11it/s]Training:  64%|██████▍   | 1022/1600 [00:50<00:28, 20.38it/s]Training:  77%|███████▋  | 1236/1600 Training loss: 112.0679, Training accuracy: 0.9788
Macro F1-score: 0.9787
Model performance on Angry speech (in training): 
	Precision: 0.9798, Recall: 0.9725, F1_score: 0.9762
Model performance on Happy speech (in training): 
	Precision: 0.9600, Recall: 0.9600, F1_score: 0.9600
Model performance on Neutral speech (in training): 
	Precision: 0.9777, Recall: 0.9850, F1_score: 0.9813
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Validation loss: 293.2737, Validation accuracy: 0.6800
Macro F1-score: 0.6778
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.7200, F1_score: 0.8372
Model performance on Happy speech (in validation): 
	Precision: 0.6667, Recall: 0.6000, F1_score: 0.6316
Model performance on Neutral speech (in validation): 
	Precision: 0.5111, Recall: 0.4600, F1_score: 0.4842
Model performance on Sad speech (in validation): 
	Precision: 0.6351, Recall: 0.9400, F1_score: 0.7581
Epoch 4/100

Training Phase:
Training loss: 95.0033, Training accuracy: 0.9806
Macro F1-score: 0.9806
Model performance on Angry speech (in training): 
	Precision: 0.9874, Recall: 0.9775, F1_score: 0.9824
Model performance on Happy speech (in training): 
	Precision: 0.9655, Recall: 0.9800, F1_score: 0.9727
Model performance on Neutral speech (in training): 
	Precision: 0.9848, Recall: 0.9725, F1_score: 0.9786
Model performance on Sad speech (in training): 
	Precision: 0.9851, Recall: 0.9925, F1_score: 0.9888

Eval Phase: 
[01:00<00:17, 20.70it/s]Training:  91%|█████████ | 1450/1600 [01:11<00:07, 20.47it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 190/1600 [00:10<01:14, 18.93it/s]Training:  24%|██▍       | 380/1600 [00:20<01:04, 18.94it/s]Training:  36%|███▌      | 573/1600 [00:30<00:53, 19.09it/s]Training:  48%|████▊     | 775/1600 [00:40<00:42, 19.50it/s]Training:  61%|██████    | 978/1600 [00:50<00:31, 19.77it/s]Training:  74%|███████▍  | 1181/1600 [01:00<00:21, 19.81it/s]Training:  86%|████████▋ | 1381/1600 [01:10<00:11, 19.84it/s]Training:  99%|█████████▉| 1586/1600 [01:20<00:00, 20.03it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]Validation loss: 168.9467, Validation accuracy: 0.7900
Macro F1-score: 0.7896
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.8600, F1_score: 0.9247
Model performance on Happy speech (in validation): 
	Precision: 0.7778, Recall: 0.5600, F1_score: 0.6512
Model performance on Neutral speech (in validation): 
	Precision: 0.6154, Recall: 0.8000, F1_score: 0.6957
Model performance on Sad speech (in validation): 
	Precision: 0.8393, Recall: 0.9400, F1_score: 0.8868
New best accuracy for layer 4 on epoch 4: 0.7900. Model saved.
Epoch 5/100

Training Phase:
Training loss: 85.3447, Training accuracy: 0.9781
Macro F1-score: 0.9781
Model performance on Angry speech (in training): 
	Precision: 0.9701, Recall: 0.9750, F1_score: 0.9726
Model performance on Happy speech (in training): 
	Precision: 0.9647, Recall: 0.9575, F1_score: 0.9611
Model performance on Neutral speech (in training): 
	Precision: 0.9800, Recall: 0.9825, F1_score: 0.9813
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Validation loss: 229.1794, Validation accuracy: 0.7350
Macro F1-score: 0.7288
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.7200, F1_score: 0.8372
Model performance on Happy speech (in validation): 
	Precision: 0.7193, Recall: 0.8200, F1_score: 0.7664
Model performance on Neutral speech (in validation): 
	Precision: 0.6571, Recall: 0.4600, F1_score: 0.5412
Model performance on Sad speech (in validation): 
	Precision: 0.6528, Recall: 0.9400, F1_score: 0.7705
Epoch 6/100

Training Phase:
                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 212/1600 [00:10<01:05, 21.11it/s]Training:  26%|██▋       | 424/1600 [00:20<00:56, 20.89it/s]Training:  40%|███▉      | 638/1600 [00:30<00:45, 21.08it/s]Training:  53%|█████▎    | 851/1600 [00:40<00:35, 21.07it/s]Training:  66%|██████▋   | 1062/1600 [00:51<00:26, 20.65it/s]Training:  79%|███████▉  | 1262/1600 [01:01<00:16, 20.12it/s]Training:  91%|█████████ | 1453/1600 [01:11<00:07, 19.77it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 202/1600 [00:10<01:09, 20.19it/s]Training:  26%|██▌       | 408/1600 [00:20<00:58, 20.37it/s]Training:  38%|███▊      | 613/1600 [00:30<00:50, 19.Training loss: 56.0102, Training accuracy: 0.9875
Macro F1-score: 0.9875
Model performance on Angry speech (in training): 
	Precision: 0.9900, Recall: 0.9875, F1_score: 0.9887
Model performance on Happy speech (in training): 
	Precision: 0.9850, Recall: 0.9850, F1_score: 0.9850
Model performance on Neutral speech (in training): 
	Precision: 0.9875, Recall: 0.9850, F1_score: 0.9862
Model performance on Sad speech (in training): 
	Precision: 0.9876, Recall: 0.9925, F1_score: 0.9900

Eval Phase: 
Validation loss: 525.0944, Validation accuracy: 0.5900
Macro F1-score: 0.5850
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.5800, F1_score: 0.7342
Model performance on Happy speech (in validation): 
	Precision: 0.5227, Recall: 0.4600, F1_score: 0.4894
Model performance on Neutral speech (in validation): 
	Precision: 0.3958, Recall: 0.3800, F1_score: 0.3878
Model performance on Sad speech (in validation): 
	Precision: 0.5949, Recall: 0.9400, F1_score: 0.7287
Epoch 7/100

Training Phase:
66it/s]Training:  50%|█████     | 802/1600 [00:41<00:41, 19.25it/s]Training:  62%|██████▏   | 997/1600 [00:51<00:31, 19.31it/s]Training:  75%|███████▌  | 1204/1600 [01:01<00:20, 19.77it/s]Training:  88%|████████▊ | 1411/1600 [01:11<00:09, 19.84it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 203/1600 [00:10<01:08, 20.26it/s]Training:  25%|██▌       | 406/1600 [00:20<00:59, 20.08it/s]Training:  38%|███▊      | 606/1600 [00:30<00:49, 20.00it/s]Training:  50%|█████     | 806/1600 [00:40<00:40, 19.76it/s]Training:  63%|██████▎   | 1007/1600 [00:50<00:29, 19.87it/s]Training:  76%|███████▌  | 1210/1600 [01:00<00:19, 20.00it/s]Training:  89%|████████▊ | 1418/1600 [01:10<00:08Training loss: 107.2128, Training accuracy: 0.9856
Macro F1-score: 0.9856
Model performance on Angry speech (in training): 
	Precision: 0.9826, Recall: 0.9875, F1_score: 0.9850
Model performance on Happy speech (in training): 
	Precision: 0.9849, Recall: 0.9800, F1_score: 0.9825
Model performance on Neutral speech (in training): 
	Precision: 0.9802, Recall: 0.9925, F1_score: 0.9863
Model performance on Sad speech (in training): 
	Precision: 0.9949, Recall: 0.9825, F1_score: 0.9887

Eval Phase: 
Validation loss: 295.4642, Validation accuracy: 0.6900
Macro F1-score: 0.6709
Model performance on Angry speech (in validation): 
	Precision: 0.9608, Recall: 0.9800, F1_score: 0.9703
Model performance on Happy speech (in validation): 
	Precision: 0.9615, Recall: 0.5000, F1_score: 0.6579
Model performance on Neutral speech (in validation): 
	Precision: 0.3889, Recall: 0.2800, F1_score: 0.3256
Model performance on Sad speech (in validation): 
	Precision: 0.5747, Recall: 1.0000, F1_score: 0.7299
Epoch 8/100

Training Phase:
Training loss: 51.2421, Training accuracy: 0.9881
Macro F1-score: 0.9881
Model performance on Angry speech (in training): 
	Precision: 0.9899, Recall: 0.9825, F1_score: 0.9862
Model performance on Happy speech (in training): 
	Precision: 0.9752, Recall: 0.9825, F1_score: 0.9788
Model performance on Neutral speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Validation loss: 375.8458, Validation accuracy: 0.6650
Macro F1-score: 0.6490
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.7200, F1_score: 0.8372
Model performance on Happy speech (in validation): 
	Precision: 0.6875, Recall: 0.6600, F1_score: 0.6735
Model performance on Neutral speech (in validation): 
	Precision: 0.4667, Recall: 0.2800, F1_score: 0.3500
Model performance on Sad speech (in validation): 
	Precision: 0.5814, Recall: 1.0000, F1_score: 0.7353
Epoch 9/100

Training Phase:
, 20.23it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 202/1600 [00:10<01:09, 20.18it/s]Training:  25%|██▌       | 404/1600 [00:20<01:00, 19.61it/s]Training:  38%|███▊      | 601/1600 [00:30<00:50, 19.61it/s]Training:  50%|█████     | 803/1600 [00:40<00:40, 19.81it/s]Training:  63%|██████▎   | 1009/1600 [00:50<00:29, 20.06it/s]Training:  77%|███████▋  | 1227/1600 [01:00<00:18, 20.63it/s]Training:  90%|█████████ | 1445/1600 [01:10<00:07, 20.82it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 208/1600 [00:10<01:07, 20.71it/s]TrTraining loss: 33.0878, Training accuracy: 0.9925
Macro F1-score: 0.9925
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912
Model performance on Happy speech (in training): 
	Precision: 0.9900, Recall: 0.9875, F1_score: 0.9887
Model performance on Neutral speech (in training): 
	Precision: 0.9901, Recall: 0.9975, F1_score: 0.9938
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962

Eval Phase: 
Validation loss: 331.5973, Validation accuracy: 0.6900
Macro F1-score: 0.6801
Model performance on Angry speech (in validation): 
	Precision: 0.9524, Recall: 0.8000, F1_score: 0.8696
Model performance on Happy speech (in validation): 
	Precision: 0.7317, Recall: 0.6000, F1_score: 0.6593
Model performance on Neutral speech (in validation): 
	Precision: 0.5000, Recall: 0.3800, F1_score: 0.4318
Model performance on Sad speech (in validation): 
	Precision: 0.6203, Recall: 0.9800, F1_score: 0.7597
Epoch 10/100

Training Phase:
aining:  26%|██▌       | 419/1600 [00:20<00:56, 20.90it/s]Training:  39%|███▉      | 630/1600 [00:30<00:46, 20.68it/s]Training:  52%|█████▏    | 839/1600 [00:40<00:36, 20.74it/s]Training:  66%|██████▌   | 1049/1600 [00:50<00:26, 20.79it/s]Training:  79%|███████▊  | 1258/1600 [01:00<00:16, 20.56it/s]Training:  91%|█████████▏| 1460/1600 [01:11<00:06, 20.29it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 212/1600 [00:10<01:05, 21.20it/s]Training:  27%|██▋       | 426/1600 [00:20<00:55, 21.31it/s]Training:  40%|████      | 640/1600 [00:30<00:46, 20.86it/s]Training:  53%|█████▎    | 844/1600 [00:40<00:36, 20.51it/s]Training:  65%|██████▌   | 1046/1600 [00:50<00:27, 20.38it/s]Training:  7Training loss: 24.7826, Training accuracy: 0.9919
Macro F1-score: 0.9919
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912
Model performance on Happy speech (in training): 
	Precision: 0.9850, Recall: 0.9875, F1_score: 0.9863
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
New best accuracy for layer 4 on epoch 10: 0.8250. Model saved.
Epoch 11/100

Training Phase:
Training loss: 71.6604, Training accuracy: 0.9881
Macro F1-score: 0.9881
Model performance on Angry speech (in training): 
	Precision: 0.9900, Recall: 0.9875, F1_score: 0.9887
Model performance on Happy speech (in training): 
	Precision: 0.9800, Recall: 0.9825, F1_score: 0.9813
Model performance on Neutral speech (in training): 
	Precision: 0.9875, Recall: 0.9875, F1_score: 0.9875
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950

Eval Phase: 
8%|███████▊  | 1248/1600 [01:00<00:17, 20.31it/s]Training:  91%|█████████ | 1451/1600 [01:10<00:07, 20.28it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 196/1600 [00:10<01:11, 19.59it/s]Training:  24%|██▍       | 392/1600 [00:20<01:02, 19.46it/s]Training:  37%|███▋      | 591/1600 [00:30<00:51, 19.63it/s]Training:  50%|████▉     | 793/1600 [00:40<00:40, 19.83it/s]Training:  62%|██████▏   | 995/1600 [00:50<00:30, 19.90it/s]Training:  75%|███████▍  | 1196/1600 [01:00<00:20, 19.87it/s]Training:  87%|████████▋ | 1395/1600 [01:10<00:10, 19.81it/s]Training: 100%|█████████▉| 1597/1600 [01:20<00:00, 19.90it/s]                                                             EvaluatinValidation loss: 280.7895, Validation accuracy: 0.7200
Macro F1-score: 0.6973
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.7857, Recall: 0.6600, F1_score: 0.7174
Model performance on Neutral speech (in validation): 
	Precision: 0.5000, Recall: 0.2800, F1_score: 0.3590
Model performance on Sad speech (in validation): 
	Precision: 0.6173, Recall: 1.0000, F1_score: 0.7634
Validation loss does not decrease for 10 epochs. End training.
Epoch 12/100

Entering 2ND training phase: change training data from de to CN
Loading cn train data: fold_1...
Preprocess cn fold_1 data for de model
Reload model and reset eval loss

Training Phase:
Training loss: 5859.5672, Training accuracy: 0.4425
Macro F1-score: 0.4387
Model performance on Angry speech (in training): 
	Precision: 0.4614, Recall: 0.7025, F1_score: 0.5570
Model performance on Happy speech (in training): 
	Precision: 0.2788, Recall: 0.4175, F1_score: 0.3343
Model performance on Neutral speech (in training): 
	Precision: 0.6118, Recall: 0.3900, F1_score: 0.4763
Model performance on Sad speech (in training): 
	Precision: 0.7591, Recall: 0.2600, F1_score: 0.3873

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 13/100

Training Phase:
g:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  10%|▉         | 154/1600 [00:10<01:34, 15.36it/s]Training:  21%|██        | 339/1600 [00:20<01:13, 17.16it/s]Training:  34%|███▍      | 541/1600 [00:30<00:57, 18.54it/s]Training:  47%|████▋     | 752/1600 [00:40<00:43, 19.53it/s]Training:  61%|██████    | 978/1600 [00:50<00:30, 20.61it/s]Training:  75%|███████▌  | 1207/1600 [01:00<00:18, 21.36it/s]Training:  90%|█████████ | 1442/1600 [01:10<00:07, 22.03it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 225/1600 [00:10<01:01, 22.48it/s]Training:  28%|██▊       | 451/1600 [00:20<00:51, 22.50it/s]Training:  42%|████Training loss: 5825.7147, Training accuracy: 0.4350
Macro F1-score: 0.4289
Model performance on Angry speech (in training): 
	Precision: 0.4592, Recall: 0.7025, F1_score: 0.5553
Model performance on Happy speech (in training): 
	Precision: 0.2724, Recall: 0.4025, F1_score: 0.3249
Model performance on Neutral speech (in training): 
	Precision: 0.5911, Recall: 0.3975, F1_score: 0.4753
Model performance on Sad speech (in training): 
	Precision: 0.7422, Recall: 0.2375, F1_score: 0.3598

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 14/100

Training Phase:
Training loss: 5859.3128, Training accuracy: 0.4375
Macro F1-score: 0.4311
Model performance on Angry speech (in training): 
	Precision: 0.4571, Recall: 0.7200, F1_score: 0.5592
Model performance on Happy speech (in training): 
	Precision: 0.2680, Recall: 0.3825, F1_score: 0.3151
Model performance on Neutral speech (in training): 
	Precision: 0.5891, Recall: 0.4050, F1_score: 0.4800
Model performance on Sad speech (in training): 
	Precision: 0.7823, Recall: 0.2425, F1_score: 0.3702

Eval Phase: 
▏     | 677/1600 [00:30<00:41, 22.42it/s]Training:  57%|█████▋    | 914/1600 [00:40<00:29, 22.91it/s]Training:  72%|███████▏  | 1151/1600 [00:50<00:19, 23.04it/s]Training:  86%|████████▋ | 1384/1600 [01:00<00:09, 22.82it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 223/1600 [00:10<01:01, 22.24it/s]Training:  28%|██▊       | 453/1600 [00:20<00:50, 22.65it/s]Training:  44%|████▎     | 696/1600 [00:30<00:38, 23.37it/s]Training:  59%|█████▉    | 942/1600 [00:40<00:27, 23.83it/s]Training:  74%|███████▍  | 1188/1600 [00:50<00:17, 23.97it/s]Training:  90%|████████▉ | 1432/1600 [01:00<00:06, 24.10it/s]                                                             Evaluating:   0%|          | 0/20Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 15/100

Training Phase:
Training loss: 5881.9509, Training accuracy: 0.4356
Macro F1-score: 0.4288
Model performance on Angry speech (in training): 
	Precision: 0.4593, Recall: 0.7050, F1_score: 0.5562
Model performance on Happy speech (in training): 
	Precision: 0.2786, Recall: 0.4075, F1_score: 0.3310
Model performance on Neutral speech (in training): 
	Precision: 0.5720, Recall: 0.3875, F1_score: 0.4620
Model performance on Sad speech (in training): 
	Precision: 0.7462, Recall: 0.2425, F1_score: 0.3660

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 16/100

Training Phase:
0 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 239/1600 [00:10<00:57, 23.81it/s]Training:  30%|███       | 480/1600 [00:20<00:46, 23.96it/s]Training:  46%|████▌     | 734/1600 [00:30<00:35, 24.59it/s]Training:  62%|██████▏   | 988/1600 [00:40<00:25, 24.12it/s]Training:  76%|███████▋  | 1223/1600 [00:51<00:15, 23.60it/s]Training:  91%|█████████ | 1451/1600 [01:01<00:06, 23.33it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 227/1600 [00:10<01:00, 22.62it/s]Training:  28%|██▊       | 454/1600 [00:20<00:50, 22.58it/s]Training:  43%|████▎     | 682/1600 [00:30<00:40, 22.67it/s]Training:  57%|█████▋    | 915/Training loss: 5846.3370, Training accuracy: 0.4419
Macro F1-score: 0.4359
Model performance on Angry speech (in training): 
	Precision: 0.4631, Recall: 0.7050, F1_score: 0.5590
Model performance on Happy speech (in training): 
	Precision: 0.2782, Recall: 0.4075, F1_score: 0.3306
Model performance on Neutral speech (in training): 
	Precision: 0.5887, Recall: 0.4150, F1_score: 0.4868
Model performance on Sad speech (in training): 
	Precision: 0.7805, Recall: 0.2400, F1_score: 0.3671

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 17/100

Training Phase:
Training loss: 5907.9166, Training accuracy: 0.4381
Macro F1-score: 0.4334
Model performance on Angry speech (in training): 
	Precision: 0.4629, Recall: 0.7025, F1_score: 0.5581
Model performance on Happy speech (in training): 
	Precision: 0.2729, Recall: 0.4100, F1_score: 0.3277
Model performance on Neutral speech (in training): 
	Precision: 0.5970, Recall: 0.3925, F1_score: 0.4736
Model performance on Sad speech (in training): 
	Precision: 0.7674, Recall: 0.2475, F1_score: 0.3743

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 18/100

Training Phase:
1600 [00:40<00:29, 22.89it/s]Training:  72%|███████▏  | 1155/1600 [00:50<00:19, 23.26it/s]Training:  88%|████████▊ | 1400/1600 [01:00<00:08, 23.66it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 234/1600 [00:10<00:58, 23.31it/s]Training:  30%|██▉       | 478/1600 [00:20<00:46, 23.94it/s]Training:  45%|████▌     | 724/1600 [00:30<00:36, 24.22it/s]Training:  61%|██████    | 970/1600 [00:40<00:25, 24.29it/s]Training:  76%|███████▌  | 1214/1600 [00:50<00:15, 24.28it/s]Training:  91%|█████████ | 1457/1600 [01:00<00:05, 24.27it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|Training loss: 5855.8095, Training accuracy: 0.4369
Macro F1-score: 0.4313
Model performance on Angry speech (in training): 
	Precision: 0.4573, Recall: 0.7100, F1_score: 0.5563
Model performance on Happy speech (in training): 
	Precision: 0.2682, Recall: 0.3875, F1_score: 0.3170
Model performance on Neutral speech (in training): 
	Precision: 0.5906, Recall: 0.4075, F1_score: 0.4822
Model performance on Sad speech (in training): 
	Precision: 0.7760, Recall: 0.2425, F1_score: 0.3695

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 19/100

Training Phase:
          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 253/1600 [00:10<00:53, 25.24it/s]Training:  32%|███▏      | 516/1600 [00:20<00:41, 25.83it/s]Training:  49%|████▊     | 779/1600 [00:30<00:32, 25.38it/s]Training:  65%|██████▍   | 1035/1600 [00:40<00:22, 25.43it/s]Training:  81%|████████  | 1291/1600 [00:50<00:12, 25.42it/s]Training:  97%|█████████▋| 1550/1600 [01:00<00:01, 25.57it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 242/1600 [00:10<00:56, 24.18it/s]Training:  31%|███       | 489/1600 [00:20<00:45, 24.47it/s]Training:  46%|████▌     | 736/1600 [00:30<00:35, 24.36it/s]Training:  61%|██████▏   | 983/1600 [00:40<00:25, 24.47it/s]Training:  77%|███████▋  | 1230/16Training loss: 5867.3435, Training accuracy: 0.4375
Macro F1-score: 0.4340
Model performance on Angry speech (in training): 
	Precision: 0.4584, Recall: 0.7025, F1_score: 0.5548
Model performance on Happy speech (in training): 
	Precision: 0.2673, Recall: 0.3950, F1_score: 0.3189
Model performance on Neutral speech (in training): 
	Precision: 0.6000, Recall: 0.3975, F1_score: 0.4782
Model performance on Sad speech (in training): 
	Precision: 0.7786, Recall: 0.2550, F1_score: 0.3842

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 20/100

Training Phase:
Training loss: 5929.8055, Training accuracy: 0.4338
Macro F1-score: 0.4272
Model performance on Angry speech (in training): 
	Precision: 0.4636, Recall: 0.7000, F1_score: 0.5578
Model performance on Happy speech (in training): 
	Precision: 0.2723, Recall: 0.4050, F1_score: 0.3256
Model performance on Neutral speech (in training): 
	Precision: 0.5745, Recall: 0.3950, F1_score: 0.4681
Model performance on Sad speech (in training): 
	Precision: 0.7460, Recall: 0.2350, F1_score: 0.3574

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 21/100

Training Phase:
00 [00:50<00:15, 24.44it/s]Training:  92%|█████████▏| 1477/1600 [01:00<00:05, 24.52it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 245/1600 [00:10<00:55, 24.44it/s]Training:  31%|███       | 492/1600 [00:20<00:45, 24.54it/s]Training:  47%|████▋     | 746/1600 [00:30<00:34, 24.93it/s]Training:  62%|██████▎   | 1000/1600 [00:40<00:23, 25.05it/s]Training:  79%|███████▉  | 1265/1600 [00:50<00:13, 25.56it/s]Training:  96%|█████████▌| 1530/1600 [01:00<00:02, 25.65it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▋        | 263/16Training loss: 5901.2511, Training accuracy: 0.4356
Macro F1-score: 0.4317
Model performance on Angry speech (in training): 
	Precision: 0.4566, Recall: 0.6975, F1_score: 0.5519
Model performance on Happy speech (in training): 
	Precision: 0.2699, Recall: 0.3975, F1_score: 0.3215
Model performance on Neutral speech (in training): 
	Precision: 0.5992, Recall: 0.3925, F1_score: 0.4743
Model performance on Sad speech (in training): 
	Precision: 0.7391, Recall: 0.2550, F1_score: 0.3792

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 22/100

Training Phase:
00 [00:10<00:50, 26.23it/s]Training:  33%|███▎      | 527/1600 [00:20<00:40, 26.31it/s]Training:  49%|████▉     | 791/1600 [00:30<00:30, 26.32it/s]Training:  66%|██████▌   | 1055/1600 [00:40<00:20, 26.20it/s]Training:  82%|████████▏ | 1316/1600 [00:50<00:11, 25.46it/s]Training:  99%|█████████▉| 1580/1600 [01:01<00:00, 25.76it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▋        | 262/1600 [00:10<00:51, 26.11it/s]Training:  33%|███▎      | 524/1600 [00:20<00:41, 25.68it/s]Training:  49%|████▊     | 778/1600 [00:30<00:33, 24.89it/s]Training:  64%|██████▎   | 1018/1600 [00:41<00:23, 24.27it/s]Training:  78%|███████▊  | 1256/1600 [00:51<00:14, 24.08it/s]Training:  94%|████████Training loss: 5870.4281, Training accuracy: 0.4381
Macro F1-score: 0.4351
Model performance on Angry speech (in training): 
	Precision: 0.4556, Recall: 0.6925, F1_score: 0.5496
Model performance on Happy speech (in training): 
	Precision: 0.2764, Recall: 0.4125, F1_score: 0.3310
Model performance on Neutral speech (in training): 
	Precision: 0.5953, Recall: 0.3825, F1_score: 0.4658
Model performance on Sad speech (in training): 
	Precision: 0.7681, Recall: 0.2650, F1_score: 0.3941

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 23/100

Training Phase:
Training loss: 5910.5487, Training accuracy: 0.4344
Macro F1-score: 0.4303
Model performance on Angry speech (in training): 
	Precision: 0.4590, Recall: 0.7000, F1_score: 0.5545
Model performance on Happy speech (in training): 
	Precision: 0.2671, Recall: 0.4000, F1_score: 0.3203
Model performance on Neutral speech (in training): 
	Precision: 0.5916, Recall: 0.3875, F1_score: 0.4683
Model performance on Sad speech (in training): 
	Precision: 0.7752, Recall: 0.2500, F1_score: 0.3781

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 24/100

Training Phase:
▍| 1502/1600 [01:01<00:04, 24.25it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 250/1600 [00:10<00:54, 24.89it/s]Training:  31%|███       | 499/1600 [00:20<00:45, 24.36it/s]Training:  46%|████▋     | 743/1600 [00:30<00:35, 24.37it/s]Training:  63%|██████▎   | 1003/1600 [00:40<00:23, 25.00it/s]Training:  79%|███████▉  | 1263/1600 [00:50<00:13, 25.05it/s]Training:  95%|█████████▌| 1522/1600 [01:00<00:03, 25.32it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 241/1600 [00:10<00:56, 24.04it/s]Training:  30%|███       | 482/160Training loss: 5928.3940, Training accuracy: 0.4406
Macro F1-score: 0.4355
Model performance on Angry speech (in training): 
	Precision: 0.4658, Recall: 0.7150, F1_score: 0.5641
Model performance on Happy speech (in training): 
	Precision: 0.2698, Recall: 0.3925, F1_score: 0.3198
Model performance on Neutral speech (in training): 
	Precision: 0.5956, Recall: 0.4050, F1_score: 0.4821
Model performance on Sad speech (in training): 
	Precision: 0.7576, Recall: 0.2500, F1_score: 0.3759

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 25/100

Training Phase:
0 [00:20<00:47, 23.63it/s]Training:  45%|████▍     | 717/1600 [00:30<00:37, 23.54it/s]Training:  45%|████▍     | 717/1600 [00:41<00:37, 23.54it/s]Training:  58%|█████▊    | 935/1600 [00:41<00:30, 22.13it/s]Training:  73%|███████▎  | 1175/1600 [00:51<00:18, 22.77it/s]Training:  89%|████████▉ | 1431/1600 [01:01<00:07, 23.70it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 233/1600 [00:10<00:58, 23.23it/s]Training:  30%|██▉       | 473/1600 [00:20<00:47, 23.66it/s]Training:  45%|████▍     | 713/1600 [00:30<00:38, 23.27it/s]Training:  59%|█████▉    | 943/1600 [00:40<00:28, 23.16it/s]Training:  73%|███████▎  | 1173/1600 [00:50<00:18, 22.99it/s]Training:  73%|███████▎  | 1173/160Training loss: 5818.8849, Training accuracy: 0.4387
Macro F1-score: 0.4343
Model performance on Angry speech (in training): 
	Precision: 0.4650, Recall: 0.6975, F1_score: 0.5580
Model performance on Happy speech (in training): 
	Precision: 0.2715, Recall: 0.4100, F1_score: 0.3267
Model performance on Neutral speech (in training): 
	Precision: 0.5978, Recall: 0.4050, F1_score: 0.4829
Model performance on Sad speech (in training): 
	Precision: 0.7760, Recall: 0.2425, F1_score: 0.3695

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 26/100

Training Phase:
Training loss: 5908.6810, Training accuracy: 0.4406
Macro F1-score: 0.4351
Model performance on Angry speech (in training): 
	Precision: 0.4629, Recall: 0.7025, F1_score: 0.5581
Model performance on Happy speech (in training): 
	Precision: 0.2744, Recall: 0.4075, F1_score: 0.3280
Model performance on Neutral speech (in training): 
	Precision: 0.6014, Recall: 0.4150, F1_score: 0.4911
Model performance on Sad speech (in training): 
	Precision: 0.7724, Recall: 0.2375, F1_score: 0.3633

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 27/100

Training Phase:
0 [01:01<00:18, 22.99it/s]Training:  87%|████████▋ | 1398/1600 [01:01<00:08, 22.54it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 207/1600 [00:10<01:07, 20.66it/s]Training:  26%|██▌       | 414/1600 [00:22<01:05, 18.18it/s]Training:  38%|███▊      | 604/1600 [00:32<00:53, 18.52it/s]Training:  51%|█████     | 812/1600 [00:42<00:40, 19.36it/s]Training:  64%|██████▍   | 1031/1600 [00:52<00:28, 20.23it/s]Training:  79%|███████▉  | 1268/1600 [01:02<00:15, 21.38it/s]Training:  94%|█████████▍| 1509/1600 [01:12<00:04, 22.24it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|       Training loss: 5911.3818, Training accuracy: 0.4375
Macro F1-score: 0.4304
Model performance on Angry speech (in training): 
	Precision: 0.4635, Recall: 0.7150, F1_score: 0.5624
Model performance on Happy speech (in training): 
	Precision: 0.2749, Recall: 0.4000, F1_score: 0.3259
Model performance on Neutral speech (in training): 
	Precision: 0.5766, Recall: 0.3950, F1_score: 0.4688
Model performance on Sad speech (in training): 
	Precision: 0.7559, Recall: 0.2400, F1_score: 0.3643

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 28/100

Training Phase:
   | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 242/1600 [00:10<00:56, 24.20it/s]Training:  31%|███       | 490/1600 [00:20<00:45, 24.53it/s]Training:  31%|███       | 490/1600 [00:31<00:45, 24.53it/s]Training:  46%|████▌     | 734/1600 [00:31<00:37, 23.28it/s]Training:  60%|█████▉    | 954/1600 [00:41<00:28, 22.58it/s]Training:  73%|███████▎  | 1174/1600 [00:51<00:19, 22.36it/s]Training:  87%|████████▋ | 1395/1600 [01:01<00:09, 22.27it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 238/1600 [00:10<00:57, 23.77it/s]Training:  30%|██▉       | 476/1600 [00:20<00:47, 23.45it/s]Training:  44%|████▍     | 709/1600 [00:30<00:38, 23.01it/s]Training:  58%|█████▊    | 935/1600 [00:40<00:29, 22.76it/s]Training loss: 5979.9146, Training accuracy: 0.4319
Macro F1-score: 0.4264
Model performance on Angry speech (in training): 
	Precision: 0.4547, Recall: 0.7025, F1_score: 0.5521
Model performance on Happy speech (in training): 
	Precision: 0.2676, Recall: 0.3900, F1_score: 0.3174
Model performance on Neutral speech (in training): 
	Precision: 0.5821, Recall: 0.3900, F1_score: 0.4671
Model performance on Sad speech (in training): 
	Precision: 0.7481, Recall: 0.2450, F1_score: 0.3691

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 29/100

Training Phase:
Training loss: 5830.8267, Training accuracy: 0.4406
Macro F1-score: 0.4343
Model performance on Angry speech (in training): 
	Precision: 0.4644, Recall: 0.7175, F1_score: 0.5639
Model performance on Happy speech (in training): 
	Precision: 0.2749, Recall: 0.4000, F1_score: 0.3259
Model performance on Neutral speech (in training): 
	Precision: 0.5861, Recall: 0.4000, F1_score: 0.4755
Model performance on Sad speech (in training): 
	Precision: 0.7717, Recall: 0.2450, F1_score: 0.3719

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 30/100

Training Phase:
Training:  72%|███████▏  | 1159/1600 [00:50<00:19, 22.59it/s]Training:  87%|████████▋ | 1386/1600 [01:00<00:09, 22.62it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 221/1600 [00:10<01:02, 22.06it/s]Training:  28%|██▊       | 447/1600 [00:20<00:51, 22.37it/s]Training:  42%|████▏     | 673/1600 [00:30<00:41, 22.22it/s]Training:  57%|█████▋    | 906/1600 [00:40<00:30, 22.64it/s]Training:  72%|███████▏  | 1154/1600 [00:50<00:19, 23.40it/s]Training:  88%|████████▊ | 1402/1600 [01:00<00:08, 23.79it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, Training loss: 5918.3064, Training accuracy: 0.4363
Macro F1-score: 0.4295
Model performance on Angry speech (in training): 
	Precision: 0.4693, Recall: 0.7075, F1_score: 0.5643
Model performance on Happy speech (in training): 
	Precision: 0.2735, Recall: 0.4075, F1_score: 0.3273
Model performance on Neutral speech (in training): 
	Precision: 0.5751, Recall: 0.3925, F1_score: 0.4666
Model performance on Sad speech (in training): 
	Precision: 0.7422, Recall: 0.2375, F1_score: 0.3598

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 31/100

Training Phase:
?it/s]Training:  16%|█▋        | 263/1600 [00:10<00:50, 26.22it/s]Training:  33%|███▎      | 526/1600 [00:20<00:41, 26.16it/s]Training:  49%|████▉     | 788/1600 [00:30<00:32, 25.34it/s]Training:  65%|██████▍   | 1033/1600 [00:40<00:22, 24.87it/s]Training:  80%|███████▉  | 1275/1600 [00:51<00:13, 24.02it/s]Training:  94%|█████████▍| 1502/1600 [01:01<00:04, 23.58it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 242/1600 [00:10<00:56, 24.18it/s]Training:  30%|███       | 484/1600 [00:20<00:46, 23.88it/s]Training:  45%|████▌     | 721/1600 [00:30<00:37, 23.35it/s]Training:  59%|█████▉    | 949/1600 [00:40<00:28, 23.10it/s]Training:  74%|███████▎  | 1177/1600 [00:50<00:18, 22.99it/s]TraTraining loss: 5908.5114, Training accuracy: 0.4381
Macro F1-score: 0.4318
Model performance on Angry speech (in training): 
	Precision: 0.4598, Recall: 0.7150, F1_score: 0.5597
Model performance on Happy speech (in training): 
	Precision: 0.2734, Recall: 0.3950, F1_score: 0.3231
Model performance on Neutral speech (in training): 
	Precision: 0.5846, Recall: 0.3975, F1_score: 0.4732
Model performance on Sad speech (in training): 
	Precision: 0.7656, Recall: 0.2450, F1_score: 0.3712

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 32/100

Training Phase:
Training loss: 5926.4722, Training accuracy: 0.4350
Macro F1-score: 0.4315
Model performance on Angry speech (in training): 
	Precision: 0.4542, Recall: 0.6950, F1_score: 0.5494
Model performance on Happy speech (in training): 
	Precision: 0.2670, Recall: 0.3925, F1_score: 0.3178
Model performance on Neutral speech (in training): 
	Precision: 0.5948, Recall: 0.4000, F1_score: 0.4783
Model performance on Sad speech (in training): 
	Precision: 0.7710, Recall: 0.2525, F1_score: 0.3804

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 33/100

Training Phase:
ining:  88%|████████▊ | 1406/1600 [01:00<00:08, 22.95it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 240/1600 [00:10<00:56, 23.96it/s]Training:  30%|███       | 483/1600 [00:20<00:46, 24.14it/s]Training:  45%|████▌     | 726/1600 [00:30<00:36, 24.18it/s]Training:  61%|██████    | 973/1600 [00:40<00:25, 24.37it/s]Training:  76%|███████▋  | 1220/1600 [00:50<00:15, 24.38it/s]Training:  92%|█████████▏| 1465/1600 [01:00<00:05, 24.40it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 265/1600 [00:10<00:50, 26.43it/s]TrainingTraining loss: 5910.0552, Training accuracy: 0.4450
Macro F1-score: 0.4400
Model performance on Angry speech (in training): 
	Precision: 0.4666, Recall: 0.7150, F1_score: 0.5647
Model performance on Happy speech (in training): 
	Precision: 0.2772, Recall: 0.4075, F1_score: 0.3300
Model performance on Neutral speech (in training): 
	Precision: 0.6045, Recall: 0.4050, F1_score: 0.4850
Model performance on Sad speech (in training): 
	Precision: 0.7710, Recall: 0.2525, F1_score: 0.3804

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 34/100

Training Phase:
:  33%|███▎      | 530/1600 [00:20<00:40, 26.14it/s]Training:  50%|████▉     | 795/1600 [00:30<00:30, 26.27it/s]Training:  66%|██████▋   | 1060/1600 [00:40<00:20, 26.25it/s]Training:  83%|████████▎ | 1323/1600 [00:51<00:11, 24.84it/s]Training:  99%|█████████▊| 1577/1600 [01:01<00:00, 25.01it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 245/1600 [00:10<00:55, 24.48it/s]Training:  31%|███       | 490/1600 [00:20<00:45, 24.16it/s]Training:  46%|████▌     | 731/1600 [00:30<00:36, 24.10it/s]Training:  61%|██████    | 972/1600 [00:40<00:26, 24.10it/s]Training:  76%|███████▌  | 1215/1600 [00:50<00:15, 24.14it/s]Training:  91%|█████████ | 1458/1600 [01:01<00:06, 23.61it/s] Training loss: 5922.4359, Training accuracy: 0.4406
Macro F1-score: 0.4381
Model performance on Angry speech (in training): 
	Precision: 0.4559, Recall: 0.7100, F1_score: 0.5552
Model performance on Happy speech (in training): 
	Precision: 0.2671, Recall: 0.3900, F1_score: 0.3171
Model performance on Neutral speech (in training): 
	Precision: 0.6172, Recall: 0.3950, F1_score: 0.4817
Model performance on Sad speech (in training): 
	Precision: 0.7810, Recall: 0.2675, F1_score: 0.3985

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 35/100

Training Phase:
Training loss: 5855.6985, Training accuracy: 0.4412
Macro F1-score: 0.4361
Model performance on Angry speech (in training): 
	Precision: 0.4655, Recall: 0.7075, F1_score: 0.5615
Model performance on Happy speech (in training): 
	Precision: 0.2720, Recall: 0.4025, F1_score: 0.3246
Model performance on Neutral speech (in training): 
	Precision: 0.6022, Recall: 0.4125, F1_score: 0.4896
Model performance on Sad speech (in training): 
	Precision: 0.7698, Recall: 0.2425, F1_score: 0.3688

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 36/100

Training Phase:
                                                            Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 235/1600 [00:10<00:58, 23.46it/s]Training:  30%|███       | 481/1600 [00:20<00:46, 24.13it/s]Training:  45%|████▌     | 727/1600 [00:30<00:36, 24.23it/s]Training:  62%|██████▏   | 989/1600 [00:40<00:24, 24.98it/s]Training:  78%|███████▊  | 1251/1600 [00:50<00:14, 24.73it/s]Training:  93%|█████████▎| 1495/1600 [01:01<00:04, 24.45it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 230/1600 [00:10<00:59, 22.90it/s]Training:  30%|██▉       | 473/1600 [00:20<00:47, 23.68it/s]Training:  45%|Training loss: 5881.8840, Training accuracy: 0.4344
Macro F1-score: 0.4287
Model performance on Angry speech (in training): 
	Precision: 0.4592, Recall: 0.7025, F1_score: 0.5553
Model performance on Happy speech (in training): 
	Precision: 0.2712, Recall: 0.4000, F1_score: 0.3232
Model performance on Neutral speech (in training): 
	Precision: 0.5836, Recall: 0.3925, F1_score: 0.4694
Model performance on Sad speech (in training): 
	Precision: 0.7519, Recall: 0.2425, F1_score: 0.3667

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 37/100

Training Phase:
Training loss: 5925.1919, Training accuracy: 0.4406
Macro F1-score: 0.4336
Model performance on Angry speech (in training): 
	Precision: 0.4666, Recall: 0.7150, F1_score: 0.5647
Model performance on Happy speech (in training): 
	Precision: 0.2799, Recall: 0.4100, F1_score: 0.3327
Model performance on Neutral speech (in training): 
	Precision: 0.5809, Recall: 0.3950, F1_score: 0.4702
Model performance on Sad speech (in training): 
	Precision: 0.7519, Recall: 0.2425, F1_score: 0.3667

Eval Phase: 
███▍     | 716/1600 [00:30<00:37, 23.68it/s]Training:  60%|██████    | 962/1600 [00:40<00:26, 24.01it/s]Training:  76%|███████▌  | 1208/1600 [00:50<00:16, 23.92it/s]Training:  90%|█████████ | 1448/1600 [01:00<00:06, 23.95it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 248/1600 [00:10<00:54, 24.72it/s]Training:  32%|███▏      | 509/1600 [00:20<00:42, 25.47it/s]Training:  48%|████▊     | 769/1600 [00:30<00:32, 25.27it/s]Training:  64%|██████▍   | 1020/1600 [00:40<00:23, 24.70it/s]Training:  80%|███████▉  | 1275/1600 [00:50<00:13, 24.98it/s]Training:  96%|█████████▌| 1537/1600 [01:01<00:02, 25.36it/s]                                                             Evaluating:   0%Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 38/100

Training Phase:
Training loss: 5920.7110, Training accuracy: 0.4369
Macro F1-score: 0.4334
Model performance on Angry speech (in training): 
	Precision: 0.4557, Recall: 0.6950, F1_score: 0.5505
Model performance on Happy speech (in training): 
	Precision: 0.2695, Recall: 0.3975, F1_score: 0.3212
Model performance on Neutral speech (in training): 
	Precision: 0.5985, Recall: 0.4025, F1_score: 0.4813
Model performance on Sad speech (in training): 
	Precision: 0.7710, Recall: 0.2525, F1_score: 0.3804

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 39/100

Training Phase:
|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 244/1600 [00:10<00:55, 24.36it/s]Training:  30%|███       | 488/1600 [00:20<00:45, 24.19it/s]Training:  46%|████▌     | 729/1600 [00:30<00:36, 23.80it/s]Training:  61%|██████    | 973/1600 [00:40<00:26, 24.01it/s]Training:  61%|██████    | 973/1600 [00:50<00:26, 24.01it/s]Training:  76%|███████▌  | 1217/1600 [00:50<00:16, 23.80it/s]Training:  91%|█████████ | 1452/1600 [01:01<00:06, 23.52it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 240/1600 [00:10<00:56, 23.92it/s]Training:  30%|███       | 482/1600 [00:20<00:46, 24.04it/s]Training:  45%|███Training loss: 5856.3950, Training accuracy: 0.4338
Macro F1-score: 0.4272
Model performance on Angry speech (in training): 
	Precision: 0.4559, Recall: 0.6975, F1_score: 0.5514
Model performance on Happy speech (in training): 
	Precision: 0.2787, Recall: 0.4125, F1_score: 0.3327
Model performance on Neutral speech (in training): 
	Precision: 0.5811, Recall: 0.3850, F1_score: 0.4632
Model performance on Sad speech (in training): 
	Precision: 0.7328, Recall: 0.2400, F1_score: 0.3616

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 40/100

Training Phase:
▌     | 725/1600 [00:30<00:36, 24.13it/s]Training:  60%|██████    | 968/1600 [00:40<00:26, 24.00it/s]Training:  75%|███████▌  | 1206/1600 [00:50<00:16, 23.47it/s]Training:  90%|████████▉ | 1432/1600 [01:00<00:07, 23.17it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 239/1600 [00:10<00:56, 23.88it/s]Training:  30%|███       | 480/1600 [00:20<00:46, 23.96it/s]Training:  45%|████▌     | 721/1600 [00:30<00:37, 23.74it/s]Training:  45%|████▌     | 721/1600 [00:40<00:37, 23.74it/s]Training:  59%|█████▉    | 948/1600 [00:40<00:28, 23.12it/s]Training:  74%|███████▍  | 1182/1600 [00:50<00:18, 23.21it/s]Training:  89%|████████▉ | 1423/1600 [01:00<00:07, 23.49it/s]                        Training loss: 5827.3129, Training accuracy: 0.4481
Macro F1-score: 0.4440
Model performance on Angry speech (in training): 
	Precision: 0.4673, Recall: 0.7150, F1_score: 0.5652
Model performance on Happy speech (in training): 
	Precision: 0.2796, Recall: 0.4075, F1_score: 0.3316
Model performance on Neutral speech (in training): 
	Precision: 0.6015, Recall: 0.4075, F1_score: 0.4858
Model performance on Sad speech (in training): 
	Precision: 0.7836, Recall: 0.2625, F1_score: 0.3933

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 41/100

Training Phase:
Training loss: 5871.7377, Training accuracy: 0.4469
Macro F1-score: 0.4419
Model performance on Angry speech (in training): 
	Precision: 0.4669, Recall: 0.7225, F1_score: 0.5672
Model performance on Happy speech (in training): 
	Precision: 0.2799, Recall: 0.4100, F1_score: 0.3327
Model performance on Neutral speech (in training): 
	Precision: 0.6031, Recall: 0.3950, F1_score: 0.4773
Model performance on Sad speech (in training): 
	Precision: 0.7820, Recall: 0.2600, F1_score: 0.3902

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 42/100

Training Phase:
                                     Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 238/1600 [00:10<00:57, 23.71it/s]Training:  30%|███       | 481/1600 [00:20<00:46, 24.02it/s]Training:  45%|████▌     | 724/1600 [00:30<00:36, 24.08it/s]Training:  60%|██████    | 966/1600 [00:40<00:26, 23.69it/s]Training:  60%|██████    | 966/1600 [00:50<00:26, 23.69it/s]Training:  75%|███████▍  | 1195/1600 [00:50<00:17, 23.28it/s]Training:  89%|████████▉ | 1421/1600 [01:00<00:07, 22.98it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 241/1600 [00:10<00:56, 24.06it/s]Training:  30%|███       | 482/1Training loss: 5893.1573, Training accuracy: 0.4400
Macro F1-score: 0.4349
Model performance on Angry speech (in training): 
	Precision: 0.4615, Recall: 0.7050, F1_score: 0.5579
Model performance on Happy speech (in training): 
	Precision: 0.2750, Recall: 0.4050, F1_score: 0.3276
Model performance on Neutral speech (in training): 
	Precision: 0.5963, Recall: 0.4025, F1_score: 0.4806
Model performance on Sad speech (in training): 
	Precision: 0.7615, Recall: 0.2475, F1_score: 0.3736

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 43/100

Training Phase:
600 [00:20<00:48, 23.15it/s]Training:  44%|████▍     | 708/1600 [00:30<00:39, 22.84it/s]Training:  59%|█████▊    | 937/1600 [00:40<00:29, 22.85it/s]Training:  74%|███████▎  | 1176/1600 [00:50<00:18, 23.21it/s]Training:  89%|████████▊ | 1418/1600 [01:00<00:07, 23.54it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 224/1600 [00:10<01:01, 22.35it/s]Training:  28%|██▊       | 453/1600 [00:20<00:50, 22.65it/s]Training:  43%|████▎     | 682/1600 [00:30<00:40, 22.62it/s]Training:  57%|█████▋    | 908/1600 [00:40<00:30, 22.61it/s]Training:  71%|███████▏  | 1141/1600 [00:50<00:20, 22.82it/s]Training:  86%|████████▌ | 1379/1600 [01:00<00:09, 23.14it/s]                                        Training loss: 5842.2698, Training accuracy: 0.4400
Macro F1-score: 0.4339
Model performance on Angry speech (in training): 
	Precision: 0.4617, Recall: 0.7075, F1_score: 0.5587
Model performance on Happy speech (in training): 
	Precision: 0.2780, Recall: 0.4100, F1_score: 0.3313
Model performance on Neutral speech (in training): 
	Precision: 0.5948, Recall: 0.4000, F1_score: 0.4783
Model performance on Sad speech (in training): 
	Precision: 0.7578, Recall: 0.2425, F1_score: 0.3674

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 44/100

Training Phase:
Training loss: 5879.8757, Training accuracy: 0.4363
Macro F1-score: 0.4318
Model performance on Angry speech (in training): 
	Precision: 0.4541, Recall: 0.7175, F1_score: 0.5562
Model performance on Happy speech (in training): 
	Precision: 0.2652, Recall: 0.3825, F1_score: 0.3132
Model performance on Neutral speech (in training): 
	Precision: 0.6008, Recall: 0.3875, F1_score: 0.4711
Model performance on Sad speech (in training): 
	Precision: 0.7744, Recall: 0.2575, F1_score: 0.3865

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 45/100

Training Phase:
                     Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 241/1600 [00:10<00:56, 24.03it/s]Training:  30%|███       | 485/1600 [00:20<00:46, 24.23it/s]Training:  46%|████▋     | 742/1600 [00:30<00:34, 24.87it/s]Training:  63%|██████▎   | 1007/1600 [00:40<00:23, 25.50it/s]Training:  80%|███████▉  | 1272/1600 [00:51<00:13, 24.49it/s]Training:  94%|█████████▍| 1509/1600 [01:01<00:03, 24.21it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 243/1600 [00:10<00:56, 24.21it/s]Training:  31%|███       | 490/1600 [00:20<00:45, 24.49it/s]Training:  47%|████▋     | 747/1600 [00:30<00Training loss: 5944.6831, Training accuracy: 0.4319
Macro F1-score: 0.4308
Model performance on Angry speech (in training): 
	Precision: 0.4529, Recall: 0.6850, F1_score: 0.5453
Model performance on Happy speech (in training): 
	Precision: 0.2591, Recall: 0.3900, F1_score: 0.3114
Model performance on Neutral speech (in training): 
	Precision: 0.6094, Recall: 0.3900, F1_score: 0.4756
Model performance on Sad speech (in training): 
	Precision: 0.7664, Recall: 0.2625, F1_score: 0.3911

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 46/100

Training Phase:
:34, 25.02it/s]Training:  47%|████▋     | 747/1600 [00:40<00:34, 25.02it/s]Training:  62%|██████▎   | 1000/1600 [00:40<00:23, 25.05it/s]Training:  78%|███████▊  | 1253/1600 [00:50<00:13, 25.12it/s]Training:  94%|█████████▍| 1509/1600 [01:00<00:03, 25.25it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 254/1600 [00:10<00:53, 25.36it/s]Training:  32%|███▏      | 508/1600 [00:20<00:43, 25.25it/s]Training:  48%|████▊     | 760/1600 [00:30<00:33, 25.18it/s]Training:  63%|██████▎   | 1012/1600 [00:40<00:23, 25.19it/s]Training:  79%|███████▉  | 1264/1600 [00:50<00:13, 24.72it/s]Training:  94%|█████████▍| 1508/1600 [01:00<00:03, 24.61it/s]                                         Training loss: 5909.4688, Training accuracy: 0.4325
Macro F1-score: 0.4270
Model performance on Angry speech (in training): 
	Precision: 0.4575, Recall: 0.7000, F1_score: 0.5534
Model performance on Happy speech (in training): 
	Precision: 0.2673, Recall: 0.3950, F1_score: 0.3189
Model performance on Neutral speech (in training): 
	Precision: 0.5852, Recall: 0.3950, F1_score: 0.4716
Model performance on Sad speech (in training): 
	Precision: 0.7559, Recall: 0.2400, F1_score: 0.3643

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 47/100

Training Phase:
Training loss: 5868.9764, Training accuracy: 0.4369
Macro F1-score: 0.4307
Model performance on Angry speech (in training): 
	Precision: 0.4651, Recall: 0.7000, F1_score: 0.5589
Model performance on Happy speech (in training): 
	Precision: 0.2768, Recall: 0.4125, F1_score: 0.3313
Model performance on Neutral speech (in training): 
	Precision: 0.5745, Recall: 0.3950, F1_score: 0.4681
Model performance on Sad speech (in training): 
	Precision: 0.7559, Recall: 0.2400, F1_score: 0.3643

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 48/100

Training Phase:
                    Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 234/1600 [00:10<00:58, 23.35it/s]Training:  29%|██▉       | 468/1600 [00:20<00:49, 22.91it/s]Training:  29%|██▉       | 468/1600 [00:30<00:49, 22.91it/s]Training:  43%|████▎     | 692/1600 [00:30<00:40, 22.66it/s]Training:  57%|█████▋    | 918/1600 [00:40<00:30, 22.62it/s]Training:  72%|███████▏  | 1144/1600 [00:50<00:20, 22.53it/s]Training:  86%|████████▌ | 1370/1600 [01:00<00:10, 22.53it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 244/1600 [00:10<00:55, 24.33it/s]Training:  30%|███       | 488/1600 [00:20<00:46, 23.99Training loss: 5974.7803, Training accuracy: 0.4356
Macro F1-score: 0.4285
Model performance on Angry speech (in training): 
	Precision: 0.4638, Recall: 0.7050, F1_score: 0.5595
Model performance on Happy speech (in training): 
	Precision: 0.2730, Recall: 0.4000, F1_score: 0.3245
Model performance on Neutral speech (in training): 
	Precision: 0.5786, Recall: 0.4050, F1_score: 0.4765
Model performance on Sad speech (in training): 
	Precision: 0.7381, Recall: 0.2325, F1_score: 0.3536

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 49/100

Training Phase:
it/s]Training:  46%|████▋     | 743/1600 [00:30<00:34, 24.67it/s]Training:  62%|██████▏   | 998/1600 [00:40<00:24, 24.63it/s]Training:  78%|███████▊  | 1244/1600 [00:50<00:14, 24.34it/s]Training:  93%|█████████▎| 1486/1600 [01:01<00:04, 24.27it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 238/1600 [00:10<00:57, 23.77it/s]Training:  30%|██▉       | 477/1600 [00:20<00:47, 23.83it/s]Training:  45%|████▍     | 718/1600 [00:30<00:36, 23.94it/s]Training:  60%|█████▉    | 959/1600 [00:40<00:26, 23.98it/s]Training:  76%|███████▌  | 1215/1600 [00:50<00:15, 24.54it/s]Training:  92%|█████████▏| 1471/1600 [01:00<00:05, 24.49it/s]                                                         Training loss: 5821.2821, Training accuracy: 0.4381
Macro F1-score: 0.4313
Model performance on Angry speech (in training): 
	Precision: 0.4648, Recall: 0.7100, F1_score: 0.5618
Model performance on Happy speech (in training): 
	Precision: 0.2774, Recall: 0.4050, F1_score: 0.3293
Model performance on Neutral speech (in training): 
	Precision: 0.5725, Recall: 0.3950, F1_score: 0.4675
Model performance on Sad speech (in training): 
	Precision: 0.7519, Recall: 0.2425, F1_score: 0.3667

Eval Phase: 
Validation loss: 158.8660, Validation accuracy: 0.8250
Macro F1-score: 0.8216
Model performance on Angry speech (in validation): 
	Precision: 0.9592, Recall: 0.9400, F1_score: 0.9495
Model performance on Happy speech (in validation): 
	Precision: 0.8723, Recall: 0.8200, F1_score: 0.8454
Model performance on Neutral speech (in validation): 
	Precision: 0.7692, Recall: 0.6000, F1_score: 0.6742
Model performance on Sad speech (in validation): 
	Precision: 0.7231, Recall: 0.9400, F1_score: 0.8174
Epoch 50/100

Two-stage training complete.
Model best accuracy on validation set: 0.8250

Test Phase: 
    Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]Testing:   1%|          | 2/200 [00:00<00:09, 19.91it/s]Testing:   3%|▎         | 6/200 [00:00<00:07, 24.75it/s]Testing:   4%|▍         | 9/200 [00:00<00:08, 21.95it/s]Testing:   6%|▋         | 13/200 [00:00<00:07, 25.57it/s]Testing:   8%|▊         | 17/200 [00:00<00:06, 28.17it/s]Testing:  12%|█▏        | 23/200 [00:00<00:05, 33.97it/s]Testing:  14%|█▍        | 29/200 [00:00<00:04, 40.01it/s]Testing:  17%|█▋        | 34/200 [00:01<00:03, 41.83it/s]Testing:  21%|██        | 42/200 [00:01<00:03, 46.32it/s]Testing:  24%|██▎       | 47/200 [00:01<00:03, 45.41it/s]Testing:  26%|██▋       | 53/200 [00:01<00:03, 48.77it/s]Testing:  31%|███       | 62/200 [00:01<00:02, 59.60it/s]Testing:  36%|███▌      | 71/200 [00:01<00:01, 66.76it/s]Testing:  40%|███▉      | 79/200 [00:01<00:01, 67.86it/Test loss: 221.1541, Test accuracy: 0.7500
Macro F1-score: 0.7511
Model performance on Angry speech (in test): 
	Precision: 1.0000, Recall: 0.8000, F1_score: 0.8889
Model performance on Happy speech (in test): 
	Precision: 0.7200, Recall: 0.7200, F1_score: 0.7200
Model performance on Neutral speech (in test): 
	Precision: 0.6042, Recall: 0.5800, F1_score: 0.5918
Model performance on Sad speech (in test): 
	Precision: 0.7258, Recall: 0.9000, F1_score: 0.8036

======================= This is fold_2 on de =======================

Load dataset: 
Loading de train data: fold_2...
Preprocess de fold_2 data for de model
Loading cn eval data: fold_2...
Preprocess cn fold_2 data for de model
Loading cn test data: fold_2...
Preprocess cn fold_2 data for de model
Use de model to add lora
================== SET ALL PARAMS =====================
modified_wav2vec2.base_model.model.masked_spec_embed: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.0.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.0.layer_norm.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.0.layer_norm.bias: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.1.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.2.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.3.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.4.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.5.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.6.conv.weight: False
modified_wav2vec2.base_model.model.feature_projection.layer_norm.weight: False
modified_wav2vec2.base_model.model.feature_projection.layer_norm.bias: False
modified_wav2vec2.base_model.model.feature_projection.projection.weight: False
modified_wav2vec2.base_model.model.feature_projection.projection.bias: False
modified_wav2vec2.base_model.model.encoder.pos_conv_embed.conv.bias: False
modified_wav2vec2.base_model.model.encoder.pos_conv_embed.conv.weight_g: False
modified_wav2vec2.base_model.model.encoder.pos_conv_embed.conv.weight_v: False
modified_wav2vec2.base_model.model.encoder.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.up.bias: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.up.bias: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.up.bias: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.up.bias: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.4.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.4.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.bottleneck_adaptor.up.bias: True
normal_classifier.dense1.weight: True
normal_classifier.dense1.bias: True
normal_classifier.dense.weight: True
normal_classifier.dense.bias: True
normal_classifier.out.weight: True
normal_classifier.out.bias: True
Set optimizer and criterion
Epoch 1/100

Training Phase:
s]Testing:  44%|████▍     | 88/200 [00:01<00:01, 71.86it/s]Testing:  48%|████▊     | 96/200 [00:01<00:01, 69.13it/s]Testing:  53%|█████▎    | 106/200 [00:02<00:01, 75.44it/s]Testing:  57%|█████▊    | 115/200 [00:02<00:01, 78.62it/s]Testing:  62%|██████▎   | 125/200 [00:02<00:00, 82.23it/s]Testing:  67%|██████▋   | 134/200 [00:02<00:00, 84.02it/s]Testing:  72%|███████▏  | 144/200 [00:02<00:00, 86.90it/s]Testing:  78%|███████▊  | 155/200 [00:02<00:00, 91.18it/s]Testing:  82%|████████▎ | 165/200 [00:02<00:00, 89.95it/s]Testing:  88%|████████▊ | 175/200 [00:02<00:00, 84.81it/s]Testing:  92%|█████████▏| 184/200 [00:02<00:00, 84.11it/s]Testing:  97%|█████████▋| 194/200 [00:03<00:00, 86.91it/s]                                                          Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:   8%|▊      Training loss: 368.4514, Training accuracy: 0.9175
Macro F1-score: 0.9174
Model performance on Angry speech (in training): 
	Precision: 0.9000, Recall: 0.9225, F1_score: 0.9111
Model performance on Happy speech (in training): 
	Precision: 0.8877, Recall: 0.8500, F1_score: 0.8685
Model performance on Neutral speech (in training): 
	Precision: 0.9002, Recall: 0.9250, F1_score: 0.9125
Model performance on Sad speech (in training): 
	Precision: 0.9823, Recall: 0.9725, F1_score: 0.9774

Eval Phase: 
Validation loss: 567.9988, Validation accuracy: 0.5000
Macro F1-score: 0.4271
Model performance on Angry speech (in validation): 
	Precision: 0.4667, Recall: 0.9800, F1_score: 0.6323
Model performance on Happy speech (in validation): 
	Precision: 0.3333, Recall: 0.0200, F1_score: 0.0377
Model performance on Neutral speech (in validation): 
	Precision: 0.5789, Recall: 0.4400, F1_score: 0.5000
Model performance on Sad speech (in validation): 
	Precision: 0.5185, Recall: 0.5600, F1_score: 0.5385
New best accuracy for layer 4 on epoch 1: 0.5000. Model saved.
Epoch 2/100

Training Phase:
   | 123/1600 [00:10<02:00, 12.29it/s]Training:  17%|█▋        | 267/1600 [00:20<01:38, 13.52it/s]Training:  27%|██▋       | 433/1600 [00:30<01:18, 14.91it/s]Training:  38%|███▊      | 609/1600 [00:40<01:02, 15.94it/s]Training:  49%|████▉     | 785/1600 [00:50<00:50, 16.27it/s]Training:  61%|██████    | 971/1600 [01:00<00:36, 17.05it/s]Training:  72%|███████▏  | 1157/1600 [01:10<00:25, 17.35it/s]Training:  84%|████████▎ | 1337/1600 [01:20<00:14, 17.54it/s]Training:  95%|█████████▌| 1522/1600 [01:30<00:04, 17.81it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 195/1600 [00:10<01:12, 19.41it/s]Training:  24%|██▍       | 390/1600 [00:20<01:02, 19.39it/s]Training:  37%|███▋      | 593/1600 [00:3Training loss: 116.8792, Training accuracy: 0.9719
Macro F1-score: 0.9719
Model performance on Angry speech (in training): 
	Precision: 0.9647, Recall: 0.9575, F1_score: 0.9611
Model performance on Happy speech (in training): 
	Precision: 0.9501, Recall: 0.9525, F1_score: 0.9513
Model performance on Neutral speech (in training): 
	Precision: 0.9777, Recall: 0.9875, F1_score: 0.9826
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9900, F1_score: 0.9925

Eval Phase: 
Validation loss: 464.1737, Validation accuracy: 0.5250
Macro F1-score: 0.4752
Model performance on Angry speech (in validation): 
	Precision: 0.4828, Recall: 0.8400, F1_score: 0.6131
Model performance on Happy speech (in validation): 
	Precision: 0.4000, Recall: 0.1200, F1_score: 0.1846
Model performance on Neutral speech (in validation): 
	Precision: 0.6538, Recall: 0.3400, F1_score: 0.4474
Model performance on Sad speech (in validation): 
	Precision: 0.5556, Recall: 0.8000, F1_score: 0.6557
New best accuracy for layer 4 on epoch 2: 0.5250. Model saved.
Epoch 3/100

Training Phase:
0<00:50, 19.76it/s]Training:  50%|████▉     | 796/1600 [00:40<00:40, 19.88it/s]Training:  62%|██████▎   | 1000/1600 [00:50<00:29, 20.05it/s]Training:  76%|███████▌  | 1208/1600 [01:00<00:19, 20.29it/s]Training:  89%|████████▊ | 1418/1600 [01:10<00:08, 20.52it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 194/1600 [00:10<01:12, 19.34it/s]Training:  24%|██▍       | 388/1600 [00:20<01:03, 19.16it/s]Training:  36%|███▋      | 581/1600 [00:30<00:53, 19.21it/s]Training:  49%|████▊     | 779/1600 [00:40<00:42, 19.41it/s]Training:  61%|██████▏   | 983/1600 [00:50<00:31, 19.74it/s]Training:  74%|███████▍  | 1187/1600 [01:00<00:20, 19.88it/s]Training:  87%|████████▋ | 1394/1600 Training loss: 102.8776, Training accuracy: 0.9794
Macro F1-score: 0.9794
Model performance on Angry speech (in training): 
	Precision: 0.9823, Recall: 0.9700, F1_score: 0.9761
Model performance on Happy speech (in training): 
	Precision: 0.9602, Recall: 0.9650, F1_score: 0.9626
Model performance on Neutral speech (in training): 
	Precision: 0.9777, Recall: 0.9875, F1_score: 0.9826
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962

Eval Phase: 
Validation loss: 409.9639, Validation accuracy: 0.5250
Macro F1-score: 0.4999
Model performance on Angry speech (in validation): 
	Precision: 0.5000, Recall: 0.7200, F1_score: 0.5902
Model performance on Happy speech (in validation): 
	Precision: 0.4828, Recall: 0.2800, F1_score: 0.3544
Model performance on Neutral speech (in validation): 
	Precision: 0.6154, Recall: 0.3200, F1_score: 0.4211
Model performance on Sad speech (in validation): 
	Precision: 0.5342, Recall: 0.7800, F1_score: 0.6341
Epoch 4/100

Training Phase:
Training loss: 82.7508, Training accuracy: 0.9838
Macro F1-score: 0.9837
Model performance on Angry speech (in training): 
	Precision: 0.9825, Recall: 0.9850, F1_score: 0.9838
Model performance on Happy speech (in training): 
	Precision: 0.9798, Recall: 0.9725, F1_score: 0.9762
Model performance on Neutral speech (in training): 
	Precision: 0.9825, Recall: 0.9850, F1_score: 0.9838
Model performance on Sad speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913

Eval Phase: 
Validation loss: 549.3205, Validation accuracy: 0.4950
Macro F1-score: 0.4299
Model performance on Angry speech (in validation): 
	Precision: 0.4845, Recall: 0.9400, F1_score: 0.6395
Model performance on Happy speech (in validation): 
	Precision: 0.1250, Recall: 0.0200, F1_score: 0.0345
Model performance on Neutral speech (in validation): 
	Precision: 0.5581, Recall: 0.4800, F1_score: 0.5161
Model performance on Sad speech (in validation): 
	Precision: 0.5192, Recall: 0.5400, F1_score: 0.5294
Epoch 5/100

Training Phase:
[01:10<00:10, 20.13it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▎        | 200/1600 [00:10<01:10, 19.91it/s]Training:  25%|██▌       | 400/1600 [00:20<01:01, 19.46it/s]Training:  37%|███▋      | 593/1600 [00:30<00:51, 19.37it/s]Training:  49%|████▉     | 789/1600 [00:40<00:41, 19.44it/s]Training:  62%|██████▏   | 985/1600 [00:50<00:31, 19.36it/s]Training:  74%|███████▎  | 1178/1600 [01:00<00:21, 19.25it/s]Training:  86%|████████▌ | 1375/1600 [01:10<00:11, 19.38it/s]Training:  98%|█████████▊| 1573/1600 [01:20<00:01, 19.50it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          Training loss: 54.6436, Training accuracy: 0.9881
Macro F1-score: 0.9881
Model performance on Angry speech (in training): 
	Precision: 0.9899, Recall: 0.9825, F1_score: 0.9862
Model performance on Happy speech (in training): 
	Precision: 0.9775, Recall: 0.9775, F1_score: 0.9775
Model performance on Neutral speech (in training): 
	Precision: 0.9876, Recall: 0.9925, F1_score: 0.9900
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988

Eval Phase: 
Validation loss: 420.0399, Validation accuracy: 0.5100
Macro F1-score: 0.5041
Model performance on Angry speech (in validation): 
	Precision: 0.5000, Recall: 0.6600, F1_score: 0.5690
Model performance on Happy speech (in validation): 
	Precision: 0.4359, Recall: 0.3400, F1_score: 0.3820
Model performance on Neutral speech (in validation): 
	Precision: 0.5714, Recall: 0.4800, F1_score: 0.5217
Model performance on Sad speech (in validation): 
	Precision: 0.5283, Recall: 0.5600, F1_score: 0.5437
Epoch 6/100

Training Phase:
| 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 201/1600 [00:10<01:09, 20.06it/s]Training:  26%|██▌       | 408/1600 [00:20<00:58, 20.40it/s]Training:  26%|██▌       | 408/1600 [00:30<00:58, 20.40it/s]Training:  38%|███▊      | 610/1600 [00:30<00:49, 19.98it/s]Training:  51%|█████     | 814/1600 [00:40<00:39, 20.10it/s]Training:  64%|██████▎   | 1017/1600 [00:50<00:28, 20.12it/s]Training:  77%|███████▋  | 1230/1600 [01:00<00:18, 20.52it/s]Training:  90%|█████████ | 1443/1600 [01:11<00:07, 20.21it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 203/1600 [00:10<01:08, 20.27it/s]Training:  26%|██▌       | 415/1600 [00:20<00:57, 20.77it/s]Training:  39%|███▉      | 627/1600 [00:30<00:47, 20.56it/s]TrainTraining loss: 46.0759, Training accuracy: 0.9894
Macro F1-score: 0.9894
Model performance on Angry speech (in training): 
	Precision: 0.9924, Recall: 0.9825, F1_score: 0.9874
Model performance on Happy speech (in training): 
	Precision: 0.9802, Recall: 0.9925, F1_score: 0.9863
Model performance on Neutral speech (in training): 
	Precision: 0.9900, Recall: 0.9875, F1_score: 0.9887
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950

Eval Phase: 
Validation loss: 472.9941, Validation accuracy: 0.5200
Macro F1-score: 0.4858
Model performance on Angry speech (in validation): 
	Precision: 0.5063, Recall: 0.8000, F1_score: 0.6202
Model performance on Happy speech (in validation): 
	Precision: 0.4231, Recall: 0.2200, F1_score: 0.2895
Model performance on Neutral speech (in validation): 
	Precision: 0.5507, Recall: 0.7600, F1_score: 0.6387
Model performance on Sad speech (in validation): 
	Precision: 0.5769, Recall: 0.3000, F1_score: 0.3947
Epoch 7/100

Training Phase:
ing:  52%|█████▏    | 834/1600 [00:40<00:37, 20.61it/s]Training:  66%|██████▌   | 1051/1600 [00:50<00:26, 20.97it/s]Training:  79%|███████▉  | 1268/1600 [01:00<00:15, 21.18it/s]Training:  93%|█████████▎| 1485/1600 [01:10<00:05, 21.21it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 204/1600 [00:10<01:08, 20.38it/s]Training:  26%|██▌       | 408/1600 [00:20<00:59, 20.14it/s]Training:  38%|███▊      | 613/1600 [00:30<00:48, 20.28it/s]Training:  51%|█████▏    | 822/1600 [00:40<00:37, 20.52it/s]Training:  51%|█████▏    | 822/1600 [00:50<00:37, 20.52it/s]Training:  64%|██████▍   | 1027/1600 [00:50<00:28, 20.25it/s]Training:  77%|███████▋  | 1225/1600 [01:01<00:18, 19.78it/s]Training loss: 46.6682, Training accuracy: 0.9894
Macro F1-score: 0.9894
Model performance on Angry speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900
Model performance on Happy speech (in training): 
	Precision: 0.9825, Recall: 0.9850, F1_score: 0.9838
Model performance on Neutral speech (in training): 
	Precision: 0.9900, Recall: 0.9875, F1_score: 0.9887
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950

Eval Phase: 
Validation loss: 598.9030, Validation accuracy: 0.4950
Macro F1-score: 0.4420
Model performance on Angry speech (in validation): 
	Precision: 0.4944, Recall: 0.8800, F1_score: 0.6331
Model performance on Happy speech (in validation): 
	Precision: 0.3125, Recall: 0.1000, F1_score: 0.1515
Model performance on Neutral speech (in validation): 
	Precision: 0.5303, Recall: 0.7000, F1_score: 0.6034
Model performance on Sad speech (in validation): 
	Precision: 0.5172, Recall: 0.3000, F1_score: 0.3797
Epoch 8/100

Training Phase:
Training loss: 28.2048, Training accuracy: 0.9956
Macro F1-score: 0.9956
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Happy speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950

Eval Phase: 
Training:  88%|████████▊ | 1414/1600 [01:11<00:09, 19.47it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 193/1600 [00:10<01:13, 19.26it/s]Training:  24%|██▍       | 389/1600 [00:20<01:02, 19.42it/s]Training:  37%|███▋      | 585/1600 [00:30<00:52, 19.35it/s]Training:  49%|████▉     | 785/1600 [00:40<00:41, 19.60it/s]Training:  62%|██████▏   | 988/1600 [00:50<00:30, 19.85it/s]Training:  74%|███████▍  | 1192/1600 [01:00<00:20, 20.03it/s]Training:  87%|████████▋ | 1396/1600 [01:10<00:10, 19.90it/s]Training: 100%|█████████▉| 1598/1600 [01:20<00:00, 19.99it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                       Validation loss: 499.5781, Validation accuracy: 0.5900
Macro F1-score: 0.5821
Model performance on Angry speech (in validation): 
	Precision: 0.5781, Recall: 0.7400, F1_score: 0.6491
Model performance on Happy speech (in validation): 
	Precision: 0.5750, Recall: 0.4600, F1_score: 0.5111
Model performance on Neutral speech (in validation): 
	Precision: 0.6875, Recall: 0.4400, F1_score: 0.5366
Model performance on Sad speech (in validation): 
	Precision: 0.5625, Recall: 0.7200, F1_score: 0.6316
New best accuracy for layer 4 on epoch 8: 0.5900. Model saved.
Epoch 9/100

Training Phase:
Training loss: 42.8093, Training accuracy: 0.9919
Macro F1-score: 0.9919
Model performance on Angry speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913
Model performance on Happy speech (in training): 
	Precision: 0.9875, Recall: 0.9850, F1_score: 0.9862
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Validation loss: 333.4028, Validation accuracy: 0.5650
Macro F1-score: 0.5643
Model performance on Angry speech (in validation): 
	Precision: 0.5536, Recall: 0.6200, F1_score: 0.5849
Model performance on Happy speech (in validation): 
	Precision: 0.5208, Recall: 0.5000, F1_score: 0.5102
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.5636, Recall: 0.6200, F1_score: 0.5905
Epoch 10/100

Training Phase:
                            Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 203/1600 [00:10<01:08, 20.28it/s]Training:  26%|██▌       | 408/1600 [00:20<00:58, 20.35it/s]Training:  39%|███▊      | 617/1600 [00:30<00:47, 20.59it/s]Training:  52%|█████▏    | 826/1600 [00:40<00:37, 20.45it/s]Training:  64%|██████▍   | 1029/1600 [00:50<00:28, 20.26it/s]Training:  77%|███████▋  | 1234/1600 [01:00<00:18, 20.32it/s]Training:  90%|████████▉ | 1439/1600 [01:10<00:07, 20.28it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 215/1600 [00:10<01:04, 21.41it/s]Training:  27%|██▋       | 430/1600 [00:20<00:56, 20.59it/s]Training:  39%|███▉      | 631/1600 [00:30<00:47, 20.27it/s]Training:  52%|Training loss: 35.6553, Training accuracy: 0.9906
Macro F1-score: 0.9906
Model performance on Angry speech (in training): 
	Precision: 0.9875, Recall: 0.9900, F1_score: 0.9888
Model performance on Happy speech (in training): 
	Precision: 0.9825, Recall: 0.9825, F1_score: 0.9825
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 370.5460, Validation accuracy: 0.5750
Macro F1-score: 0.5700
Model performance on Angry speech (in validation): 
	Precision: 0.5538, Recall: 0.7200, F1_score: 0.6261
Model performance on Happy speech (in validation): 
	Precision: 0.5250, Recall: 0.4200, F1_score: 0.4667
Model performance on Neutral speech (in validation): 
	Precision: 0.6500, Recall: 0.5200, F1_score: 0.5778
Model performance on Sad speech (in validation): 
	Precision: 0.5818, Recall: 0.6400, F1_score: 0.6095
Epoch 11/100

Training Phase:
█████▏    | 836/1600 [00:40<00:37, 20.32it/s]Training:  65%|██████▌   | 1040/1600 [00:50<00:27, 20.31it/s]Training:  78%|███████▊  | 1244/1600 [01:00<00:17, 20.33it/s]Training:  90%|█████████ | 1448/1600 [01:11<00:07, 20.26it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 203/1600 [00:10<01:08, 20.30it/s]Training:  26%|██▌       | 408/1600 [00:20<00:58, 20.37it/s]Training:  38%|███▊      | 613/1600 [00:30<00:48, 20.42it/s]Training:  51%|█████     | 818/1600 [00:40<00:38, 20.27it/s]Training:  64%|██████▍   | 1024/1600 [00:50<00:28, 20.37it/s]Training:  77%|███████▋  | 1230/1600 [01:00<00:18, 20.41it/s]Training:  90%|████████▉ | 1437/1600 [01:10<00:07, 20.49it/s]       Training loss: 22.7698, Training accuracy: 0.9956
Macro F1-score: 0.9956
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963
Model performance on Happy speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950

Eval Phase: 
Validation loss: 470.1986, Validation accuracy: 0.5750
Macro F1-score: 0.5422
Model performance on Angry speech (in validation): 
	Precision: 0.5176, Recall: 0.8800, F1_score: 0.6519
Model performance on Happy speech (in validation): 
	Precision: 0.5000, Recall: 0.1800, F1_score: 0.2647
Model performance on Neutral speech (in validation): 
	Precision: 0.7027, Recall: 0.5200, F1_score: 0.5977
Model performance on Sad speech (in validation): 
	Precision: 0.6000, Recall: 0.7200, F1_score: 0.6545
Epoch 12/100

Training Phase:
Training loss: 21.3254, Training accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Validation loss: 591.3883, Validation accuracy: 0.5550
Macro F1-score: 0.5265
Model performance on Angry speech (in validation): 
	Precision: 0.5556, Recall: 0.7000, F1_score: 0.6195
Model performance on Happy speech (in validation): 
	Precision: 0.5385, Recall: 0.4200, F1_score: 0.4719
Model performance on Neutral speech (in validation): 
	Precision: 0.7059, Recall: 0.2400, F1_score: 0.3582
Model performance on Sad speech (in validation): 
	Precision: 0.5309, Recall: 0.8600, F1_score: 0.6565
Epoch 13/100

Training Phase:
                                                      Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 209/1600 [00:10<01:06, 20.85it/s]Training:  26%|██▋       | 421/1600 [00:20<00:56, 21.01it/s]Training:  40%|███▉      | 633/1600 [00:30<00:46, 20.85it/s]Training:  53%|█████▎    | 841/1600 [00:40<00:36, 20.80it/s]Training:  66%|██████▌   | 1049/1600 [00:50<00:27, 20.39it/s]Training:  78%|███████▊  | 1254/1600 [01:00<00:16, 20.39it/s]Training:  78%|███████▊  | 1254/1600 [01:11<00:16, 20.39it/s]Training:  91%|█████████ | 1456/1600 [01:11<00:07, 20.25it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]TraininTraining loss: 33.3101, Training accuracy: 0.9938
Macro F1-score: 0.9938
Model performance on Angry speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900
Model performance on Happy speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Validation loss: 426.3878, Validation accuracy: 0.6100
Macro F1-score: 0.6043
Model performance on Angry speech (in validation): 
	Precision: 0.6750, Recall: 0.5400, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.5714, Recall: 0.7200, F1_score: 0.6372
Model performance on Neutral speech (in validation): 
	Precision: 0.6875, Recall: 0.4400, F1_score: 0.5366
Model performance on Sad speech (in validation): 
	Precision: 0.5692, Recall: 0.7400, F1_score: 0.6435
New best accuracy for layer 4 on epoch 13: 0.6100. Model saved.
Epoch 14/100

Training Phase:
g:  12%|█▎        | 200/1600 [00:10<01:10, 19.94it/s]Training:  25%|██▌       | 400/1600 [00:20<01:00, 19.89it/s]Training:  38%|███▊      | 603/1600 [00:30<00:49, 20.05it/s]Training:  51%|█████     | 811/1600 [00:40<00:38, 20.32it/s]Training:  64%|██████▎   | 1019/1600 [00:50<00:28, 20.42it/s]Training:  77%|███████▋  | 1227/1600 [01:00<00:18, 20.53it/s]Training:  90%|████████▉ | 1435/1600 [01:10<00:08, 20.54it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 202/1600 [00:10<01:09, 20.12it/s]Training:  26%|██▌       | 408/1600 [00:20<00:58, 20.38it/s]Training:  26%|██▌       | 408/1600 [00:30<00:58, 20.38it/s]Training:  38%|███▊      | 615/1600 [00:30<00:48, 20.50it/s]Training:  51%|█████▏    |Training loss: 33.4668, Training accuracy: 0.9944
Macro F1-score: 0.9944
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Neutral speech (in training): 
	Precision: 0.9900, Recall: 0.9875, F1_score: 0.9887
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963

Eval Phase: 
Validation loss: 453.7374, Validation accuracy: 0.6050
Macro F1-score: 0.5994
Model performance on Angry speech (in validation): 
	Precision: 0.5849, Recall: 0.6200, F1_score: 0.6019
Model performance on Happy speech (in validation): 
	Precision: 0.5192, Recall: 0.5400, F1_score: 0.5294
Model performance on Neutral speech (in validation): 
	Precision: 0.8148, Recall: 0.4400, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.6029, Recall: 0.8200, F1_score: 0.6949
Epoch 15/100

Training Phase:
 822/1600 [00:40<00:37, 20.57it/s]Training:  64%|██████▍   | 1029/1600 [00:50<00:27, 20.53it/s]Training:  77%|███████▋  | 1238/1600 [01:00<00:17, 20.63it/s]Training:  90%|█████████ | 1447/1600 [01:10<00:07, 20.63it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 211/1600 [00:10<01:06, 21.05it/s]Training:  26%|██▋       | 422/1600 [00:20<00:56, 20.97it/s]Training:  40%|███▉      | 632/1600 [00:30<00:46, 20.91it/s]Training:  53%|█████▎    | 841/1600 [00:40<00:36, 20.89it/s]Training:  66%|██████▌   | 1050/1600 [00:50<00:26, 20.79it/s]Training:  66%|██████▌   | 1050/1600 [01:00<00:26, 20.79it/s]Training:  78%|███████▊  | 1246/1600 [01:00<00:17, 20.19it/s]Training:  90%|█████Training loss: 5.2103, Training accuracy: 0.9988
Macro F1-score: 0.9987
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.9950, F1_score: 0.9975
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 1.0000, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 577.2184, Validation accuracy: 0.5650
Macro F1-score: 0.5652
Model performance on Angry speech (in validation): 
	Precision: 0.5600, Recall: 0.5600, F1_score: 0.5600
Model performance on Happy speech (in validation): 
	Precision: 0.4821, Recall: 0.5400, F1_score: 0.5094
Model performance on Neutral speech (in validation): 
	Precision: 0.6757, Recall: 0.5000, F1_score: 0.5747
Model performance on Sad speech (in validation): 
	Precision: 0.5789, Recall: 0.6600, F1_score: 0.6168
Epoch 16/100

Training Phase:
Training loss: 16.9986, Training accuracy: 0.9975
Macro F1-score: 0.9975
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 617.0087, Validation accuracy: 0.5700
Macro F1-score: 0.5458
Model performance on Angry speech (in validation): 
	Precision: 0.5692, Recall: 0.7400, F1_score: 0.6435
Model performance on Happy speech (in validation): 
	Precision: 0.5250, Recall: 0.4200, F1_score: 0.4667
Model performance on Neutral speech (in validation): 
	Precision: 0.7778, Recall: 0.2800, F1_score: 0.4118
Model performance on Sad speech (in validation): 
	Precision: 0.5455, Recall: 0.8400, F1_score: 0.6614
Epoch 17/100

Training Phase:
██▉ | 1437/1600 [01:10<00:08, 19.74it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 195/1600 [00:10<01:12, 19.41it/s]Training:  25%|██▍       | 394/1600 [00:20<01:01, 19.66it/s]Training:  37%|███▋      | 598/1600 [00:30<00:50, 19.97it/s]Training:  50%|█████     | 802/1600 [00:40<00:40, 19.94it/s]Training:  63%|██████▎   | 1006/1600 [00:50<00:29, 20.10it/s]Training:  76%|███████▌  | 1219/1600 [01:00<00:18, 20.50it/s]Training:  90%|████████▉ | 1432/1600 [01:10<00:08, 20.70it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 2Training loss: 33.1843, Training accuracy: 0.9931
Macro F1-score: 0.9931
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in training): 
	Precision: 0.9875, Recall: 0.9875, F1_score: 0.9875
Model performance on Neutral speech (in training): 
	Precision: 0.9875, Recall: 0.9850, F1_score: 0.9862
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988

Eval Phase: 
Validation loss: 566.3077, Validation accuracy: 0.5850
Macro F1-score: 0.5780
Model performance on Angry speech (in validation): 
	Precision: 0.5741, Recall: 0.6200, F1_score: 0.5962
Model performance on Happy speech (in validation): 
	Precision: 0.5417, Recall: 0.5200, F1_score: 0.5306
Model performance on Neutral speech (in validation): 
	Precision: 0.6774, Recall: 0.4200, F1_score: 0.5185
Model performance on Sad speech (in validation): 
	Precision: 0.5821, Recall: 0.7800, F1_score: 0.6667
Epoch 18/100

Training Phase:
02/1600 [00:10<01:09, 20.15it/s]Training:  13%|█▎        | 202/1600 [00:20<01:09, 20.15it/s]Training:  25%|██▌       | 401/1600 [00:20<01:01, 19.62it/s]Training:  38%|███▊      | 603/1600 [00:30<00:50, 19.84it/s]Training:  50%|█████     | 808/1600 [00:40<00:39, 20.08it/s]Training:  63%|██████▎   | 1013/1600 [00:50<00:29, 20.10it/s]Training:  76%|███████▌  | 1215/1600 [01:00<00:19, 20.00it/s]Training:  89%|████████▊ | 1419/1600 [01:10<00:09, 20.11it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 209/1600 [00:10<01:06, 20.81it/s]Training:  26%|██▌       | 418/1600 [00:20<00:56, 20.85it/s]Training:  39%|███▉      | 627/1600 [00:30<00:47, 20.46it/s]Training:  52%|█████▏    | 832/1600 [00:40<00:37, 20.Training loss: 11.2213, Training accuracy: 0.9981
Macro F1-score: 0.9981
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987

Eval Phase: 
Validation loss: 491.4383, Validation accuracy: 0.6000
Macro F1-score: 0.5991
Model performance on Angry speech (in validation): 
	Precision: 0.6078, Recall: 0.6200, F1_score: 0.6139
Model performance on Happy speech (in validation): 
	Precision: 0.5577, Recall: 0.5800, F1_score: 0.5686
Model performance on Neutral speech (in validation): 
	Precision: 0.6667, Recall: 0.5200, F1_score: 0.5843
Model performance on Sad speech (in validation): 
	Precision: 0.5862, Recall: 0.6800, F1_score: 0.6296
Epoch 19/100

Training Phase:
44it/s]Training:  65%|██████▍   | 1037/1600 [00:50<00:27, 20.32it/s]Training:  77%|███████▋  | 1239/1600 [01:00<00:17, 20.20it/s]Training:  90%|████████▉ | 1439/1600 [01:10<00:08, 20.06it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 196/1600 [00:10<01:11, 19.58it/s]Training:  25%|██▍       | 394/1600 [00:20<01:01, 19.68it/s]Training:  37%|███▋      | 599/1600 [00:30<00:49, 20.04it/s]Training:  50%|█████     | 804/1600 [00:40<00:39, 20.08it/s]Training:  63%|██████▎   | 1006/1600 [00:50<00:29, 20.04it/s]Training:  75%|███████▌  | 1206/1600 [01:00<00:19, 20.02it/s]Training:  88%|████████▊ | 1406/1600 [01:10<00:09, 20.00it/s]                                                         Training loss: 18.5030, Training accuracy: 0.9975
Macro F1-score: 0.9975
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963

Eval Phase: 
Validation loss: 503.4519, Validation accuracy: 0.5650
Macro F1-score: 0.5643
Model performance on Angry speech (in validation): 
	Precision: 0.5370, Recall: 0.5800, F1_score: 0.5577
Model performance on Happy speech (in validation): 
	Precision: 0.4902, Recall: 0.5000, F1_score: 0.4950
Model performance on Neutral speech (in validation): 
	Precision: 0.6757, Recall: 0.5000, F1_score: 0.5747
Model performance on Sad speech (in validation): 
	Precision: 0.5862, Recall: 0.6800, F1_score: 0.6296
Validation loss does not decrease for 10 epochs. End training.
Epoch 20/100

Entering 2ND training phase: change training data from de to CN
Loading cn train data: fold_2...
Preprocess cn fold_2 data for de model
Reload model and reset eval loss

Training Phase:
Training loss: 5528.6767, Training accuracy: 0.4350
Macro F1-score: 0.4180
Model performance on Angry speech (in training): 
	Precision: 0.6591, Recall: 0.2175, F1_score: 0.3271
Model performance on Happy speech (in training): 
	Precision: 0.3230, Recall: 0.8850, F1_score: 0.4733
Model performance on Neutral speech (in training): 
	Precision: 0.6019, Recall: 0.3250, F1_score: 0.4221
Model performance on Sad speech (in training): 
	Precision: 0.8013, Recall: 0.3125, F1_score: 0.4496

Eval Phase: 
Validation loss: 426.3878, Validation accuracy: 0.6100
Macro F1-score: 0.6043
Model performance on Angry speech (in validation): 
	Precision: 0.6750, Recall: 0.5400, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.5714, Recall: 0.7200, F1_score: 0.6372
Model performance on Neutral speech (in validation): 
	Precision: 0.6875, Recall: 0.4400, F1_score: 0.5366
Model performance on Sad speech (in validation): 
	Precision: 0.5692, Recall: 0.7400, F1_score: 0.6435
Epoch 21/100

Training Phase:
    Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  10%|█         | 166/1600 [00:10<01:26, 16.56it/s]Training:  23%|██▎       | 366/1600 [00:20<01:06, 18.56it/s]Training:  36%|███▋      | 582/1600 [00:30<00:51, 19.94it/s]Training:  50%|█████     | 801/1600 [00:40<00:38, 20.71it/s]Training:  65%|██████▍   | 1034/1600 [00:50<00:26, 21.63it/s]Training:  79%|███████▉  | 1267/1600 [01:00<00:15, 22.11it/s]Training:  94%|█████████▍| 1503/1600 [01:10<00:04, 22.57it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 240/1600 [00:10<00:56, 23.93it/s]Training:  30%|███       | 483/1600 [00:20<00:46, 24.13it/s]TrainTraining loss: 5514.6437, Training accuracy: 0.4344
Macro F1-score: 0.4163
Model performance on Angry speech (in training): 
	Precision: 0.6316, Recall: 0.2100, F1_score: 0.3152
Model performance on Happy speech (in training): 
	Precision: 0.3236, Recall: 0.8900, F1_score: 0.4747
Model performance on Neutral speech (in training): 
	Precision: 0.6176, Recall: 0.3150, F1_score: 0.4172
Model performance on Sad speech (in training): 
	Precision: 0.7914, Recall: 0.3225, F1_score: 0.4583

Eval Phase: 
Validation loss: 426.3878, Validation accuracy: 0.6100
Macro F1-score: 0.6043
Model performance on Angry speech (in validation): 
	Precision: 0.6750, Recall: 0.5400, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.5714, Recall: 0.7200, F1_score: 0.6372
Model performance on Neutral speech (in validation): 
	Precision: 0.6875, Recall: 0.4400, F1_score: 0.5366
Model performance on Sad speech (in validation): 
	Precision: 0.5692, Recall: 0.7400, F1_score: 0.6435
Epoch 22/100

Training Phase:
Training loss: 5506.0146, Training accuracy: 0.4319
Macro F1-score: 0.4158
Model performance on Angry speech (in training): 
	Precision: 0.6493, Recall: 0.2175, F1_score: 0.3258
Model performance on Happy speech (in training): 
	Precision: 0.3207, Recall: 0.8700, F1_score: 0.4687
Model performance on Neutral speech (in training): 
	Precision: 0.5856, Recall: 0.3250, F1_score: 0.4180
Model performance on Sad speech (in training): 
	Precision: 0.7925, Recall: 0.3150, F1_score: 0.4508

Eval Phase: 
ing:  45%|████▌     | 726/1600 [00:30<00:36, 23.84it/s]Training:  61%|██████▏   | 981/1600 [00:40<00:25, 24.45it/s]Training:  77%|███████▋  | 1238/1600 [00:50<00:14, 24.87it/s]Training:  93%|█████████▎| 1495/1600 [01:00<00:04, 24.97it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 236/1600 [00:10<00:57, 23.55it/s]Training:  30%|██▉       | 474/1600 [00:20<00:47, 23.67it/s]Training:  45%|████▍     | 713/1600 [00:30<00:37, 23.75it/s]Training:  60%|█████▉    | 955/1600 [00:40<00:26, 23.93it/s]Training:  75%|███████▍  | 1197/1600 [00:50<00:16, 23.92it/s]Training:  90%|████████▉ | 1437/1600 [01:00<00:06, 23.86it/s]                                                             EvaluatValidation loss: 426.3878, Validation accuracy: 0.6100
Macro F1-score: 0.6043
Model performance on Angry speech (in validation): 
	Precision: 0.6750, Recall: 0.5400, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.5714, Recall: 0.7200, F1_score: 0.6372
Model performance on Neutral speech (in validation): 
	Precision: 0.6875, Recall: 0.4400, F1_score: 0.5366
Model performance on Sad speech (in validation): 
	Precision: 0.5692, Recall: 0.7400, F1_score: 0.6435
Epoch 23/100

Training Phase:
Training loss: 5557.5425, Training accuracy: 0.4294
Macro F1-score: 0.4111
Model performance on Angry speech (in training): 
	Precision: 0.6538, Recall: 0.2125, F1_score: 0.3208
Model performance on Happy speech (in training): 
	Precision: 0.3220, Recall: 0.8775, F1_score: 0.4711
Model performance on Neutral speech (in training): 
	Precision: 0.5747, Recall: 0.3175, F1_score: 0.4090
Model performance on Sad speech (in training): 
	Precision: 0.7799, Recall: 0.3100, F1_score: 0.4436

Eval Phase: 
Validation loss: 426.3878, Validation accuracy: 0.6100
Macro F1-score: 0.6043
Model performance on Angry speech (in validation): 
	Precision: 0.6750, Recall: 0.5400, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.5714, Recall: 0.7200, F1_score: 0.6372
Model performance on Neutral speech (in validation): 
	Precision: 0.6875, Recall: 0.4400, F1_score: 0.5366
Model performance on Sad speech (in validation): 
	Precision: 0.5692, Recall: 0.7400, F1_score: 0.6435
Epoch 24/100

Training Phase:
ing:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 248/1600 [00:10<00:54, 24.72it/s]Training:  31%|███       | 496/1600 [00:20<00:45, 24.37it/s]Training:  46%|████▌     | 738/1600 [00:30<00:35, 24.01it/s]Training:  61%|██████    | 975/1600 [00:40<00:26, 23.86it/s]Training:  76%|███████▌  | 1216/1600 [00:50<00:16, 23.93it/s]Training:  91%|█████████ | 1457/1600 [01:00<00:05, 23.91it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 242/1600 [00:10<00:56, 24.16it/s]Training:  31%|███       | 492/1600 [00:20<00:45, 24.60it/s]Training:  46%|████▋     | 743/1600 [00:30<00:34, 24.80it/s]Training:  62%|█Training loss: 5556.4211, Training accuracy: 0.4338
Macro F1-score: 0.4168
Model performance on Angry speech (in training): 
	Precision: 0.6815, Recall: 0.2300, F1_score: 0.3439
Model performance on Happy speech (in training): 
	Precision: 0.3256, Recall: 0.8750, F1_score: 0.4746
Model performance on Neutral speech (in training): 
	Precision: 0.5574, Recall: 0.3275, F1_score: 0.4126
Model performance on Sad speech (in training): 
	Precision: 0.7806, Recall: 0.3025, F1_score: 0.4360

Eval Phase: 
Validation loss: 426.3878, Validation accuracy: 0.6100
Macro F1-score: 0.6043
Model performance on Angry speech (in validation): 
	Precision: 0.6750, Recall: 0.5400, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.5714, Recall: 0.7200, F1_score: 0.6372
Model performance on Neutral speech (in validation): 
	Precision: 0.6875, Recall: 0.4400, F1_score: 0.5366
Model performance on Sad speech (in validation): 
	Precision: 0.5692, Recall: 0.7400, F1_score: 0.6435
Epoch 25/100

Training Phase:
Training loss: 5563.3746, Training accuracy: 0.4319
Macro F1-score: 0.4129
Model performance on Angry speech (in training): 
	Precision: 0.6880, Recall: 0.2150, F1_score: 0.3276
Model performance on Happy speech (in training): 
	Precision: 0.3239, Recall: 0.8900, F1_score: 0.4750
Model performance on Neutral speech (in training): 
	Precision: 0.5762, Recall: 0.3025, F1_score: 0.3967
Model performance on Sad speech (in training): 
	Precision: 0.7711, Recall: 0.3200, F1_score: 0.4523

Eval Phase: 
████▏   | 994/1600 [00:40<00:24, 24.88it/s]Training:  78%|███████▊  | 1245/1600 [00:50<00:14, 24.76it/s]Training:  94%|█████████▎| 1496/1600 [01:00<00:04, 24.86it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 246/1600 [00:10<00:55, 24.58it/s]Training:  31%|███       | 492/1600 [00:20<00:45, 24.35it/s]Training:  46%|████▌     | 734/1600 [00:30<00:35, 24.21it/s]Training:  61%|██████    | 975/1600 [00:40<00:26, 24.03it/s]Training:  76%|███████▌  | 1213/1600 [00:50<00:16, 23.47it/s]Training:  90%|████████▉ | 1439/1600 [01:00<00:06, 23.17it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                        Validation loss: 426.3878, Validation accuracy: 0.6100
Macro F1-score: 0.6043
Model performance on Angry speech (in validation): 
	Precision: 0.6750, Recall: 0.5400, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.5714, Recall: 0.7200, F1_score: 0.6372
Model performance on Neutral speech (in validation): 
	Precision: 0.6875, Recall: 0.4400, F1_score: 0.5366
Model performance on Sad speech (in validation): 
	Precision: 0.5692, Recall: 0.7400, F1_score: 0.6435
Epoch 26/100

Training Phase:
Training loss: 5511.0047, Training accuracy: 0.4288
Macro F1-score: 0.4144
Model performance on Angry speech (in training): 
	Precision: 0.6127, Recall: 0.2175, F1_score: 0.3210
Model performance on Happy speech (in training): 
	Precision: 0.3161, Recall: 0.8575, F1_score: 0.4620
Model performance on Neutral speech (in training): 
	Precision: 0.6087, Recall: 0.3150, F1_score: 0.4152
Model performance on Sad speech (in training): 
	Precision: 0.7831, Recall: 0.3250, F1_score: 0.4594

Eval Phase: 
Validation loss: 426.3878, Validation accuracy: 0.6100
Macro F1-score: 0.6043
Model performance on Angry speech (in validation): 
	Precision: 0.6750, Recall: 0.5400, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.5714, Recall: 0.7200, F1_score: 0.6372
Model performance on Neutral speech (in validation): 
	Precision: 0.6875, Recall: 0.4400, F1_score: 0.5366
Model performance on Sad speech (in validation): 
	Precision: 0.5692, Recall: 0.7400, F1_score: 0.6435
Epoch 27/100

Training Phase:
           Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 250/1600 [00:10<00:54, 24.97it/s]Training:  31%|███▏      | 500/1600 [00:20<00:44, 24.88it/s]Training:  47%|████▋     | 749/1600 [00:30<00:35, 24.24it/s]Training:  62%|██████▏   | 995/1600 [00:40<00:24, 24.38it/s]Training:  78%|███████▊  | 1247/1600 [00:50<00:14, 24.65it/s]Training:  94%|█████████▎| 1499/1600 [01:00<00:04, 24.71it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 249/1600 [00:10<00:54, 24.89it/s]Training:  31%|███▏      | 502/1600 [00:20<00:43, 25.12it/s]Training:  47%|████▋     | 755/1600 [00:30<00:33, 24.85it/s]Training:  63%|██████▎   | 1001/1600 [00:40<00:24, 24.44it/s]Training:  78%|█Training loss: 5517.4615, Training accuracy: 0.4338
Macro F1-score: 0.4165
Model performance on Angry speech (in training): 
	Precision: 0.6719, Recall: 0.2150, F1_score: 0.3258
Model performance on Happy speech (in training): 
	Precision: 0.3230, Recall: 0.8825, F1_score: 0.4729
Model performance on Neutral speech (in training): 
	Precision: 0.5810, Recall: 0.3050, F1_score: 0.4000
Model performance on Sad speech (in training): 
	Precision: 0.7870, Recall: 0.3325, F1_score: 0.4675

Eval Phase: 
Validation loss: 426.3878, Validation accuracy: 0.6100
Macro F1-score: 0.6043
Model performance on Angry speech (in validation): 
	Precision: 0.6750, Recall: 0.5400, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.5714, Recall: 0.7200, F1_score: 0.6372
Model performance on Neutral speech (in validation): 
	Precision: 0.6875, Recall: 0.4400, F1_score: 0.5366
Model performance on Sad speech (in validation): 
	Precision: 0.5692, Recall: 0.7400, F1_score: 0.6435
Epoch 28/100

Training Phase:
Training loss: 5500.2570, Training accuracy: 0.4350
Macro F1-score: 0.4172
Model performance on Angry speech (in training): 
	Precision: 0.6618, Recall: 0.2250, F1_score: 0.3358
Model performance on Happy speech (in training): 
	Precision: 0.3257, Recall: 0.8875, F1_score: 0.4765
Model performance on Neutral speech (in training): 
	Precision: 0.5972, Recall: 0.3150, F1_score: 0.4124
Model performance on Sad speech (in training): 
	Precision: 0.7669, Recall: 0.3125, F1_score: 0.4440

Eval Phase: 
Validation loss: 426.3878, Validation accuracy: 0.6100
Macro F1-score: 0.6043
Model performance on Angry speech (in validation): 
	Precision: 0.6750, Recall: 0.5400, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.5714, Recall: 0.7200, F1_score: 0.6372
Model performance on Neutral speech (in validation): 
	Precision: 0.6875, Recall: 0.4400, F1_score: 0.5366
Model performance on Sad speech (in validation): 
	Precision: 0.5692, Recall: 0.7400, F1_score: 0.6435
Epoch 29/100

Training Phase:
█████▊  | 1242/1600 [00:50<00:14, 24.30it/s]Training:  93%|█████████▎| 1483/1600 [01:00<00:04, 24.13it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 236/1600 [00:10<00:57, 23.58it/s]Training:  30%|███       | 488/1600 [00:20<00:45, 24.52it/s]Training:  46%|████▋     | 740/1600 [00:30<00:35, 24.18it/s]Training:  61%|██████    | 978/1600 [00:41<00:26, 23.61it/s]Training:  76%|███████▌  | 1217/1600 [00:51<00:16, 23.68it/s]Training:  91%|█████████ | 1458/1600 [01:01<00:05, 23.80it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  1Training loss: 5532.4884, Training accuracy: 0.4288
Macro F1-score: 0.4119
Model performance on Angry speech (in training): 
	Precision: 0.6769, Recall: 0.2200, F1_score: 0.3321
Model performance on Happy speech (in training): 
	Precision: 0.3191, Recall: 0.8750, F1_score: 0.4676
Model performance on Neutral speech (in training): 
	Precision: 0.5735, Recall: 0.3025, F1_score: 0.3961
Model performance on Sad speech (in training): 
	Precision: 0.7840, Recall: 0.3175, F1_score: 0.4520

Eval Phase: 
Validation loss: 426.3878, Validation accuracy: 0.6100
Macro F1-score: 0.6043
Model performance on Angry speech (in validation): 
	Precision: 0.6750, Recall: 0.5400, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.5714, Recall: 0.7200, F1_score: 0.6372
Model performance on Neutral speech (in validation): 
	Precision: 0.6875, Recall: 0.4400, F1_score: 0.5366
Model performance on Sad speech (in validation): 
	Precision: 0.5692, Recall: 0.7400, F1_score: 0.6435
Epoch 30/100

Training Phase:
6%|█▌        | 255/1600 [00:10<00:52, 25.48it/s]Training:  32%|███▏      | 510/1600 [00:20<00:43, 25.15it/s]Training:  48%|████▊     | 761/1600 [00:30<00:33, 25.09it/s]Training:  63%|██████▎   | 1012/1600 [00:40<00:23, 24.96it/s]Training:  79%|███████▉  | 1260/1600 [00:51<00:14, 24.27it/s]Training:  93%|█████████▎| 1492/1600 [01:01<00:04, 23.75it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 241/1600 [00:10<00:56, 24.09it/s]Training:  30%|███       | 482/1600 [00:20<00:48, 23.21it/s]Training:  45%|████▍     | 714/1600 [00:30<00:38, 23.17it/s]Training:  59%|█████▉    | 949/1600 [00:40<00:27, 23.26it/s]Training:  74%|███████▍  | 1184/1600 [00:50<00:17, 23.24it/s]Training:  89%|██Training loss: 5569.3272, Training accuracy: 0.4306
Macro F1-score: 0.4136
Model performance on Angry speech (in training): 
	Precision: 0.6288, Recall: 0.2075, F1_score: 0.3120
Model performance on Happy speech (in training): 
	Precision: 0.3202, Recall: 0.8725, F1_score: 0.4685
Model performance on Neutral speech (in training): 
	Precision: 0.6027, Recall: 0.3300, F1_score: 0.4265
Model performance on Sad speech (in training): 
	Precision: 0.7862, Recall: 0.3125, F1_score: 0.4472

Eval Phase: 
Validation loss: 426.3878, Validation accuracy: 0.6100
Macro F1-score: 0.6043
Model performance on Angry speech (in validation): 
	Precision: 0.6750, Recall: 0.5400, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.5714, Recall: 0.7200, F1_score: 0.6372
Model performance on Neutral speech (in validation): 
	Precision: 0.6875, Recall: 0.4400, F1_score: 0.5366
Model performance on Sad speech (in validation): 
	Precision: 0.5692, Recall: 0.7400, F1_score: 0.6435
Epoch 31/100

Training Phase:
Training loss: 5549.1009, Training accuracy: 0.4275
Macro F1-score: 0.4104
Model performance on Angry speech (in training): 
	Precision: 0.6142, Recall: 0.1950, F1_score: 0.2960
Model performance on Happy speech (in training): 
	Precision: 0.3177, Recall: 0.8650, F1_score: 0.4647
Model performance on Neutral speech (in training): 
	Precision: 0.5880, Recall: 0.3175, F1_score: 0.4123
Model performance on Sad speech (in training): 
	Precision: 0.7917, Recall: 0.3325, F1_score: 0.4683

Eval Phase: 
Validation loss: 426.3878, Validation accuracy: 0.6100
Macro F1-score: 0.6043
Model performance on Angry speech (in validation): 
	Precision: 0.6750, Recall: 0.5400, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.5714, Recall: 0.7200, F1_score: 0.6372
Model performance on Neutral speech (in validation): 
	Precision: 0.6875, Recall: 0.4400, F1_score: 0.5366
Model performance on Sad speech (in validation): 
	Precision: 0.5692, Recall: 0.7400, F1_score: 0.6435
Epoch 32/100

Training Phase:
█████▊ | 1417/1600 [01:01<00:08, 22.71it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 232/1600 [00:10<00:59, 23.11it/s]Training:  29%|██▉       | 468/1600 [00:20<00:48, 23.36it/s]Training:  44%|████▍     | 704/1600 [00:30<00:38, 23.35it/s]Training:  59%|█████▊    | 938/1600 [00:40<00:28, 23.10it/s]Training:  73%|███████▎  | 1166/1600 [00:50<00:18, 22.98it/s]Training:  87%|████████▋ | 1395/1600 [01:00<00:08, 22.94it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 237/1600 [00:10<00:57, 23.63it/s]Training:  31%|███     Training loss: 5477.4067, Training accuracy: 0.4300
Macro F1-score: 0.4138
Model performance on Angry speech (in training): 
	Precision: 0.6172, Recall: 0.1975, F1_score: 0.2992
Model performance on Happy speech (in training): 
	Precision: 0.3174, Recall: 0.8650, F1_score: 0.4644
Model performance on Neutral speech (in training): 
	Precision: 0.6045, Recall: 0.3325, F1_score: 0.4290
Model performance on Sad speech (in training): 
	Precision: 0.8025, Recall: 0.3250, F1_score: 0.4626

Eval Phase: 
Validation loss: 426.3878, Validation accuracy: 0.6100
Macro F1-score: 0.6043
Model performance on Angry speech (in validation): 
	Precision: 0.6750, Recall: 0.5400, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.5714, Recall: 0.7200, F1_score: 0.6372
Model performance on Neutral speech (in validation): 
	Precision: 0.6875, Recall: 0.4400, F1_score: 0.5366
Model performance on Sad speech (in validation): 
	Precision: 0.5692, Recall: 0.7400, F1_score: 0.6435
Epoch 33/100

Training Phase:
  | 493/1600 [00:20<00:44, 24.77it/s]Training:  47%|████▋     | 751/1600 [00:30<00:33, 25.20it/s]Training:  47%|████▋     | 751/1600 [00:40<00:33, 25.20it/s]Training:  63%|██████▎   | 1007/1600 [00:40<00:23, 25.32it/s]Training:  79%|███████▉  | 1265/1600 [00:50<00:13, 25.47it/s]Training:  95%|█████████▌| 1523/1600 [01:00<00:03, 25.13it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 255/1600 [00:10<00:52, 25.38it/s]Training:  32%|███▏      | 514/1600 [00:20<00:42, 25.65it/s]Training:  48%|████▊     | 775/1600 [00:30<00:31, 25.85it/s]Training:  65%|██████▍   | 1036/1600 [00:40<00:21, 25.81it/s]Training:  81%|████████  | 1294/1600 [00:50<00:11, 25.76it/s]Training:  97%|█████Training loss: 5533.0589, Training accuracy: 0.4275
Macro F1-score: 0.4117
Model performance on Angry speech (in training): 
	Precision: 0.6250, Recall: 0.2125, F1_score: 0.3172
Model performance on Happy speech (in training): 
	Precision: 0.3168, Recall: 0.8625, F1_score: 0.4634
Model performance on Neutral speech (in training): 
	Precision: 0.5981, Recall: 0.3200, F1_score: 0.4169
Model performance on Sad speech (in training): 
	Precision: 0.7826, Recall: 0.3150, F1_score: 0.4492

Eval Phase: 
Validation loss: 426.3878, Validation accuracy: 0.6100
Macro F1-score: 0.6043
Model performance on Angry speech (in validation): 
	Precision: 0.6750, Recall: 0.5400, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.5714, Recall: 0.7200, F1_score: 0.6372
Model performance on Neutral speech (in validation): 
	Precision: 0.6875, Recall: 0.4400, F1_score: 0.5366
Model performance on Sad speech (in validation): 
	Precision: 0.5692, Recall: 0.7400, F1_score: 0.6435
Epoch 34/100

Training Phase:
Training loss: 5576.2345, Training accuracy: 0.4250
Macro F1-score: 0.4080
Model performance on Angry speech (in training): 
	Precision: 0.6667, Recall: 0.2250, F1_score: 0.3364
Model performance on Happy speech (in training): 
	Precision: 0.3181, Recall: 0.8675, F1_score: 0.4655
Model performance on Neutral speech (in training): 
	Precision: 0.5625, Recall: 0.2925, F1_score: 0.3849
Model performance on Sad speech (in training): 
	Precision: 0.7590, Recall: 0.3150, F1_score: 0.4452

Eval Phase: 
Validation loss: 426.3878, Validation accuracy: 0.6100
Macro F1-score: 0.6043
Model performance on Angry speech (in validation): 
	Precision: 0.6750, Recall: 0.5400, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.5714, Recall: 0.7200, F1_score: 0.6372
Model performance on Neutral speech (in validation): 
	Precision: 0.6875, Recall: 0.4400, F1_score: 0.5366
Model performance on Sad speech (in validation): 
	Precision: 0.5692, Recall: 0.7400, F1_score: 0.6435
Epoch 35/100

Training Phase:
████▋| 1556/1600 [01:00<00:01, 25.89it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▋        | 260/1600 [00:10<00:51, 25.99it/s]Training:  32%|███▎      | 520/1600 [00:20<00:41, 25.86it/s]Training:  49%|████▉     | 780/1600 [00:30<00:31, 25.89it/s]Training:  65%|██████▌   | 1040/1600 [00:40<00:21, 25.86it/s]Training:  65%|██████▌   | 1040/1600 [00:50<00:21, 25.86it/s]Training:  81%|████████  | 1297/1600 [00:50<00:11, 25.31it/s]Training:  96%|█████████▋| 1542/1600 [01:00<00:02, 25.03it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|Training loss: 5523.3790, Training accuracy: 0.4275
Macro F1-score: 0.4095
Model performance on Angry speech (in training): 
	Precision: 0.6515, Recall: 0.2150, F1_score: 0.3233
Model performance on Happy speech (in training): 
	Precision: 0.3211, Recall: 0.8725, F1_score: 0.4694
Model performance on Neutral speech (in training): 
	Precision: 0.5676, Recall: 0.3150, F1_score: 0.4051
Model performance on Sad speech (in training): 
	Precision: 0.7736, Recall: 0.3075, F1_score: 0.4401

Eval Phase: 
Validation loss: 426.3878, Validation accuracy: 0.6100
Macro F1-score: 0.6043
Model performance on Angry speech (in validation): 
	Precision: 0.6750, Recall: 0.5400, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.5714, Recall: 0.7200, F1_score: 0.6372
Model performance on Neutral speech (in validation): 
	Precision: 0.6875, Recall: 0.4400, F1_score: 0.5366
Model performance on Sad speech (in validation): 
	Precision: 0.5692, Recall: 0.7400, F1_score: 0.6435
Epoch 36/100

Training Phase:
▌        | 245/1600 [00:10<00:55, 24.43it/s]Training:  32%|███▏      | 504/1600 [00:20<00:43, 25.26it/s]Training:  48%|████▊     | 763/1600 [00:30<00:33, 25.29it/s]Training:  64%|██████▎   | 1017/1600 [00:40<00:23, 25.19it/s]Training:  80%|███████▉  | 1272/1600 [00:50<00:12, 25.28it/s]Training:  95%|█████████▌| 1527/1600 [01:00<00:02, 24.94it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 257/1600 [00:10<00:52, 25.67it/s]Training:  32%|███▏      | 514/1600 [00:20<00:44, 24.58it/s]Training:  47%|████▋     | 753/1600 [00:31<00:35, 23.96it/s]Training:  62%|██████▏   | 986/1600 [00:41<00:25, 23.66it/s]Training:  76%|███████▋  | 1220/1600 [00:51<00:16, 23.56it/s]Training:  91%|██Training loss: 5515.9608, Training accuracy: 0.4294
Macro F1-score: 0.4091
Model performance on Angry speech (in training): 
	Precision: 0.6562, Recall: 0.2100, F1_score: 0.3182
Model performance on Happy speech (in training): 
	Precision: 0.3236, Recall: 0.8900, F1_score: 0.4747
Model performance on Neutral speech (in training): 
	Precision: 0.5864, Recall: 0.3225, F1_score: 0.4161
Model performance on Sad speech (in training): 
	Precision: 0.7763, Recall: 0.2950, F1_score: 0.4275

Eval Phase: 
Validation loss: 426.3878, Validation accuracy: 0.6100
Macro F1-score: 0.6043
Model performance on Angry speech (in validation): 
	Precision: 0.6750, Recall: 0.5400, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.5714, Recall: 0.7200, F1_score: 0.6372
Model performance on Neutral speech (in validation): 
	Precision: 0.6875, Recall: 0.4400, F1_score: 0.5366
Model performance on Sad speech (in validation): 
	Precision: 0.5692, Recall: 0.7400, F1_score: 0.6435
Epoch 37/100

Training Phase:
Training loss: 5555.0367, Training accuracy: 0.4256
Macro F1-score: 0.4063
Model performance on Angry speech (in training): 
	Precision: 0.6613, Recall: 0.2050, F1_score: 0.3130
Model performance on Happy speech (in training): 
	Precision: 0.3197, Recall: 0.8775, F1_score: 0.4686
Model performance on Neutral speech (in training): 
	Precision: 0.5695, Recall: 0.3175, F1_score: 0.4077
Model performance on Sad speech (in training): 
	Precision: 0.7806, Recall: 0.3025, F1_score: 0.4360

Eval Phase: 
Validation loss: 426.3878, Validation accuracy: 0.6100
Macro F1-score: 0.6043
Model performance on Angry speech (in validation): 
	Precision: 0.6750, Recall: 0.5400, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.5714, Recall: 0.7200, F1_score: 0.6372
Model performance on Neutral speech (in validation): 
	Precision: 0.6875, Recall: 0.4400, F1_score: 0.5366
Model performance on Sad speech (in validation): 
	Precision: 0.5692, Recall: 0.7400, F1_score: 0.6435
Epoch 38/100

Training Phase:
██████ | 1455/1600 [01:01<00:06, 23.52it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 238/1600 [00:10<00:57, 23.78it/s]Training:  15%|█▍        | 238/1600 [00:20<00:57, 23.78it/s]Training:  30%|██▉       | 474/1600 [00:20<00:47, 23.65it/s]Training:  45%|████▍     | 714/1600 [00:30<00:37, 23.78it/s]Training:  60%|█████▉    | 954/1600 [00:40<00:27, 23.85it/s]Training:  75%|███████▍  | 1194/1600 [00:50<00:16, 23.89it/s]Training:  90%|█████████ | 1448/1600 [01:00<00:06, 24.40it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        |Training loss: 5531.1881, Training accuracy: 0.4256
Macro F1-score: 0.4075
Model performance on Angry speech (in training): 
	Precision: 0.6124, Recall: 0.1975, F1_score: 0.2987
Model performance on Happy speech (in training): 
	Precision: 0.3178, Recall: 0.8700, F1_score: 0.4656
Model performance on Neutral speech (in training): 
	Precision: 0.5880, Recall: 0.3175, F1_score: 0.4123
Model performance on Sad speech (in training): 
	Precision: 0.7937, Recall: 0.3175, F1_score: 0.4536

Eval Phase: 
Validation loss: 426.3878, Validation accuracy: 0.6100
Macro F1-score: 0.6043
Model performance on Angry speech (in validation): 
	Precision: 0.6750, Recall: 0.5400, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.5714, Recall: 0.7200, F1_score: 0.6372
Model performance on Neutral speech (in validation): 
	Precision: 0.6875, Recall: 0.4400, F1_score: 0.5366
Model performance on Sad speech (in validation): 
	Precision: 0.5692, Recall: 0.7400, F1_score: 0.6435
Epoch 39/100

Training Phase:
 259/1600 [00:10<00:51, 25.86it/s]Training:  32%|███▏      | 518/1600 [00:20<00:41, 25.78it/s]Training:  48%|████▊     | 776/1600 [00:30<00:32, 25.40it/s]Training:  65%|██████▍   | 1035/1600 [00:40<00:22, 25.56it/s]Training:  81%|████████  | 1294/1600 [00:50<00:12, 25.36it/s]Training:  97%|█████████▋| 1545/1600 [01:01<00:02, 24.65it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 238/1600 [00:10<00:57, 23.78it/s]Training:  30%|██▉       | 478/1600 [00:20<00:47, 23.87it/s]Training:  45%|████▍     | 718/1600 [00:30<00:37, 23.74it/s]Training:  60%|█████▉    | 959/1600 [00:40<00:26, 23.84it/s]Training:  75%|███████▌  | 1201/1600 [00:50<00:16, 23.95it/s]Training:  90%|████████Training loss: 5481.9720, Training accuracy: 0.4319
Macro F1-score: 0.4139
Model performance on Angry speech (in training): 
	Precision: 0.6560, Recall: 0.2050, F1_score: 0.3124
Model performance on Happy speech (in training): 
	Precision: 0.3215, Recall: 0.8825, F1_score: 0.4713
Model performance on Neutral speech (in training): 
	Precision: 0.5935, Recall: 0.3175, F1_score: 0.4137
Model performance on Sad speech (in training): 
	Precision: 0.7914, Recall: 0.3225, F1_score: 0.4583

Eval Phase: 
Validation loss: 426.3878, Validation accuracy: 0.6100
Macro F1-score: 0.6043
Model performance on Angry speech (in validation): 
	Precision: 0.6750, Recall: 0.5400, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.5714, Recall: 0.7200, F1_score: 0.6372
Model performance on Neutral speech (in validation): 
	Precision: 0.6875, Recall: 0.4400, F1_score: 0.5366
Model performance on Sad speech (in validation): 
	Precision: 0.5692, Recall: 0.7400, F1_score: 0.6435
Epoch 40/100

Training Phase:
Training loss: 5552.7798, Training accuracy: 0.4288
Macro F1-score: 0.4114
Model performance on Angry speech (in training): 
	Precision: 0.6496, Recall: 0.2225, F1_score: 0.3315
Model performance on Happy speech (in training): 
	Precision: 0.3211, Recall: 0.8750, F1_score: 0.4698
Model performance on Neutral speech (in training): 
	Precision: 0.5734, Recall: 0.3125, F1_score: 0.4045
Model performance on Sad speech (in training): 
	Precision: 0.7871, Recall: 0.3050, F1_score: 0.4396

Eval Phase: 
Validation loss: 426.3878, Validation accuracy: 0.6100
Macro F1-score: 0.6043
Model performance on Angry speech (in validation): 
	Precision: 0.6750, Recall: 0.5400, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.5714, Recall: 0.7200, F1_score: 0.6372
Model performance on Neutral speech (in validation): 
	Precision: 0.6875, Recall: 0.4400, F1_score: 0.5366
Model performance on Sad speech (in validation): 
	Precision: 0.5692, Recall: 0.7400, F1_score: 0.6435
Epoch 41/100

Training Phase:
 | 1445/1600 [01:00<00:06, 24.10it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 239/1600 [00:10<00:57, 23.82it/s]Training:  31%|███       | 489/1600 [00:20<00:45, 24.50it/s]Training:  47%|████▋     | 748/1600 [00:30<00:33, 25.10it/s]Training:  47%|████▋     | 748/1600 [00:40<00:33, 25.10it/s]Training:  63%|██████▎   | 1007/1600 [00:40<00:23, 25.31it/s]Training:  63%|██████▎   | 1007/1600 [00:50<00:23, 25.31it/s]Training:  78%|███████▊  | 1255/1600 [00:50<00:13, 25.10it/s]Training:  95%|█████████▍| 1516/1600 [01:00<00:03, 25.44it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:  Training loss: 5535.5238, Training accuracy: 0.4288
Macro F1-score: 0.4110
Model performance on Angry speech (in training): 
	Precision: 0.6250, Recall: 0.2125, F1_score: 0.3172
Model performance on Happy speech (in training): 
	Precision: 0.3217, Recall: 0.8725, F1_score: 0.4700
Model performance on Neutral speech (in training): 
	Precision: 0.5865, Recall: 0.3050, F1_score: 0.4013
Model performance on Sad speech (in training): 
	Precision: 0.7602, Recall: 0.3250, F1_score: 0.4553

Eval Phase: 
Validation loss: 426.3878, Validation accuracy: 0.6100
Macro F1-score: 0.6043
Model performance on Angry speech (in validation): 
	Precision: 0.6750, Recall: 0.5400, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.5714, Recall: 0.7200, F1_score: 0.6372
Model performance on Neutral speech (in validation): 
	Precision: 0.6875, Recall: 0.4400, F1_score: 0.5366
Model performance on Sad speech (in validation): 
	Precision: 0.5692, Recall: 0.7400, F1_score: 0.6435
Epoch 42/100

Training Phase:
 0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 241/1600 [00:10<00:56, 24.01it/s]Training:  30%|███       | 482/1600 [00:20<00:46, 23.95it/s]Training:  45%|████▌     | 722/1600 [00:30<00:36, 23.75it/s]Training:  60%|██████    | 963/1600 [00:40<00:26, 23.88it/s]Training:  76%|███████▌  | 1216/1600 [00:50<00:15, 24.36it/s]Training:  92%|█████████▏| 1470/1600 [01:00<00:05, 24.69it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 240/1600 [00:10<00:56, 23.93it/s]Training:  30%|███       | 481/1600 [00:20<00:46, 24.02it/s]Training:  45%|████▌     | 722/1600 [00:30<00:36, 23.89it/s]Training:  60%|██████    | 964/1600 [00:40<00:26, 23.97it/s]Training:  75%|███████▌  | 1205/1600 Training loss: 5502.2487, Training accuracy: 0.4400
Macro F1-score: 0.4244
Model performance on Angry speech (in training): 
	Precision: 0.6667, Recall: 0.2250, F1_score: 0.3364
Model performance on Happy speech (in training): 
	Precision: 0.3251, Recall: 0.8850, F1_score: 0.4755
Model performance on Neutral speech (in training): 
	Precision: 0.6121, Recall: 0.3275, F1_score: 0.4267
Model performance on Sad speech (in training): 
	Precision: 0.7963, Recall: 0.3225, F1_score: 0.4591

Eval Phase: 
Validation loss: 426.3878, Validation accuracy: 0.6100
Macro F1-score: 0.6043
Model performance on Angry speech (in validation): 
	Precision: 0.6750, Recall: 0.5400, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.5714, Recall: 0.7200, F1_score: 0.6372
Model performance on Neutral speech (in validation): 
	Precision: 0.6875, Recall: 0.4400, F1_score: 0.5366
Model performance on Sad speech (in validation): 
	Precision: 0.5692, Recall: 0.7400, F1_score: 0.6435
Epoch 43/100

Training Phase:
Training loss: 5515.3949, Training accuracy: 0.4275
Macro F1-score: 0.4117
Model performance on Angry speech (in training): 
	Precision: 0.6541, Recall: 0.2175, F1_score: 0.3265
Model performance on Happy speech (in training): 
	Precision: 0.3179, Recall: 0.8600, F1_score: 0.4642
Model performance on Neutral speech (in training): 
	Precision: 0.5670, Recall: 0.3175, F1_score: 0.4071
Model performance on Sad speech (in training): 
	Precision: 0.7826, Recall: 0.3150, F1_score: 0.4492

Eval Phase: 
Validation loss: 426.3878, Validation accuracy: 0.6100
Macro F1-score: 0.6043
Model performance on Angry speech (in validation): 
	Precision: 0.6750, Recall: 0.5400, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.5714, Recall: 0.7200, F1_score: 0.6372
Model performance on Neutral speech (in validation): 
	Precision: 0.6875, Recall: 0.4400, F1_score: 0.5366
Model performance on Sad speech (in validation): 
	Precision: 0.5692, Recall: 0.7400, F1_score: 0.6435
Epoch 44/100

Training Phase:
[00:50<00:16, 23.99it/s]Training:  90%|█████████ | 1446/1600 [01:00<00:06, 24.00it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 249/1600 [00:10<00:54, 24.85it/s]Training:  32%|███▏      | 509/1600 [00:20<00:42, 25.50it/s]Training:  48%|████▊     | 769/1600 [00:30<00:33, 24.76it/s]Training:  64%|██████▍   | 1027/1600 [00:40<00:22, 25.15it/s]Training:  80%|████████  | 1285/1600 [00:51<00:12, 25.24it/s]Training:  96%|█████████▋| 1540/1600 [01:01<00:02, 25.16it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▋        | 261/1600 Training loss: 5547.4756, Training accuracy: 0.4281
Macro F1-score: 0.4106
Model performance on Angry speech (in training): 
	Precision: 0.6357, Recall: 0.2050, F1_score: 0.3100
Model performance on Happy speech (in training): 
	Precision: 0.3185, Recall: 0.8750, F1_score: 0.4670
Model performance on Neutral speech (in training): 
	Precision: 0.5907, Recall: 0.3175, F1_score: 0.4130
Model performance on Sad speech (in training): 
	Precision: 0.8025, Recall: 0.3150, F1_score: 0.4524

Eval Phase: 
Validation loss: 426.3878, Validation accuracy: 0.6100
Macro F1-score: 0.6043
Model performance on Angry speech (in validation): 
	Precision: 0.6750, Recall: 0.5400, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.5714, Recall: 0.7200, F1_score: 0.6372
Model performance on Neutral speech (in validation): 
	Precision: 0.6875, Recall: 0.4400, F1_score: 0.5366
Model performance on Sad speech (in validation): 
	Precision: 0.5692, Recall: 0.7400, F1_score: 0.6435
Epoch 45/100

Training Phase:
[00:10<00:51, 26.05it/s]Training:  33%|███▎      | 522/1600 [00:20<00:41, 25.86it/s]Training:  49%|████▉     | 781/1600 [00:30<00:31, 25.87it/s]Training:  49%|████▉     | 781/1600 [00:40<00:31, 25.87it/s]Training:  65%|██████▍   | 1038/1600 [00:40<00:22, 25.54it/s]Training:  81%|████████▏ | 1300/1600 [00:50<00:11, 25.77it/s]Training:  98%|█████████▊| 1562/1600 [01:00<00:01, 25.77it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 247/1600 [00:10<00:54, 24.68it/s]Training:  31%|███       | 495/1600 [00:20<00:44, 24.71it/s]Training:  46%|████▋     | 743/1600 [00:30<00:35, 24.19it/s]Training:  61%|██████▏   | 980/1600 [00:40<00:25, 23.94it/s]Training:  76%|███████▋  | 1222/1600 Training loss: 5539.6597, Training accuracy: 0.4319
Macro F1-score: 0.4151
Model performance on Angry speech (in training): 
	Precision: 0.6641, Recall: 0.2175, F1_score: 0.3277
Model performance on Happy speech (in training): 
	Precision: 0.3217, Recall: 0.8750, F1_score: 0.4704
Model performance on Neutral speech (in training): 
	Precision: 0.5818, Recall: 0.3200, F1_score: 0.4129
Model performance on Sad speech (in training): 
	Precision: 0.7826, Recall: 0.3150, F1_score: 0.4492

Eval Phase: 
Validation loss: 426.3878, Validation accuracy: 0.6100
Macro F1-score: 0.6043
Model performance on Angry speech (in validation): 
	Precision: 0.6750, Recall: 0.5400, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.5714, Recall: 0.7200, F1_score: 0.6372
Model performance on Neutral speech (in validation): 
	Precision: 0.6875, Recall: 0.4400, F1_score: 0.5366
Model performance on Sad speech (in validation): 
	Precision: 0.5692, Recall: 0.7400, F1_score: 0.6435
Epoch 46/100

Training Phase:
Training loss: 5545.5688, Training accuracy: 0.4350
Macro F1-score: 0.4198
Model performance on Angry speech (in training): 
	Precision: 0.6562, Recall: 0.2100, F1_score: 0.3182
Model performance on Happy speech (in training): 
	Precision: 0.3193, Recall: 0.8750, F1_score: 0.4679
Model performance on Neutral speech (in training): 
	Precision: 0.6143, Recall: 0.3225, F1_score: 0.4230
Model performance on Sad speech (in training): 
	Precision: 0.8012, Recall: 0.3325, F1_score: 0.4700

Eval Phase: 
Validation loss: 426.3878, Validation accuracy: 0.6100
Macro F1-score: 0.6043
Model performance on Angry speech (in validation): 
	Precision: 0.6750, Recall: 0.5400, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.5714, Recall: 0.7200, F1_score: 0.6372
Model performance on Neutral speech (in validation): 
	Precision: 0.6875, Recall: 0.4400, F1_score: 0.5366
Model performance on Sad speech (in validation): 
	Precision: 0.5692, Recall: 0.7400, F1_score: 0.6435
Epoch 47/100

Training Phase:
[00:50<00:15, 24.00it/s]Training:  92%|█████████▏| 1464/1600 [01:00<00:05, 23.99it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 241/1600 [00:10<00:56, 24.07it/s]Training:  30%|███       | 484/1600 [00:20<00:46, 24.20it/s]Training:  46%|████▌     | 728/1600 [00:30<00:35, 24.26it/s]Training:  46%|████▌     | 728/1600 [00:40<00:35, 24.26it/s]Training:  61%|██████    | 970/1600 [00:40<00:26, 24.19it/s]Training:  76%|███████▌  | 1217/1600 [00:50<00:15, 24.37it/s]Training:  92%|█████████▏| 1475/1600 [01:00<00:05, 24.84it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|        Training loss: 5535.8951, Training accuracy: 0.4281
Macro F1-score: 0.4111
Model performance on Angry speech (in training): 
	Precision: 0.6391, Recall: 0.2125, F1_score: 0.3189
Model performance on Happy speech (in training): 
	Precision: 0.3193, Recall: 0.8700, F1_score: 0.4671
Model performance on Neutral speech (in training): 
	Precision: 0.5849, Recall: 0.3100, F1_score: 0.4052
Model performance on Sad speech (in training): 
	Precision: 0.7758, Recall: 0.3200, F1_score: 0.4531

Eval Phase: 
Validation loss: 426.3878, Validation accuracy: 0.6100
Macro F1-score: 0.6043
Model performance on Angry speech (in validation): 
	Precision: 0.6750, Recall: 0.5400, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.5714, Recall: 0.7200, F1_score: 0.6372
Model performance on Neutral speech (in validation): 
	Precision: 0.6875, Recall: 0.4400, F1_score: 0.5366
Model performance on Sad speech (in validation): 
	Precision: 0.5692, Recall: 0.7400, F1_score: 0.6435
Epoch 48/100

Training Phase:
  | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 239/1600 [00:10<00:57, 23.83it/s]Training:  30%|███       | 480/1600 [00:20<00:46, 23.97it/s]Training:  45%|████▌     | 721/1600 [00:30<00:36, 23.99it/s]Training:  60%|██████    | 962/1600 [00:40<00:26, 23.86it/s]Training:  75%|███████▌  | 1202/1600 [00:50<00:16, 23.90it/s]Training:  91%|█████████ | 1453/1600 [01:00<00:06, 24.31it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 241/1600 [00:10<00:56, 24.05it/s]Training:  30%|███       | 485/1600 [00:20<00:46, 24.22it/s]Training:  46%|████▌     | 729/1600 [00:30<00:35, 24.27it/s]Training:  61%|██████    | 973/1600 [00:40<00:25, 24.26it/s]Training:  76%|███████▌  | 1216/1600 [00:50<00:15, Training loss: 5498.2505, Training accuracy: 0.4387
Macro F1-score: 0.4228
Model performance on Angry speech (in training): 
	Precision: 0.6507, Recall: 0.2375, F1_score: 0.3480
Model performance on Happy speech (in training): 
	Precision: 0.3266, Recall: 0.8850, F1_score: 0.4771
Model performance on Neutral speech (in training): 
	Precision: 0.6066, Recall: 0.3200, F1_score: 0.4190
Model performance on Sad speech (in training): 
	Precision: 0.7862, Recall: 0.3125, F1_score: 0.4472

Eval Phase: 
Validation loss: 426.3878, Validation accuracy: 0.6100
Macro F1-score: 0.6043
Model performance on Angry speech (in validation): 
	Precision: 0.6750, Recall: 0.5400, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.5714, Recall: 0.7200, F1_score: 0.6372
Model performance on Neutral speech (in validation): 
	Precision: 0.6875, Recall: 0.4400, F1_score: 0.5366
Model performance on Sad speech (in validation): 
	Precision: 0.5692, Recall: 0.7400, F1_score: 0.6435
Epoch 49/100

Training Phase:
Training loss: 5511.1674, Training accuracy: 0.4313
Macro F1-score: 0.4129
Model performance on Angry speech (in training): 
	Precision: 0.6593, Recall: 0.2225, F1_score: 0.3327
Model performance on Happy speech (in training): 
	Precision: 0.3250, Recall: 0.8800, F1_score: 0.4747
Model performance on Neutral speech (in training): 
	Precision: 0.5664, Recall: 0.3200, F1_score: 0.4089
Model performance on Sad speech (in training): 
	Precision: 0.7756, Recall: 0.3025, F1_score: 0.4353

Eval Phase: 
Validation loss: 426.3878, Validation accuracy: 0.6100
Macro F1-score: 0.6043
Model performance on Angry speech (in validation): 
	Precision: 0.6750, Recall: 0.5400, F1_score: 0.6000
Model performance on Happy speech (in validation): 
	Precision: 0.5714, Recall: 0.7200, F1_score: 0.6372
Model performance on Neutral speech (in validation): 
	Precision: 0.6875, Recall: 0.4400, F1_score: 0.5366
Model performance on Sad speech (in validation): 
	Precision: 0.5692, Recall: 0.7400, F1_score: 0.6435
Epoch 50/100

Two-stage training complete.
Model best accuracy on validation set: 0.6100

Test Phase: 
24.13it/s]Training:  91%|█████████ | 1457/1600 [01:00<00:05, 24.09it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 242/1600 [00:10<00:56, 24.19it/s]Training:  30%|███       | 484/1600 [00:20<00:46, 24.10it/s]Training:  45%|████▌     | 725/1600 [00:30<00:36, 23.87it/s]Training:  61%|██████    | 974/1600 [00:40<00:25, 24.25it/s]Training:  76%|███████▋  | 1224/1600 [00:50<00:15, 24.50it/s]Training:  92%|█████████▏| 1474/1600 [01:00<00:05, 24.50it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]Testing:   2%|▏         | 3/200 [00:00<00:08, 24.55it/s]Testing:   3%|▎         | 6/200 [00:00<00:07, 24.79it/s]Testing:   6%|▌         | 11/200 [00:00<00:06, 30.30it/s]Testing:   7%|▋         | 14/200 [00:00<00:06, 30.06it/s]Testing:   8%|▊         | 17/200 [00:00<00:06, 29.28it/s]Testing:  10%|█         | 20/200 [00:00<00:06, 28.27it/s]Testing:  13%|█▎        | 26/200 [00:00<00:04, 35.41it/s]Testing:  15%|█▌        | 30/200 [00:00<00:05, 33.83it/s]Testing:  18%|█▊        | 36/200 [00:01<00:04, 39.73it/s]Testing:  21%|██        | 42/200 [00:01<00:03, 45.22it/s]Testing:  24%|██▍       | 48/200 [00:01<00:03, 48.63it/s]Testing:  28%|██▊       | 55/200 [00:01<00:02, 52.10it/s]Testing:  30%|███       | 61/200 [00:01<00:02, 50.08it/s]Testing:  34%|███▍      | 69/200 [00:01<00:02, 57.10it/s]Testing:  38%|███▊      | 75/200 [00:01<00:02, 57.67it/s]Testing:  40%|████      | 81/200 [00:01<00:02, 54.30it/s]Testing:  44%|████▎     | 87/200 [00:02<00:02, 47.49it/s]Testing:  48%|██Test loss: 449.7484, Test accuracy: 0.5500
Macro F1-score: 0.5433
Model performance on Angry speech (in test): 
	Precision: 0.5750, Recall: 0.4600, F1_score: 0.5111
Model performance on Happy speech (in test): 
	Precision: 0.5397, Recall: 0.6800, F1_score: 0.6018
Model performance on Neutral speech (in test): 
	Precision: 0.5882, Recall: 0.4000, F1_score: 0.4762
Model performance on Sad speech (in test): 
	Precision: 0.5238, Recall: 0.6600, F1_score: 0.5841

======================= This is fold_3 on de =======================

Load dataset: 
Loading de train data: fold_3...
Preprocess de fold_3 data for de model
Loading cn eval data: fold_3...
Preprocess cn fold_3 data for de model
Loading cn test data: fold_3...
Preprocess cn fold_3 data for de model
Use de model to add lora
================== SET ALL PARAMS =====================
modified_wav2vec2.base_model.model.masked_spec_embed: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.0.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.0.layer_norm.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.0.layer_norm.bias: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.1.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.2.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.3.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.4.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.5.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.6.conv.weight: False
modified_wav2vec2.base_model.model.feature_projection.layer_norm.weight: False
modified_wav2vec2.base_model.model.feature_projection.layer_norm.bias: False
modified_wav2vec2.base_model.model.feature_projection.projection.weight: False
modified_wav2vec2.base_model.model.feature_projection.projection.bias: False
modified_wav2vec2.base_model.model.encoder.pos_conv_embed.conv.bias: False
modified_wav2vec2.base_model.model.encoder.pos_conv_embed.conv.weight_g: False
modified_wav2vec2.base_model.model.encoder.pos_conv_embed.conv.weight_v: False
modified_wav2vec2.base_model.model.encoder.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.up.bias: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.up.bias: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.up.bias: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.up.bias: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.4.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.4.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.bottleneck_adaptor.up.bias: True
normal_classifier.dense1.weight: True
normal_classifier.dense1.bias: True
normal_classifier.dense.weight: True
normal_classifier.dense.bias: True
normal_classifier.out.weight: True
normal_classifier.out.bias: True
Set optimizer and criterion
Epoch 1/100

Training Phase:
█▊     | 96/200 [00:02<00:01, 57.44it/s]Testing:  52%|█████▏    | 104/200 [00:02<00:01, 63.25it/s]Testing:  56%|█████▋    | 113/200 [00:02<00:01, 70.02it/s]Testing:  60%|██████    | 121/200 [00:02<00:01, 70.33it/s]Testing:  64%|██████▍   | 129/200 [00:02<00:01, 66.86it/s]Testing:  68%|██████▊   | 136/200 [00:02<00:00, 66.76it/s]Testing:  72%|███████▏  | 143/200 [00:02<00:00, 65.98it/s]Testing:  76%|███████▌  | 152/200 [00:02<00:00, 68.10it/s]Testing:  80%|████████  | 161/200 [00:03<00:00, 70.27it/s]Testing:  84%|████████▍ | 169/200 [00:03<00:00, 71.61it/s]Testing:  89%|████████▉ | 178/200 [00:03<00:00, 76.63it/s]Testing:  93%|█████████▎| 186/200 [00:03<00:00, 70.29it/s]Testing:  98%|█████████▊| 196/200 [00:03<00:00, 77.11it/s]                                                          Training:   0%|      Training loss: 303.7509, Training accuracy: 0.9325
Macro F1-score: 0.9323
Model performance on Angry speech (in training): 
	Precision: 0.9279, Recall: 0.9325, F1_score: 0.9302
Model performance on Happy speech (in training): 
	Precision: 0.9110, Recall: 0.8700, F1_score: 0.8900
Model performance on Neutral speech (in training): 
	Precision: 0.9071, Recall: 0.9525, F1_score: 0.9293
Model performance on Sad speech (in training): 
	Precision: 0.9848, Recall: 0.9750, F1_score: 0.9799

Eval Phase: 
Validation loss: 216.8216, Validation accuracy: 0.6450
Macro F1-score: 0.6262
Model performance on Angry speech (in validation): 
	Precision: 0.6290, Recall: 0.7800, F1_score: 0.6964
Model performance on Happy speech (in validation): 
	Precision: 0.6522, Recall: 0.6000, F1_score: 0.6250
Model performance on Neutral speech (in validation): 
	Precision: 0.5789, Recall: 0.8800, F1_score: 0.6984
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.3200, F1_score: 0.4848
New best accuracy for layer 4 on epoch 1: 0.6450. Model saved.
Epoch 2/100

Training Phase:
    | 0/1600 [00:00<?, ?it/s]Training:   8%|▊         | 132/1600 [00:10<01:51, 13.19it/s]Training:  18%|█▊        | 290/1600 [00:20<01:29, 14.69it/s]Training:  29%|██▉       | 462/1600 [00:30<01:11, 15.83it/s]Training:  40%|███▉      | 637/1600 [00:40<00:58, 16.47it/s]Training:  51%|█████▏    | 822/1600 [00:50<00:45, 17.19it/s]Training:  63%|██████▎   | 1013/1600 [01:00<00:32, 17.82it/s]Training:  75%|███████▌  | 1204/1600 [01:10<00:21, 18.22it/s]Training:  87%|████████▋ | 1395/1600 [01:20<00:11, 18.10it/s]Training:  99%|█████████▉| 1588/1600 [01:30<00:00, 18.47it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 196/1600 [00:10<01:11, 19.57it/s]Training:  24%|██▍       | 392/1600 [00:20<01:01, 1Training loss: 126.2157, Training accuracy: 0.9762
Macro F1-score: 0.9763
Model performance on Angry speech (in training): 
	Precision: 0.9773, Recall: 0.9700, F1_score: 0.9737
Model performance on Happy speech (in training): 
	Precision: 0.9601, Recall: 0.9625, F1_score: 0.9613
Model performance on Neutral speech (in training): 
	Precision: 0.9727, Recall: 0.9800, F1_score: 0.9763
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937

Eval Phase: 
Validation loss: 317.1460, Validation accuracy: 0.5050
Macro F1-score: 0.4793
Model performance on Angry speech (in validation): 
	Precision: 0.6591, Recall: 0.5800, F1_score: 0.6170
Model performance on Happy speech (in validation): 
	Precision: 0.4062, Recall: 0.7800, F1_score: 0.5342
Model performance on Neutral speech (in validation): 
	Precision: 0.4808, Recall: 0.5000, F1_score: 0.4902
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Epoch 3/100

Training Phase:
9.58it/s]Training:  37%|███▋      | 593/1600 [00:30<00:50, 19.82it/s]Training:  50%|████▉     | 797/1600 [00:40<00:40, 20.01it/s]Training:  63%|██████▎   | 1001/1600 [00:50<00:29, 20.04it/s]Training:  75%|███████▌  | 1202/1600 [01:00<00:20, 19.86it/s]Training:  87%|████████▋ | 1398/1600 [01:10<00:10, 19.62it/s]Training:  99%|█████████▉| 1591/1600 [01:20<00:00, 19.51it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 189/1600 [00:10<01:14, 18.88it/s]Training:  24%|██▎       | 378/1600 [00:20<01:04, 18.86it/s]Training:  36%|███▌      | 574/1600 [00:30<00:53, 19.18it/s]Training:  49%|████▉     | 780/1600 [00:40<00:41, 19.71it/s]Training:  62%|██████▏   | 987/1600 [00:50<00:30, 20.Training loss: 71.9929, Training accuracy: 0.9838
Macro F1-score: 0.9838
Model performance on Angry speech (in training): 
	Precision: 0.9823, Recall: 0.9725, F1_score: 0.9774
Model performance on Happy speech (in training): 
	Precision: 0.9630, Recall: 0.9750, F1_score: 0.9689
Model performance on Neutral speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987

Eval Phase: 
Validation loss: 195.3926, Validation accuracy: 0.6350
Macro F1-score: 0.6350
Model performance on Angry speech (in validation): 
	Precision: 0.7632, Recall: 0.5800, F1_score: 0.6591
Model performance on Happy speech (in validation): 
	Precision: 0.5479, Recall: 0.8000, F1_score: 0.6504
Model performance on Neutral speech (in validation): 
	Precision: 0.5593, Recall: 0.6600, F1_score: 0.6055
Model performance on Sad speech (in validation): 
	Precision: 0.8333, Recall: 0.5000, F1_score: 0.6250
Epoch 4/100

Training Phase:
Training loss: 46.3920, Training accuracy: 0.9888
Macro F1-score: 0.9888
Model performance on Angry speech (in training): 
	Precision: 0.9899, Recall: 0.9850, F1_score: 0.9875
Model performance on Happy speech (in training): 
	Precision: 0.9777, Recall: 0.9875, F1_score: 0.9826
Model performance on Neutral speech (in training): 
	Precision: 0.9949, Recall: 0.9850, F1_score: 0.9899
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9975, F1_score: 0.9950

Eval Phase: 
06it/s]Training:  75%|███████▍  | 1199/1600 [01:00<00:19, 20.44it/s]Training:  88%|████████▊ | 1411/1600 [01:10<00:09, 20.63it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 209/1600 [00:10<01:06, 20.90it/s]Training:  26%|██▌       | 418/1600 [00:20<00:57, 20.67it/s]Training:  39%|███▉      | 624/1600 [00:30<00:47, 20.48it/s]Training:  52%|█████▏    | 827/1600 [00:40<00:38, 19.97it/s]Training:  64%|██████▍   | 1020/1600 [00:51<00:29, 19.64it/s]Training:  76%|███████▌  | 1214/1600 [01:01<00:19, 19.52it/s]Training:  88%|████████▊ | 1407/1600 [01:11<00:10, 19.29it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                Validation loss: 339.6774, Validation accuracy: 0.5700
Macro F1-score: 0.5488
Model performance on Angry speech (in validation): 
	Precision: 0.7949, Recall: 0.6200, F1_score: 0.6966
Model performance on Happy speech (in validation): 
	Precision: 0.4835, Recall: 0.8800, F1_score: 0.6241
Model performance on Neutral speech (in validation): 
	Precision: 0.4746, Recall: 0.5600, F1_score: 0.5138
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.2200, F1_score: 0.3607
Epoch 5/100

Training Phase:
Training loss: 67.8690, Training accuracy: 0.9869
Macro F1-score: 0.9869
Model performance on Angry speech (in training): 
	Precision: 0.9899, Recall: 0.9800, F1_score: 0.9849
Model performance on Happy speech (in training): 
	Precision: 0.9752, Recall: 0.9825, F1_score: 0.9788
Model performance on Neutral speech (in training): 
	Precision: 0.9875, Recall: 0.9900, F1_score: 0.9888
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950

Eval Phase: 
Validation loss: 431.7618, Validation accuracy: 0.4900
Macro F1-score: 0.4286
Model performance on Angry speech (in validation): 
	Precision: 0.7714, Recall: 0.5400, F1_score: 0.6353
Model performance on Happy speech (in validation): 
	Precision: 0.4245, Recall: 0.9000, F1_score: 0.5769
Model performance on Neutral speech (in validation): 
	Precision: 0.4310, Recall: 0.5000, F1_score: 0.4630
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Epoch 6/100

Training Phase:
                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 213/1600 [00:10<01:05, 21.21it/s]Training:  27%|██▋       | 426/1600 [00:20<00:55, 21.01it/s]Training:  40%|███▉      | 635/1600 [00:30<00:47, 20.44it/s]Training:  52%|█████▎    | 840/1600 [00:40<00:37, 20.43it/s]Training:  65%|██████▌   | 1045/1600 [00:51<00:27, 20.10it/s]Training:  78%|███████▊  | 1249/1600 [01:01<00:17, 20.17it/s]Training:  91%|█████████ | 1457/1600 [01:11<00:07, 20.34it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 217/1600 [00:10<01:03, 21.62it/s]Training:  27%|██▋       | 436/1600 [00:20<00:53, 21.72it/s]Training:  41%|████      | 654/1600 [00:30<00:43, 21.60it/s]TrainingTraining loss: 31.3175, Training accuracy: 0.9944
Macro F1-score: 0.9944
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950

Eval Phase: 
Validation loss: 287.6044, Validation accuracy: 0.6000
Macro F1-score: 0.5708
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.5625, Recall: 0.9000, F1_score: 0.6923
Model performance on Neutral speech (in validation): 
	Precision: 0.4429, Recall: 0.6200, F1_score: 0.5167
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.1800, F1_score: 0.3051
Epoch 7/100

Training Phase:
:  54%|█████▍    | 869/1600 [00:40<00:33, 21.51it/s]Training:  68%|██████▊   | 1084/1600 [00:50<00:24, 21.47it/s]Training:  81%|████████▏ | 1303/1600 [01:00<00:13, 21.59it/s]Training:  95%|█████████▌| 1522/1600 [01:10<00:03, 21.49it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 203/1600 [00:10<01:08, 20.25it/s]Training:  26%|██▌       | 413/1600 [00:20<00:57, 20.67it/s]Training:  39%|███▉      | 623/1600 [00:30<00:47, 20.48it/s]Training:  52%|█████▏    | 826/1600 [00:40<00:37, 20.37it/s]Training:  64%|██████▍   | 1032/1600 [00:50<00:27, 20.42it/s]Training:  77%|███████▋  | 1238/1600 [01:00<00:17, 20.47it/s]Training:  90%|█████████ | 1446/1600 [01:10<00:07, 20.57Training loss: 49.9704, Training accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Happy speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900
Model performance on Neutral speech (in training): 
	Precision: 0.9825, Recall: 0.9825, F1_score: 0.9825
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925

Eval Phase: 
Validation loss: 324.8150, Validation accuracy: 0.5750
Macro F1-score: 0.5532
Model performance on Angry speech (in validation): 
	Precision: 0.8250, Recall: 0.6600, F1_score: 0.7333
Model performance on Happy speech (in validation): 
	Precision: 0.4839, Recall: 0.9000, F1_score: 0.6294
Model performance on Neutral speech (in validation): 
	Precision: 0.4727, Recall: 0.5200, F1_score: 0.4952
Model performance on Sad speech (in validation): 
	Precision: 0.9167, Recall: 0.2200, F1_score: 0.3548
Epoch 8/100

Training Phase:
Training loss: 8.8765, Training accuracy: 0.9981
Macro F1-score: 0.9981
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
New best accuracy for layer 4 on epoch 8: 0.6600. Model saved.
Epoch 9/100

Training Phase:
it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 203/1600 [00:10<01:09, 20.24it/s]Training:  26%|██▌       | 410/1600 [00:20<00:58, 20.49it/s]Training:  39%|███▊      | 618/1600 [00:30<00:47, 20.61it/s]Training:  52%|█████▏    | 826/1600 [00:40<00:37, 20.51it/s]Training:  64%|██████▍   | 1030/1600 [00:50<00:28, 20.34it/s]Training:  78%|███████▊  | 1241/1600 [01:00<00:17, 20.58it/s]Training:  91%|█████████▏| 1462/1600 [01:10<00:06, 21.07it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 202/1600 [00:10<01:09, 20.19it/s]TrainTraining loss: 32.0300, Training accuracy: 0.9931
Macro F1-score: 0.9931
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912
Model performance on Happy speech (in training): 
	Precision: 0.9875, Recall: 0.9850, F1_score: 0.9862
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9975, F1_score: 0.9950
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 322.6713, Validation accuracy: 0.5900
Macro F1-score: 0.5467
Model performance on Angry speech (in validation): 
	Precision: 0.6522, Recall: 0.9000, F1_score: 0.7563
Model performance on Happy speech (in validation): 
	Precision: 0.5493, Recall: 0.7800, F1_score: 0.6446
Model performance on Neutral speech (in validation): 
	Precision: 0.5098, Recall: 0.5200, F1_score: 0.5149
Model performance on Sad speech (in validation): 
	Precision: 0.8889, Recall: 0.1600, F1_score: 0.2712
Epoch 10/100

Training Phase:
ing:  26%|██▌       | 408/1600 [00:20<00:58, 20.42it/s]Training:  38%|███▊      | 615/1600 [00:30<00:48, 20.52it/s]Training:  38%|███▊      | 615/1600 [00:40<00:48, 20.52it/s]Training:  51%|█████▏    | 823/1600 [00:40<00:37, 20.61it/s]Training:  65%|██████▍   | 1035/1600 [00:50<00:27, 20.79it/s]Training:  78%|███████▊  | 1247/1600 [01:00<00:16, 20.83it/s]Training:  91%|█████████▏| 1463/1600 [01:10<00:06, 21.08it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 204/1600 [00:10<01:08, 20.38it/s]Training:  26%|██▌       | 408/1600 [00:20<00:58, 20.28it/s]Training:  39%|███▉      | 621/1600 [00:30<00:47, 20.73it/s]Training:  52%|█████▏    | 834/1600 [00:40<00:37, 20.53it/s]Training:  65%|██Training loss: 27.9774, Training accuracy: 0.9962
Macro F1-score: 0.9962
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9975, F1_score: 0.9950
Model performance on Happy speech (in training): 
	Precision: 0.9975, Recall: 0.9925, F1_score: 0.9950
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Validation loss: 358.3881, Validation accuracy: 0.5650
Macro F1-score: 0.5200
Model performance on Angry speech (in validation): 
	Precision: 0.8250, Recall: 0.6600, F1_score: 0.7333
Model performance on Happy speech (in validation): 
	Precision: 0.5114, Recall: 0.9000, F1_score: 0.6522
Model performance on Neutral speech (in validation): 
	Precision: 0.4478, Recall: 0.6000, F1_score: 0.5128
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.1000, F1_score: 0.1818
Epoch 11/100

Training Phase:
███▍   | 1037/1600 [00:50<00:27, 20.42it/s]Training:  78%|███████▊  | 1241/1600 [01:00<00:17, 20.41it/s]Training:  90%|█████████ | 1445/1600 [01:10<00:07, 20.37it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 216/1600 [00:10<01:04, 21.58it/s]Training:  27%|██▋       | 432/1600 [00:20<00:55, 21.13it/s]Training:  40%|████      | 641/1600 [00:30<00:46, 20.85it/s]Training:  40%|████      | 641/1600 [00:40<00:46, 20.85it/s]Training:  53%|█████▎    | 845/1600 [00:40<00:36, 20.47it/s]Training:  66%|██████▌   | 1048/1600 [00:50<00:27, 20.40it/s]Training:  78%|███████▊  | 1251/1600 [01:01<00:17, 20.17it/s]Training:  91%|█████████ | 1456/1600 [01:11<00:07, 20.25it/s]                Training loss: 34.6239, Training accuracy: 0.9938
Macro F1-score: 0.9937
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Happy speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9875, F1_score: 0.9900
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963

Eval Phase: 
Validation loss: 487.3835, Validation accuracy: 0.5150
Macro F1-score: 0.4605
Model performance on Angry speech (in validation): 
	Precision: 0.6739, Recall: 0.6200, F1_score: 0.6458
Model performance on Happy speech (in validation): 
	Precision: 0.4356, Recall: 0.8800, F1_score: 0.5828
Model performance on Neutral speech (in validation): 
	Precision: 0.5000, Recall: 0.5000, F1_score: 0.5000
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.0600, F1_score: 0.1132
Epoch 12/100

Training Phase:
Training loss: 20.9558, Training accuracy: 0.9962
Macro F1-score: 0.9963
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 259.3527, Validation accuracy: 0.6100
Macro F1-score: 0.5982
Model performance on Angry speech (in validation): 
	Precision: 0.7800, Recall: 0.7800, F1_score: 0.7800
Model performance on Happy speech (in validation): 
	Precision: 0.5556, Recall: 0.8000, F1_score: 0.6557
Model performance on Neutral speech (in validation): 
	Precision: 0.4444, Recall: 0.5600, F1_score: 0.4956
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.3000, F1_score: 0.4615
Epoch 13/100

Training Phase:
                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 207/1600 [00:10<01:07, 20.68it/s]Training:  26%|██▌       | 414/1600 [00:20<00:58, 20.33it/s]Training:  39%|███▊      | 617/1600 [00:30<00:48, 20.30it/s]Training:  52%|█████▏    | 824/1600 [00:40<00:37, 20.42it/s]Training:  64%|██████▍   | 1031/1600 [00:50<00:28, 20.29it/s]Training:  77%|███████▋  | 1237/1600 [01:00<00:17, 20.37it/s]Training:  90%|█████████ | 1444/1600 [01:10<00:07, 20.46it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 203/1600 [00:10<01:08, 20.26it/s]Training:  26%|██▌     Training loss: 36.3349, Training accuracy: 0.9931
Macro F1-score: 0.9931
Model performance on Angry speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913
Model performance on Happy speech (in training): 
	Precision: 0.9899, Recall: 0.9825, F1_score: 0.9862
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9975, F1_score: 0.9950
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 326.8114, Validation accuracy: 0.5850
Macro F1-score: 0.5744
Model performance on Angry speech (in validation): 
	Precision: 0.8529, Recall: 0.5800, F1_score: 0.6905
Model performance on Happy speech (in validation): 
	Precision: 0.5172, Recall: 0.9000, F1_score: 0.6569
Model performance on Neutral speech (in validation): 
	Precision: 0.4444, Recall: 0.5600, F1_score: 0.4956
Model performance on Sad speech (in validation): 
	Precision: 0.9375, Recall: 0.3000, F1_score: 0.4545
Validation loss does not decrease for 10 epochs. End training.
Epoch 14/100

Entering 2ND training phase: change training data from de to CN
Loading cn train data: fold_3...
Preprocess cn fold_3 data for de model
Reload model and reset eval loss

Training Phase:
  | 416/1600 [00:20<00:56, 20.80it/s]Training:  40%|███▉      | 632/1600 [00:30<00:45, 21.16it/s]Training:  53%|█████▎    | 848/1600 [00:40<00:35, 21.27it/s]Training:  66%|██████▋   | 1063/1600 [00:50<00:25, 21.15it/s]Training:  66%|██████▋   | 1063/1600 [01:00<00:25, 21.15it/s]Training:  79%|███████▉  | 1271/1600 [01:00<00:15, 20.88it/s]Training:  92%|█████████▏| 1477/1600 [01:10<00:05, 20.76it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  10%|█         | 164/1600 [00:10<01:27, 16.37it/s]Training:  23%|██▎       | 370/1600 [00:20<01:05, 18.80it/s]Training:  37%|███▋      | 588/1600 [00:30<00:50, 20.16it/s]Training:  50%|█████     | 807/1600 [00:40<00:38, 20.83it/s]Training:  65%|██████▍   | 10Training loss: 3377.1225, Training accuracy: 0.5269
Macro F1-score: 0.5299
Model performance on Angry speech (in training): 
	Precision: 0.5153, Recall: 0.5900, F1_score: 0.5501
Model performance on Happy speech (in training): 
	Precision: 0.3890, Recall: 0.4425, F1_score: 0.4140
Model performance on Neutral speech (in training): 
	Precision: 0.5929, Recall: 0.5825, F1_score: 0.5876
Model performance on Sad speech (in training): 
	Precision: 0.6701, Recall: 0.4925, F1_score: 0.5677

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Epoch 15/100

Training Phase:
Training loss: 3363.4961, Training accuracy: 0.5244
Macro F1-score: 0.5277
Model performance on Angry speech (in training): 
	Precision: 0.5208, Recall: 0.5950, F1_score: 0.5554
Model performance on Happy speech (in training): 
	Precision: 0.3849, Recall: 0.4475, F1_score: 0.4139
Model performance on Neutral speech (in training): 
	Precision: 0.5835, Recall: 0.5675, F1_score: 0.5754
Model performance on Sad speech (in training): 
	Precision: 0.6747, Recall: 0.4875, F1_score: 0.5660

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Epoch 16/100

Training Phase:
35/1600 [00:50<00:26, 21.53it/s]Training:  79%|███████▉  | 1263/1600 [01:00<00:15, 21.74it/s]Training:  94%|█████████▎| 1497/1600 [01:10<00:04, 22.26it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 249/1600 [00:10<00:54, 24.88it/s]Training:  32%|███▏      | 511/1600 [00:20<00:42, 25.61it/s]Training:  48%|████▊     | 773/1600 [00:30<00:32, 25.54it/s]Training:  64%|██████▍   | 1032/1600 [00:40<00:22, 25.66it/s]Training:  81%|████████  | 1291/1600 [00:50<00:12, 25.61it/s]Training:  97%|█████████▋| 1548/1600 [01:00<00:02, 25.63it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   TraTraining loss: 3386.6252, Training accuracy: 0.5262
Macro F1-score: 0.5282
Model performance on Angry speech (in training): 
	Precision: 0.5248, Recall: 0.6075, F1_score: 0.5632
Model performance on Happy speech (in training): 
	Precision: 0.3969, Recall: 0.4475, F1_score: 0.4207
Model performance on Neutral speech (in training): 
	Precision: 0.5816, Recall: 0.5700, F1_score: 0.5758
Model performance on Sad speech (in training): 
	Precision: 0.6531, Recall: 0.4800, F1_score: 0.5533

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Epoch 17/100

Training Phase:
ining:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 256/1600 [00:10<00:52, 25.56it/s]Training:  16%|█▌        | 256/1600 [00:20<00:52, 25.56it/s]Training:  32%|███▏      | 517/1600 [00:20<00:41, 25.85it/s]Training:  49%|████▊     | 778/1600 [00:30<00:32, 25.55it/s]Training:  65%|██████▍   | 1035/1600 [00:40<00:22, 25.60it/s]Training:  81%|████████  | 1292/1600 [00:50<00:12, 25.59it/s]Training:  97%|█████████▋| 1550/1600 [01:00<00:01, 25.65it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 259/1600 [00:10<00:51, 25.85it/s]Training:  32%|███▏      | 519/1600 [00:20<00:41, 25.90it/s]Training:  49%|████▊     | 779/1600 [00:30<00:31, 25.80it/s]Training:  65%|██████▍   | 1036/Training loss: 3368.0490, Training accuracy: 0.5238
Macro F1-score: 0.5271
Model performance on Angry speech (in training): 
	Precision: 0.5130, Recall: 0.5925, F1_score: 0.5499
Model performance on Happy speech (in training): 
	Precision: 0.3807, Recall: 0.4350, F1_score: 0.4061
Model performance on Neutral speech (in training): 
	Precision: 0.5878, Recall: 0.5775, F1_score: 0.5826
Model performance on Sad speech (in training): 
	Precision: 0.6806, Recall: 0.4900, F1_score: 0.5698

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Epoch 18/100

Training Phase:
Training loss: 3409.1745, Training accuracy: 0.5337
Macro F1-score: 0.5374
Model performance on Angry speech (in training): 
	Precision: 0.5241, Recall: 0.5975, F1_score: 0.5584
Model performance on Happy speech (in training): 
	Precision: 0.3936, Recall: 0.4625, F1_score: 0.4253
Model performance on Neutral speech (in training): 
	Precision: 0.6031, Recall: 0.5775, F1_score: 0.5900
Model performance on Sad speech (in training): 
	Precision: 0.6838, Recall: 0.4975, F1_score: 0.5760

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Epoch 19/100

Training Phase:
1600 [00:40<00:21, 25.76it/s]Training:  81%|████████  | 1293/1600 [00:50<00:11, 25.67it/s]Training:  97%|█████████▋| 1548/1600 [01:00<00:02, 25.59it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 257/1600 [00:10<00:52, 25.68it/s]Training:  32%|███▏      | 516/1600 [00:20<00:42, 25.78it/s]Training:  48%|████▊     | 775/1600 [00:30<00:32, 25.73it/s]Training:  65%|██████▍   | 1033/1600 [00:40<00:22, 25.73it/s]Training:  81%|████████  | 1292/1600 [00:50<00:11, 25.77it/s]Training:  97%|█████████▋| 1551/1600 [01:00<00:01, 25.67it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   TrainiTraining loss: 3431.8333, Training accuracy: 0.5244
Macro F1-score: 0.5273
Model performance on Angry speech (in training): 
	Precision: 0.5139, Recall: 0.6025, F1_score: 0.5547
Model performance on Happy speech (in training): 
	Precision: 0.3819, Recall: 0.4325, F1_score: 0.4056
Model performance on Neutral speech (in training): 
	Precision: 0.5948, Recall: 0.5725, F1_score: 0.5834
Model performance on Sad speech (in training): 
	Precision: 0.6689, Recall: 0.4900, F1_score: 0.5657

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Epoch 20/100

Training Phase:
ng:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 256/1600 [00:10<00:52, 25.53it/s]Training:  32%|███▏      | 512/1600 [00:20<00:42, 25.56it/s]Training:  48%|████▊     | 772/1600 [00:30<00:32, 25.73it/s]Training:  64%|██████▍   | 1032/1600 [00:40<00:22, 25.61it/s]Training:  80%|████████  | 1287/1600 [00:50<00:12, 25.43it/s]Training:  96%|█████████▌| 1539/1600 [01:00<00:02, 25.08it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 243/1600 [00:10<00:55, 24.27it/s]Training:  30%|███       | 486/1600 [00:20<00:46, 23.76it/s]Training:  45%|████▌     | 721/1600 [00:30<00:37, 23.55it/s]Training:  60%|█████▉    | 954/1600 [00:40<00:27, 23.25it/s]Training:  74%|███████▍  | Training loss: 3302.2475, Training accuracy: 0.5413
Macro F1-score: 0.5430
Model performance on Angry speech (in training): 
	Precision: 0.5256, Recall: 0.6150, F1_score: 0.5668
Model performance on Happy speech (in training): 
	Precision: 0.4136, Recall: 0.4550, F1_score: 0.4333
Model performance on Neutral speech (in training): 
	Precision: 0.6040, Recall: 0.6025, F1_score: 0.6033
Model performance on Sad speech (in training): 
	Precision: 0.6724, Recall: 0.4925, F1_score: 0.5685

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Epoch 21/100

Training Phase:
Training loss: 3407.8569, Training accuracy: 0.5356
Macro F1-score: 0.5383
Model performance on Angry speech (in training): 
	Precision: 0.5259, Recall: 0.6100, F1_score: 0.5648
Model performance on Happy speech (in training): 
	Precision: 0.3996, Recall: 0.4525, F1_score: 0.4244
Model performance on Neutral speech (in training): 
	Precision: 0.6036, Recall: 0.5825, F1_score: 0.5929
Model performance on Sad speech (in training): 
	Precision: 0.6700, Recall: 0.4975, F1_score: 0.5710

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Epoch 22/100

Training Phase:
1183/1600 [00:50<00:18, 23.04it/s]Training:  88%|████████▊ | 1410/1600 [01:00<00:08, 22.92it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 256/1600 [00:10<00:52, 25.52it/s]Training:  32%|███▏      | 512/1600 [00:20<00:42, 25.43it/s]Training:  48%|████▊     | 766/1600 [00:30<00:32, 25.35it/s]Training:  64%|██████▍   | 1020/1600 [00:40<00:22, 25.34it/s]Training:  80%|███████▉  | 1275/1600 [00:50<00:12, 25.36it/s]Training:  96%|█████████▌| 1530/1600 [01:00<00:02, 25.36it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        |Training loss: 3408.1378, Training accuracy: 0.5269
Macro F1-score: 0.5296
Model performance on Angry speech (in training): 
	Precision: 0.5166, Recall: 0.5850, F1_score: 0.5487
Model performance on Happy speech (in training): 
	Precision: 0.3890, Recall: 0.4425, F1_score: 0.4140
Model performance on Neutral speech (in training): 
	Precision: 0.5872, Recall: 0.5975, F1_score: 0.5923
Model performance on Sad speech (in training): 
	Precision: 0.6772, Recall: 0.4825, F1_score: 0.5635

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Epoch 23/100

Training Phase:
 253/1600 [00:10<00:53, 25.25it/s]Training:  32%|███▏      | 506/1600 [00:20<00:43, 25.26it/s]Training:  48%|████▊     | 763/1600 [00:30<00:32, 25.44it/s]Training:  64%|██████▍   | 1020/1600 [00:40<00:22, 25.33it/s]Training:  80%|███████▉  | 1272/1600 [00:50<00:13, 25.02it/s]Training:  95%|█████████▍| 1518/1600 [01:00<00:03, 24.85it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 247/1600 [00:10<00:54, 24.62it/s]Training:  31%|███▏      | 501/1600 [00:20<00:43, 25.06it/s]Training:  31%|███▏      | 501/1600 [00:30<00:43, 25.06it/s]Training:  47%|████▋     | 750/1600 [00:30<00:34, 24.88it/s]Training:  62%|██████▏   | 997/1600 [00:40<00:24, 24.76it/s]Training:  78%|███████▊  | 12Training loss: 3398.2584, Training accuracy: 0.5212
Macro F1-score: 0.5246
Model performance on Angry speech (in training): 
	Precision: 0.5178, Recall: 0.5825, F1_score: 0.5482
Model performance on Happy speech (in training): 
	Precision: 0.3858, Recall: 0.4475, F1_score: 0.4144
Model performance on Neutral speech (in training): 
	Precision: 0.5792, Recall: 0.5575, F1_score: 0.5682
Model performance on Sad speech (in training): 
	Precision: 0.6611, Recall: 0.4975, F1_score: 0.5678

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Epoch 24/100

Training Phase:
Training loss: 3377.8314, Training accuracy: 0.5319
Macro F1-score: 0.5342
Model performance on Angry speech (in training): 
	Precision: 0.5268, Recall: 0.6150, F1_score: 0.5675
Model performance on Happy speech (in training): 
	Precision: 0.3901, Recall: 0.4350, F1_score: 0.4113
Model performance on Neutral speech (in training): 
	Precision: 0.5909, Recall: 0.5850, F1_score: 0.5879
Model performance on Sad speech (in training): 
	Precision: 0.6770, Recall: 0.4925, F1_score: 0.5702

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Epoch 25/100

Training Phase:
43/1600 [00:50<00:14, 24.58it/s]Training:  94%|█████████▍| 1507/1600 [01:00<00:03, 25.17it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 252/1600 [00:10<00:53, 25.13it/s]Training:  32%|███▏      | 504/1600 [00:20<00:44, 24.88it/s]Training:  47%|████▋     | 752/1600 [00:30<00:34, 24.56it/s]Training:  62%|██████▏   | 996/1600 [00:40<00:24, 24.49it/s]Training:  78%|███████▊  | 1252/1600 [00:50<00:13, 24.87it/s]Training:  94%|█████████▍| 1511/1600 [01:00<00:03, 25.21it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | Training loss: 3422.1030, Training accuracy: 0.5256
Macro F1-score: 0.5283
Model performance on Angry speech (in training): 
	Precision: 0.5197, Recall: 0.5950, F1_score: 0.5548
Model performance on Happy speech (in training): 
	Precision: 0.3853, Recall: 0.4325, F1_score: 0.4075
Model performance on Neutral speech (in training): 
	Precision: 0.5802, Recall: 0.5875, F1_score: 0.5839
Model performance on Sad speech (in training): 
	Precision: 0.6771, Recall: 0.4875, F1_score: 0.5669

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Epoch 26/100

Training Phase:
247/1600 [00:10<00:54, 24.68it/s]Training:  31%|███       | 494/1600 [00:20<00:45, 24.43it/s]Training:  46%|████▋     | 740/1600 [00:30<00:35, 24.47it/s]Training:  62%|██████▏   | 987/1600 [00:40<00:25, 24.51it/s]Training:  77%|███████▋  | 1236/1600 [00:50<00:14, 24.64it/s]Training:  93%|█████████▎| 1485/1600 [01:00<00:04, 24.63it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 244/1600 [00:10<00:55, 24.39it/s]Training:  31%|███       | 491/1600 [00:20<00:45, 24.55it/s]Training:  46%|████▌     | 738/1600 [00:30<00:35, 24.50it/s]Training:  62%|██████▏   | 985/1600 [00:40<00:25, 24.55it/s]Training:  78%|███████▊  | 1241/1600 [00:50<00:14, 24.88it/s]Training:  94%|█████████Training loss: 3392.7567, Training accuracy: 0.5275
Macro F1-score: 0.5297
Model performance on Angry speech (in training): 
	Precision: 0.5192, Recall: 0.6075, F1_score: 0.5599
Model performance on Happy speech (in training): 
	Precision: 0.3910, Recall: 0.4350, F1_score: 0.4118
Model performance on Neutral speech (in training): 
	Precision: 0.5869, Recall: 0.5825, F1_score: 0.5847
Model performance on Sad speech (in training): 
	Precision: 0.6690, Recall: 0.4850, F1_score: 0.5623

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Epoch 27/100

Training Phase:
Training loss: 3400.3900, Training accuracy: 0.5231
Macro F1-score: 0.5263
Model performance on Angry speech (in training): 
	Precision: 0.5097, Recall: 0.5925, F1_score: 0.5480
Model performance on Happy speech (in training): 
	Precision: 0.3819, Recall: 0.4325, F1_score: 0.4056
Model performance on Neutral speech (in training): 
	Precision: 0.5928, Recall: 0.5750, F1_score: 0.5838
Model performance on Sad speech (in training): 
	Precision: 0.6701, Recall: 0.4925, F1_score: 0.5677

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Epoch 28/100

Training Phase:
▍| 1506/1600 [01:00<00:03, 25.41it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 228/1600 [00:10<01:00, 22.80it/s]Training:  30%|██▉       | 472/1600 [00:20<00:47, 23.74it/s]Training:  45%|████▍     | 717/1600 [00:30<00:36, 24.07it/s]Training:  60%|██████    | 962/1600 [00:40<00:26, 24.22it/s]Training:  75%|███████▌  | 1207/1600 [00:50<00:16, 24.24it/s]Training:  91%|█████████ | 1450/1600 [01:00<00:06, 23.86it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 238/1600 [00:10<00:57, 23.72it/s]Training:  30%|███       | 480/1600 [00:2Training loss: 3378.3105, Training accuracy: 0.5231
Macro F1-score: 0.5264
Model performance on Angry speech (in training): 
	Precision: 0.5076, Recall: 0.5875, F1_score: 0.5446
Model performance on Happy speech (in training): 
	Precision: 0.3797, Recall: 0.4300, F1_score: 0.4033
Model performance on Neutral speech (in training): 
	Precision: 0.5964, Recall: 0.5800, F1_score: 0.5881
Model performance on Sad speech (in training): 
	Precision: 0.6712, Recall: 0.4950, F1_score: 0.5698

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Epoch 29/100

Training Phase:
0<00:46, 23.96it/s]Training:  45%|████▌     | 722/1600 [00:30<00:36, 24.01it/s]Training:  60%|██████    | 965/1600 [00:40<00:26, 24.10it/s]Training:  76%|███████▌  | 1208/1600 [00:50<00:16, 24.14it/s]Training:  91%|█████████ | 1451/1600 [01:00<00:06, 23.83it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 225/1600 [00:10<01:01, 22.47it/s]Training:  28%|██▊       | 452/1600 [00:20<00:50, 22.58it/s]Training:  42%|████▏     | 679/1600 [00:30<00:40, 22.55it/s]Training:  57%|█████▋    | 905/1600 [00:40<00:30, 22.53it/s]Training:  57%|█████▋    | 905/1600 [00:50<00:30, 22.53it/s]Training:  71%|███████   | 1132/1600 [00:50<00:20, 22.57it/s]Training:  85%|████████▌ | 1361/1600 [01Training loss: 3384.9504, Training accuracy: 0.5350
Macro F1-score: 0.5377
Model performance on Angry speech (in training): 
	Precision: 0.5284, Recall: 0.6050, F1_score: 0.5641
Model performance on Happy speech (in training): 
	Precision: 0.3987, Recall: 0.4525, F1_score: 0.4239
Model performance on Neutral speech (in training): 
	Precision: 0.5919, Recall: 0.5875, F1_score: 0.5897
Model performance on Sad speech (in training): 
	Precision: 0.6804, Recall: 0.4950, F1_score: 0.5731

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Epoch 30/100

Training Phase:
Training loss: 3372.0128, Training accuracy: 0.5275
Macro F1-score: 0.5297
Model performance on Angry speech (in training): 
	Precision: 0.5217, Recall: 0.6000, F1_score: 0.5581
Model performance on Happy speech (in training): 
	Precision: 0.4009, Recall: 0.4550, F1_score: 0.4262
Model performance on Neutral speech (in training): 
	Precision: 0.5789, Recall: 0.5775, F1_score: 0.5782
Model performance on Sad speech (in training): 
	Precision: 0.6655, Recall: 0.4775, F1_score: 0.5560

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Epoch 31/100

Training Phase:
:00<00:10, 22.65it/s]Training:  99%|█████████▉| 1590/1600 [01:10<00:00, 22.71it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 229/1600 [00:10<00:59, 22.89it/s]Training:  29%|██▊       | 458/1600 [00:20<00:50, 22.79it/s]Training:  44%|████▎     | 698/1600 [00:30<00:38, 23.34it/s]Training:  60%|█████▉    | 954/1600 [00:40<00:26, 24.20it/s]Training:  76%|███████▌  | 1210/1600 [00:50<00:15, 24.66it/s]Training:  92%|█████████▏| 1465/1600 [01:00<00:05, 24.93it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 254/1600 [00:10Training loss: 3391.2161, Training accuracy: 0.5281
Macro F1-score: 0.5311
Model performance on Angry speech (in training): 
	Precision: 0.5173, Recall: 0.5975, F1_score: 0.5545
Model performance on Happy speech (in training): 
	Precision: 0.3939, Recall: 0.4500, F1_score: 0.4201
Model performance on Neutral speech (in training): 
	Precision: 0.5917, Recall: 0.5725, F1_score: 0.5820
Model performance on Sad speech (in training): 
	Precision: 0.6701, Recall: 0.4925, F1_score: 0.5677

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Epoch 32/100

Training Phase:
<00:53, 25.34it/s]Training:  32%|███▏      | 513/1600 [00:20<00:42, 25.65it/s]Training:  32%|███▏      | 513/1600 [00:30<00:42, 25.65it/s]Training:  48%|████▊     | 765/1600 [00:30<00:32, 25.38it/s]Training:  64%|██████▎   | 1016/1600 [00:40<00:23, 24.83it/s]Training:  79%|███████▉  | 1266/1600 [00:50<00:13, 24.88it/s]Training:  95%|█████████▌| 1527/1600 [01:00<00:02, 25.27it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▋        | 260/1600 [00:10<00:51, 25.98it/s]Training:  33%|███▎      | 521/1600 [00:20<00:41, 26.05it/s]Training:  49%|████▉     | 782/1600 [00:30<00:32, 25.27it/s]Training:  64%|██████▍   | 1028/1600 [00:40<00:22, 25.01it/s]Training:  81%|████████  | 1291/1600 [00:50<Training loss: 3408.8686, Training accuracy: 0.5281
Macro F1-score: 0.5312
Model performance on Angry speech (in training): 
	Precision: 0.5161, Recall: 0.6025, F1_score: 0.5559
Model performance on Happy speech (in training): 
	Precision: 0.3846, Recall: 0.4375, F1_score: 0.4094
Model performance on Neutral speech (in training): 
	Precision: 0.6036, Recall: 0.5825, F1_score: 0.5929
Model performance on Sad speech (in training): 
	Precision: 0.6712, Recall: 0.4900, F1_score: 0.5665

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Epoch 33/100

Training Phase:
Training loss: 3373.5993, Training accuracy: 0.5250
Macro F1-score: 0.5272
Model performance on Angry speech (in training): 
	Precision: 0.5194, Recall: 0.6025, F1_score: 0.5579
Model performance on Happy speech (in training): 
	Precision: 0.3911, Recall: 0.4400, F1_score: 0.4141
Model performance on Neutral speech (in training): 
	Precision: 0.5848, Recall: 0.5775, F1_score: 0.5811
Model performance on Sad speech (in training): 
	Precision: 0.6598, Recall: 0.4800, F1_score: 0.5557

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Epoch 34/100

Training Phase:
00:12, 25.47it/s]Training:  97%|█████████▋| 1554/1600 [01:00<00:01, 25.67it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▋        | 261/1600 [00:10<00:51, 26.07it/s]Training:  33%|███▎      | 522/1600 [00:20<00:42, 25.57it/s]Training:  48%|████▊     | 775/1600 [00:30<00:32, 25.27it/s]Training:  64%|██████▍   | 1025/1600 [00:40<00:22, 25.10it/s]Training:  80%|███████▉  | 1274/1600 [00:50<00:13, 25.00it/s]Training:  95%|█████████▌| 1523/1600 [01:00<00:03, 24.95it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 249/1600 [00:1Training loss: 3390.0710, Training accuracy: 0.5325
Macro F1-score: 0.5356
Model performance on Angry speech (in training): 
	Precision: 0.5137, Recall: 0.6075, F1_score: 0.5567
Model performance on Happy speech (in training): 
	Precision: 0.3870, Recall: 0.4325, F1_score: 0.4085
Model performance on Neutral speech (in training): 
	Precision: 0.6067, Recall: 0.5900, F1_score: 0.5982
Model performance on Sad speech (in training): 
	Precision: 0.6873, Recall: 0.5000, F1_score: 0.5789

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Epoch 35/100

Training Phase:
0<00:54, 24.82it/s]Training:  31%|███       | 498/1600 [00:20<00:44, 24.80it/s]Training:  47%|████▋     | 746/1600 [00:30<00:34, 24.66it/s]Training:  62%|██████▏   | 992/1600 [00:40<00:24, 24.60it/s]Training:  78%|███████▊  | 1254/1600 [00:50<00:13, 25.16it/s]Training:  95%|█████████▌| 1520/1600 [01:00<00:03, 25.63it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 256/1600 [00:10<00:52, 25.52it/s]Training:  32%|███▏      | 512/1600 [00:20<00:43, 25.04it/s]Training:  48%|████▊     | 760/1600 [00:30<00:33, 24.77it/s]Training:  63%|██████▎   | 1005/1600 [00:40<00:24, 24.64it/s]Training:  78%|███████▊  | 1250/1600 [00:50<00:14, 24.59it/s]Training:  93%|█████████▎| 1495/1Training loss: 3334.4144, Training accuracy: 0.5350
Macro F1-score: 0.5379
Model performance on Angry speech (in training): 
	Precision: 0.5197, Recall: 0.5950, F1_score: 0.5548
Model performance on Happy speech (in training): 
	Precision: 0.4013, Recall: 0.4575, F1_score: 0.4276
Model performance on Neutral speech (in training): 
	Precision: 0.6067, Recall: 0.5900, F1_score: 0.5982
Model performance on Sad speech (in training): 
	Precision: 0.6700, Recall: 0.4975, F1_score: 0.5710

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Epoch 36/100

Training Phase:
Training loss: 3409.2403, Training accuracy: 0.5369
Macro F1-score: 0.5390
Model performance on Angry speech (in training): 
	Precision: 0.5280, Recall: 0.6125, F1_score: 0.5671
Model performance on Happy speech (in training): 
	Precision: 0.4018, Recall: 0.4450, F1_score: 0.4223
Model performance on Neutral speech (in training): 
	Precision: 0.5990, Recall: 0.5900, F1_score: 0.5945
Model performance on Sad speech (in training): 
	Precision: 0.6689, Recall: 0.5000, F1_score: 0.5722

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Epoch 37/100

Training Phase:
600 [01:00<00:04, 24.55it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 244/1600 [00:10<00:55, 24.36it/s]Training:  31%|███       | 490/1600 [00:20<00:45, 24.44it/s]Training:  46%|████▌     | 735/1600 [00:30<00:35, 24.41it/s]Training:  62%|██████▏   | 993/1600 [00:40<00:24, 24.92it/s]Training:  78%|███████▊  | 1251/1600 [00:50<00:14, 24.83it/s]Training:  94%|█████████▎| 1498/1600 [01:00<00:04, 24.78it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 244/1600 [00:10<00:55, 24.32it/s]Training:  15%|█▌        | 244/1600 [00:22<00:55, Training loss: 3345.8564, Training accuracy: 0.5381
Macro F1-score: 0.5408
Model performance on Angry speech (in training): 
	Precision: 0.5361, Recall: 0.6125, F1_score: 0.5718
Model performance on Happy speech (in training): 
	Precision: 0.4056, Recall: 0.4675, F1_score: 0.4344
Model performance on Neutral speech (in training): 
	Precision: 0.5974, Recall: 0.5750, F1_score: 0.5860
Model performance on Sad speech (in training): 
	Precision: 0.6700, Recall: 0.4975, F1_score: 0.5710

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Epoch 38/100

Training Phase:
24.32it/s]Training:  29%|██▉       | 462/1600 [00:22<00:58, 19.46it/s]Training:  40%|████      | 642/1600 [00:33<00:50, 18.82it/s]Training:  53%|█████▎    | 846/1600 [00:43<00:38, 19.39it/s]Training:  67%|██████▋   | 1065/1600 [00:53<00:26, 20.26it/s]Training:  80%|████████  | 1284/1600 [01:03<00:15, 20.43it/s]Training:  94%|█████████▎| 1499/1600 [01:13<00:04, 20.75it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 257/1600 [00:10<00:52, 25.66it/s]Training:  32%|███▏      | 514/1600 [00:20<00:42, 25.31it/s]Training:  48%|████▊     | 765/1600 [00:31<00:35, 23.82it/s]Training:  62%|██████▏   | 988/1600 [00:41<00:26, 23.23it/s]Training:  77%|███████▋  | 1227/1600 [00:51<00:15, 23Training loss: 3378.1133, Training accuracy: 0.5300
Macro F1-score: 0.5323
Model performance on Angry speech (in training): 
	Precision: 0.5184, Recall: 0.6000, F1_score: 0.5562
Model performance on Happy speech (in training): 
	Precision: 0.3915, Recall: 0.4375, F1_score: 0.4132
Model performance on Neutral speech (in training): 
	Precision: 0.5926, Recall: 0.6000, F1_score: 0.5963
Model performance on Sad speech (in training): 
	Precision: 0.6772, Recall: 0.4825, F1_score: 0.5635

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Epoch 39/100

Training Phase:
Training loss: 3411.8196, Training accuracy: 0.5294
Macro F1-score: 0.5320
Model performance on Angry speech (in training): 
	Precision: 0.5209, Recall: 0.5925, F1_score: 0.5544
Model performance on Happy speech (in training): 
	Precision: 0.3894, Recall: 0.4400, F1_score: 0.4131
Model performance on Neutral speech (in training): 
	Precision: 0.5945, Recall: 0.5975, F1_score: 0.5960
Model performance on Sad speech (in training): 
	Precision: 0.6701, Recall: 0.4875, F1_score: 0.5644

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Epoch 40/100

Training Phase:
.44it/s]Training:  92%|█████████▏| 1466/1600 [01:02<00:05, 23.27it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▋        | 264/1600 [00:10<00:50, 26.39it/s]Training:  33%|███▎      | 528/1600 [00:20<00:42, 25.50it/s]Training:  49%|████▊     | 778/1600 [00:31<00:33, 24.57it/s]Training:  63%|██████▎   | 1013/1600 [00:41<00:24, 23.90it/s]Training:  79%|███████▊  | 1259/1600 [00:51<00:14, 24.12it/s]Training:  79%|███████▊  | 1259/1600 [01:01<00:14, 24.12it/s]Training:  94%|█████████▎| 1498/1600 [01:01<00:04, 23.80it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | Training loss: 3347.6673, Training accuracy: 0.5350
Macro F1-score: 0.5378
Model performance on Angry speech (in training): 
	Precision: 0.5261, Recall: 0.6050, F1_score: 0.5628
Model performance on Happy speech (in training): 
	Precision: 0.3960, Recall: 0.4475, F1_score: 0.4202
Model performance on Neutral speech (in training): 
	Precision: 0.6010, Recall: 0.5875, F1_score: 0.5942
Model performance on Sad speech (in training): 
	Precision: 0.6734, Recall: 0.5000, F1_score: 0.5739

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Epoch 41/100

Training Phase:
0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 248/1600 [00:10<00:54, 24.77it/s]Training:  32%|███▏      | 504/1600 [00:20<00:43, 25.20it/s]Training:  48%|████▊     | 772/1600 [00:30<00:31, 25.90it/s]Training:  65%|██████▌   | 1040/1600 [00:40<00:21, 26.16it/s]Training:  82%|████████▏ | 1306/1600 [00:50<00:11, 26.30it/s]Training:  98%|█████████▊| 1572/1600 [01:00<00:01, 26.33it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 267/1600 [00:10<00:49, 26.69it/s]Training:  33%|███▎      | 534/1600 [00:20<00:40, 26.58it/s]Training:  50%|█████     | 800/1600 [00:30<00:30, 26.23it/s]Training:  50%|█████     | 800/1600 [00:40<00:30, 26.23it/s]Training:  66%|██████▌   | 1050/1600 [00:40<00:2Training loss: 3360.2564, Training accuracy: 0.5225
Macro F1-score: 0.5258
Model performance on Angry speech (in training): 
	Precision: 0.5185, Recall: 0.5950, F1_score: 0.5541
Model performance on Happy speech (in training): 
	Precision: 0.3818, Recall: 0.4400, F1_score: 0.4088
Model performance on Neutral speech (in training): 
	Precision: 0.5814, Recall: 0.5625, F1_score: 0.5718
Model performance on Sad speech (in training): 
	Precision: 0.6724, Recall: 0.4925, F1_score: 0.5685

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Epoch 42/100

Training Phase:
Training loss: 3405.1077, Training accuracy: 0.5281
Macro F1-score: 0.5310
Model performance on Angry speech (in training): 
	Precision: 0.5251, Recall: 0.6025, F1_score: 0.5611
Model performance on Happy speech (in training): 
	Precision: 0.3926, Recall: 0.4525, F1_score: 0.4204
Model performance on Neutral speech (in training): 
	Precision: 0.5816, Recall: 0.5700, F1_score: 0.5758
Model performance on Sad speech (in training): 
	Precision: 0.6771, Recall: 0.4875, F1_score: 0.5669

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Epoch 43/100

Training Phase:
1, 25.63it/s]Training:  81%|████████  | 1299/1600 [00:50<00:11, 25.34it/s]Training:  97%|█████████▋| 1548/1600 [01:00<00:02, 25.19it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 246/1600 [00:10<00:55, 24.58it/s]Training:  31%|███▏      | 503/1600 [00:20<00:43, 25.23it/s]Training:  48%|████▊     | 772/1600 [00:30<00:31, 25.98it/s]Training:  65%|██████▌   | 1041/1600 [00:40<00:21, 25.77it/s]Training:  81%|████████  | 1296/1600 [00:50<00:11, 25.35it/s]Training:  97%|█████████▋| 1545/1600 [01:00<00:02, 25.18it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|       Training loss: 3390.9437, Training accuracy: 0.5288
Macro F1-score: 0.5306
Model performance on Angry speech (in training): 
	Precision: 0.5171, Recall: 0.6050, F1_score: 0.5576
Model performance on Happy speech (in training): 
	Precision: 0.3946, Recall: 0.4350, F1_score: 0.4138
Model performance on Neutral speech (in training): 
	Precision: 0.5891, Recall: 0.5950, F1_score: 0.5920
Model performance on Sad speech (in training): 
	Precision: 0.6690, Recall: 0.4800, F1_score: 0.5590

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Epoch 44/100

Training Phase:
   | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 254/1600 [00:10<00:53, 25.37it/s]Training:  32%|███▏      | 508/1600 [00:20<00:43, 24.98it/s]Training:  48%|████▊     | 761/1600 [00:30<00:33, 25.09it/s]Training:  63%|██████▎   | 1014/1600 [00:40<00:23, 24.96it/s]Training:  79%|███████▉  | 1265/1600 [00:50<00:13, 25.00it/s]Training:  95%|█████████▍| 1517/1600 [01:00<00:03, 25.04it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 248/1600 [00:10<00:54, 24.77it/s]Training:  31%|███▏      | 503/1600 [00:20<00:43, 25.19it/s]Training:  47%|████▋     | 758/1600 [00:30<00:33, 24.91it/s]Training:  64%|██████▎   | 1016/1600 [00:40<00:23, 25.22it/s]Training:  80%|███████▉  | 1274/1600 [Training loss: 3388.7466, Training accuracy: 0.5244
Macro F1-score: 0.5277
Model performance on Angry speech (in training): 
	Precision: 0.5152, Recall: 0.5925, F1_score: 0.5512
Model performance on Happy speech (in training): 
	Precision: 0.3851, Recall: 0.4400, F1_score: 0.4107
Model performance on Neutral speech (in training): 
	Precision: 0.5870, Recall: 0.5650, F1_score: 0.5758
Model performance on Sad speech (in training): 
	Precision: 0.6711, Recall: 0.5000, F1_score: 0.5731

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Epoch 45/100

Training Phase:
Training loss: 3416.5652, Training accuracy: 0.5250
Macro F1-score: 0.5287
Model performance on Angry speech (in training): 
	Precision: 0.5109, Recall: 0.5850, F1_score: 0.5455
Model performance on Happy speech (in training): 
	Precision: 0.3769, Recall: 0.4325, F1_score: 0.4028
Model performance on Neutral speech (in training): 
	Precision: 0.6000, Recall: 0.5850, F1_score: 0.5924
Model performance on Sad speech (in training): 
	Precision: 0.6792, Recall: 0.4975, F1_score: 0.5743

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Epoch 46/100

Training Phase:
00:50<00:12, 25.09it/s]Training:  95%|█████████▌| 1523/1600 [01:00<00:03, 25.03it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 253/1600 [00:10<00:53, 25.28it/s]Training:  32%|███▏      | 506/1600 [00:20<00:43, 25.13it/s]Training:  47%|████▋     | 757/1600 [00:30<00:33, 24.98it/s]Training:  63%|██████▎   | 1006/1600 [00:40<00:23, 24.92it/s]Training:  79%|███████▊  | 1257/1600 [00:50<00:13, 24.95it/s]Training:  94%|█████████▍| 1508/1600 [01:00<00:03, 24.87it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 248/1600Training loss: 3384.0174, Training accuracy: 0.5319
Macro F1-score: 0.5342
Model performance on Angry speech (in training): 
	Precision: 0.5194, Recall: 0.6025, F1_score: 0.5579
Model performance on Happy speech (in training): 
	Precision: 0.4018, Recall: 0.4500, F1_score: 0.4245
Model performance on Neutral speech (in training): 
	Precision: 0.5939, Recall: 0.5850, F1_score: 0.5894
Model performance on Sad speech (in training): 
	Precision: 0.6667, Recall: 0.4900, F1_score: 0.5648

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Epoch 47/100

Training Phase:
 [00:10<00:54, 24.79it/s]Training:  31%|███       | 496/1600 [00:20<00:44, 24.63it/s]Training:  47%|████▋     | 750/1600 [00:30<00:34, 24.98it/s]Training:  63%|██████▎   | 1006/1600 [00:40<00:23, 25.21it/s]Training:  79%|███████▉  | 1262/1600 [00:50<00:13, 25.04it/s]Training:  94%|█████████▍| 1510/1600 [01:00<00:03, 24.90it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 247/1600 [00:10<00:54, 24.61it/s]Training:  31%|███       | 494/1600 [00:20<00:44, 24.63it/s]Training:  46%|████▋     | 741/1600 [00:30<00:35, 24.36it/s]Training:  62%|██████▏   | 990/1600 [00:40<00:24, 24.54it/s]Training:  77%|███████▋  | 1239/1600 [00:50<00:14, 24.50it/s]Training:  93%|█████████▎| 14Training loss: 3411.2874, Training accuracy: 0.5269
Macro F1-score: 0.5298
Model performance on Angry speech (in training): 
	Precision: 0.5144, Recall: 0.5800, F1_score: 0.5452
Model performance on Happy speech (in training): 
	Precision: 0.3970, Recall: 0.4575, F1_score: 0.4251
Model performance on Neutral speech (in training): 
	Precision: 0.5879, Recall: 0.5850, F1_score: 0.5865
Model performance on Sad speech (in training): 
	Precision: 0.6690, Recall: 0.4850, F1_score: 0.5623

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Epoch 48/100

Training Phase:
Training loss: 3439.9395, Training accuracy: 0.5244
Macro F1-score: 0.5277
Model performance on Angry speech (in training): 
	Precision: 0.5075, Recall: 0.5900, F1_score: 0.5457
Model performance on Happy speech (in training): 
	Precision: 0.3821, Recall: 0.4375, F1_score: 0.4079
Model performance on Neutral speech (in training): 
	Precision: 0.5980, Recall: 0.5875, F1_score: 0.5927
Model performance on Sad speech (in training): 
	Precision: 0.6796, Recall: 0.4825, F1_score: 0.5643

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Epoch 49/100

Training Phase:
84/1600 [01:01<00:04, 23.93it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 230/1600 [00:10<00:59, 22.98it/s]Training:  29%|██▉       | 460/1600 [00:20<00:49, 22.93it/s]Training:  44%|████▎     | 696/1600 [00:30<00:38, 23.22it/s]Training:  60%|█████▉    | 953/1600 [00:40<00:26, 24.18it/s]Training:  76%|███████▌  | 1210/1600 [00:50<00:15, 24.48it/s]Training:  91%|█████████▏| 1461/1600 [01:00<00:05, 24.68it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 252/1600 [00:10<00:53, 25.12it/s]Training:  32%|███▏      | 519/1600 [00:20<0Training loss: 3400.8249, Training accuracy: 0.5244
Macro F1-score: 0.5273
Model performance on Angry speech (in training): 
	Precision: 0.5153, Recall: 0.5900, F1_score: 0.5501
Model performance on Happy speech (in training): 
	Precision: 0.3908, Recall: 0.4475, F1_score: 0.4172
Model performance on Neutral speech (in training): 
	Precision: 0.5827, Recall: 0.5725, F1_score: 0.5776
Model performance on Sad speech (in training): 
	Precision: 0.6701, Recall: 0.4875, F1_score: 0.5644

Eval Phase: 
Validation loss: 225.7875, Validation accuracy: 0.6600
Macro F1-score: 0.6521
Model performance on Angry speech (in validation): 
	Precision: 0.8537, Recall: 0.7000, F1_score: 0.7692
Model performance on Happy speech (in validation): 
	Precision: 0.6552, Recall: 0.7600, F1_score: 0.7037
Model performance on Neutral speech (in validation): 
	Precision: 0.5190, Recall: 0.8200, F1_score: 0.6357
Model performance on Sad speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Epoch 50/100

Two-stage training complete.
Model best accuracy on validation set: 0.6600

Test Phase: 
0:41, 26.00it/s]Training:  49%|████▉     | 786/1600 [00:30<00:31, 26.21it/s]Training:  66%|██████▌   | 1051/1600 [00:40<00:21, 25.83it/s]Training:  82%|████████▏ | 1304/1600 [00:50<00:11, 25.41it/s]Training:  97%|█████████▋| 1559/1600 [01:00<00:01, 25.42it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]Testing:   1%|          | 2/200 [00:00<00:11, 17.97it/s]Testing:   2%|▎         | 5/200 [00:00<00:09, 20.10it/s]Testing:   4%|▍         | 8/200 [00:00<00:09, 20.98it/s]Testing:   6%|▌         | 12/200 [00:00<00:07, 26.16it/s]Testing:   8%|▊         | 15/200 [00:00<00:06, 27.02it/s]Testing:  10%|█         | 21/200 [00:00<00:05, 35.34it/s]Testing:  12%|█▎        | 25/200 [00:00<00:04, 35.52it/s]Testing:  16%|█▌        | 31/200 [00:00<00:04, 42.15it/s]Testing:  18%|█▊        | 37/200 [00:01<00:03, 47.27it/s]Testing:  22%|██▏       | 44/200 [00:01<00:02, 53.22it/s]Testing:  25%|██▌       | 50/200 [00:01<00:02, 51.56it/s]Testing:  28%|██▊       | 57/200 [00:01<00:02, 55.97it/s]Testing:  32%|███▏      | 64/200 [00:01<00:02, 58.53it/s]Testing:  35%|███▌      | 70/200 [00:01<00:02, 48.10it/s]Testing:  39%|███▉      | 78/200 [00:01<00:02, 54.19it/s]Testing:  44%|████▎     | 87/200 [00:01<00:01, 62.13it/s]Testing:  48%|████▊     | 97/200 [00:01<00:01, 69.78it/s]Testing:  52%|█████▎    | 105/200 [00:02<00:01, 71.12it/s]Testing:  57%|█████▋    | 114/200 [00:02<00:01, 75.32it/s]Testing:  62%|██████▏   | 123/200 [00:02<00:01, 75.17it/s]Testing:  66%|██████▋   | 133/200 [00:02<00:00, 80.08it/s]Testing:  71%|███████   | 142/200 [00:02<00:00, 70.95it/s]Testing:  76%|███████▌  | 152/200 [00:02<00:00, 77.32it/s]TeTest loss: 208.0471, Test accuracy: 0.7200
Macro F1-score: 0.7175
Model performance on Angry speech (in test): 
	Precision: 0.9429, Recall: 0.6600, F1_score: 0.7765
Model performance on Happy speech (in test): 
	Precision: 0.7097, Recall: 0.8800, F1_score: 0.7857
Model performance on Neutral speech (in test): 
	Precision: 0.5753, Recall: 0.8400, F1_score: 0.6829
Model performance on Sad speech (in test): 
	Precision: 0.8333, Recall: 0.5000, F1_score: 0.6250

======================= This is fold_4 on de =======================

Load dataset: 
Loading de train data: fold_4...
Preprocess de fold_4 data for de model
Loading cn eval data: fold_4...
Preprocess cn fold_4 data for de model
Loading cn test data: fold_4...
Preprocess cn fold_4 data for de model
Use de model to add lora
================== SET ALL PARAMS =====================
modified_wav2vec2.base_model.model.masked_spec_embed: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.0.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.0.layer_norm.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.0.layer_norm.bias: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.1.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.2.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.3.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.4.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.5.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.6.conv.weight: False
modified_wav2vec2.base_model.model.feature_projection.layer_norm.weight: False
modified_wav2vec2.base_model.model.feature_projection.layer_norm.bias: False
modified_wav2vec2.base_model.model.feature_projection.projection.weight: False
modified_wav2vec2.base_model.model.feature_projection.projection.bias: False
modified_wav2vec2.base_model.model.encoder.pos_conv_embed.conv.bias: False
modified_wav2vec2.base_model.model.encoder.pos_conv_embed.conv.weight_g: False
modified_wav2vec2.base_model.model.encoder.pos_conv_embed.conv.weight_v: False
modified_wav2vec2.base_model.model.encoder.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.up.bias: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.up.bias: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.up.bias: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.up.bias: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.4.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.4.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.4.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.4.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.4.bottleneck_adaptor.up.bias: True
normal_classifier.dense1.weight: True
normal_classifier.dense1.bias: True
normal_classifier.dense.weight: True
normal_classifier.dense.bias: True
normal_classifier.out.weight: True
normal_classifier.out.bias: True
Set optimizer and criterion
Epoch 1/100

Training Phase:
sting:  81%|████████  | 162/200 [00:02<00:00, 83.18it/s]Testing:  86%|████████▌ | 172/200 [00:02<00:00, 85.63it/s]Testing:  92%|█████████▏| 183/200 [00:03<00:00, 90.49it/s]Testing:  97%|█████████▋| 194/200 [00:03<00:00, 94.37it/s]                                                          Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:   8%|▊         | 120/1600 [00:10<02:04, 11.90it/s]Training:  17%|█▋        | 271/1600 [00:20<01:36, 13.73it/s]Training:  27%|██▋       | 431/1600 [00:30<01:19, 14.75it/s]Training:  37%|███▋      | 599/1600 [00:40<01:04, 15.53it/s]Training:  49%|████▉     | 789/1600 [00:50<00:48, 16.75it/s]Training:  61%|██████    | 979/1600 [01:00<00:35, 17.28it/s]Training:  73%|███████▎  | 1162/1600 [01:11<00:25, 17.39it/s]Training:  84%|████████▍ | 1347/1600 [01:21<00:14, 17.72it/s]Training:  96%|████████Training loss: 293.1118, Training accuracy: 0.9394
Macro F1-score: 0.9394
Model performance on Angry speech (in training): 
	Precision: 0.9350, Recall: 0.9350, F1_score: 0.9350
Model performance on Happy speech (in training): 
	Precision: 0.9203, Recall: 0.8950, F1_score: 0.9075
Model performance on Neutral speech (in training): 
	Precision: 0.9141, Recall: 0.9575, F1_score: 0.9353
Model performance on Sad speech (in training): 
	Precision: 0.9898, Recall: 0.9700, F1_score: 0.9798

Eval Phase: 
Validation loss: 322.8991, Validation accuracy: 0.5200
Macro F1-score: 0.5358
Model performance on Angry speech (in validation): 
	Precision: 0.4423, Recall: 0.4600, F1_score: 0.4510
Model performance on Happy speech (in validation): 
	Precision: 0.3506, Recall: 0.5400, F1_score: 0.4252
Model performance on Neutral speech (in validation): 
	Precision: 0.6383, Recall: 0.6000, F1_score: 0.6186
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.4800, F1_score: 0.6486
New best accuracy for layer 4 on epoch 1: 0.5200. Model saved.
Epoch 2/100

Training Phase:
Training loss: 94.7095, Training accuracy: 0.9825
Macro F1-score: 0.9825
Model performance on Angry speech (in training): 
	Precision: 0.9850, Recall: 0.9875, F1_score: 0.9863
Model performance on Happy speech (in training): 
	Precision: 0.9748, Recall: 0.9675, F1_score: 0.9711
Model performance on Neutral speech (in training): 
	Precision: 0.9752, Recall: 0.9825, F1_score: 0.9788
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937

Eval Phase: 
Validation loss: 360.9477, Validation accuracy: 0.5150
Macro F1-score: 0.5258
Model performance on Angry speech (in validation): 
	Precision: 0.4143, Recall: 0.5800, F1_score: 0.4833
Model performance on Happy speech (in validation): 
	Precision: 0.3273, Recall: 0.3600, F1_score: 0.3429
Model performance on Neutral speech (in validation): 
	Precision: 0.6346, Recall: 0.6600, F1_score: 0.6471
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.4600, F1_score: 0.6301
Epoch 3/100

Training Phase:
█▋| 1542/1600 [01:31<00:03, 18.25it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 209/1600 [00:10<01:06, 20.89it/s]Training:  26%|██▌       | 418/1600 [00:20<00:57, 20.52it/s]Training:  39%|███▉      | 622/1600 [00:30<00:47, 20.43it/s]Training:  52%|█████▏    | 828/1600 [00:40<00:37, 20.49it/s]Training:  65%|██████▍   | 1037/1600 [00:50<00:27, 20.61it/s]Training:  78%|███████▊  | 1246/1600 [01:00<00:17, 20.56it/s]Training:  91%|█████████ | 1452/1600 [01:10<00:07, 20.53it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 208/Training loss: 79.8260, Training accuracy: 0.9825
Macro F1-score: 0.9825
Model performance on Angry speech (in training): 
	Precision: 0.9825, Recall: 0.9800, F1_score: 0.9812
Model performance on Happy speech (in training): 
	Precision: 0.9725, Recall: 0.9725, F1_score: 0.9725
Model performance on Neutral speech (in training): 
	Precision: 0.9825, Recall: 0.9850, F1_score: 0.9838
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925

Eval Phase: 
Validation loss: 408.1782, Validation accuracy: 0.4750
Macro F1-score: 0.4847
Model performance on Angry speech (in validation): 
	Precision: 0.3919, Recall: 0.5800, F1_score: 0.4677
Model performance on Happy speech (in validation): 
	Precision: 0.2642, Recall: 0.2800, F1_score: 0.2718
Model performance on Neutral speech (in validation): 
	Precision: 0.5962, Recall: 0.6200, F1_score: 0.6078
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.4200, F1_score: 0.5915
Epoch 4/100

Training Phase:
1600 [00:10<01:07, 20.68it/s]Training:  26%|██▌       | 419/1600 [00:20<00:56, 20.89it/s]Training:  39%|███▉      | 630/1600 [00:30<00:46, 20.82it/s]Training:  52%|█████▏    | 838/1600 [00:40<00:36, 20.79it/s]Training:  65%|██████▌   | 1046/1600 [00:50<00:26, 20.75it/s]Training:  78%|███████▊  | 1253/1600 [01:00<00:16, 20.59it/s]Training:  91%|█████████▏| 1460/1600 [01:10<00:06, 20.61it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  10%|█         | 160/1600 [00:10<01:30, 15.92it/s]Training:  22%|██▏       | 357/1600 [00:20<01:08, 18.12it/s]Training:  35%|███▍      | 559/1600 [00:30<00:54, 19.05it/s]Training:  48%|████▊     | 761/1600 [00:40<00:43, 19.39it/s]Training:  60%|██████    | 960/1600 [00:50<00:32Training loss: 63.7567, Training accuracy: 0.9856
Macro F1-score: 0.9856
Model performance on Angry speech (in training): 
	Precision: 0.9874, Recall: 0.9825, F1_score: 0.9850
Model performance on Happy speech (in training): 
	Precision: 0.9751, Recall: 0.9800, F1_score: 0.9776
Model performance on Neutral speech (in training): 
	Precision: 0.9850, Recall: 0.9875, F1_score: 0.9863
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937

Eval Phase: 
Validation loss: 419.6732, Validation accuracy: 0.4650
Macro F1-score: 0.4840
Model performance on Angry speech (in validation): 
	Precision: 0.4561, Recall: 0.5200, F1_score: 0.4860
Model performance on Happy speech (in validation): 
	Precision: 0.2658, Recall: 0.4200, F1_score: 0.3256
Model performance on Neutral speech (in validation): 
	Precision: 0.5909, Recall: 0.5200, F1_score: 0.5532
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.4000, F1_score: 0.5714
Epoch 5/100

Training Phase:
, 19.42it/s]Training:  73%|███████▎  | 1164/1600 [01:00<00:22, 19.71it/s]Training:  86%|████████▌ | 1372/1600 [01:10<00:11, 20.05it/s]Training:  99%|█████████▉| 1580/1600 [01:20<00:00, 20.25it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 195/1600 [00:10<01:12, 19.49it/s]Training:  24%|██▍       | 390/1600 [00:20<01:02, 19.41it/s]Training:  37%|███▋      | 593/1600 [00:30<00:50, 19.78it/s]Training:  50%|█████     | 800/1600 [00:40<00:39, 20.13it/s]Training:  63%|██████▎   | 1013/1600 [00:50<00:28, 20.53it/s]Training:  77%|███████▋  | 1229/1600 [01:00<00:17, 20.87it/s]Training:  90%|█████████ | 1445/1600 [01:10<00:07, 20.90it/s]                                              Training loss: 29.6724, Training accuracy: 0.9931
Macro F1-score: 0.9931
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912
Model performance on Happy speech (in training): 
	Precision: 0.9875, Recall: 0.9875, F1_score: 0.9875
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988

Eval Phase: 
Validation loss: 513.4541, Validation accuracy: 0.4950
Macro F1-score: 0.5032
Model performance on Angry speech (in validation): 
	Precision: 0.5758, Recall: 0.3800, F1_score: 0.4578
Model performance on Happy speech (in validation): 
	Precision: 0.3462, Recall: 0.7200, F1_score: 0.4675
Model performance on Neutral speech (in validation): 
	Precision: 0.5581, Recall: 0.4800, F1_score: 0.5161
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.4000, F1_score: 0.5714
Epoch 6/100

Training Phase:
Training loss: 18.7376, Training accuracy: 0.9969
Macro F1-score: 0.9969
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 543.8355, Validation accuracy: 0.4750
Macro F1-score: 0.4945
Model performance on Angry speech (in validation): 
	Precision: 0.4600, Recall: 0.4600, F1_score: 0.4600
Model performance on Happy speech (in validation): 
	Precision: 0.3011, Recall: 0.5600, F1_score: 0.3916
Model performance on Neutral speech (in validation): 
	Precision: 0.6389, Recall: 0.4600, F1_score: 0.5349
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.4200, F1_score: 0.5915
Epoch 7/100

Training Phase:
               Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 207/1600 [00:10<01:07, 20.60it/s]Training:  26%|██▌       | 414/1600 [00:20<00:57, 20.63it/s]Training:  39%|███▉      | 625/1600 [00:30<00:46, 20.82it/s]Training:  53%|█████▎    | 844/1600 [00:40<00:35, 21.21it/s]Training:  66%|██████▋   | 1063/1600 [00:50<00:25, 21.26it/s]Training:  80%|███████▉  | 1278/1600 [01:00<00:15, 21.32it/s]Training:  93%|█████████▎| 1493/1600 [01:10<00:05, 21.31it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 214/1600 [00:10<01:05, 21.19it/s]Training:  27%|██▋       | 426/1600 [00:20<00:56, 2Training loss: 32.8382, Training accuracy: 0.9925
Macro F1-score: 0.9925
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Happy speech (in training): 
	Precision: 0.9875, Recall: 0.9875, F1_score: 0.9875
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Validation loss: 562.3978, Validation accuracy: 0.4450
Macro F1-score: 0.4594
Model performance on Angry speech (in validation): 
	Precision: 0.4310, Recall: 0.5000, F1_score: 0.4630
Model performance on Happy speech (in validation): 
	Precision: 0.2658, Recall: 0.4200, F1_score: 0.3256
Model performance on Neutral speech (in validation): 
	Precision: 0.5652, Recall: 0.5200, F1_score: 0.5417
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.3400, F1_score: 0.5075
Epoch 8/100

Training Phase:
0.95it/s]Training:  40%|███▉      | 634/1600 [00:30<00:46, 20.71it/s]Training:  52%|█████▏    | 839/1600 [00:40<00:37, 20.44it/s]Training:  66%|██████▌   | 1055/1600 [00:50<00:26, 20.85it/s]Training:  79%|███████▉  | 1271/1600 [01:01<00:16, 20.38it/s]Training:  79%|███████▉  | 1271/1600 [01:11<00:16, 20.38it/s]Training:  92%|█████████▏| 1466/1600 [01:11<00:06, 20.04it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 203/1600 [00:10<01:08, 20.26it/s]Training:  26%|██▌       | 410/1600 [00:20<00:58, 20.49it/s]Training:  39%|███▊      | 617/1600 [00:30<00:47, 20.58it/s]Training:  52%|█████▏    | 825/1600 [00:40<00:37, 20.64it/s]Training:  65%|██████▍   | 1034/1600 [00:50<00:27, Training loss: 29.4254, Training accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962

Eval Phase: 
Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
New best accuracy for layer 4 on epoch 8: 0.5450. Model saved.
Epoch 9/100

Training Phase:
Training loss: 16.8346, Training accuracy: 0.9962
Macro F1-score: 0.9963
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937
Model performance on Neutral speech (in training): 
	Precision: 0.9900, Recall: 0.9950, F1_score: 0.9925
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987

Eval Phase: 
20.72it/s]Training:  78%|███████▊  | 1244/1600 [01:00<00:17, 20.79it/s]Training:  91%|█████████ | 1454/1600 [01:10<00:07, 20.77it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▎        | 200/1600 [00:10<01:10, 19.91it/s]Training:  25%|██▌       | 405/1600 [00:20<00:58, 20.26it/s]Training:  38%|███▊      | 615/1600 [00:30<00:47, 20.56it/s]Training:  52%|█████▏    | 827/1600 [00:40<00:37, 20.80it/s]Training:  65%|██████▌   | 1041/1600 [00:50<00:26, 20.99it/s]Training:  78%|███████▊  | 1255/1600 [01:00<00:16, 20.98it/s]Training:  92%|█████████▏| 1468/1600 [01:10<00:06, 21.07it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]           Validation loss: 724.9926, Validation accuracy: 0.4700
Macro F1-score: 0.4900
Model performance on Angry speech (in validation): 
	Precision: 0.4500, Recall: 0.5400, F1_score: 0.4909
Model performance on Happy speech (in validation): 
	Precision: 0.2771, Recall: 0.4600, F1_score: 0.3459
Model performance on Neutral speech (in validation): 
	Precision: 0.6486, Recall: 0.4800, F1_score: 0.5517
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.4000, F1_score: 0.5714
Epoch 10/100

Training Phase:
Training loss: 45.1749, Training accuracy: 0.9919
Macro F1-score: 0.9919
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9875, F1_score: 0.9900
Model performance on Happy speech (in training): 
	Precision: 0.9876, Recall: 0.9925, F1_score: 0.9900
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937

Eval Phase: 
Validation loss: 573.1187, Validation accuracy: 0.4750
Macro F1-score: 0.4858
Model performance on Angry speech (in validation): 
	Precision: 0.4792, Recall: 0.4600, F1_score: 0.4694
Model performance on Happy speech (in validation): 
	Precision: 0.3261, Recall: 0.6000, F1_score: 0.4225
Model performance on Neutral speech (in validation): 
	Precision: 0.5714, Recall: 0.4800, F1_score: 0.5217
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.3600, F1_score: 0.5294
Epoch 11/100

Training Phase:
                                        Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 211/1600 [00:10<01:06, 21.02it/s]Training:  26%|██▋       | 422/1600 [00:20<00:56, 20.95it/s]Training:  40%|███▉      | 632/1600 [00:30<00:46, 20.89it/s]Training:  53%|█████▎    | 841/1600 [00:40<00:36, 20.84it/s]Training:  66%|██████▌   | 1049/1600 [00:50<00:26, 20.77it/s]Training:  79%|███████▉  | 1260/1600 [01:00<00:16, 20.86it/s]Training:  92%|█████████▏| 1475/1600 [01:10<00:05, 21.06it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 222/1600 [00:10<01:02, 22.15it/s]Training:  28%|██▊       | 444/1600 [00:20<00:52, 21.95it/s]Training:  41%|████▏     | 663/1600 [00:30<00:42, 21.89it/s]Training loss: 3.8225, Training accuracy: 0.9994
Macro F1-score: 0.9994
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 775.3510, Validation accuracy: 0.4900
Macro F1-score: 0.4907
Model performance on Angry speech (in validation): 
	Precision: 0.5000, Recall: 0.2400, F1_score: 0.3243
Model performance on Happy speech (in validation): 
	Precision: 0.3448, Recall: 0.8000, F1_score: 0.4819
Model performance on Neutral speech (in validation): 
	Precision: 0.6316, Recall: 0.4800, F1_score: 0.5455
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.4400, F1_score: 0.6111
Validation loss does not decrease for 10 epochs. End training.
Epoch 12/100

Entering 2ND training phase: change training data from de to CN
Loading cn train data: fold_4...
Preprocess cn fold_4 data for de model
Reload model and reset eval loss

Training Phase:
Training:  55%|█████▌    | 882/1600 [00:40<00:32, 21.81it/s]Training:  69%|██████▉   | 1102/1600 [00:50<00:22, 21.87it/s]Training:  83%|████████▎ | 1323/1600 [01:00<00:12, 21.94it/s]Training:  96%|█████████▋| 1544/1600 [01:10<00:02, 21.95it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  10%|▉         | 152/1600 [00:10<01:35, 15.14it/s]Training:  21%|██▏       | 340/1600 [00:20<01:13, 17.26it/s]Training:  34%|███▍      | 545/1600 [00:30<00:56, 18.71it/s]Training:  48%|████▊     | 761/1600 [00:40<00:42, 19.83it/s]Training:  62%|██████▏   | 998/1600 [00:50<00:28, 21.20it/s]Training:  77%|███████▋  | 1239/1600 [01:00<00:16, 22.16it/s]Training:  93%|█████████▎| 1486/1600 [01:10<00:04,Training loss: 2965.5647, Training accuracy: 0.5763
Macro F1-score: 0.5745
Model performance on Angry speech (in training): 
	Precision: 0.5568, Recall: 0.7600, F1_score: 0.6427
Model performance on Happy speech (in training): 
	Precision: 0.4476, Recall: 0.4375, F1_score: 0.4425
Model performance on Neutral speech (in training): 
	Precision: 0.6197, Recall: 0.5500, F1_score: 0.5828
Model performance on Sad speech (in training): 
	Precision: 0.7240, Recall: 0.5575, F1_score: 0.6299

Eval Phase: 
Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 13/100

Training Phase:
Training loss: 3007.8853, Training accuracy: 0.5787
Macro F1-score: 0.5761
Model performance on Angry speech (in training): 
	Precision: 0.5615, Recall: 0.7650, F1_score: 0.6476
Model performance on Happy speech (in training): 
	Precision: 0.4714, Recall: 0.4525, F1_score: 0.4617
Model performance on Neutral speech (in training): 
	Precision: 0.6088, Recall: 0.5525, F1_score: 0.5793
Model performance on Sad speech (in training): 
	Precision: 0.7078, Recall: 0.5450, F1_score: 0.6158

Eval Phase: 
Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 14/100

Training Phase:
 22.99it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 267/1600 [00:10<00:49, 26.66it/s]Training:  33%|███▎      | 534/1600 [00:20<00:40, 26.35it/s]Training:  50%|████▉     | 796/1600 [00:30<00:31, 25.71it/s]Training:  65%|██████▌   | 1046/1600 [00:40<00:21, 25.23it/s]Training:  81%|████████  | 1291/1600 [00:50<00:12, 24.91it/s]Training:  96%|█████████▌| 1535/1600 [01:01<00:02, 24.71it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 247/1600 [00:10<00:54, 24.69it/s]Training:  31%|███       | 494/1600 [00:20<00:44, 24.64it/s]TTraining loss: 2968.0525, Training accuracy: 0.5819
Macro F1-score: 0.5791
Model performance on Angry speech (in training): 
	Precision: 0.5606, Recall: 0.7750, F1_score: 0.6506
Model performance on Happy speech (in training): 
	Precision: 0.4714, Recall: 0.4525, F1_score: 0.4617
Model performance on Neutral speech (in training): 
	Precision: 0.6197, Recall: 0.5500, F1_score: 0.5828
Model performance on Sad speech (in training): 
	Precision: 0.7143, Recall: 0.5500, F1_score: 0.6215

Eval Phase: 
Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 15/100

Training Phase:
raining:  46%|████▋     | 741/1600 [00:30<00:35, 24.52it/s]Training:  62%|██████▏   | 999/1600 [00:40<00:24, 25.00it/s]Training:  79%|███████▉  | 1265/1600 [00:50<00:13, 25.57it/s]Training:  96%|█████████▌| 1531/1600 [01:00<00:02, 25.88it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▋        | 261/1600 [00:10<00:51, 26.01it/s]Training:  33%|███▎      | 522/1600 [00:20<00:42, 25.24it/s]Training:  48%|████▊     | 775/1600 [00:30<00:32, 25.23it/s]Training:  65%|██████▍   | 1037/1600 [00:40<00:21, 25.61it/s]Training:  81%|████████▏ | 1302/1600 [00:50<00:11, 25.90it/s]Training:  98%|█████████▊| 1568/1600 [01:00<00:01, 26.11it/s]                                                         Training loss: 2957.8658, Training accuracy: 0.5763
Macro F1-score: 0.5730
Model performance on Angry speech (in training): 
	Precision: 0.5608, Recall: 0.7725, F1_score: 0.6498
Model performance on Happy speech (in training): 
	Precision: 0.4670, Recall: 0.4425, F1_score: 0.4544
Model performance on Neutral speech (in training): 
	Precision: 0.6034, Recall: 0.5400, F1_score: 0.5699
Model performance on Sad speech (in training): 
	Precision: 0.7051, Recall: 0.5500, F1_score: 0.6180

Eval Phase: 
Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 16/100

Training Phase:
Training loss: 2994.3239, Training accuracy: 0.5694
Macro F1-score: 0.5659
Model performance on Angry speech (in training): 
	Precision: 0.5560, Recall: 0.7700, F1_score: 0.6457
Model performance on Happy speech (in training): 
	Precision: 0.4562, Recall: 0.4300, F1_score: 0.4427
Model performance on Neutral speech (in training): 
	Precision: 0.5960, Recall: 0.5275, F1_score: 0.5597
Model performance on Sad speech (in training): 
	Precision: 0.6984, Recall: 0.5500, F1_score: 0.6154

Eval Phase: 
Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 17/100

Training Phase:
    Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▋        | 262/1600 [00:10<00:51, 26.11it/s]Training:  33%|███▎      | 525/1600 [00:20<00:41, 26.20it/s]Training:  49%|████▉     | 791/1600 [00:30<00:30, 26.37it/s]Training:  66%|██████▌   | 1058/1600 [00:40<00:20, 26.47it/s]Training:  66%|██████▌   | 1058/1600 [00:50<00:20, 26.47it/s]Training:  83%|████████▎ | 1323/1600 [00:50<00:10, 26.30it/s]Training:  99%|█████████▉| 1584/1600 [01:00<00:00, 25.97it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 246/1600 [00:10<00:55, 24.53it/s]Training:  31%|███       | 492/1600 [00:20<00:45, 24.Training loss: 2994.1658, Training accuracy: 0.5744
Macro F1-score: 0.5719
Model performance on Angry speech (in training): 
	Precision: 0.5471, Recall: 0.7550, F1_score: 0.6345
Model performance on Happy speech (in training): 
	Precision: 0.4626, Recall: 0.4325, F1_score: 0.4470
Model performance on Neutral speech (in training): 
	Precision: 0.6167, Recall: 0.5550, F1_score: 0.5842
Model performance on Sad speech (in training): 
	Precision: 0.7070, Recall: 0.5550, F1_score: 0.6218

Eval Phase: 
Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 18/100

Training Phase:
43it/s]Training:  46%|████▌     | 739/1600 [00:30<00:35, 24.55it/s]Training:  62%|██████▏   | 991/1600 [00:40<00:24, 24.80it/s]Training:  78%|███████▊  | 1243/1600 [00:50<00:14, 24.82it/s]Training:  93%|█████████▎| 1492/1600 [01:00<00:04, 24.79it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 251/1600 [00:10<00:53, 25.06it/s]Training:  16%|█▌        | 251/1600 [00:20<00:53, 25.06it/s]Training:  31%|███▏      | 501/1600 [00:20<00:44, 24.91it/s]Training:  48%|████▊     | 763/1600 [00:30<00:32, 25.48it/s]Training:  64%|██████▍   | 1030/1600 [00:40<00:21, 25.93it/s]Training:  81%|████████  | 1297/1600 [00:50<00:11, 26.14it/s]Training:  98%|█████████▊| 1562/1600 [01:00<00:Training loss: 2991.2105, Training accuracy: 0.5769
Macro F1-score: 0.5753
Model performance on Angry speech (in training): 
	Precision: 0.5425, Recall: 0.7500, F1_score: 0.6296
Model performance on Happy speech (in training): 
	Precision: 0.4607, Recall: 0.4400, F1_score: 0.4501
Model performance on Neutral speech (in training): 
	Precision: 0.6296, Recall: 0.5525, F1_score: 0.5885
Model performance on Sad speech (in training): 
	Precision: 0.7197, Recall: 0.5650, F1_score: 0.6331

Eval Phase: 
Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 19/100

Training Phase:
Training loss: 2935.0454, Training accuracy: 0.5856
Macro F1-score: 0.5837
Model performance on Angry speech (in training): 
	Precision: 0.5602, Recall: 0.7675, F1_score: 0.6477
Model performance on Happy speech (in training): 
	Precision: 0.4770, Recall: 0.4675, F1_score: 0.4722
Model performance on Neutral speech (in training): 
	Precision: 0.6289, Recall: 0.5550, F1_score: 0.5896
Model performance on Sad speech (in training): 
	Precision: 0.7199, Recall: 0.5525, F1_score: 0.6252

Eval Phase: 
Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 20/100

Training Phase:
01, 25.76it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 251/1600 [00:10<00:53, 25.03it/s]Training:  31%|███▏      | 502/1600 [00:20<00:44, 24.72it/s]Training:  47%|████▋     | 751/1600 [00:30<00:34, 24.77it/s]Training:  62%|██████▎   | 1000/1600 [00:40<00:24, 24.73it/s]Training:  78%|███████▊  | 1248/1600 [00:50<00:14, 24.73it/s]Training:  94%|█████████▎| 1496/1600 [01:00<00:04, 24.68it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 246/1600 [00:10<00:55, 24.59it/s]Training:  31%|███       | 493/1600 [00:20<00:44, 24.60it/sTraining loss: 2968.8595, Training accuracy: 0.5875
Macro F1-score: 0.5843
Model performance on Angry speech (in training): 
	Precision: 0.5678, Recall: 0.7850, F1_score: 0.6590
Model performance on Happy speech (in training): 
	Precision: 0.4720, Recall: 0.4425, F1_score: 0.4568
Model performance on Neutral speech (in training): 
	Precision: 0.6246, Recall: 0.5575, F1_score: 0.5892
Model performance on Sad speech (in training): 
	Precision: 0.7175, Recall: 0.5650, F1_score: 0.6322

Eval Phase: 
Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 21/100

Training Phase:
]Training:  47%|████▋     | 746/1600 [00:30<00:34, 24.92it/s]Training:  63%|██████▎   | 1009/1600 [00:40<00:23, 25.43it/s]Training:  80%|███████▉  | 1272/1600 [00:50<00:12, 25.59it/s]Training:  96%|█████████▌| 1532/1600 [01:00<00:02, 25.71it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▋        | 260/1600 [00:10<00:51, 25.92it/s]Training:  32%|███▎      | 520/1600 [00:20<00:41, 25.78it/s]Training:  49%|████▉     | 782/1600 [00:30<00:31, 25.94it/s]Training:  65%|██████▌   | 1047/1600 [00:40<00:21, 26.13it/s]Training:  82%|████████▏ | 1312/1600 [00:51<00:11, 25.49it/s]Training:  97%|█████████▋| 1557/1600 [01:01<00:01, 25.06it/s]                                                     Training loss: 2949.7336, Training accuracy: 0.5831
Macro F1-score: 0.5803
Model performance on Angry speech (in training): 
	Precision: 0.5580, Recall: 0.7700, F1_score: 0.6471
Model performance on Happy speech (in training): 
	Precision: 0.4772, Recall: 0.4450, F1_score: 0.4605
Model performance on Neutral speech (in training): 
	Precision: 0.6181, Recall: 0.5625, F1_score: 0.5890
Model performance on Sad speech (in training): 
	Precision: 0.7138, Recall: 0.5550, F1_score: 0.6245

Eval Phase: 
Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 22/100

Training Phase:
Training loss: 2959.4777, Training accuracy: 0.5844
Macro F1-score: 0.5832
Model performance on Angry speech (in training): 
	Precision: 0.5632, Recall: 0.7575, F1_score: 0.6461
Model performance on Happy speech (in training): 
	Precision: 0.4690, Recall: 0.4725, F1_score: 0.4707
Model performance on Neutral speech (in training): 
	Precision: 0.6218, Recall: 0.5425, F1_score: 0.5794
Model performance on Sad speech (in training): 
	Precision: 0.7290, Recall: 0.5650, F1_score: 0.6366

Eval Phase: 
Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 23/100

Training Phase:
        Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 241/1600 [00:10<00:56, 24.10it/s]Training:  30%|███       | 486/1600 [00:20<00:45, 24.27it/s]Training:  46%|████▌     | 731/1600 [00:30<00:35, 24.37it/s]Training:  61%|██████    | 976/1600 [00:40<00:25, 24.25it/s]Training:  76%|███████▋  | 1220/1600 [00:50<00:15, 24.31it/s]Training:  92%|█████████▏| 1464/1600 [01:00<00:05, 24.28it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 243/1600 [00:10<00:55, 24.25it/s]Training:  31%|███       | 489/1600 [00:20<00:45, 24.42it/s]Training:  46%|████▌     | 735/1600 [00:30<00:35, 24.36it/s]Training loss: 2952.5707, Training accuracy: 0.5806
Macro F1-score: 0.5781
Model performance on Angry speech (in training): 
	Precision: 0.5588, Recall: 0.7725, F1_score: 0.6485
Model performance on Happy speech (in training): 
	Precision: 0.4635, Recall: 0.4450, F1_score: 0.4541
Model performance on Neutral speech (in training): 
	Precision: 0.6193, Recall: 0.5450, F1_score: 0.5798
Model performance on Sad speech (in training): 
	Precision: 0.7203, Recall: 0.5600, F1_score: 0.6301

Eval Phase: 
Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 24/100

Training Phase:
Training loss: 2974.8635, Training accuracy: 0.5806
Macro F1-score: 0.5785
Model performance on Angry speech (in training): 
	Precision: 0.5593, Recall: 0.7550, F1_score: 0.6426
Model performance on Happy speech (in training): 
	Precision: 0.4752, Recall: 0.4550, F1_score: 0.4649
Model performance on Neutral speech (in training): 
	Precision: 0.6110, Recall: 0.5575, F1_score: 0.5830
Model performance on Sad speech (in training): 
	Precision: 0.7115, Recall: 0.5550, F1_score: 0.6236

Eval Phase: 
Training:  61%|██████▏   | 983/1600 [00:40<00:25, 24.53it/s]Training:  77%|███████▋  | 1231/1600 [00:50<00:15, 24.58it/s]Training:  93%|█████████▎| 1494/1600 [01:00<00:04, 25.13it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 247/1600 [00:10<00:54, 24.70it/s]Training:  31%|███       | 494/1600 [00:20<00:44, 24.63it/s]Training:  46%|████▋     | 741/1600 [00:30<00:34, 24.64it/s]Training:  62%|██████▏   | 992/1600 [00:40<00:24, 24.82it/s]Training:  78%|███████▊  | 1243/1600 [00:50<00:14, 24.82it/s]Training:  93%|█████████▎| 1492/1600 [01:00<00:04, 24.73it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                 Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 25/100

Training Phase:
Training loss: 3005.0318, Training accuracy: 0.5725
Macro F1-score: 0.5707
Model performance on Angry speech (in training): 
	Precision: 0.5415, Recall: 0.7500, F1_score: 0.6289
Model performance on Happy speech (in training): 
	Precision: 0.4430, Recall: 0.4175, F1_score: 0.4299
Model performance on Neutral speech (in training): 
	Precision: 0.6229, Recall: 0.5575, F1_score: 0.5884
Model performance on Sad speech (in training): 
	Precision: 0.7267, Recall: 0.5650, F1_score: 0.6357

Eval Phase: 
Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 26/100

Training Phase:
                                  Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 248/1600 [00:10<00:54, 24.72it/s]Training:  31%|███▏      | 503/1600 [00:20<00:43, 25.11it/s]Training:  47%|████▋     | 757/1600 [00:30<00:33, 24.82it/s]Training:  63%|██████▎   | 1002/1600 [00:40<00:24, 24.35it/s]Training:  77%|███████▋  | 1239/1600 [00:50<00:15, 24.02it/s]Training:  93%|█████████▎| 1486/1600 [01:00<00:04, 24.23it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 241/1600 [00:10<00:56, 24.01it/s]Training:  31%|███       | 496/1600 [00:20<00:44, 24.83it/s]Training:  47%|████▋     | 751/1600 [00:31<00:35, 24.00it/s]Training:  62%|██████▏   | 984/1600 [00:41<00:25, 23.71it/s]Training loss: 3005.6242, Training accuracy: 0.5787
Macro F1-score: 0.5754
Model performance on Angry speech (in training): 
	Precision: 0.5586, Recall: 0.7750, F1_score: 0.6492
Model performance on Happy speech (in training): 
	Precision: 0.4679, Recall: 0.4375, F1_score: 0.4522
Model performance on Neutral speech (in training): 
	Precision: 0.6121, Recall: 0.5325, F1_score: 0.5695
Model performance on Sad speech (in training): 
	Precision: 0.7059, Recall: 0.5700, F1_score: 0.6307

Eval Phase: 
Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 27/100

Training Phase:
Training loss: 2969.7152, Training accuracy: 0.5881
Macro F1-score: 0.5859
Model performance on Angry speech (in training): 
	Precision: 0.5631, Recall: 0.7700, F1_score: 0.6505
Model performance on Happy speech (in training): 
	Precision: 0.4764, Recall: 0.4550, F1_score: 0.4655
Model performance on Neutral speech (in training): 
	Precision: 0.6260, Recall: 0.5650, F1_score: 0.5940
Model performance on Sad speech (in training): 
	Precision: 0.7258, Recall: 0.5625, F1_score: 0.6338

Eval Phase: 
Training:  76%|███████▌  | 1217/1600 [00:51<00:16, 23.50it/s]Training:  76%|███████▌  | 1217/1600 [01:01<00:16, 23.50it/s]Training:  92%|█████████▏| 1467/1600 [01:01<00:05, 23.98it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 239/1600 [00:10<00:57, 23.87it/s]Training:  30%|██▉       | 478/1600 [00:20<00:47, 23.46it/s]Training:  44%|████▍     | 711/1600 [00:30<00:38, 23.35it/s]Training:  59%|█████▉    | 946/1600 [00:40<00:27, 23.37it/s]Training:  74%|███████▍  | 1183/1600 [00:50<00:17, 23.47it/s]Training:  90%|█████████ | 1441/1600 [01:00<00:06, 24.26it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                 Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 28/100

Training Phase:
Training loss: 2989.1612, Training accuracy: 0.5769
Macro F1-score: 0.5741
Model performance on Angry speech (in training): 
	Precision: 0.5510, Recall: 0.7700, F1_score: 0.6423
Model performance on Happy speech (in training): 
	Precision: 0.4630, Recall: 0.4375, F1_score: 0.4499
Model performance on Neutral speech (in training): 
	Precision: 0.6215, Recall: 0.5500, F1_score: 0.5836
Model performance on Sad speech (in training): 
	Precision: 0.7120, Recall: 0.5500, F1_score: 0.6206

Eval Phase: 
Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 29/100

Training Phase:
                                  Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 249/1600 [00:10<00:54, 24.87it/s]Training:  31%|███       | 499/1600 [00:20<00:44, 24.92it/s]Training:  47%|████▋     | 750/1600 [00:30<00:34, 24.99it/s]Training:  63%|██████▎   | 1001/1600 [00:40<00:24, 24.89it/s]Training:  78%|███████▊  | 1249/1600 [00:50<00:14, 24.81it/s]Training:  94%|█████████▎| 1496/1600 [01:00<00:04, 24.70it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 250/1600 [00:10<00:54, 24.91it/s]Training:  31%|███▏      | 500/1600 [00:20<00:44, 24.95it/s]Training:  31%|███▏      | 500/1600 [00:30<00:44, 24.95it/s]Training:  47%|████▋     | 749/1600 [00:30<00:34, 24.80it/s]TrainTraining loss: 2968.7925, Training accuracy: 0.5819
Macro F1-score: 0.5805
Model performance on Angry speech (in training): 
	Precision: 0.5593, Recall: 0.7550, F1_score: 0.6426
Model performance on Happy speech (in training): 
	Precision: 0.4646, Recall: 0.4600, F1_score: 0.4623
Model performance on Neutral speech (in training): 
	Precision: 0.6239, Recall: 0.5475, F1_score: 0.5832
Model performance on Sad speech (in training): 
	Precision: 0.7220, Recall: 0.5650, F1_score: 0.6339

Eval Phase: 
Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 30/100

Training Phase:
Training loss: 2975.3562, Training accuracy: 0.5825
Macro F1-score: 0.5795
Model performance on Angry speech (in training): 
	Precision: 0.5554, Recall: 0.7775, F1_score: 0.6479
Model performance on Happy speech (in training): 
	Precision: 0.4731, Recall: 0.4400, F1_score: 0.4560
Model performance on Neutral speech (in training): 
	Precision: 0.6194, Recall: 0.5575, F1_score: 0.5868
Model performance on Sad speech (in training): 
	Precision: 0.7208, Recall: 0.5550, F1_score: 0.6271

Eval Phase: 
ing:  62%|██████▏   | 998/1600 [00:40<00:24, 24.82it/s]Training:  78%|███████▊  | 1254/1600 [00:50<00:13, 25.09it/s]Training:  95%|█████████▍| 1513/1600 [01:00<00:03, 25.36it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 233/1600 [00:10<00:58, 23.23it/s]Training:  30%|██▉       | 473/1600 [00:20<00:47, 23.66it/s]Training:  45%|████▍     | 718/1600 [00:30<00:36, 24.02it/s]Training:  61%|██████    | 978/1600 [00:40<00:25, 24.77it/s]Training:  77%|███████▋  | 1238/1600 [00:50<00:14, 24.55it/s]Training:  92%|█████████▎| 1480/1600 [01:00<00:04, 24.39it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                        Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 31/100

Training Phase:
Training loss: 2954.1464, Training accuracy: 0.5825
Macro F1-score: 0.5790
Model performance on Angry speech (in training): 
	Precision: 0.5637, Recall: 0.7850, F1_score: 0.6562
Model performance on Happy speech (in training): 
	Precision: 0.4692, Recall: 0.4375, F1_score: 0.4528
Model performance on Neutral speech (in training): 
	Precision: 0.6152, Recall: 0.5475, F1_score: 0.5794
Model performance on Sad speech (in training): 
	Precision: 0.7134, Recall: 0.5600, F1_score: 0.6275

Eval Phase: 
Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 32/100

Training Phase:
                           Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 247/1600 [00:10<00:54, 24.68it/s]Training:  31%|███       | 494/1600 [00:20<00:44, 24.65it/s]Training:  46%|████▋     | 741/1600 [00:30<00:35, 24.44it/s]Training:  62%|██████▏   | 984/1600 [00:40<00:25, 24.38it/s]Training:  77%|███████▋  | 1229/1600 [00:50<00:15, 24.40it/s]Training:  92%|█████████▏| 1474/1600 [01:00<00:05, 24.31it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 246/1600 [00:10<00:55, 24.59it/s]Training:  31%|███       | 494/1600 [00:20<00:44, 24.66it/s]Training:  46%|████▋     | 743/1600 [00:30<00:34, 24.72it/s]Training:  62%|██████▏   | 991/1600 [00:40<00:24, 24.74it/s]Training:Training loss: 2994.4709, Training accuracy: 0.5756
Macro F1-score: 0.5733
Model performance on Angry speech (in training): 
	Precision: 0.5572, Recall: 0.7550, F1_score: 0.6412
Model performance on Happy speech (in training): 
	Precision: 0.4701, Recall: 0.4525, F1_score: 0.4611
Model performance on Neutral speech (in training): 
	Precision: 0.6045, Recall: 0.5425, F1_score: 0.5718
Model performance on Sad speech (in training): 
	Precision: 0.7038, Recall: 0.5525, F1_score: 0.6190

Eval Phase: 
Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 33/100

Training Phase:
Training loss: 2960.4007, Training accuracy: 0.5781
Macro F1-score: 0.5755
Model performance on Angry speech (in training): 
	Precision: 0.5588, Recall: 0.7725, F1_score: 0.6485
Model performance on Happy speech (in training): 
	Precision: 0.4569, Recall: 0.4375, F1_score: 0.4470
Model performance on Neutral speech (in training): 
	Precision: 0.6132, Recall: 0.5350, F1_score: 0.5714
Model performance on Sad speech (in training): 
	Precision: 0.7206, Recall: 0.5675, F1_score: 0.6350

Eval Phase: 
Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 34/100

Training Phase:
  78%|███████▊  | 1240/1600 [00:50<00:14, 24.79it/s]Training:  94%|█████████▎| 1498/1600 [01:00<00:04, 25.12it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 265/1600 [00:10<00:50, 26.46it/s]Training:  33%|███▎      | 531/1600 [00:20<00:40, 26.54it/s]Training:  50%|████▉     | 797/1600 [00:30<00:31, 25.74it/s]Training:  65%|██████▌   | 1046/1600 [00:40<00:21, 25.25it/s]Training:  81%|████████  | 1292/1600 [00:50<00:12, 25.00it/s]Training:  96%|█████████▌| 1538/1600 [01:00<00:02, 24.86it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?Training loss: 2973.0666, Training accuracy: 0.5813
Macro F1-score: 0.5785
Model performance on Angry speech (in training): 
	Precision: 0.5704, Recall: 0.7700, F1_score: 0.6553
Model performance on Happy speech (in training): 
	Precision: 0.4621, Recall: 0.4425, F1_score: 0.4521
Model performance on Neutral speech (in training): 
	Precision: 0.6073, Recall: 0.5375, F1_score: 0.5703
Model performance on Sad speech (in training): 
	Precision: 0.7121, Recall: 0.5750, F1_score: 0.6362

Eval Phase: 
Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 35/100

Training Phase:
it/s]Training:  15%|█▌        | 241/1600 [00:10<00:56, 24.08it/s]Training:  31%|███       | 489/1600 [00:20<00:45, 24.49it/s]Training:  46%|████▌     | 739/1600 [00:30<00:34, 24.71it/s]Training:  62%|██████▏   | 991/1600 [00:40<00:24, 24.90it/s]Training:  78%|███████▊  | 1252/1600 [00:50<00:13, 25.32it/s]Training:  95%|█████████▍| 1513/1600 [01:00<00:03, 25.50it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▋        | 261/1600 [00:10<00:51, 26.03it/s]Training:  33%|███▎      | 524/1600 [00:20<00:41, 26.17it/s]Training:  49%|████▉     | 787/1600 [00:30<00:31, 26.13it/s]Training:  66%|██████▌   | 1050/1600 [00:40<00:21, 26.16it/s]Training:  82%|████████▏ | 1313/1600 [00:50<00:11, 26.05it/s]Training loss: 2984.3577, Training accuracy: 0.5775
Macro F1-score: 0.5759
Model performance on Angry speech (in training): 
	Precision: 0.5613, Recall: 0.7550, F1_score: 0.6439
Model performance on Happy speech (in training): 
	Precision: 0.4490, Recall: 0.4400, F1_score: 0.4444
Model performance on Neutral speech (in training): 
	Precision: 0.6160, Recall: 0.5575, F1_score: 0.5853
Model performance on Sad speech (in training): 
	Precision: 0.7240, Recall: 0.5575, F1_score: 0.6299

Eval Phase: 
Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 36/100

Training Phase:
Training loss: 2929.3255, Training accuracy: 0.5819
Macro F1-score: 0.5784
Model performance on Angry speech (in training): 
	Precision: 0.5644, Recall: 0.7775, F1_score: 0.6540
Model performance on Happy speech (in training): 
	Precision: 0.4771, Recall: 0.4425, F1_score: 0.4591
Model performance on Neutral speech (in training): 
	Precision: 0.6055, Recall: 0.5525, F1_score: 0.5778
Model performance on Sad speech (in training): 
	Precision: 0.7093, Recall: 0.5550, F1_score: 0.6227

Eval Phase: 
Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 37/100

Training Phase:
Training:  98%|█████████▊| 1573/1600 [01:00<00:01, 26.03it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 259/1600 [00:10<00:51, 25.88it/s]Training:  32%|███▏      | 518/1600 [00:20<00:41, 25.87it/s]Training:  49%|████▊     | 779/1600 [00:30<00:31, 25.98it/s]Training:  65%|██████▌   | 1040/1600 [00:40<00:21, 25.97it/s]Training:  82%|████████▏ | 1304/1600 [00:50<00:11, 26.10it/s]Training:  98%|█████████▊| 1568/1600 [01:00<00:01, 26.19it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▋        | 262/1600 [00:10<00:51, 26.14itTraining loss: 2957.6633, Training accuracy: 0.5775
Macro F1-score: 0.5740
Model performance on Angry speech (in training): 
	Precision: 0.5622, Recall: 0.7800, F1_score: 0.6534
Model performance on Happy speech (in training): 
	Precision: 0.4667, Recall: 0.4375, F1_score: 0.4516
Model performance on Neutral speech (in training): 
	Precision: 0.6006, Recall: 0.5450, F1_score: 0.5714
Model performance on Sad speech (in training): 
	Precision: 0.7134, Recall: 0.5475, F1_score: 0.6195

Eval Phase: 
Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 38/100

Training Phase:
/s]Training:  33%|███▎      | 524/1600 [00:20<00:41, 25.92it/s]Training:  49%|████▉     | 783/1600 [00:30<00:31, 25.86it/s]Training:  65%|██████▌   | 1042/1600 [00:40<00:21, 25.86it/s]Training:  81%|████████▏ | 1301/1600 [00:50<00:11, 25.86it/s]Training:  98%|█████████▊| 1560/1600 [01:00<00:01, 25.84it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▋        | 261/1600 [00:10<00:51, 26.08it/s]Training:  33%|███▎      | 525/1600 [00:20<00:40, 26.24it/s]Training:  49%|████▉     | 789/1600 [00:30<00:30, 26.21it/s]Training:  66%|██████▌   | 1051/1600 [00:40<00:21, 26.13it/s]Training:  82%|████████▏ | 1312/1600 [00:50<00:11, 26.05it/s]Training:  98%|█████████▊| 1574/1600 [01:0Training loss: 2999.8763, Training accuracy: 0.5787
Macro F1-score: 0.5778
Model performance on Angry speech (in training): 
	Precision: 0.5583, Recall: 0.7425, F1_score: 0.6373
Model performance on Happy speech (in training): 
	Precision: 0.4573, Recall: 0.4550, F1_score: 0.4561
Model performance on Neutral speech (in training): 
	Precision: 0.6205, Recall: 0.5600, F1_score: 0.5887
Model performance on Sad speech (in training): 
	Precision: 0.7217, Recall: 0.5575, F1_score: 0.6291

Eval Phase: 
Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 39/100

Training Phase:
Training loss: 2988.2056, Training accuracy: 0.5744
Macro F1-score: 0.5712
Model performance on Angry speech (in training): 
	Precision: 0.5580, Recall: 0.7700, F1_score: 0.6471
Model performance on Happy speech (in training): 
	Precision: 0.4521, Recall: 0.4250, F1_score: 0.4381
Model performance on Neutral speech (in training): 
	Precision: 0.6091, Recall: 0.5375, F1_score: 0.5710
Model performance on Sad speech (in training): 
	Precision: 0.7085, Recall: 0.5650, F1_score: 0.6287

Eval Phase: 
Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 40/100

Training Phase:
0<00:00, 26.09it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 257/1600 [00:10<00:52, 25.61it/s]Training:  32%|███▏      | 516/1600 [00:20<00:42, 25.73it/s]Training:  48%|████▊     | 775/1600 [00:30<00:32, 25.69it/s]Training:  64%|██████▍   | 1032/1600 [00:41<00:22, 24.87it/s]Training:  79%|███████▉  | 1270/1600 [00:51<00:13, 24.33it/s]Training:  94%|█████████▍| 1504/1600 [01:01<00:03, 24.00it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▋        | 260/1600 [00:10<00:51, 25.99it/s]Training:  32%|███▎      | 520/1600 [00:20<00:41, 25Training loss: 2992.7044, Training accuracy: 0.5719
Macro F1-score: 0.5693
Model performance on Angry speech (in training): 
	Precision: 0.5558, Recall: 0.7600, F1_score: 0.6420
Model performance on Happy speech (in training): 
	Precision: 0.4613, Recall: 0.4475, F1_score: 0.4543
Model performance on Neutral speech (in training): 
	Precision: 0.6057, Recall: 0.5300, F1_score: 0.5653
Model performance on Sad speech (in training): 
	Precision: 0.6984, Recall: 0.5500, F1_score: 0.6154

Eval Phase: 
Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 41/100

Training Phase:
.85it/s]Training:  49%|████▊     | 778/1600 [00:30<00:32, 25.33it/s]Training:  49%|████▊     | 778/1600 [00:40<00:32, 25.33it/s]Training:  64%|██████▎   | 1016/1600 [00:40<00:23, 24.55it/s]Training:  79%|███████▊  | 1259/1600 [00:50<00:13, 24.45it/s]Training:  94%|█████████▍| 1502/1600 [01:01<00:04, 24.16it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 230/1600 [00:10<00:59, 22.99it/s]Training:  29%|██▉       | 462/1600 [00:20<00:49, 23.06it/s]Training:  43%|████▎     | 694/1600 [00:30<00:39, 23.09it/s]Training:  58%|█████▊    | 926/1600 [00:40<00:29, 22.88it/s]Training:  72%|███████▏  | 1157/1600 [00:50<00:19, 22.95it/s]Training:  87%|████████▋ | 1388/1600 [01:00<00Training loss: 2983.2401, Training accuracy: 0.5800
Macro F1-score: 0.5768
Model performance on Angry speech (in training): 
	Precision: 0.5566, Recall: 0.7750, F1_score: 0.6479
Model performance on Happy speech (in training): 
	Precision: 0.4663, Recall: 0.4325, F1_score: 0.4488
Model performance on Neutral speech (in training): 
	Precision: 0.6158, Recall: 0.5450, F1_score: 0.5782
Model performance on Sad speech (in training): 
	Precision: 0.7138, Recall: 0.5675, F1_score: 0.6323

Eval Phase: 
Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 42/100

Training Phase:
Training loss: 2963.1872, Training accuracy: 0.5737
Macro F1-score: 0.5723
Model performance on Angry speech (in training): 
	Precision: 0.5503, Recall: 0.7525, F1_score: 0.6357
Model performance on Happy speech (in training): 
	Precision: 0.4506, Recall: 0.4450, F1_score: 0.4478
Model performance on Neutral speech (in training): 
	Precision: 0.6174, Recall: 0.5325, F1_score: 0.5718
Model performance on Sad speech (in training): 
	Precision: 0.7220, Recall: 0.5650, F1_score: 0.6339

Eval Phase: 
Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 43/100

Training Phase:
:09, 22.96it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 231/1600 [00:10<00:59, 23.06it/s]Training:  29%|██▉       | 462/1600 [00:20<00:49, 22.94it/s]Training:  43%|████▎     | 693/1600 [00:30<00:39, 22.99it/s]Training:  58%|█████▊    | 924/1600 [00:40<00:29, 22.95it/s]Training:  72%|███████▏  | 1155/1600 [00:50<00:19, 22.98it/s]Training:  87%|████████▋ | 1386/1600 [01:00<00:09, 22.96it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 230/1600 [00:10<00:59, 22.93it/s]Training:  29%|██▉       | 461/1600 [00:20<00:49, 23.01it/s]TraiTraining loss: 2990.2777, Training accuracy: 0.5787
Macro F1-score: 0.5759
Model performance on Angry speech (in training): 
	Precision: 0.5680, Recall: 0.7725, F1_score: 0.6547
Model performance on Happy speech (in training): 
	Precision: 0.4706, Recall: 0.4600, F1_score: 0.4652
Model performance on Neutral speech (in training): 
	Precision: 0.6006, Recall: 0.5300, F1_score: 0.5631
Model performance on Sad speech (in training): 
	Precision: 0.7083, Recall: 0.5525, F1_score: 0.6208

Eval Phase: 
Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 44/100

Training Phase:
Training loss: 2969.4119, Training accuracy: 0.5806
Macro F1-score: 0.5789
Model performance on Angry speech (in training): 
	Precision: 0.5632, Recall: 0.7575, F1_score: 0.6461
Model performance on Happy speech (in training): 
	Precision: 0.4658, Recall: 0.4600, F1_score: 0.4629
Model performance on Neutral speech (in training): 
	Precision: 0.6162, Recall: 0.5500, F1_score: 0.5812
Model performance on Sad speech (in training): 
	Precision: 0.7161, Recall: 0.5550, F1_score: 0.6254

Eval Phase: 
ning:  43%|████▎     | 692/1600 [00:30<00:39, 22.93it/s]Training:  58%|█████▊    | 923/1600 [00:40<00:29, 22.96it/s]Training:  72%|███████▏  | 1154/1600 [00:50<00:19, 22.97it/s]Training:  86%|████████▋ | 1384/1600 [01:00<00:09, 22.95it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 229/1600 [00:10<01:00, 22.84it/s]Training:  29%|██▊       | 459/1600 [00:20<00:49, 22.89it/s]Training:  43%|████▎     | 690/1600 [00:30<00:39, 22.96it/s]Training:  58%|█████▊    | 921/1600 [00:40<00:29, 22.93it/s]Training:  72%|███████▏  | 1153/1600 [00:50<00:19, 22.99it/s]Training:  87%|████████▋ | 1385/1600 [01:00<00:09, 22.95it/s]                                                             EvaluatingValidation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 45/100

Training Phase:
Training loss: 2983.6349, Training accuracy: 0.5744
Macro F1-score: 0.5724
Model performance on Angry speech (in training): 
	Precision: 0.5584, Recall: 0.7525, F1_score: 0.6411
Model performance on Happy speech (in training): 
	Precision: 0.4617, Recall: 0.4525, F1_score: 0.4571
Model performance on Neutral speech (in training): 
	Precision: 0.6034, Recall: 0.5325, F1_score: 0.5657
Model performance on Sad speech (in training): 
	Precision: 0.7089, Recall: 0.5600, F1_score: 0.6257

Eval Phase: 
Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 46/100

Training Phase:
:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 230/1600 [00:10<00:59, 22.99it/s]Training:  29%|██▉       | 460/1600 [00:20<00:49, 22.89it/s]Training:  43%|████▎     | 689/1600 [00:30<00:39, 22.90it/s]Training:  57%|█████▋    | 918/1600 [00:40<00:29, 22.84it/s]Training:  72%|███████▏  | 1146/1600 [00:51<00:20, 21.79it/s]Training:  86%|████████▌ | 1376/1600 [01:01<00:10, 22.16it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 225/1600 [00:10<01:01, 22.45it/s]Training:  29%|██▉       | 468/1600 [00:20<00:48, 23.50it/s]Training:  45%|████▍     | 713/1600 [00:30<00:37, 23.94it/s]Training:  60%|██Training loss: 2976.8373, Training accuracy: 0.5800
Macro F1-score: 0.5777
Model performance on Angry speech (in training): 
	Precision: 0.5572, Recall: 0.7675, F1_score: 0.6456
Model performance on Happy speech (in training): 
	Precision: 0.4609, Recall: 0.4425, F1_score: 0.4515
Model performance on Neutral speech (in training): 
	Precision: 0.6193, Recall: 0.5450, F1_score: 0.5798
Model performance on Sad speech (in training): 
	Precision: 0.7220, Recall: 0.5650, F1_score: 0.6339

Eval Phase: 
Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 47/100

Training Phase:
Training loss: 2992.1138, Training accuracy: 0.5750
Macro F1-score: 0.5728
Model performance on Angry speech (in training): 
	Precision: 0.5622, Recall: 0.7575, F1_score: 0.6454
Model performance on Happy speech (in training): 
	Precision: 0.4576, Recall: 0.4450, F1_score: 0.4512
Model performance on Neutral speech (in training): 
	Precision: 0.6039, Recall: 0.5375, F1_score: 0.5688
Model performance on Sad speech (in training): 
	Precision: 0.7089, Recall: 0.5600, F1_score: 0.6257

Eval Phase: 
██▉    | 958/1600 [00:40<00:26, 24.07it/s]Training:  75%|███████▌  | 1202/1600 [00:50<00:16, 24.17it/s]Training:  90%|█████████ | 1446/1600 [01:00<00:06, 24.02it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 243/1600 [00:10<00:55, 24.28it/s]Training:  30%|███       | 488/1600 [00:20<00:45, 24.41it/s]Training:  46%|████▌     | 733/1600 [00:30<00:35, 24.40it/s]Training:  61%|██████▏   | 980/1600 [00:40<00:25, 24.49it/s]Training:  77%|███████▋  | 1227/1600 [00:50<00:15, 24.17it/s]Training:  92%|█████████▏| 1472/1600 [01:00<00:05, 24.26it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                           Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 48/100

Training Phase:
Training loss: 2969.3490, Training accuracy: 0.5831
Macro F1-score: 0.5801
Model performance on Angry speech (in training): 
	Precision: 0.5683, Recall: 0.7800, F1_score: 0.6575
Model performance on Happy speech (in training): 
	Precision: 0.4688, Recall: 0.4500, F1_score: 0.4592
Model performance on Neutral speech (in training): 
	Precision: 0.6121, Recall: 0.5325, F1_score: 0.5695
Model performance on Sad speech (in training): 
	Precision: 0.7147, Recall: 0.5700, F1_score: 0.6342

Eval Phase: 
Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 49/100

Training Phase:
        Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 267/1600 [00:10<00:49, 26.69it/s]Training:  33%|███▎      | 534/1600 [00:20<00:40, 26.51it/s]Training:  50%|████▉     | 799/1600 [00:30<00:30, 26.49it/s]Training:  66%|██████▋   | 1064/1600 [00:40<00:20, 26.33it/s]Training:  83%|████████▎ | 1327/1600 [00:50<00:10, 26.30it/s]Training:  83%|████████▎ | 1327/1600 [01:00<00:10, 26.30it/s]Training:  99%|█████████▉| 1584/1600 [01:00<00:00, 25.89it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 249/1600 [00:10<00:54, 24.89it/s]Training:  31%|███       | 498/1600 [00:20<00:45, 24.49it/s]Training:  46%|████▋     | 744/1600 [00:30<00:34, 24.52it/s]Training:  62%|█Training loss: 2954.9357, Training accuracy: 0.5719
Macro F1-score: 0.5703
Model performance on Angry speech (in training): 
	Precision: 0.5425, Recall: 0.7500, F1_score: 0.6296
Model performance on Happy speech (in training): 
	Precision: 0.4522, Recall: 0.4375, F1_score: 0.4447
Model performance on Neutral speech (in training): 
	Precision: 0.6211, Recall: 0.5450, F1_score: 0.5806
Model performance on Sad speech (in training): 
	Precision: 0.7184, Recall: 0.5550, F1_score: 0.6262

Eval Phase: 
Validation loss: 427.8677, Validation accuracy: 0.5450
Macro F1-score: 0.5543
Model performance on Angry speech (in validation): 
	Precision: 0.4737, Recall: 0.5400, F1_score: 0.5047
Model performance on Happy speech (in validation): 
	Precision: 0.3559, Recall: 0.4200, F1_score: 0.3853
Model performance on Neutral speech (in validation): 
	Precision: 0.6102, Recall: 0.7200, F1_score: 0.6606
Model performance on Sad speech (in validation): 
	Precision: 1.0000, Recall: 0.5000, F1_score: 0.6667
Epoch 50/100

Two-stage training complete.
Model best accuracy on validation set: 0.5450

Test Phase: 
█████▏   | 990/1600 [00:40<00:25, 24.07it/s]Training:  77%|███████▋  | 1225/1600 [00:51<00:15, 23.54it/s]Training:  92%|█████████▏| 1469/1600 [01:01<00:05, 23.81it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]Testing:   2%|▏         | 3/200 [00:00<00:09, 20.47it/s]Testing:   3%|▎         | 6/200 [00:00<00:07, 24.92it/s]Testing:   4%|▍         | 9/200 [00:00<00:07, 25.38it/s]Testing:   7%|▋         | 14/200 [00:00<00:05, 32.56it/s]Testing:  10%|▉         | 19/200 [00:00<00:05, 35.99it/s]Testing:  12%|█▎        | 25/200 [00:00<00:04, 41.78it/s]Testing:  15%|█▌        | 30/200 [00:00<00:03, 44.08it/s]Testing:  18%|█▊        | 36/200 [00:00<00:03, 47.62it/s]Testing:  22%|██▏       | 43/200 [00:01<00:02, 53.38it/s]Testing:  25%|██▌       | 50/200 [00:01<00:02, 53.71it/s]Testing:  28%|██▊       | 56/200 [00:01<00:02, 54.66it/s]Testing:  31%|███       | 62/200 [00:01<00:02, 51.70it/s]Testing:  34%|███▍      | 69/200 [00:01<00:02, 56.47it/s]Testing:  38%|███▊      | 77/200 [00:01<00:02, 61.19it/s]Testing:  44%|████▎     | 87/200 [00:01<00:01, 71.68it/s]Testing:  48%|████▊     | 95/200 [00:01<00:01, 73.77it/s]Testing:  52%|█████▏    | 103/200 [00:01<00:01, 70.22it/s]Testing:  56%|█████▌    | 112/200 [00:02<00:01, 75.35it/s]Testing:  60%|██████    | 120/200 [00:02<00:01, 73.40it/s]Testing:  64%|██████▍   | 128/200 [00:02<00:00, 74.45it/s]Testing:  68%|██████▊   | 137/200 [00:02<00:00, 77.40it/s]Testing:  73%|███████▎  | 146/200 [00:02<00:00, 77.03it/s]Testing:  78%|███████▊  | 157/200 [00:02<00:00, 82.76it/s]Testing:  83%|████████▎ | 166/200 [00:02<00:00, 83.26it/s]Testing:  88%|██Test loss: 452.6465, Test accuracy: 0.5250
Macro F1-score: 0.5342
Model performance on Angry speech (in test): 
	Precision: 0.4310, Recall: 0.5000, F1_score: 0.4630
Model performance on Happy speech (in test): 
	Precision: 0.3220, Recall: 0.3800, F1_score: 0.3486
Model performance on Neutral speech (in test): 
	Precision: 0.6379, Recall: 0.7400, F1_score: 0.6852
Model performance on Sad speech (in test): 
	Precision: 0.9600, Recall: 0.4800, F1_score: 0.6400

de, all folds layer accuracy: ['0.3300', '0.7500', '0.5500', '0.7200', '0.5250']
de, all emo precision: {'Angry': ['0.4369', '1.0000', '0.5750', '0.9429', '0.4310'], 'Happy': ['0.1000', '0.7200', '0.5397', '0.7097', '0.3220'], 'Neutral': ['0.7647', '0.6042', '0.5882', '0.5753', '0.6379'], 'Sad': ['0.0000', '0.7258', '0.5238', '0.8333', '0.9600']}
de, all emo recall: {'Angry': ['0.9000', '0.8000', '0.4600', '0.6600', '0.5000'], 'Happy': ['0.1600', '0.7200', '0.6800', '0.8800', '0.3800'], 'Neutral': ['0.2600', '0.5800', '0.4000', '0.8400', '0.7400'], 'Sad': ['0.0000', '0.9000', '0.6600', '0.5000', '0.4800']}
de, all emo f1score: {'Angry': ['0.5882', '0.8889', '0.5111', '0.7765', '0.4630'], 'Happy': ['0.1231', '0.7200', '0.6018', '0.7857', '0.3486'], 'Neutral': ['0.3881', '0.5918', '0.4762', '0.6829', '0.6852'], 'Sad': ['0.0000', '0.8036', '0.5841', '0.6250', '0.6400']}
█████▊ | 176/200 [00:02<00:00, 87.36it/s]Testing:  94%|█████████▎| 187/200 [00:02<00:00, 91.19it/s]Testing:  98%|█████████▊| 197/200 [00:03<00:00, 92.83it/s]                                                          ------------------NEXT SCRIPT: RUNNER_CN, former -> current ----------------------
/work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Matplotlib created a temporary cache directory at /dev/shm/zhan7721_5912030/matplotlib-c1rgo8_0 because the default path (/home/tc062/tc062/zhan7721/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.

======================= This is fold_0 on cn =======================

Load dataset: 
Loading cn train data: fold_0...
Preprocess cn fold_0 data for cn model
Loading de eval data: fold_0...
Preprocess de fold_0 data for cn model
Loading de test data: fold_0...
Preprocess de fold_0 data for cn model
Use cn model to add lora
================== SET ALL PARAMS =====================
modified_wav2vec2.base_model.model.masked_spec_embed: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.0.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.0.layer_norm.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.0.layer_norm.bias: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.1.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.2.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.3.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.4.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.5.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.6.conv.weight: False
modified_wav2vec2.base_model.model.feature_projection.layer_norm.weight: False
modified_wav2vec2.base_model.model.feature_projection.layer_norm.bias: False
modified_wav2vec2.base_model.model.feature_projection.projection.weight: False
modified_wav2vec2.base_model.model.feature_projection.projection.bias: False
modified_wav2vec2.base_model.model.encoder.pos_conv_embed.conv.bias: False
modified_wav2vec2.base_model.model.encoder.pos_conv_embed.conv.weight_g: False
modified_wav2vec2.base_model.model.encoder.pos_conv_embed.conv.weight_v: False
modified_wav2vec2.base_model.model.encoder.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.up.bias: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.up.bias: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.up.bias: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.up.bias: True
normal_classifier.dense1.weight: True
normal_classifier.dense1.bias: True
normal_classifier.dense.weight: True
normal_classifier.dense.bias: True
normal_classifier.out.weight: True
normal_classifier.out.bias: True
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training loss: 1314.9543, Training accuracy: 0.6531
Macro F1-score: 0.6448
Model performance on Angry speech (in training): 
	Precision: 0.8783, Recall: 0.2525, F1_score: 0.3922
Model performance on Happy speech (in training): 
	Precision: 0.4319, Recall: 0.8875, F1_score: 0.5810
Model performance on Neutral speech (in training): 
	Precision: 0.8529, Recall: 0.6525, F1_score: 0.7394
Model performance on Sad speech (in training): 
	Precision: 0.9188, Recall: 0.8200, F1_score: 0.8666

Eval Phase: 
Validation loss: 561.2525, Validation accuracy: 0.3950
Macro F1-score: 0.3134
Model performance on Angry speech (in validation): 
	Precision: 0.8929, Recall: 0.5000, F1_score: 0.6410
Model performance on Happy speech (in validation): 
	Precision: 0.7500, Recall: 0.0600, F1_score: 0.1111
Model performance on Neutral speech (in validation): 
	Precision: 0.5000, Recall: 0.0200, F1_score: 0.0385
Model performance on Sad speech (in validation): 
	Precision: 0.3012, Recall: 1.0000, F1_score: 0.4630
New best accuracy for layer 3 on epoch 1: 0.3950. Model saved.
Epoch 2/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:   0%|          | 1/1600 [00:14<6:30:18, 14.65s/it]Training:  12%|█▏        | 185/1600 [00:24<02:35,  9.12it/s]Training:  26%|██▋       | 421/1600 [00:34<01:18, 15.10it/s]Training:  41%|████▏     | 661/1600 [00:44<00:51, 18.40it/s]Training:  57%|█████▋    | 919/1600 [00:54<00:32, 20.94it/s]Training:  74%|███████▍  | 1180/1600 [01:04<00:18, 22.64it/s]Training:  90%|█████████ | 1443/1600 [01:14<00:06, 23.79it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  18%|█▊        | 290/1600 [00:10<00:45, 28.97it/s]Training:  36%|███▋      | 580/1600 [00:20<00:36, 27.84it/s]Training:  53%|█████▎    | 855/1600 [00:30<00:26, 27.66it/s]Training:  72%|███████▏  | 1146/160Training loss: 405.0586, Training accuracy: 0.9256
Macro F1-score: 0.9256
Model performance on Angry speech (in training): 
	Precision: 0.9023, Recall: 0.9000, F1_score: 0.9011
Model performance on Happy speech (in training): 
	Precision: 0.8853, Recall: 0.8875, F1_score: 0.8864
Model performance on Neutral speech (in training): 
	Precision: 0.9500, Recall: 0.9500, F1_score: 0.9500
Model performance on Sad speech (in training): 
	Precision: 0.9650, Recall: 0.9650, F1_score: 0.9650

Eval Phase: 
Validation loss: 419.5408, Validation accuracy: 0.5400
Macro F1-score: 0.4524
Model performance on Angry speech (in validation): 
	Precision: 0.7931, Recall: 0.9200, F1_score: 0.8519
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0400, F1_score: 0.0769
Model performance on Neutral speech (in validation): 
	Precision: 0.7143, Recall: 0.2000, F1_score: 0.3125
Model performance on Sad speech (in validation): 
	Precision: 0.3968, Recall: 1.0000, F1_score: 0.5682
New best accuracy for layer 3 on epoch 2: 0.5400. Model saved.
Epoch 3/100

Training Phase:
Training loss: 236.2861, Training accuracy: 0.9531
Macro F1-score: 0.9531
Model performance on Angry speech (in training): 
	Precision: 0.9352, Recall: 0.9375, F1_score: 0.9363
Model performance on Happy speech (in training): 
	Precision: 0.9246, Recall: 0.9200, F1_score: 0.9223
Model performance on Neutral speech (in training): 
	Precision: 0.9656, Recall: 0.9825, F1_score: 0.9740
Model performance on Sad speech (in training): 
	Precision: 0.9873, Recall: 0.9725, F1_score: 0.9798

Eval Phase: 
Validation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
New best accuracy for layer 3 on epoch 3: 0.5900. Model saved.
Epoch 4/100

Training Phase:
0 [00:40<00:16, 28.20it/s]Training:  90%|████████▉ | 1439/1600 [00:50<00:05, 28.57it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  20%|█▉        | 313/1600 [00:10<00:41, 31.21it/s]Training:  39%|███▉      | 626/1600 [00:20<00:31, 31.17it/s]Training:  59%|█████▉    | 945/1600 [00:30<00:20, 31.48it/s]Training:  79%|███████▉  | 1264/1600 [00:40<00:10, 31.36it/s]Training:  98%|█████████▊| 1576/1600 [00:50<00:00, 31.28it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  20%|█▉        | 315/1600 [00:10<00:40, 31.43it/s]Training:  39%|███▉      | 630/1600 [00Training loss: 176.9029, Training accuracy: 0.9656
Macro F1-score: 0.9656
Model performance on Angry speech (in training): 
	Precision: 0.9501, Recall: 0.9525, F1_score: 0.9513
Model performance on Happy speech (in training): 
	Precision: 0.9447, Recall: 0.9400, F1_score: 0.9424
Model performance on Neutral speech (in training): 
	Precision: 0.9703, Recall: 0.9800, F1_score: 0.9751
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9900, F1_score: 0.9937

Eval Phase: 
:20<00:30, 31.36it/s]Training:  59%|█████▉    | 944/1600 [00:30<00:21, 30.28it/s]Training:  77%|███████▋  | 1239/1600 [00:40<00:12, 29.96it/s]Training:  96%|█████████▌| 1534/1600 [00:50<00:02, 29.74it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 622.2258, Validation accuracy: 0.5200
Macro F1-score: 0.3979
Model performance on Angry speech (in validation): 
	Precision: 0.6957, Recall: 0.9600, F1_score: 0.8067
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.6667, Recall: 0.1200, F1_score: 0.2034
Model performance on Sad speech (in validation): 
	Precision: 0.4098, Recall: 1.0000, F1_score: 0.5814
Epoch 5/100

Training Phase:
Training loss: 121.7060, Training accuracy: 0.9788
Macro F1-score: 0.9787
Model performance on Angry speech (in training): 
	Precision: 0.9676, Recall: 0.9700, F1_score: 0.9688
Model performance on Happy speech (in training): 
	Precision: 0.9724, Recall: 0.9700, F1_score: 0.9712
Model performance on Neutral speech (in training): 
	Precision: 0.9850, Recall: 0.9825, F1_score: 0.9837
Model performance on Sad speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 311/1600 [00:10<00:41, 31.02it/s]Training:  39%|███▉      | 625/1600 [00:20<00:31, 31.23it/s]Training:  59%|█████▊    | 939/1600 [00:30<00:21, 30.80it/s]Training:  78%|███████▊  | 1243/1600 [00:40<00:11, 30.19it/s]Training:  97%|█████████▋| 1545/1600 [00:50<00:01, 30.19it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 560.9815, Validation accuracy: 0.5700
Macro F1-score: 0.4742
Model performance on Angry speech (in validation): 
	Precision: 0.7460, Recall: 0.9400, F1_score: 0.8319
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.6071, Recall: 0.3400, F1_score: 0.4359
Model performance on Sad speech (in validation): 
	Precision: 0.4587, Recall: 1.0000, F1_score: 0.6289
Epoch 6/100

Training Phase:
Training loss: 102.9602, Training accuracy: 0.9862
Macro F1-score: 0.9862
Model performance on Angry speech (in training): 
	Precision: 0.9773, Recall: 0.9700, F1_score: 0.9737
Model performance on Happy speech (in training): 
	Precision: 0.9751, Recall: 0.9800, F1_score: 0.9776
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9975, F1_score: 0.9950
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  20%|█▉        | 313/1600 [00:10<00:41, 31.22it/s]Training:  39%|███▉      | 626/1600 [00:20<00:31, 31.21it/s]Training:  59%|█████▊    | 938/1600 [00:30<00:21, 31.17it/s]Training:  78%|███████▊  | 1250/1600 [00:40<00:11, 30.46it/s]Training:  97%|█████████▋| 1545/1600 [00:50<00:01, 30.02it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 754.4800, Validation accuracy: 0.5450
Macro F1-score: 0.4294
Model performance on Angry speech (in validation): 
	Precision: 0.6533, Recall: 0.9800, F1_score: 0.7840
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.7143, Recall: 0.2000, F1_score: 0.3125
Model performance on Sad speech (in validation): 
	Precision: 0.4505, Recall: 1.0000, F1_score: 0.6211
Epoch 7/100

Training Phase:
Training loss: 96.9411, Training accuracy: 0.9831
Macro F1-score: 0.9831
Model performance on Angry speech (in training): 
	Precision: 0.9773, Recall: 0.9700, F1_score: 0.9737
Model performance on Happy speech (in training): 
	Precision: 0.9654, Recall: 0.9775, F1_score: 0.9714
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937

Eval Phase: 
Validation loss: 587.4168, Validation accuracy: 0.5250
Macro F1-score: 0.4267
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9000, F1_score: 0.8182
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5000, Recall: 0.1800, F1_score: 0.2647
Model performance on Sad speech (in validation): 
	Precision: 0.4132, Recall: 1.0000, F1_score: 0.5848
Epoch 8/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  20%|█▉        | 314/1600 [00:10<00:40, 31.39it/s]Training:  39%|███▉      | 628/1600 [00:20<00:31, 31.25it/s]Training:  59%|█████▉    | 940/1600 [00:30<00:21, 31.19it/s]Training:  78%|███████▊  | 1252/1600 [00:40<00:11, 30.64it/s]Training:  97%|█████████▋| 1551/1600 [00:50<00:01, 30.06it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  18%|█▊        | 293/1600 [00:10<00:44, 29.30it/s]Training:  37%|███▋      | 586/1600 [00:20<00:34, 29.15it/s]Training:  55%|█████▍    | 877/1600 [00:30<00:24, 29.12it/s]Training:  73%|███████▎  | 1168/1600 [00:40<00:14, 29.05it/s]Training:  91%|█████████ | 1458/1600 [00:50<00:04, 28.62it/s]                     Training loss: 101.2111, Training accuracy: 0.9812
Macro F1-score: 0.9813
Model performance on Angry speech (in training): 
	Precision: 0.9824, Recall: 0.9775, F1_score: 0.9799
Model performance on Happy speech (in training): 
	Precision: 0.9677, Recall: 0.9725, F1_score: 0.9701
Model performance on Neutral speech (in training): 
	Precision: 0.9825, Recall: 0.9850, F1_score: 0.9838
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912

Eval Phase: 
Validation loss: 874.6159, Validation accuracy: 0.4700
Macro F1-score: 0.3546
Model performance on Angry speech (in validation): 
	Precision: 0.8077, Recall: 0.8400, F1_score: 0.8235
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0400, F1_score: 0.0769
Model performance on Neutral speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Sad speech (in validation): 
	Precision: 0.3497, Recall: 1.0000, F1_score: 0.5181
Epoch 9/100

Training Phase:
Training loss: 62.9597, Training accuracy: 0.9869
Macro F1-score: 0.9869
Model performance on Angry speech (in training): 
	Precision: 0.9777, Recall: 0.9875, F1_score: 0.9826
Model performance on Happy speech (in training): 
	Precision: 0.9849, Recall: 0.9800, F1_score: 0.9825
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912

Eval Phase: 
                                        Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 276/1600 [00:10<00:48, 27.56it/s]Training:  35%|███▌      | 564/1600 [00:20<00:36, 28.26it/s]Training:  53%|█████▎    | 854/1600 [00:30<00:26, 28.60it/s]Training:  72%|███████▏  | 1144/1600 [00:40<00:15, 28.66it/s]Training:  90%|████████▉ | 1432/1600 [00:50<00:05, 28.50it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 831.0483, Validation accuracy: 0.5050
Macro F1-score: 0.3707
Model performance on Angry speech (in validation): 
	Precision: 0.6957, Recall: 0.9600, F1_score: 0.8067
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.7500, Recall: 0.0600, F1_score: 0.1111
Model performance on Sad speech (in validation): 
	Precision: 0.3937, Recall: 1.0000, F1_score: 0.5650
Epoch 10/100

Training Phase:
Training loss: 80.3557, Training accuracy: 0.9856
Macro F1-score: 0.9856
Model performance on Angry speech (in training): 
	Precision: 0.9826, Recall: 0.9875, F1_score: 0.9850
Model performance on Happy speech (in training): 
	Precision: 0.9799, Recall: 0.9750, F1_score: 0.9774
Model performance on Neutral speech (in training): 
	Precision: 0.9899, Recall: 0.9850, F1_score: 0.9875
Model performance on Sad speech (in training): 
	Precision: 0.9900, Recall: 0.9950, F1_score: 0.9925

Eval Phase: 
Validation loss: 568.7724, Validation accuracy: 0.5550
Macro F1-score: 0.4653
Model performance on Angry speech (in validation): 
	Precision: 0.7966, Recall: 0.9400, F1_score: 0.8624
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.6500, Recall: 0.2600, F1_score: 0.3714
Model performance on Sad speech (in validation): 
	Precision: 0.4167, Recall: 1.0000, F1_score: 0.5882
Epoch 11/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 277/1600 [00:10<00:47, 27.70it/s]Training:  35%|███▍      | 554/1600 [00:20<00:38, 27.49it/s]Training:  52%|█████▏    | 828/1600 [00:30<00:28, 27.40it/s]Training:  70%|██████▉   | 1119/1600 [00:40<00:17, 28.05it/s]Training:  89%|████████▉ | 1431/1600 [00:50<00:05, 29.16it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 307/1600 [00:10<00:42, 30.65it/s]Training:  39%|███▉      | 622/1600 [00:20<00:31, 31.11it/s]Training:  59%|█████▊    | 937/1600 [00:30<00:21, 30.99it/s]Training:  78%|███████▊  | 1246/1600 [00:40<00:11, 30.94it/s]Training:  97%|█████████▋| 1559/1600 [00:50<00:01, 31.04it/s]                       Training loss: 100.6339, Training accuracy: 0.9788
Macro F1-score: 0.9787
Model performance on Angry speech (in training): 
	Precision: 0.9821, Recall: 0.9575, F1_score: 0.9696
Model performance on Happy speech (in training): 
	Precision: 0.9580, Recall: 0.9700, F1_score: 0.9640
Model performance on Neutral speech (in training): 
	Precision: 0.9778, Recall: 0.9900, F1_score: 0.9839
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Validation loss: 717.4383, Validation accuracy: 0.5250
Macro F1-score: 0.3896
Model performance on Angry speech (in validation): 
	Precision: 0.6098, Recall: 1.0000, F1_score: 0.7576
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0800, F1_score: 0.1481
Model performance on Neutral speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Sad speech (in validation): 
	Precision: 0.4425, Recall: 1.0000, F1_score: 0.6135
Epoch 12/100

Training Phase:
Training loss: 66.1830, Training accuracy: 0.9881
Macro F1-score: 0.9881
Model performance on Angry speech (in training): 
	Precision: 0.9875, Recall: 0.9850, F1_score: 0.9862
Model performance on Happy speech (in training): 
	Precision: 0.9800, Recall: 0.9825, F1_score: 0.9813
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938

Eval Phase: 
                                      Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  20%|█▉        | 312/1600 [00:10<00:41, 31.15it/s]Training:  39%|███▉      | 624/1600 [00:20<00:31, 31.04it/s]Training:  58%|█████▊    | 936/1600 [00:30<00:21, 31.08it/s]Training:  78%|███████▊  | 1248/1600 [00:40<00:11, 31.10it/s]Training:  98%|█████████▊| 1560/1600 [00:50<00:01, 31.04it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 1179.3698, Validation accuracy: 0.4600
Macro F1-score: 0.3321
Model performance on Angry speech (in validation): 
	Precision: 0.7925, Recall: 0.8400, F1_score: 0.8155
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Sad speech (in validation): 
	Precision: 0.3448, Recall: 1.0000, F1_score: 0.5128
Epoch 13/100

Training Phase:
Training loss: 64.6630, Training accuracy: 0.9881
Macro F1-score: 0.9881
Model performance on Angry speech (in training): 
	Precision: 0.9851, Recall: 0.9900, F1_score: 0.9875
Model performance on Happy speech (in training): 
	Precision: 0.9900, Recall: 0.9875, F1_score: 0.9887
Model performance on Neutral speech (in training): 
	Precision: 0.9875, Recall: 0.9850, F1_score: 0.9862
Model performance on Sad speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900

Eval Phase: 
Validation loss: 519.2679, Validation accuracy: 0.5550
Macro F1-score: 0.4774
Model performance on Angry speech (in validation): 
	Precision: 0.7667, Recall: 0.9200, F1_score: 0.8364
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1000, F1_score: 0.1818
Model performance on Neutral speech (in validation): 
	Precision: 0.4762, Recall: 0.2000, F1_score: 0.2817
Model performance on Sad speech (in validation): 
	Precision: 0.4386, Recall: 1.0000, F1_score: 0.6098
Validation loss does not decrease for 10 epochs. End training.
Epoch 14/100

Entering 2ND training phase: change training data from cn to DE
Loading de train data: fold_0...
Preprocess de fold_0 data for cn model
Reload model and reset eval loss

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  20%|█▉        | 313/1600 [00:10<00:41, 31.21it/s]Training:  39%|███▉      | 628/1600 [00:20<00:31, 31.31it/s]Training:  59%|█████▉    | 942/1600 [00:30<00:21, 31.22it/s]Training:  78%|███████▊  | 1254/1600 [00:40<00:11, 31.15it/s]Training:  98%|█████████▊| 1566/1600 [00:50<00:01, 31.13it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:   9%|▊         | 138/1600 [00:10<01:46, 13.77it/s]Training:  19%|█▉        | 308/1600 [00:20<01:22, 15.61it/s]Training:  31%|███       | 497/1600 [00:30<01:04, 17.10it/s]Training:  44%|████▍     | 700/1600 [00:40<00:49, 18.32it/s]Training:  57%|█████▋    | 908/1600 [00:50<00:36, 19.19it/s]Training:  70%|███████   | 1122/1Training loss: 2142.1380, Training accuracy: 0.6244
Macro F1-score: 0.5918
Model performance on Angry speech (in training): 
	Precision: 0.8402, Recall: 0.8150, F1_score: 0.8274
Model performance on Happy speech (in training): 
	Precision: 0.8987, Recall: 0.1775, F1_score: 0.2965
Model performance on Neutral speech (in training): 
	Precision: 0.6292, Recall: 0.6025, F1_score: 0.6156
Model performance on Sad speech (in training): 
	Precision: 0.4813, Recall: 0.9025, F1_score: 0.6278

Eval Phase: 
Validation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
Epoch 15/100

Training Phase:
Training loss: 2010.6378, Training accuracy: 0.6406
Macro F1-score: 0.6060
Model performance on Angry speech (in training): 
	Precision: 0.8477, Recall: 0.8350, F1_score: 0.8413
Model performance on Happy speech (in training): 
	Precision: 0.8675, Recall: 0.1800, F1_score: 0.2981
Model performance on Neutral speech (in training): 
	Precision: 0.6364, Recall: 0.6300, F1_score: 0.6332
Model performance on Sad speech (in training): 
	Precision: 0.5048, Recall: 0.9175, F1_score: 0.6513

Eval Phase: 
600 [01:00<00:23, 19.94it/s]Training:  70%|███████   | 1122/1600 [01:10<00:23, 19.94it/s]Training:  84%|████████▎ | 1336/1600 [01:10<00:13, 20.22it/s]Training:  97%|█████████▋| 1551/1600 [01:20<00:02, 20.63it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 243/1600 [00:10<00:55, 24.29it/s]Training:  30%|███       | 486/1600 [00:20<00:46, 23.99it/s]Training:  46%|████▌     | 728/1600 [00:30<00:36, 24.05it/s]Training:  61%|██████    | 970/1600 [00:40<00:26, 23.99it/s]Training:  76%|███████▌  | 1209/1600 [00:50<00:16, 23.94it/s]Training:  91%|█████████ | 1451/1600 [01:00<00:06, 24.01it/s]                                                             Evaluating:   0%|          | 0/200 [00:00Validation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
Epoch 16/100

Training Phase:
Training loss: 2115.6417, Training accuracy: 0.6106
Macro F1-score: 0.5759
Model performance on Angry speech (in training): 
	Precision: 0.8312, Recall: 0.8000, F1_score: 0.8153
Model performance on Happy speech (in training): 
	Precision: 0.8553, Recall: 0.1625, F1_score: 0.2731
Model performance on Neutral speech (in training): 
	Precision: 0.6005, Recall: 0.5825, F1_score: 0.5914
Model performance on Sad speech (in training): 
	Precision: 0.4780, Recall: 0.8975, F1_score: 0.6238

Eval Phase: 
Validation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
Epoch 17/100

Training Phase:
<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 243/1600 [00:10<00:55, 24.23it/s]Training:  30%|███       | 486/1600 [00:20<00:46, 23.87it/s]Training:  45%|████▌     | 724/1600 [00:30<00:36, 23.82it/s]Training:  61%|██████    | 971/1600 [00:40<00:26, 24.14it/s]Training:  76%|███████▌  | 1218/1600 [00:50<00:15, 24.06it/s]Training:  91%|█████████ | 1458/1600 [01:00<00:05, 23.92it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 240/1600 [00:10<00:56, 23.94it/s]Training:  30%|███       | 482/1600 [00:20<00:46, 24.05it/s]Training:  45%|████▌     | 727/1600 [00:30<00:36, 24.24it/s]Training:  61%|██████    | 972/1600 [00:4Training loss: 2148.7380, Training accuracy: 0.6256
Macro F1-score: 0.5924
Model performance on Angry speech (in training): 
	Precision: 0.8535, Recall: 0.8300, F1_score: 0.8416
Model performance on Happy speech (in training): 
	Precision: 0.9024, Recall: 0.1850, F1_score: 0.3071
Model performance on Neutral speech (in training): 
	Precision: 0.5821, Recall: 0.5675, F1_score: 0.5747
Model performance on Sad speech (in training): 
	Precision: 0.4980, Recall: 0.9200, F1_score: 0.6462

Eval Phase: 
Validation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
Epoch 18/100

Training Phase:
Training loss: 2101.6693, Training accuracy: 0.6094
Macro F1-score: 0.5721
Model performance on Angry speech (in training): 
	Precision: 0.8633, Recall: 0.8050, F1_score: 0.8331
Model performance on Happy speech (in training): 
	Precision: 0.8382, Recall: 0.1425, F1_score: 0.2436
Model performance on Neutral speech (in training): 
	Precision: 0.6000, Recall: 0.5850, F1_score: 0.5924
Model performance on Sad speech (in training): 
	Precision: 0.4707, Recall: 0.9050, F1_score: 0.6193

Eval Phase: 
Validation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
Epoch 19/100

Training Phase:
0<00:25, 24.27it/s]Training:  76%|███████▌  | 1216/1600 [00:50<00:15, 24.03it/s]Training:  91%|█████████ | 1458/1600 [01:00<00:05, 24.04it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 242/1600 [00:10<00:56, 24.13it/s]Training:  30%|███       | 484/1600 [00:20<00:46, 24.10it/s]Training:  45%|████▌     | 726/1600 [00:30<00:36, 24.11it/s]Training:  60%|██████    | 968/1600 [00:40<00:26, 24.14it/s]Training:  76%|███████▌  | 1210/1600 [00:50<00:16, 23.96it/s]Training:  91%|█████████ | 1453/1600 [01:00<00:06, 24.02it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          Training loss: 2067.5982, Training accuracy: 0.6200
Macro F1-score: 0.5840
Model performance on Angry speech (in training): 
	Precision: 0.8383, Recall: 0.8425, F1_score: 0.8404
Model performance on Happy speech (in training): 
	Precision: 0.9167, Recall: 0.1650, F1_score: 0.2797
Model performance on Neutral speech (in training): 
	Precision: 0.6021, Recall: 0.5750, F1_score: 0.5882
Model performance on Sad speech (in training): 
	Precision: 0.4825, Recall: 0.8975, F1_score: 0.6276

Eval Phase: 
Validation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
Epoch 20/100

Training Phase:
| 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 242/1600 [00:10<00:56, 24.16it/s]Training:  30%|███       | 487/1600 [00:20<00:45, 24.32it/s]Training:  46%|████▌     | 732/1600 [00:30<00:35, 24.14it/s]Training:  61%|██████    | 974/1600 [00:40<00:25, 24.16it/s]Training:  76%|███████▌  | 1216/1600 [00:50<00:16, 23.99it/s]Training:  91%|█████████ | 1454/1600 [01:00<00:06, 23.92it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 190/1600 [00:10<01:14, 18.94it/s]Training:  27%|██▋       | 431/1600 [00:20<00:53, 21.93it/s]Training:  42%|████▏     | 672/1600 [00:30<00:40, 22.82it/s]Training:  57%|█████▋    | 911/1600 [00:40<00:29, 23.15it/s]Training:  72%|███████▏  | 1150/1600 [00:50<00:19, 23Training loss: 2063.7571, Training accuracy: 0.6194
Macro F1-score: 0.5839
Model performance on Angry speech (in training): 
	Precision: 0.8425, Recall: 0.8025, F1_score: 0.8220
Model performance on Happy speech (in training): 
	Precision: 0.8767, Recall: 0.1600, F1_score: 0.2706
Model performance on Neutral speech (in training): 
	Precision: 0.6215, Recall: 0.6075, F1_score: 0.6144
Model performance on Sad speech (in training): 
	Precision: 0.4808, Recall: 0.9075, F1_score: 0.6286

Eval Phase: 
Validation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
Epoch 21/100

Training Phase:
Training loss: 2095.7918, Training accuracy: 0.6206
Macro F1-score: 0.5770
Model performance on Angry speech (in training): 
	Precision: 0.8403, Recall: 0.8550, F1_score: 0.8476
Model performance on Happy speech (in training): 
	Precision: 0.8814, Recall: 0.1300, F1_score: 0.2266
Model performance on Neutral speech (in training): 
	Precision: 0.6156, Recall: 0.5925, F1_score: 0.6038
Model performance on Sad speech (in training): 
	Precision: 0.4833, Recall: 0.9050, F1_score: 0.6301

Eval Phase: 
Validation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
Epoch 22/100

Training Phase:
.42it/s]Training:  87%|████████▋ | 1389/1600 [01:00<00:08, 23.55it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 225/1600 [00:10<01:01, 22.42it/s]Training:  14%|█▍        | 225/1600 [00:20<01:01, 22.42it/s]Training:  28%|██▊       | 444/1600 [00:20<00:52, 22.07it/s]Training:  42%|████▏     | 668/1600 [00:30<00:41, 22.21it/s]Training:  57%|█████▋    | 907/1600 [00:40<00:30, 22.87it/s]Training:  72%|███████▏  | 1147/1600 [00:50<00:19, 23.26it/s]Training:  87%|████████▋ | 1388/1600 [01:00<00:09, 23.54it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/sTraining loss: 2117.8206, Training accuracy: 0.6156
Macro F1-score: 0.5812
Model performance on Angry speech (in training): 
	Precision: 0.8509, Recall: 0.8275, F1_score: 0.8390
Model performance on Happy speech (in training): 
	Precision: 0.9054, Recall: 0.1675, F1_score: 0.2827
Model performance on Neutral speech (in training): 
	Precision: 0.6027, Recall: 0.5575, F1_score: 0.5792
Model performance on Sad speech (in training): 
	Precision: 0.4746, Recall: 0.9100, F1_score: 0.6238

Eval Phase: 
Validation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
Epoch 23/100

Training Phase:
]Training:  14%|█▍        | 229/1600 [00:10<01:00, 22.83it/s]Training:  29%|██▉       | 460/1600 [00:20<00:49, 22.95it/s]Training:  43%|████▎     | 692/1600 [00:30<00:39, 23.06it/s]Training:  58%|█████▊    | 924/1600 [00:40<00:29, 23.10it/s]Training:  72%|███████▏  | 1156/1600 [00:50<00:19, 22.94it/s]Training:  87%|████████▋ | 1388/1600 [01:00<00:09, 23.00it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 228/1600 [00:10<01:00, 22.75it/s]Training:  29%|██▉       | 468/1600 [00:20<00:48, 23.43it/s]Training:  44%|████▍     | 708/1600 [00:30<00:37, 23.64it/s]Training:  59%|█████▉    | 947/1600 [00:40<00:27, 23.59it/s]Training:  74%|███████▍  | 1183/1600 [00:50<00:17, 23.57it/s]Training:  89%|Training loss: 2186.0016, Training accuracy: 0.6244
Macro F1-score: 0.5891
Model performance on Angry speech (in training): 
	Precision: 0.8550, Recall: 0.8400, F1_score: 0.8474
Model performance on Happy speech (in training): 
	Precision: 0.9041, Recall: 0.1650, F1_score: 0.2791
Model performance on Neutral speech (in training): 
	Precision: 0.6162, Recall: 0.5900, F1_score: 0.6028
Model performance on Sad speech (in training): 
	Precision: 0.4807, Recall: 0.9025, F1_score: 0.6273

Eval Phase: 
Validation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
Epoch 24/100

Training Phase:
Training loss: 2076.7781, Training accuracy: 0.6156
Macro F1-score: 0.5805
Model performance on Angry speech (in training): 
	Precision: 0.8288, Recall: 0.8350, F1_score: 0.8319
Model performance on Happy speech (in training): 
	Precision: 0.9079, Recall: 0.1725, F1_score: 0.2899
Model performance on Neutral speech (in training): 
	Precision: 0.5930, Recall: 0.5500, F1_score: 0.5707
Model performance on Sad speech (in training): 
	Precision: 0.4827, Recall: 0.9050, F1_score: 0.6296

Eval Phase: 
Validation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
Epoch 25/100

Training Phase:
████████▊ | 1419/1600 [01:00<00:07, 23.35it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 227/1600 [00:10<01:00, 22.66it/s]Training:  29%|██▊       | 459/1600 [00:20<00:49, 22.97it/s]Training:  43%|████▎     | 691/1600 [00:30<00:39, 22.79it/s]Training:  57%|█████▋    | 917/1600 [00:40<00:30, 22.69it/s]Training:  72%|███████▏  | 1145/1600 [00:50<00:20, 22.72it/s]Training:  86%|████████▌ | 1373/1600 [01:00<00:10, 22.51it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 225/1600 [00:10<01:01, 22.48it/s]Training:  28%|██Training loss: 2064.7853, Training accuracy: 0.6219
Macro F1-score: 0.5904
Model performance on Angry speech (in training): 
	Precision: 0.8753, Recall: 0.8250, F1_score: 0.8494
Model performance on Happy speech (in training): 
	Precision: 0.8353, Recall: 0.1775, F1_score: 0.2928
Model performance on Neutral speech (in training): 
	Precision: 0.6156, Recall: 0.5725, F1_score: 0.5933
Model performance on Sad speech (in training): 
	Precision: 0.4765, Recall: 0.9125, F1_score: 0.6261

Eval Phase: 
Validation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
Epoch 26/100

Training Phase:
       | 451/1600 [00:20<00:51, 22.52it/s]Training:  42%|████▏     | 677/1600 [00:30<00:41, 22.50it/s]Training:  57%|█████▋    | 911/1600 [00:40<00:30, 22.83it/s]Training:  72%|███████▏  | 1145/1600 [00:50<00:19, 22.80it/s]Training:  86%|████████▌ | 1377/1600 [01:00<00:09, 22.91it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 223/1600 [00:10<01:02, 22.20it/s]Training:  29%|██▉       | 461/1600 [00:20<00:49, 23.11it/s]Training:  44%|████▎     | 699/1600 [00:30<00:38, 23.30it/s]Training:  59%|█████▊    | 939/1600 [00:40<00:28, 23.57it/s]Training:  74%|███████▍  | 1187/1600 [00:50<00:17, 23.98it/s]Training:  90%|████████▉ | 1435/1600 [01:00<00:06, 24.05it/s]                        Training loss: 2046.3324, Training accuracy: 0.6175
Macro F1-score: 0.5782
Model performance on Angry speech (in training): 
	Precision: 0.8392, Recall: 0.8350, F1_score: 0.8371
Model performance on Happy speech (in training): 
	Precision: 0.8824, Recall: 0.1500, F1_score: 0.2564
Model performance on Neutral speech (in training): 
	Precision: 0.5959, Recall: 0.5750, F1_score: 0.5852
Model performance on Sad speech (in training): 
	Precision: 0.4866, Recall: 0.9100, F1_score: 0.6341

Eval Phase: 
Validation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
Epoch 27/100

Training Phase:
Training loss: 2076.1053, Training accuracy: 0.6256
Macro F1-score: 0.5898
Model performance on Angry speech (in training): 
	Precision: 0.8458, Recall: 0.8225, F1_score: 0.8340
Model performance on Happy speech (in training): 
	Precision: 0.8919, Recall: 0.1650, F1_score: 0.2785
Model performance on Neutral speech (in training): 
	Precision: 0.6218, Recall: 0.6000, F1_score: 0.6107
Model performance on Sad speech (in training): 
	Precision: 0.4874, Recall: 0.9150, F1_score: 0.6360

Eval Phase: 
Validation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
Epoch 28/100

Training Phase:
                                     Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 230/1600 [00:10<00:59, 22.90it/s]Training:  29%|██▉       | 460/1600 [00:20<00:50, 22.76it/s]Training:  43%|████▎     | 688/1600 [00:30<00:40, 22.77it/s]Training:  57%|█████▊    | 920/1600 [00:40<00:29, 22.92it/s]Training:  72%|███████▏  | 1152/1600 [00:50<00:19, 22.97it/s]Training:  86%|████████▋ | 1383/1600 [01:00<00:09, 22.91it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 231/1600 [00:10<00:59, 23.05it/s]Training:  29%|██▉       | 462/1600 [00:20<00:49, 23.05it/s]Training:  43%|████▎     | 693/160Training loss: 2099.8454, Training accuracy: 0.6188
Macro F1-score: 0.5822
Model performance on Angry speech (in training): 
	Precision: 0.8442, Recall: 0.8400, F1_score: 0.8421
Model performance on Happy speech (in training): 
	Precision: 0.8732, Recall: 0.1550, F1_score: 0.2633
Model performance on Neutral speech (in training): 
	Precision: 0.6172, Recall: 0.5925, F1_score: 0.6046
Model performance on Sad speech (in training): 
	Precision: 0.4752, Recall: 0.8875, F1_score: 0.6190

Eval Phase: 
Validation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
Epoch 29/100

Training Phase:
0 [00:30<00:39, 22.95it/s]Training:  58%|█████▊    | 924/1600 [00:40<00:29, 22.99it/s]Training:  58%|█████▊    | 924/1600 [00:50<00:29, 22.99it/s]Training:  72%|███████▏  | 1155/1600 [00:50<00:19, 22.98it/s]Training:  87%|████████▋ | 1385/1600 [01:00<00:09, 22.89it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 233/1600 [00:10<00:58, 23.24it/s]Training:  29%|██▉       | 466/1600 [00:20<00:49, 23.12it/s]Training:  44%|████▎     | 698/1600 [00:30<00:38, 23.14it/s]Training:  44%|████▎     | 698/1600 [00:40<00:38, 23.14it/s]Training:  58%|█████▊    | 930/1600 [00:40<00:29, 23.02it/s]Training:  72%|███████▎  | 1160/1600 [00:50<00:19, 23.01it/s]Training:  87%|████████▋ | 1390Training loss: 2089.5768, Training accuracy: 0.6231
Macro F1-score: 0.5903
Model performance on Angry speech (in training): 
	Precision: 0.8496, Recall: 0.8050, F1_score: 0.8267
Model performance on Happy speech (in training): 
	Precision: 0.8861, Recall: 0.1750, F1_score: 0.2923
Model performance on Neutral speech (in training): 
	Precision: 0.6195, Recall: 0.6025, F1_score: 0.6109
Model performance on Sad speech (in training): 
	Precision: 0.4834, Recall: 0.9100, F1_score: 0.6314

Eval Phase: 
Validation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
Epoch 30/100

Training Phase:
Training loss: 2031.3270, Training accuracy: 0.6331
Macro F1-score: 0.6032
Model performance on Angry speech (in training): 
	Precision: 0.8575, Recall: 0.8275, F1_score: 0.8422
Model performance on Happy speech (in training): 
	Precision: 0.8977, Recall: 0.1975, F1_score: 0.3238
Model performance on Neutral speech (in training): 
	Precision: 0.6270, Recall: 0.5925, F1_score: 0.6093
Model performance on Sad speech (in training): 
	Precision: 0.4893, Recall: 0.9150, F1_score: 0.6376

Eval Phase: 
Validation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
Epoch 31/100

Training Phase:
/1600 [01:00<00:09, 22.85it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 231/1600 [00:10<00:59, 23.08it/s]Training:  29%|██▉       | 462/1600 [00:20<00:49, 22.89it/s]Training:  43%|████▎     | 693/1600 [00:30<00:39, 22.97it/s]Training:  58%|█████▊    | 931/1600 [00:40<00:28, 23.27it/s]Training:  73%|███████▎  | 1172/1600 [00:50<00:18, 23.57it/s]Training:  88%|████████▊ | 1414/1600 [01:00<00:07, 23.75it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 237/1600 [00:10<00:57, 23.70it/s]Training:  30%|██▉       | 474/1600 [00:20<00:48, Training loss: 2104.2617, Training accuracy: 0.6125
Macro F1-score: 0.5775
Model performance on Angry speech (in training): 
	Precision: 0.8460, Recall: 0.8100, F1_score: 0.8276
Model performance on Happy speech (in training): 
	Precision: 0.8767, Recall: 0.1600, F1_score: 0.2706
Model performance on Neutral speech (in training): 
	Precision: 0.5871, Recall: 0.5900, F1_score: 0.5885
Model performance on Sad speech (in training): 
	Precision: 0.4798, Recall: 0.8900, F1_score: 0.6235

Eval Phase: 
Validation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
Epoch 32/100

Training Phase:
23.15it/s]Training:  45%|████▌     | 720/1600 [00:30<00:36, 23.78it/s]Training:  60%|██████    | 966/1600 [00:40<00:26, 24.07it/s]Training:  76%|███████▌  | 1212/1600 [00:50<00:16, 24.07it/s]Training:  91%|█████████ | 1454/1600 [01:00<00:06, 24.09it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 242/1600 [00:10<00:56, 24.12it/s]Training:  15%|█▌        | 242/1600 [00:20<00:56, 24.12it/s]Training:  30%|███       | 486/1600 [00:20<00:45, 24.26it/s]Training:  46%|████▌     | 730/1600 [00:30<00:35, 24.21it/s]Training:  61%|██████    | 974/1600 [00:40<00:25, 24.27it/s]Training:  76%|███████▌  | 1218/1600 [00:50<00:15, 24.31it/s]Training:  91%|█████████▏| 1462/1600 [01:00<00:05, 24Training loss: 2085.7166, Training accuracy: 0.6244
Macro F1-score: 0.5888
Model performance on Angry speech (in training): 
	Precision: 0.8486, Recall: 0.8125, F1_score: 0.8301
Model performance on Happy speech (in training): 
	Precision: 0.8784, Recall: 0.1625, F1_score: 0.2743
Model performance on Neutral speech (in training): 
	Precision: 0.6139, Recall: 0.6200, F1_score: 0.6169
Model performance on Sad speech (in training): 
	Precision: 0.4885, Recall: 0.9025, F1_score: 0.6339

Eval Phase: 
Validation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
Epoch 33/100

Training Phase:
Training loss: 2060.2514, Training accuracy: 0.6206
Macro F1-score: 0.5800
Model performance on Angry speech (in training): 
	Precision: 0.8438, Recall: 0.8375, F1_score: 0.8407
Model performance on Happy speech (in training): 
	Precision: 0.9062, Recall: 0.1450, F1_score: 0.2500
Model performance on Neutral speech (in training): 
	Precision: 0.5985, Recall: 0.5850, F1_score: 0.5917
Model performance on Sad speech (in training): 
	Precision: 0.4893, Recall: 0.9150, F1_score: 0.6376

Eval Phase: 
Validation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
Epoch 34/100

Training Phase:
.14it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 235/1600 [00:10<00:58, 23.48it/s]Training:  30%|██▉       | 478/1600 [00:20<00:46, 23.92it/s]Training:  45%|████▌     | 721/1600 [00:30<00:36, 23.98it/s]Training:  60%|██████    | 965/1600 [00:40<00:26, 24.13it/s]Training:  76%|███████▌  | 1209/1600 [00:50<00:16, 23.82it/s]Training:  90%|█████████ | 1442/1600 [01:00<00:06, 23.42it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 236/1600 [00:10<00:57, 23.60it/s]Training:  30%|██▉       | 477/1600 [00:20<00:47, 23.86it/s]Training:  Training loss: 2117.5995, Training accuracy: 0.6238
Macro F1-score: 0.5863
Model performance on Angry speech (in training): 
	Precision: 0.8375, Recall: 0.8375, F1_score: 0.8375
Model performance on Happy speech (in training): 
	Precision: 0.9028, Recall: 0.1625, F1_score: 0.2754
Model performance on Neutral speech (in training): 
	Precision: 0.6089, Recall: 0.5800, F1_score: 0.5941
Model performance on Sad speech (in training): 
	Precision: 0.4900, Recall: 0.9150, F1_score: 0.6382

Eval Phase: 
Validation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
Epoch 35/100

Training Phase:
Training loss: 2144.2163, Training accuracy: 0.6150
Macro F1-score: 0.5818
Model performance on Angry speech (in training): 
	Precision: 0.8425, Recall: 0.8025, F1_score: 0.8220
Model performance on Happy speech (in training): 
	Precision: 0.8293, Recall: 0.1700, F1_score: 0.2822
Model performance on Neutral speech (in training): 
	Precision: 0.6020, Recall: 0.5900, F1_score: 0.5960
Model performance on Sad speech (in training): 
	Precision: 0.4819, Recall: 0.8975, F1_score: 0.6271

Eval Phase: 
45%|████▌     | 722/1600 [00:30<00:36, 24.14it/s]Training:  60%|██████    | 967/1600 [00:40<00:26, 23.84it/s]Training:  76%|███████▌  | 1209/1600 [00:50<00:16, 23.94it/s]Training:  91%|█████████ | 1455/1600 [01:00<00:06, 24.15it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 238/1600 [00:10<00:57, 23.77it/s]Training:  30%|███       | 480/1600 [00:20<00:46, 24.01it/s]Training:  45%|████▌     | 722/1600 [00:30<00:37, 23.48it/s]Training:  59%|█████▉    | 951/1600 [00:40<00:27, 23.25it/s]Training:  74%|███████▍  | 1183/1600 [00:50<00:17, 23.20it/s]Training:  90%|████████▉ | 1433/1600 [01:00<00:07, 23.79it/s]                                                             Evaluating:   0%|Validation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
Epoch 36/100

Training Phase:
Training loss: 2137.1916, Training accuracy: 0.6119
Macro F1-score: 0.5770
Model performance on Angry speech (in training): 
	Precision: 0.8394, Recall: 0.8100, F1_score: 0.8244
Model performance on Happy speech (in training): 
	Precision: 0.8684, Recall: 0.1650, F1_score: 0.2773
Model performance on Neutral speech (in training): 
	Precision: 0.6022, Recall: 0.5600, F1_score: 0.5803
Model performance on Sad speech (in training): 
	Precision: 0.4765, Recall: 0.9125, F1_score: 0.6261

Eval Phase: 
Validation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
Epoch 37/100

Training Phase:
          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 236/1600 [00:10<00:57, 23.56it/s]Training:  30%|██▉       | 477/1600 [00:20<00:47, 23.87it/s]Training:  45%|████▍     | 718/1600 [00:30<00:36, 23.91it/s]Training:  60%|█████▉    | 958/1600 [00:40<00:27, 23.68it/s]Training:  74%|███████▍  | 1192/1600 [00:50<00:17, 23.34it/s]Training:  89%|████████▉ | 1425/1600 [01:00<00:07, 23.32it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 241/1600 [00:10<00:56, 24.05it/s]Training:  30%|███       | 482/1600 [00:20<00:46, 23.94it/s]Training:  45%|████▌     | 721/1600 [00:30<00:36, 23.88it/s]Training:  60%|████Training loss: 2115.4429, Training accuracy: 0.6138
Macro F1-score: 0.5829
Model performance on Angry speech (in training): 
	Precision: 0.8647, Recall: 0.8150, F1_score: 0.8391
Model performance on Happy speech (in training): 
	Precision: 0.8987, Recall: 0.1775, F1_score: 0.2965
Model performance on Neutral speech (in training): 
	Precision: 0.5881, Recall: 0.5675, F1_score: 0.5776
Model performance on Sad speech (in training): 
	Precision: 0.4723, Recall: 0.8950, F1_score: 0.6183

Eval Phase: 
Validation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
Epoch 38/100

Training Phase:
Training loss: 2048.6822, Training accuracy: 0.6200
Macro F1-score: 0.5850
Model performance on Angry speech (in training): 
	Precision: 0.8458, Recall: 0.8225, F1_score: 0.8340
Model performance on Happy speech (in training): 
	Precision: 0.9444, Recall: 0.1700, F1_score: 0.2881
Model performance on Neutral speech (in training): 
	Precision: 0.5913, Recall: 0.5750, F1_score: 0.5830
Model performance on Sad speech (in training): 
	Precision: 0.4867, Recall: 0.9125, F1_score: 0.6348

Eval Phase: 
Validation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
Epoch 39/100

Training Phase:
█    | 968/1600 [00:40<00:26, 24.17it/s]Training:  76%|███████▌  | 1215/1600 [00:50<00:15, 24.07it/s]Training:  91%|█████████ | 1455/1600 [01:00<00:06, 23.91it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 226/1600 [00:10<01:00, 22.58it/s]Training:  30%|██▉       | 472/1600 [00:20<00:47, 23.77it/s]Training:  45%|████▍     | 718/1600 [00:30<00:36, 23.89it/s]Training:  60%|██████    | 963/1600 [00:40<00:26, 24.12it/s]Training:  76%|███████▌  | 1208/1600 [00:50<00:16, 24.17it/s]Training:  91%|█████████ | 1451/1600 [01:00<00:06, 24.15it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   TTraining loss: 2070.3047, Training accuracy: 0.6219
Macro F1-score: 0.5861
Model performance on Angry speech (in training): 
	Precision: 0.8489, Recall: 0.8425, F1_score: 0.8457
Model performance on Happy speech (in training): 
	Precision: 0.9306, Recall: 0.1675, F1_score: 0.2839
Model performance on Neutral speech (in training): 
	Precision: 0.6027, Recall: 0.5650, F1_score: 0.5832
Model performance on Sad speech (in training): 
	Precision: 0.4828, Recall: 0.9125, F1_score: 0.6315

Eval Phase: 
Validation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
Epoch 40/100

Training Phase:
raining:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 239/1600 [00:10<00:57, 23.87it/s]Training:  30%|██▉       | 478/1600 [00:20<00:47, 23.71it/s]Training:  45%|████▍     | 716/1600 [00:30<00:37, 23.74it/s]Training:  60%|██████    | 962/1600 [00:40<00:26, 24.06it/s]Training:  76%|███████▌  | 1208/1600 [00:50<00:16, 24.21it/s]Training:  91%|█████████ | 1453/1600 [01:00<00:06, 24.30it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 242/1600 [00:10<00:56, 24.12it/s]Training:  30%|███       | 484/1600 [00:20<00:46, 24.07it/s]Training:  45%|████▌     | 725/1600 [00:30<00:36, 23.93it/s]Training:  60%|██████    | 968/1600 [00:40<00:26, 24.08it/s]Training:  76%|███████▌  | 12Training loss: 2073.7795, Training accuracy: 0.6206
Macro F1-score: 0.5886
Model performance on Angry speech (in training): 
	Precision: 0.8500, Recall: 0.8075, F1_score: 0.8282
Model performance on Happy speech (in training): 
	Precision: 0.9000, Recall: 0.1800, F1_score: 0.3000
Model performance on Neutral speech (in training): 
	Precision: 0.6047, Recall: 0.5850, F1_score: 0.5947
Model performance on Sad speech (in training): 
	Precision: 0.4834, Recall: 0.9100, F1_score: 0.6314

Eval Phase: 
Validation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
Epoch 41/100

Training Phase:
Training loss: 2147.9576, Training accuracy: 0.6094
Macro F1-score: 0.5729
Model performance on Angry speech (in training): 
	Precision: 0.8654, Recall: 0.8200, F1_score: 0.8421
Model performance on Happy speech (in training): 
	Precision: 0.9077, Recall: 0.1475, F1_score: 0.2538
Model performance on Neutral speech (in training): 
	Precision: 0.5819, Recall: 0.5775, F1_score: 0.5797
Model performance on Sad speech (in training): 
	Precision: 0.4704, Recall: 0.8925, F1_score: 0.6160

Eval Phase: 
Validation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
Epoch 42/100

Training Phase:
11/1600 [00:50<00:16, 24.15it/s]Training:  91%|█████████ | 1454/1600 [01:01<00:06, 23.59it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 225/1600 [00:10<01:01, 22.49it/s]Training:  29%|██▊       | 458/1600 [00:20<00:49, 22.96it/s]Training:  43%|████▎     | 691/1600 [00:30<00:39, 22.77it/s]Training:  58%|█████▊    | 924/1600 [00:40<00:29, 22.97it/s]Training:  72%|███████▏  | 1157/1600 [00:50<00:19, 23.00it/s]Training:  87%|████████▋ | 1389/1600 [01:00<00:09, 23.05it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 207/1600Training loss: 2135.0634, Training accuracy: 0.6200
Macro F1-score: 0.5840
Model performance on Angry speech (in training): 
	Precision: 0.8394, Recall: 0.8100, F1_score: 0.8244
Model performance on Happy speech (in training): 
	Precision: 0.8889, Recall: 0.1600, F1_score: 0.2712
Model performance on Neutral speech (in training): 
	Precision: 0.6195, Recall: 0.6025, F1_score: 0.6109
Model performance on Sad speech (in training): 
	Precision: 0.4821, Recall: 0.9075, F1_score: 0.6297

Eval Phase: 
Validation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
Epoch 43/100

Training Phase:
 [00:10<01:07, 20.64it/s]Training:  28%|██▊       | 452/1600 [00:20<00:50, 22.90it/s]Training:  44%|████▎     | 697/1600 [00:30<00:39, 22.79it/s]Training:  58%|█████▊    | 925/1600 [00:40<00:29, 22.77it/s]Training:  72%|███████▏  | 1154/1600 [00:50<00:19, 22.79it/s]Training:  86%|████████▋ | 1383/1600 [01:00<00:09, 22.83it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 231/1600 [00:10<00:59, 23.04it/s]Training:  29%|██▉       | 464/1600 [00:20<00:49, 23.14it/s]Training:  44%|████▎     | 697/1600 [00:30<00:39, 22.94it/s]Training:  58%|█████▊    | 925/1600 [00:40<00:29, 22.82it/s]Training:  72%|███████▏  | 1157/1600 [00:50<00:19, 22.93it/s]Training:  87%|████████▋ | 1390/1600 [Training loss: 2104.2077, Training accuracy: 0.6162
Macro F1-score: 0.5809
Model performance on Angry speech (in training): 
	Precision: 0.8440, Recall: 0.8250, F1_score: 0.8344
Model performance on Happy speech (in training): 
	Precision: 0.8904, Recall: 0.1625, F1_score: 0.2748
Model performance on Neutral speech (in training): 
	Precision: 0.5842, Recall: 0.5900, F1_score: 0.5871
Model performance on Sad speech (in training): 
	Precision: 0.4850, Recall: 0.8875, F1_score: 0.6272

Eval Phase: 
Validation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
Epoch 44/100

Training Phase:
Training loss: 2092.8393, Training accuracy: 0.6138
Macro F1-score: 0.5775
Model performance on Angry speech (in training): 
	Precision: 0.8494, Recall: 0.8175, F1_score: 0.8331
Model performance on Happy speech (in training): 
	Precision: 0.8841, Recall: 0.1525, F1_score: 0.2601
Model performance on Neutral speech (in training): 
	Precision: 0.6072, Recall: 0.5875, F1_score: 0.5972
Model performance on Sad speech (in training): 
	Precision: 0.4730, Recall: 0.8975, F1_score: 0.6195

Eval Phase: 
Validation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
Epoch 45/100

Training Phase:
01:00<00:09, 23.04it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 235/1600 [00:10<00:58, 23.40it/s]Training:  29%|██▉       | 470/1600 [00:20<00:48, 23.28it/s]Training:  44%|████▍     | 711/1600 [00:30<00:37, 23.63it/s]Training:  60%|█████▉    | 952/1600 [00:40<00:27, 23.44it/s]Training:  74%|███████▍  | 1184/1600 [00:50<00:17, 23.35it/s]Training:  88%|████████▊ | 1416/1600 [01:00<00:07, 23.24it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 231/1600 [00:10<00:59, 23.09it/s]Training:  29%|██▉       | 462/1600 [00:20<00:49, 23.04itTraining loss: 2095.1104, Training accuracy: 0.6075
Macro F1-score: 0.5700
Model performance on Angry speech (in training): 
	Precision: 0.8355, Recall: 0.8000, F1_score: 0.8174
Model performance on Happy speech (in training): 
	Precision: 0.8551, Recall: 0.1475, F1_score: 0.2516
Model performance on Neutral speech (in training): 
	Precision: 0.5909, Recall: 0.5850, F1_score: 0.5879
Model performance on Sad speech (in training): 
	Precision: 0.4774, Recall: 0.8975, F1_score: 0.6233

Eval Phase: 
Validation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
Epoch 46/100

Training Phase:
Training loss: 2112.2488, Training accuracy: 0.6200
Macro F1-score: 0.5828
Model performance on Angry speech (in training): 
	Precision: 0.8481, Recall: 0.8375, F1_score: 0.8428
Model performance on Happy speech (in training): 
	Precision: 0.8857, Recall: 0.1550, F1_score: 0.2638
Model performance on Neutral speech (in training): 
	Precision: 0.6015, Recall: 0.5925, F1_score: 0.5970
Model performance on Sad speech (in training): 
	Precision: 0.4831, Recall: 0.8950, F1_score: 0.6275

Eval Phase: 
/s]Training:  43%|████▎     | 692/1600 [00:30<00:39, 22.99it/s]Training:  58%|█████▊    | 922/1600 [00:40<00:29, 22.94it/s]Training:  72%|███████▏  | 1151/1600 [00:50<00:19, 22.87it/s]Training:  86%|████████▋ | 1382/1600 [01:00<00:09, 22.92it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 230/1600 [00:10<00:59, 22.98it/s]Training:  29%|██▉       | 460/1600 [00:20<00:49, 22.80it/s]Training:  43%|████▎     | 689/1600 [00:30<00:39, 22.83it/s]Training:  57%|█████▋    | 918/1600 [00:40<00:29, 22.74it/s]Training:  72%|███████▏  | 1147/1600 [00:50<00:19, 22.77it/s]Training:  86%|████████▌ | 1376/1600 [01:00<00:09, 22.76it/s]                                                             EvValidation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
Epoch 47/100

Training Phase:
Training loss: 2043.4256, Training accuracy: 0.6256
Macro F1-score: 0.5890
Model performance on Angry speech (in training): 
	Precision: 0.8617, Recall: 0.8100, F1_score: 0.8351
Model performance on Happy speech (in training): 
	Precision: 0.8750, Recall: 0.1575, F1_score: 0.2669
Model performance on Neutral speech (in training): 
	Precision: 0.6129, Recall: 0.6175, F1_score: 0.6152
Model performance on Sad speech (in training): 
	Precision: 0.4900, Recall: 0.9175, F1_score: 0.6388

Eval Phase: 
Validation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
Epoch 48/100

Training Phase:
aluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 229/1600 [00:10<01:00, 22.83it/s]Training:  29%|██▉       | 460/1600 [00:20<00:49, 22.97it/s]Training:  43%|████▎     | 691/1600 [00:30<00:39, 22.95it/s]Training:  58%|█████▊    | 923/1600 [00:40<00:29, 23.03it/s]Training:  73%|███████▎  | 1164/1600 [00:50<00:18, 23.38it/s]Training:  88%|████████▊ | 1405/1600 [01:00<00:08, 23.32it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 240/1600 [00:10<00:56, 23.93it/s]Training:  30%|███       | 482/1600 [00:20<00:46, 24.05it/s]Training:  45%|████▌     | 724/1600 [00:30<00:36, 23.98it/s]Training:  60%Training loss: 2047.2455, Training accuracy: 0.6281
Macro F1-score: 0.5946
Model performance on Angry speech (in training): 
	Precision: 0.8410, Recall: 0.8200, F1_score: 0.8304
Model performance on Happy speech (in training): 
	Precision: 0.9103, Recall: 0.1775, F1_score: 0.2971
Model performance on Neutral speech (in training): 
	Precision: 0.6171, Recall: 0.6125, F1_score: 0.6148
Model performance on Sad speech (in training): 
	Precision: 0.4912, Recall: 0.9025, F1_score: 0.6361

Eval Phase: 
Validation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
Epoch 49/100

Training Phase:
Training loss: 2058.5880, Training accuracy: 0.6169
Macro F1-score: 0.5780
Model performance on Angry speech (in training): 
	Precision: 0.8433, Recall: 0.8075, F1_score: 0.8250
Model performance on Happy speech (in training): 
	Precision: 0.8788, Recall: 0.1450, F1_score: 0.2489
Model performance on Neutral speech (in training): 
	Precision: 0.6154, Recall: 0.6000, F1_score: 0.6076
Model performance on Sad speech (in training): 
	Precision: 0.4809, Recall: 0.9150, F1_score: 0.6305

Eval Phase: 
|██████    | 964/1600 [00:40<00:26, 23.60it/s]Training:  75%|███████▍  | 1195/1600 [00:50<00:17, 23.28it/s]Training:  89%|████████▉ | 1426/1600 [01:00<00:07, 23.21it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 233/1600 [00:10<00:58, 23.27it/s]Training:  29%|██▉       | 466/1600 [00:20<00:49, 23.01it/s]Training:  43%|████▎     | 695/1600 [00:30<00:39, 22.90it/s]Training:  58%|█████▊    | 929/1600 [00:40<00:29, 23.07it/s]Training:  73%|███████▎  | 1163/1600 [00:50<00:18, 23.05it/s]Training:  87%|████████▋ | 1394/1600 [01:00<00:08, 22.95it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                       Validation loss: 332.7697, Validation accuracy: 0.5900
Macro F1-score: 0.5583
Model performance on Angry speech (in validation): 
	Precision: 0.8409, Recall: 0.7400, F1_score: 0.7872
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6341, Recall: 0.5200, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.4393, Recall: 0.9400, F1_score: 0.5987
Epoch 50/100

Two-stage training complete.
Model best accuracy on validation set: 0.5900

Test Phase: 
            Testing:   0%|          | 0/200 [00:00<?, ?it/s]Testing:   1%|          | 2/200 [00:00<00:09, 20.00it/s]Testing:   2%|▎         | 5/200 [00:00<00:08, 22.41it/s]Testing:   4%|▍         | 8/200 [00:00<00:07, 24.14it/s]Testing:   6%|▌         | 11/200 [00:00<00:07, 24.30it/s]Testing:   7%|▋         | 14/200 [00:00<00:08, 22.77it/s]Testing:   8%|▊         | 17/200 [00:00<00:07, 23.17it/s]Testing:  10%|█         | 21/200 [00:00<00:06, 27.47it/s]Testing:  14%|█▎        | 27/200 [00:00<00:04, 35.62it/s]Testing:  16%|█▌        | 31/200 [00:01<00:05, 33.35it/s]Testing:  18%|█▊        | 37/200 [00:01<00:04, 38.65it/s]Testing:  21%|██        | 42/200 [00:01<00:03, 40.74it/s]Testing:  24%|██▍       | 48/200 [00:01<00:03, 41.85it/s]Testing:  28%|██▊       | 55/200 [00:01<00:03, 44.36it/s]Testing:  32%|███▏      | 63/200 [00:01<00:02, 52.94it/s]Testing:  34%|███▍      | 69/200 [00:01<00:02, 50.23it/s]Testing:  38%|███▊      | 75/200 [00:01<00:02, 50.09it/s]Testing:  40%|████      | 81/200 [00:02<00:02, 51.79it/s]Testing:  44%|████▍     | 88/200 [00:02<00:01, 56.27it/s]Testing:  50%|████▉     | 99/200 [00:02<00:01, 68.34it/s]Testing:  54%|█████▎    | 107/200 [00:02<00:01, 71.06it/s]Testing:  57%|█████▊    | 115/200 [00:02<00:01, 70.02it/s]Testing:  62%|██████▏   | 123/200 [00:02<00:01, 65.54it/s]Testing:  66%|██████▌   | 131/200 [00:02<00:01, 66.36it/s]Testing:  70%|██████▉   | 139/200 [00:02<00:00, 69.78it/s]Testing:  74%|███████▎  | 147/200 [00:02<00:00, 68.29it/s]Testing:  77%|███████▋  | 154/200 [00:03<00:00, 66.98it/s]Testing:  82%|████████▏ | 164/200 [00:03<00:00, 71.08it/s]Testing:  86%|████████▋ | 173/200 [00:03<00:00, 75.94it/s]Testing:  92%|█████████▏| 183/200 [00:03<00:00, 82.41it/s]Testing:  97%|█████████▋| 194/Test loss: 297.6185, Test accuracy: 0.6550
Macro F1-score: 0.6256
Model performance on Angry speech (in test): 
	Precision: 0.8400, Recall: 0.8400, F1_score: 0.8400
Model performance on Happy speech (in test): 
	Precision: 1.0000, Recall: 0.2000, F1_score: 0.3333
Model performance on Neutral speech (in test): 
	Precision: 0.7333, Recall: 0.6600, F1_score: 0.6947
Model performance on Sad speech (in test): 
	Precision: 0.4842, Recall: 0.9200, F1_score: 0.6345

======================= This is fold_1 on cn =======================

Load dataset: 
Loading cn train data: fold_1...
Preprocess cn fold_1 data for cn model
Loading de eval data: fold_1...
Preprocess de fold_1 data for cn model
Loading de test data: fold_1...
Preprocess de fold_1 data for cn model
Use cn model to add lora
================== SET ALL PARAMS =====================
modified_wav2vec2.base_model.model.masked_spec_embed: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.0.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.0.layer_norm.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.0.layer_norm.bias: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.1.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.2.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.3.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.4.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.5.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.6.conv.weight: False
modified_wav2vec2.base_model.model.feature_projection.layer_norm.weight: False
modified_wav2vec2.base_model.model.feature_projection.layer_norm.bias: False
modified_wav2vec2.base_model.model.feature_projection.projection.weight: False
modified_wav2vec2.base_model.model.feature_projection.projection.bias: False
modified_wav2vec2.base_model.model.encoder.pos_conv_embed.conv.bias: False
modified_wav2vec2.base_model.model.encoder.pos_conv_embed.conv.weight_g: False
modified_wav2vec2.base_model.model.encoder.pos_conv_embed.conv.weight_v: False
modified_wav2vec2.base_model.model.encoder.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.up.bias: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.up.bias: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.up.bias: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.up.bias: True
normal_classifier.dense1.weight: True
normal_classifier.dense1.bias: True
normal_classifier.dense.weight: True
normal_classifier.dense.bias: True
normal_classifier.out.weight: True
normal_classifier.out.bias: True
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training loss: 372.6169, Training accuracy: 0.9306
Macro F1-score: 0.9307
Model performance on Angry speech (in training): 
	Precision: 0.8955, Recall: 0.9000, F1_score: 0.8978
Model performance on Happy speech (in training): 
	Precision: 0.9038, Recall: 0.8925, F1_score: 0.8981
Model performance on Neutral speech (in training): 
	Precision: 0.9348, Recall: 0.9675, F1_score: 0.9509
Model performance on Sad speech (in training): 
	Precision: 0.9897, Recall: 0.9625, F1_score: 0.9759

Eval Phase: 
200 [00:03<00:00, 88.12it/s]                                                          Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 191/1600 [00:10<01:13, 19.06it/s]Training:  27%|██▋       | 428/1600 [00:20<00:53, 21.76it/s]Training:  43%|████▎     | 684/1600 [00:30<00:38, 23.50it/s]Training:  60%|█████▉    | 957/1600 [00:40<00:25, 24.98it/s]Training:  77%|███████▋  | 1237/1600 [00:50<00:13, 26.03it/s]Training:  95%|█████████▍| 1516/1600 [01:00<00:03, 26.26it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 312.0669, Validation accuracy: 0.6800
Macro F1-score: 0.5943
Model performance on Angry speech (in validation): 
	Precision: 0.9412, Recall: 0.9600, F1_score: 0.9505
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.4878, Recall: 0.8000, F1_score: 0.6061
Model performance on Sad speech (in validation): 
	Precision: 0.7164, Recall: 0.9600, F1_score: 0.8205
New best accuracy for layer 3 on epoch 1: 0.6800. Model saved.
Epoch 2/100

Training Phase:
Training loss: 165.3974, Training accuracy: 0.9700
Macro F1-score: 0.9700
Model performance on Angry speech (in training): 
	Precision: 0.9556, Recall: 0.9675, F1_score: 0.9615
Model performance on Happy speech (in training): 
	Precision: 0.9644, Recall: 0.9475, F1_score: 0.9559
Model performance on Neutral speech (in training): 
	Precision: 0.9703, Recall: 0.9800, F1_score: 0.9751
Model performance on Sad speech (in training): 
	Precision: 0.9899, Recall: 0.9850, F1_score: 0.9875

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  18%|█▊        | 285/1600 [00:10<00:46, 28.47it/s]Training:  36%|███▌      | 573/1600 [00:20<00:35, 28.61it/s]Training:  54%|█████▍    | 861/1600 [00:30<00:25, 28.65it/s]Training:  72%|███████▏  | 1148/1600 [00:40<00:15, 28.66it/s]Training:  72%|███████▏  | 1148/1600 [00:50<00:15, 28.66it/s]Training:  90%|████████▉ | 1434/1600 [00:50<00:05, 28.55it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 428.0395, Validation accuracy: 0.5950
Macro F1-score: 0.5059
Model performance on Angry speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.4286, Recall: 0.4200, F1_score: 0.4242
Model performance on Sad speech (in validation): 
	Precision: 0.5208, Recall: 1.0000, F1_score: 0.6849
Epoch 3/100

Training Phase:
Training loss: 104.3786, Training accuracy: 0.9800
Macro F1-score: 0.9800
Model performance on Angry speech (in training): 
	Precision: 0.9700, Recall: 0.9700, F1_score: 0.9700
Model performance on Happy speech (in training): 
	Precision: 0.9698, Recall: 0.9650, F1_score: 0.9674
Model performance on Neutral speech (in training): 
	Precision: 0.9851, Recall: 0.9900, F1_score: 0.9875
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
New best accuracy for layer 3 on epoch 3: 0.7150. Model saved.
Epoch 4/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 271/1600 [00:10<00:49, 27.01it/s]Training:  34%|███▍      | 550/1600 [00:20<00:38, 27.48it/s]Training:  52%|█████▏    | 835/1600 [00:30<00:27, 27.93it/s]Training:  70%|███████   | 1120/1600 [00:40<00:17, 28.13it/s]Training:  88%|████████▊ | 1408/1600 [00:50<00:06, 28.35it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 268/1600 [00:10<00:49, 26.80it/s]Training:  34%|███▎      | 536/1600 [00:20<00:39, 26.73it/s]Training:  51%|█████     | 810/1600 [00:30<00:29, 27.02it/s]Training:  68%|██████▊   | 1095/1600 [00:40<00:18, 27.59it/s]Training:  86%|████████▋ | 1381/1600 [00:50<00:07, 27.94it/s]                             Training loss: 103.1688, Training accuracy: 0.9756
Macro F1-score: 0.9756
Model performance on Angry speech (in training): 
	Precision: 0.9696, Recall: 0.9575, F1_score: 0.9635
Model performance on Happy speech (in training): 
	Precision: 0.9627, Recall: 0.9675, F1_score: 0.9651
Model performance on Neutral speech (in training): 
	Precision: 0.9827, Recall: 0.9925, F1_score: 0.9876
Model performance on Sad speech (in training): 
	Precision: 0.9875, Recall: 0.9850, F1_score: 0.9862

Eval Phase: 
                                Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 453.7282, Validation accuracy: 0.6900
Macro F1-score: 0.6033
Model performance on Angry speech (in validation): 
	Precision: 0.8909, Recall: 0.9800, F1_score: 0.9333
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.4884, Recall: 0.8400, F1_score: 0.6176
Model performance on Sad speech (in validation): 
	Precision: 0.7966, Recall: 0.9400, F1_score: 0.8624
Epoch 5/100

Training Phase:
Training loss: 93.3226, Training accuracy: 0.9875
Macro F1-score: 0.9875
Model performance on Angry speech (in training): 
	Precision: 0.9826, Recall: 0.9900, F1_score: 0.9863
Model performance on Happy speech (in training): 
	Precision: 0.9824, Recall: 0.9750, F1_score: 0.9787
Model performance on Neutral speech (in training): 
	Precision: 0.9876, Recall: 0.9950, F1_score: 0.9913
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9900, F1_score: 0.9937

Eval Phase: 
Validation loss: 342.2601, Validation accuracy: 0.6750
Macro F1-score: 0.6039
Model performance on Angry speech (in validation): 
	Precision: 0.9574, Recall: 0.9000, F1_score: 0.9278
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0400, F1_score: 0.0769
Model performance on Neutral speech (in validation): 
	Precision: 0.4938, Recall: 0.8000, F1_score: 0.6107
Model performance on Sad speech (in validation): 
	Precision: 0.6857, Recall: 0.9600, F1_score: 0.8000
Epoch 6/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  18%|█▊        | 288/1600 [00:10<00:45, 28.78it/s]Training:  36%|███▌      | 576/1600 [00:20<00:35, 28.72it/s]Training:  54%|█████▍    | 863/1600 [00:30<00:25, 28.48it/s]Training:  72%|███████▏  | 1154/1600 [00:40<00:15, 28.71it/s]Training:  90%|█████████ | 1445/1600 [00:50<00:05, 28.79it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  18%|█▊        | 284/1600 [00:10<00:46, 28.38it/s]Training:  36%|███▌      | 574/1600 [00:20<00:35, 28.71it/s]Training:  54%|█████▍    | 864/1600 [00:30<00:25, 28.67it/s]Training:  72%|███████▏  | 1153/1600 [00:40<00:15, 28.75it/s]Training:  90%|█████████ | 1442/1600 [00:50<00:05, 28.80it/s]                       Training loss: 51.7655, Training accuracy: 0.9931
Macro F1-score: 0.9931
Model performance on Angry speech (in training): 
	Precision: 0.9850, Recall: 0.9875, F1_score: 0.9863
Model performance on Happy speech (in training): 
	Precision: 0.9900, Recall: 0.9875, F1_score: 0.9887
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
                                      Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 471.7010, Validation accuracy: 0.6700
Macro F1-score: 0.5798
Model performance on Angry speech (in validation): 
	Precision: 0.8571, Recall: 0.9600, F1_score: 0.9057
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.5000, Recall: 0.7400, F1_score: 0.5968
Model performance on Sad speech (in validation): 
	Precision: 0.7000, Recall: 0.9800, F1_score: 0.8167
Epoch 7/100

Training Phase:
Training loss: 49.5977, Training accuracy: 0.9888
Macro F1-score: 0.9888
Model performance on Angry speech (in training): 
	Precision: 0.9777, Recall: 0.9875, F1_score: 0.9826
Model performance on Happy speech (in training): 
	Precision: 0.9850, Recall: 0.9825, F1_score: 0.9837
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 0.9950, F1_score: 0.9975

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 302/1600 [00:10<00:43, 30.14it/s]Training:  38%|███▊      | 611/1600 [00:20<00:32, 30.53it/s]Training:  57%|█████▋    | 919/1600 [00:30<00:22, 30.27it/s]Training:  77%|███████▋  | 1228/1600 [00:40<00:12, 30.51it/s]Training:  96%|█████████▌| 1538/1600 [00:50<00:02, 30.66it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 648.7801, Validation accuracy: 0.5800
Macro F1-score: 0.5066
Model performance on Angry speech (in validation): 
	Precision: 0.9744, Recall: 0.7600, F1_score: 0.8539
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.4242, Recall: 0.5600, F1_score: 0.4828
Model performance on Sad speech (in validation): 
	Precision: 0.5263, Recall: 1.0000, F1_score: 0.6897
Epoch 8/100

Training Phase:
Training loss: 64.7668, Training accuracy: 0.9888
Macro F1-score: 0.9888
Model performance on Angry speech (in training): 
	Precision: 0.9899, Recall: 0.9825, F1_score: 0.9862
Model performance on Happy speech (in training): 
	Precision: 0.9777, Recall: 0.9875, F1_score: 0.9826
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 307/1600 [00:10<00:42, 30.62it/s]Training:  38%|███▊      | 614/1600 [00:20<00:32, 30.62it/s]Training:  58%|█████▊    | 922/1600 [00:30<00:22, 30.68it/s]Training:  77%|███████▋  | 1232/1600 [00:40<00:11, 30.78it/s]Training:  96%|█████████▋| 1542/1600 [00:50<00:01, 30.82it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 595.5271, Validation accuracy: 0.6600
Macro F1-score: 0.5790
Model performance on Angry speech (in validation): 
	Precision: 0.9583, Recall: 0.9200, F1_score: 0.9388
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.4512, Recall: 0.7400, F1_score: 0.5606
Model performance on Sad speech (in validation): 
	Precision: 0.7000, Recall: 0.9800, F1_score: 0.8167
Epoch 9/100

Training Phase:
Training loss: 45.3990, Training accuracy: 0.9912
Macro F1-score: 0.9912
Model performance on Angry speech (in training): 
	Precision: 0.9802, Recall: 0.9900, F1_score: 0.9851
Model performance on Happy speech (in training): 
	Precision: 0.9899, Recall: 0.9800, F1_score: 0.9849
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 307/1600 [00:10<00:42, 30.68it/s]Training:  38%|███▊      | 614/1600 [00:20<00:32, 30.67it/s]Training:  58%|█████▊    | 923/1600 [00:30<00:22, 30.74it/s]Training:  77%|███████▋  | 1232/1600 [00:40<00:11, 30.70it/s]Training:  96%|█████████▋| 1540/1600 [00:50<00:01, 30.73it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 579.0144, Validation accuracy: 0.6600
Macro F1-score: 0.5823
Model performance on Angry speech (in validation): 
	Precision: 0.9423, Recall: 0.9800, F1_score: 0.9608
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.4516, Recall: 0.8400, F1_score: 0.5874
Model performance on Sad speech (in validation): 
	Precision: 0.7455, Recall: 0.8200, F1_score: 0.7810
Epoch 10/100

Training Phase:
Training loss: 46.8604, Training accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9875, F1_score: 0.9912
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938
Model performance on Neutral speech (in training): 
	Precision: 0.9851, Recall: 0.9900, F1_score: 0.9875
Model performance on Sad speech (in training): 
	Precision: 0.9875, Recall: 0.9875, F1_score: 0.9875

Eval Phase: 
Validation loss: 550.3493, Validation accuracy: 0.5700
Macro F1-score: 0.4793
Model performance on Angry speech (in validation): 
	Precision: 0.8448, Recall: 0.9800, F1_score: 0.9074
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.4516, Recall: 0.2800, F1_score: 0.3457
Model performance on Sad speech (in validation): 
	Precision: 0.4545, Recall: 1.0000, F1_score: 0.6250
Epoch 11/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 310/1600 [00:10<00:41, 30.99it/s]Training:  39%|███▉      | 620/1600 [00:20<00:31, 30.93it/s]Training:  58%|█████▊    | 929/1600 [00:30<00:21, 30.74it/s]Training:  77%|███████▋  | 1235/1600 [00:41<00:12, 29.41it/s]Training:  95%|█████████▍| 1519/1600 [00:51<00:02, 29.02it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 304/1600 [00:10<00:42, 30.35it/s]Training:  38%|███▊      | 608/1600 [00:20<00:33, 29.34it/s]Training:  57%|█████▋    | 911/1600 [00:30<00:23, 29.77it/s]Training:  76%|███████▌  | 1217/1600 [00:40<00:12, 30.06it/s]Training:  95%|█████████▌| 1523/1600 [00:51<00:02, 29.25it/s]                   Training loss: 32.0364, Training accuracy: 0.9938
Macro F1-score: 0.9937
Model performance on Angry speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900
Model performance on Happy speech (in training): 
	Precision: 0.9900, Recall: 0.9875, F1_score: 0.9887
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988

Eval Phase: 
                                          Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 489.7680, Validation accuracy: 0.6750
Macro F1-score: 0.5792
Model performance on Angry speech (in validation): 
	Precision: 0.7538, Recall: 0.9800, F1_score: 0.8522
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.5441, Recall: 0.7400, F1_score: 0.6271
Model performance on Sad speech (in validation): 
	Precision: 0.7313, Recall: 0.9800, F1_score: 0.8376
Validation loss does not decrease for 10 epochs. End training.
Epoch 12/100

Entering 2ND training phase: change training data from cn to DE
Loading de train data: fold_1...
Preprocess de fold_1 data for cn model
Reload model and reset eval loss

Training Phase:
Training loss: 2758.1742, Training accuracy: 0.7069
Macro F1-score: 0.6267
Model performance on Angry speech (in training): 
	Precision: 0.7075, Recall: 0.9675, F1_score: 0.8173
Model performance on Happy speech (in training): 
	Precision: 0.9048, Recall: 0.0475, F1_score: 0.0903
Model performance on Neutral speech (in training): 
	Precision: 0.5957, Recall: 0.9025, F1_score: 0.7177
Model performance on Sad speech (in training): 
	Precision: 0.8545, Recall: 0.9100, F1_score: 0.8814

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 13/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:   9%|▉         | 141/1600 [00:10<01:43, 14.07it/s]Training:  19%|█▉        | 308/1600 [00:20<01:22, 15.58it/s]Training:  31%|███       | 498/1600 [00:30<01:04, 17.12it/s]Training:  44%|████▍     | 701/1600 [00:40<00:48, 18.37it/s]Training:  56%|█████▋    | 904/1600 [00:51<00:37, 18.45it/s]Training:  68%|██████▊   | 1090/1600 [01:01<00:28, 18.09it/s]Training:  82%|████████▏ | 1304/1600 [01:11<00:15, 19.12it/s]Training:  95%|█████████▌| 1525/1600 [01:21<00:03, 20.04it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 246/1600 [00:10<00:55, 24.56it/s]Training:  31%|███       | 492/1600 [00:20<00:45, 24.18it/s]Training:  46%|████▌     | 733/160Training loss: 2823.9956, Training accuracy: 0.7044
Macro F1-score: 0.6207
Model performance on Angry speech (in training): 
	Precision: 0.7052, Recall: 0.9750, F1_score: 0.8185
Model performance on Happy speech (in training): 
	Precision: 0.8824, Recall: 0.0375, F1_score: 0.0719
Model performance on Neutral speech (in training): 
	Precision: 0.6010, Recall: 0.9075, F1_score: 0.7231
Model performance on Sad speech (in training): 
	Precision: 0.8427, Recall: 0.8975, F1_score: 0.8692

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 14/100

Training Phase:
Training loss: 2796.1525, Training accuracy: 0.7150
Macro F1-score: 0.6305
Model performance on Angry speech (in training): 
	Precision: 0.7075, Recall: 0.9675, F1_score: 0.8173
Model performance on Happy speech (in training): 
	Precision: 0.7000, Recall: 0.0350, F1_score: 0.0667
Model performance on Neutral speech (in training): 
	Precision: 0.6114, Recall: 0.9400, F1_score: 0.7409
Model performance on Sad speech (in training): 
	Precision: 0.8780, Recall: 0.9175, F1_score: 0.8973

Eval Phase: 
0 [00:30<00:35, 24.09it/s]Training:  61%|██████    | 976/1600 [00:40<00:25, 24.15it/s]Training:  76%|███████▌  | 1219/1600 [00:50<00:15, 24.14it/s]Training:  91%|█████████▏| 1463/1600 [01:00<00:05, 24.22it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 241/1600 [00:10<00:56, 24.02it/s]Training:  30%|███       | 482/1600 [00:20<00:46, 23.88it/s]Training:  46%|████▌     | 728/1600 [00:30<00:36, 24.17it/s]Training:  61%|██████    | 974/1600 [00:40<00:25, 24.13it/s]Training:  76%|███████▌  | 1215/1600 [00:50<00:16, 24.02it/s]Training:  91%|█████████ | 1454/1600 [01:00<00:06, 23.97it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?itValidation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 15/100

Training Phase:
Training loss: 2785.3951, Training accuracy: 0.7131
Macro F1-score: 0.6332
Model performance on Angry speech (in training): 
	Precision: 0.7032, Recall: 0.9775, F1_score: 0.8180
Model performance on Happy speech (in training): 
	Precision: 0.9545, Recall: 0.0525, F1_score: 0.0995
Model performance on Neutral speech (in training): 
	Precision: 0.6091, Recall: 0.9075, F1_score: 0.7289
Model performance on Sad speech (in training): 
	Precision: 0.8592, Recall: 0.9150, F1_score: 0.8862

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 16/100

Training Phase:
/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 241/1600 [00:10<00:56, 24.08it/s]Training:  30%|███       | 485/1600 [00:20<00:46, 24.24it/s]Training:  46%|████▌     | 730/1600 [00:30<00:35, 24.32it/s]Training:  61%|██████    | 975/1600 [00:40<00:25, 24.22it/s]Training:  76%|███████▌  | 1216/1600 [00:50<00:15, 24.13it/s]Training:  91%|█████████▏| 1462/1600 [01:00<00:05, 24.27it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 239/1600 [00:10<00:57, 23.84it/s]Training:  30%|███       | 486/1600 [00:20<00:45, 24.32it/s]Training:  46%|████▌     | 733/1600 [00:30<00:35, 24.12it/s]Training:  61%|██████    | 978/1600 [00:40<00:Training loss: 2779.0908, Training accuracy: 0.7100
Macro F1-score: 0.6287
Model performance on Angry speech (in training): 
	Precision: 0.7174, Recall: 0.9775, F1_score: 0.8275
Model performance on Happy speech (in training): 
	Precision: 0.9000, Recall: 0.0450, F1_score: 0.0857
Model performance on Neutral speech (in training): 
	Precision: 0.5961, Recall: 0.9225, F1_score: 0.7242
Model performance on Sad speech (in training): 
	Precision: 0.8606, Recall: 0.8950, F1_score: 0.8775

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 17/100

Training Phase:
Training loss: 2793.9423, Training accuracy: 0.7094
Macro F1-score: 0.6244
Model performance on Angry speech (in training): 
	Precision: 0.7193, Recall: 0.9800, F1_score: 0.8296
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.0350, F1_score: 0.0676
Model performance on Neutral speech (in training): 
	Precision: 0.5925, Recall: 0.9050, F1_score: 0.7161
Model performance on Sad speech (in training): 
	Precision: 0.8535, Recall: 0.9175, F1_score: 0.8843

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 18/100

Training Phase:
25, 24.23it/s]Training:  76%|███████▋  | 1223/1600 [00:50<00:15, 23.92it/s]Training:  92%|█████████▏| 1470/1600 [01:00<00:05, 24.16it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 243/1600 [00:10<00:55, 24.23it/s]Training:  30%|███       | 486/1600 [00:20<00:46, 24.19it/s]Training:  46%|████▌     | 728/1600 [00:30<00:36, 23.99it/s]Training:  60%|██████    | 967/1600 [00:40<00:26, 23.93it/s]Training:  76%|███████▌  | 1212/1600 [00:50<00:16, 24.11it/s]Training:  91%|█████████ | 1458/1600 [01:00<00:05, 24.27it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0Training loss: 2814.1063, Training accuracy: 0.7081
Macro F1-score: 0.6207
Model performance on Angry speech (in training): 
	Precision: 0.7159, Recall: 0.9700, F1_score: 0.8238
Model performance on Happy speech (in training): 
	Precision: 0.8333, Recall: 0.0250, F1_score: 0.0485
Model performance on Neutral speech (in training): 
	Precision: 0.5939, Recall: 0.9250, F1_score: 0.7234
Model performance on Sad speech (in training): 
	Precision: 0.8629, Recall: 0.9125, F1_score: 0.8870

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 19/100

Training Phase:
/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 245/1600 [00:10<00:55, 24.41it/s]Training:  31%|███       | 490/1600 [00:20<00:45, 24.40it/s]Training:  46%|████▌     | 734/1600 [00:30<00:35, 24.24it/s]Training:  61%|██████    | 977/1600 [00:40<00:25, 24.24it/s]Training:  76%|███████▋  | 1220/1600 [00:50<00:15, 24.06it/s]Training:  91%|█████████ | 1459/1600 [01:00<00:05, 23.98it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 239/1600 [00:10<00:56, 23.90it/s]Training:  30%|███       | 483/1600 [00:20<00:46, 24.17it/s]Training:  45%|████▌     | 727/1600 [00:30<00:36, 24.07it/s]Training:  60%|██████    | 968/1600 [00:40<00:26, 24.06it/s]Training:  76%|███████▌  | 1211/1600 [00:50<00:16, 24.12Training loss: 2794.2312, Training accuracy: 0.7063
Macro F1-score: 0.6264
Model performance on Angry speech (in training): 
	Precision: 0.7180, Recall: 0.9675, F1_score: 0.8243
Model performance on Happy speech (in training): 
	Precision: 0.9048, Recall: 0.0475, F1_score: 0.0903
Model performance on Neutral speech (in training): 
	Precision: 0.5904, Recall: 0.9225, F1_score: 0.7200
Model performance on Sad speech (in training): 
	Precision: 0.8554, Recall: 0.8875, F1_score: 0.8712

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 20/100

Training Phase:
Training loss: 2789.7403, Training accuracy: 0.7056
Macro F1-score: 0.6234
Model performance on Angry speech (in training): 
	Precision: 0.7209, Recall: 0.9750, F1_score: 0.8289
Model performance on Happy speech (in training): 
	Precision: 0.9412, Recall: 0.0400, F1_score: 0.0767
Model performance on Neutral speech (in training): 
	Precision: 0.5845, Recall: 0.9075, F1_score: 0.7111
Model performance on Sad speech (in training): 
	Precision: 0.8551, Recall: 0.9000, F1_score: 0.8770

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 21/100

Training Phase:
it/s]Training:  91%|█████████ | 1455/1600 [01:00<00:05, 24.21it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 244/1600 [00:10<00:55, 24.37it/s]Training:  30%|███       | 488/1600 [00:20<00:46, 24.11it/s]Training:  46%|████▌     | 730/1600 [00:30<00:36, 24.14it/s]Training:  61%|██████    | 973/1600 [00:40<00:25, 24.19it/s]Training:  76%|███████▌  | 1216/1600 [00:50<00:15, 24.10it/s]Training:  91%|█████████ | 1456/1600 [01:00<00:05, 24.02it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 246/1600 [00:10<00:55, 24.55it/s]TTraining loss: 2764.2851, Training accuracy: 0.7150
Macro F1-score: 0.6305
Model performance on Angry speech (in training): 
	Precision: 0.7120, Recall: 0.9825, F1_score: 0.8256
Model performance on Happy speech (in training): 
	Precision: 0.9375, Recall: 0.0375, F1_score: 0.0721
Model performance on Neutral speech (in training): 
	Precision: 0.6029, Recall: 0.9225, F1_score: 0.7292
Model performance on Sad speech (in training): 
	Precision: 0.8738, Recall: 0.9175, F1_score: 0.8951

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 22/100

Training Phase:
raining:  15%|█▌        | 246/1600 [00:20<00:55, 24.55it/s]Training:  31%|███       | 492/1600 [00:20<00:45, 24.30it/s]Training:  46%|████▌     | 734/1600 [00:30<00:35, 24.19it/s]Training:  61%|██████    | 978/1600 [00:40<00:25, 24.25it/s]Training:  76%|███████▋  | 1222/1600 [00:50<00:15, 24.01it/s]Training:  92%|█████████▏| 1464/1600 [01:00<00:05, 24.06it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 235/1600 [00:10<00:58, 23.42it/s]Training:  30%|██▉       | 475/1600 [00:20<00:47, 23.76it/s]Training:  30%|██▉       | 475/1600 [00:30<00:47, 23.76it/s]Training:  44%|████▍     | 708/1600 [00:30<00:38, 23.34it/s]Training:  59%|█████▉    | 947/1600 [00:40<00:27, 23.54it/s]Training:  75%|████Training loss: 2686.3535, Training accuracy: 0.7150
Macro F1-score: 0.6351
Model performance on Angry speech (in training): 
	Precision: 0.7280, Recall: 0.9700, F1_score: 0.8317
Model performance on Happy speech (in training): 
	Precision: 0.8696, Recall: 0.0500, F1_score: 0.0946
Model performance on Neutral speech (in training): 
	Precision: 0.5971, Recall: 0.9300, F1_score: 0.7273
Model performance on Sad speech (in training): 
	Precision: 0.8646, Recall: 0.9100, F1_score: 0.8867

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 23/100

Training Phase:
Training loss: 2836.2794, Training accuracy: 0.7019
Macro F1-score: 0.6180
Model performance on Angry speech (in training): 
	Precision: 0.6993, Recall: 0.9650, F1_score: 0.8109
Model performance on Happy speech (in training): 
	Precision: 0.8824, Recall: 0.0375, F1_score: 0.0719
Model performance on Neutral speech (in training): 
	Precision: 0.6077, Recall: 0.9025, F1_score: 0.7264
Model performance on Sad speech (in training): 
	Precision: 0.8261, Recall: 0.9025, F1_score: 0.8626

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 24/100

Training Phase:
███▍  | 1196/1600 [00:50<00:16, 24.00it/s]Training:  90%|█████████ | 1445/1600 [01:00<00:06, 23.92it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 245/1600 [00:10<00:55, 24.48it/s]Training:  31%|███       | 490/1600 [00:20<00:47, 23.21it/s]Training:  45%|████▍     | 714/1600 [00:31<00:39, 22.70it/s]Training:  58%|█████▊    | 935/1600 [00:41<00:29, 22.46it/s]Training:  72%|███████▎  | 1160/1600 [00:51<00:19, 22.45it/s]Training:  87%|████████▋ | 1385/1600 [01:01<00:09, 22.44it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍Training loss: 2797.6689, Training accuracy: 0.7075
Macro F1-score: 0.6235
Model performance on Angry speech (in training): 
	Precision: 0.7000, Recall: 0.9800, F1_score: 0.8167
Model performance on Happy speech (in training): 
	Precision: 0.8824, Recall: 0.0375, F1_score: 0.0719
Model performance on Neutral speech (in training): 
	Precision: 0.6076, Recall: 0.9175, F1_score: 0.7311
Model performance on Sad speech (in training): 
	Precision: 0.8544, Recall: 0.8950, F1_score: 0.8742

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 25/100

Training Phase:
        | 231/1600 [00:10<00:59, 23.03it/s]Training:  29%|██▉       | 465/1600 [00:20<00:48, 23.22it/s]Training:  44%|████▍     | 700/1600 [00:30<00:38, 23.34it/s]Training:  59%|█████▊    | 939/1600 [00:40<00:28, 23.54it/s]Training:  74%|███████▎  | 1179/1600 [00:50<00:17, 23.70it/s]Training:  89%|████████▉ | 1420/1600 [01:00<00:07, 23.82it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 246/1600 [00:10<00:55, 24.59it/s]Training:  31%|███       | 492/1600 [00:20<00:46, 23.91it/s]Training:  45%|████▌     | 727/1600 [00:30<00:36, 23.65it/s]Training:  60%|██████    | 961/1600 [00:40<00:27, 23.28it/s]Training:  75%|███████▍  | 1195/1600 [00:50<00:17, 23.30it/s]Training:  89%|███████Training loss: 2738.7487, Training accuracy: 0.7100
Macro F1-score: 0.6303
Model performance on Angry speech (in training): 
	Precision: 0.7213, Recall: 0.9575, F1_score: 0.8228
Model performance on Happy speech (in training): 
	Precision: 0.9524, Recall: 0.0500, F1_score: 0.0950
Model performance on Neutral speech (in training): 
	Precision: 0.5936, Recall: 0.9275, F1_score: 0.7239
Model performance on Sad speech (in training): 
	Precision: 0.8558, Recall: 0.9050, F1_score: 0.8797

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 26/100

Training Phase:
Training loss: 2792.2898, Training accuracy: 0.7031
Macro F1-score: 0.6197
Model performance on Angry speech (in training): 
	Precision: 0.7122, Recall: 0.9650, F1_score: 0.8195
Model performance on Happy speech (in training): 
	Precision: 0.7778, Recall: 0.0350, F1_score: 0.0670
Model performance on Neutral speech (in training): 
	Precision: 0.5925, Recall: 0.9125, F1_score: 0.7185
Model performance on Sad speech (in training): 
	Precision: 0.8491, Recall: 0.9000, F1_score: 0.8738

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 27/100

Training Phase:
▉ | 1430/1600 [01:00<00:07, 23.36it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 235/1600 [00:10<00:58, 23.50it/s]Training:  30%|██▉       | 473/1600 [00:20<00:47, 23.63it/s]Training:  44%|████▍     | 711/1600 [00:30<00:38, 23.32it/s]Training:  59%|█████▉    | 942/1600 [00:40<00:28, 23.19it/s]Training:  73%|███████▎  | 1172/1600 [00:50<00:18, 22.84it/s]Training:  88%|████████▊ | 1406/1600 [01:00<00:08, 23.00it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 228/1600 [00:10<01:00, 22.74it/s]Training:  29%|██▉       | 461/1600 [00Training loss: 2714.6770, Training accuracy: 0.7219
Macro F1-score: 0.6447
Model performance on Angry speech (in training): 
	Precision: 0.7190, Recall: 0.9850, F1_score: 0.8312
Model performance on Happy speech (in training): 
	Precision: 0.9630, Recall: 0.0650, F1_score: 0.1218
Model performance on Neutral speech (in training): 
	Precision: 0.6133, Recall: 0.9200, F1_score: 0.7360
Model performance on Sad speech (in training): 
	Precision: 0.8635, Recall: 0.9175, F1_score: 0.8897

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 28/100

Training Phase:
:20<00:49, 23.03it/s]Training:  44%|████▎     | 697/1600 [00:30<00:38, 23.26it/s]Training:  44%|████▎     | 697/1600 [00:40<00:38, 23.26it/s]Training:  58%|█████▊    | 928/1600 [00:40<00:29, 23.04it/s]Training:  73%|███████▎  | 1161/1600 [00:50<00:19, 23.10it/s]Training:  87%|████████▋ | 1394/1600 [01:00<00:08, 23.04it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 232/1600 [00:10<00:59, 23.11it/s]Training:  29%|██▉       | 465/1600 [00:20<00:48, 23.18it/s]Training:  44%|████▎     | 698/1600 [00:30<00:38, 23.14it/s]Training:  58%|█████▊    | 934/1600 [00:40<00:28, 23.31it/s]Training:  73%|███████▎  | 1170/1600 [00:50<00:18, 23.13it/s]Training:  88%|████████▊ | 1401/1600 [Training loss: 2805.8233, Training accuracy: 0.7156
Macro F1-score: 0.6312
Model performance on Angry speech (in training): 
	Precision: 0.7014, Recall: 0.9750, F1_score: 0.8159
Model performance on Happy speech (in training): 
	Precision: 0.9412, Recall: 0.0400, F1_score: 0.0767
Model performance on Neutral speech (in training): 
	Precision: 0.6190, Recall: 0.9425, F1_score: 0.7473
Model performance on Sad speech (in training): 
	Precision: 0.8660, Recall: 0.9050, F1_score: 0.8851

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 29/100

Training Phase:
Training loss: 2801.2119, Training accuracy: 0.7044
Macro F1-score: 0.6143
Model performance on Angry speech (in training): 
	Precision: 0.7244, Recall: 0.9725, F1_score: 0.8303
Model performance on Happy speech (in training): 
	Precision: 0.8750, Recall: 0.0175, F1_score: 0.0343
Model performance on Neutral speech (in training): 
	Precision: 0.5880, Recall: 0.9100, F1_score: 0.7144
Model performance on Sad speech (in training): 
	Precision: 0.8417, Recall: 0.9175, F1_score: 0.8780

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 30/100

Training Phase:
01:00<00:08, 23.09it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 230/1600 [00:10<00:59, 22.94it/s]Training:  29%|██▉       | 462/1600 [00:20<00:49, 23.08it/s]Training:  43%|████▎     | 694/1600 [00:30<00:39, 23.10it/s]Training:  58%|█████▊    | 931/1600 [00:40<00:28, 23.32it/s]Training:  73%|███████▎  | 1168/1600 [00:50<00:18, 23.08it/s]Training:  87%|████████▋ | 1398/1600 [01:00<00:08, 23.04it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 235/1600 [00:10<00:58, 23.49it/s]Training:  29%|██▉       | 470/1600 [00:20<00:48, 23.14itTraining loss: 2790.2817, Training accuracy: 0.7194
Macro F1-score: 0.6378
Model performance on Angry speech (in training): 
	Precision: 0.7201, Recall: 0.9775, F1_score: 0.8293
Model performance on Happy speech (in training): 
	Precision: 0.9500, Recall: 0.0475, F1_score: 0.0905
Model performance on Neutral speech (in training): 
	Precision: 0.6023, Recall: 0.9275, F1_score: 0.7303
Model performance on Sad speech (in training): 
	Precision: 0.8789, Recall: 0.9250, F1_score: 0.9013

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 31/100

Training Phase:
/s]Training:  44%|████▍     | 703/1600 [00:30<00:38, 23.20it/s]Training:  58%|█████▊    | 936/1600 [00:40<00:28, 23.12it/s]Training:  73%|███████▎  | 1167/1600 [00:50<00:18, 23.11it/s]Training:  87%|████████▋ | 1398/1600 [01:01<00:08, 22.64it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 206/1600 [00:10<01:07, 20.51it/s]Training:  26%|██▋       | 422/1600 [00:20<00:55, 21.11it/s]Training:  41%|████      | 650/1600 [00:30<00:43, 21.86it/s]Training:  55%|█████▌    | 883/1600 [00:40<00:31, 22.41it/s]Training:  70%|██████▉   | 1116/1600 [00:50<00:21, 22.51it/s]Training:  85%|████████▍ | 1356/1600 [01:00<00:10, 23.00it/s]Training: 100%|█████████▉| 1597/1600 [01:10<00:00Training loss: 2802.8321, Training accuracy: 0.7081
Macro F1-score: 0.6243
Model performance on Angry speech (in training): 
	Precision: 0.7038, Recall: 0.9625, F1_score: 0.8131
Model performance on Happy speech (in training): 
	Precision: 0.8824, Recall: 0.0375, F1_score: 0.0719
Model performance on Neutral speech (in training): 
	Precision: 0.6040, Recall: 0.9150, F1_score: 0.7276
Model performance on Sad speech (in training): 
	Precision: 0.8535, Recall: 0.9175, F1_score: 0.8843

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 32/100

Training Phase:
Training loss: 2765.2999, Training accuracy: 0.7169
Macro F1-score: 0.6379
Model performance on Angry speech (in training): 
	Precision: 0.7182, Recall: 0.9750, F1_score: 0.8271
Model performance on Happy speech (in training): 
	Precision: 0.9167, Recall: 0.0550, F1_score: 0.1038
Model performance on Neutral speech (in training): 
	Precision: 0.6049, Recall: 0.9300, F1_score: 0.7330
Model performance on Sad speech (in training): 
	Precision: 0.8684, Recall: 0.9075, F1_score: 0.8875

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 33/100

Training Phase:
, 23.33it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 227/1600 [00:10<01:00, 22.66it/s]Training:  29%|██▉       | 467/1600 [00:20<00:48, 23.43it/s]Training:  29%|██▉       | 467/1600 [00:30<00:48, 23.43it/s]Training:  44%|████▍     | 707/1600 [00:30<00:37, 23.57it/s]Training:  59%|█████▉    | 949/1600 [00:40<00:27, 23.81it/s]Training:  74%|███████▍  | 1192/1600 [00:50<00:17, 23.98it/s]Training:  90%|████████▉ | 1435/1600 [01:00<00:06, 24.02it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 237/1600 [00:10<00:57, 23.62it/s]TraininTraining loss: 2744.6830, Training accuracy: 0.7181
Macro F1-score: 0.6354
Model performance on Angry speech (in training): 
	Precision: 0.7158, Recall: 0.9825, F1_score: 0.8282
Model performance on Happy speech (in training): 
	Precision: 0.9000, Recall: 0.0450, F1_score: 0.0857
Model performance on Neutral speech (in training): 
	Precision: 0.6127, Recall: 0.9375, F1_score: 0.7411
Model performance on Sad speech (in training): 
	Precision: 0.8663, Recall: 0.9075, F1_score: 0.8864

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 34/100

Training Phase:
g:  30%|██▉       | 479/1600 [00:20<00:46, 23.94it/s]Training:  45%|████▌     | 721/1600 [00:30<00:36, 24.00it/s]Training:  60%|██████    | 963/1600 [00:40<00:26, 24.06it/s]Training:  75%|███████▌  | 1206/1600 [00:50<00:16, 24.14it/s]Training:  91%|█████████ | 1450/1600 [01:00<00:06, 24.20it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 243/1600 [00:10<00:55, 24.29it/s]Training:  30%|███       | 486/1600 [00:20<00:45, 24.23it/s]Training:  46%|████▌     | 728/1600 [00:30<00:36, 24.16it/s]Training:  61%|██████    | 972/1600 [00:40<00:25, 24.25it/s]Training:  76%|███████▌  | 1216/1600 [00:50<00:15, 24.07it/s]Training:  91%|█████████ | 1457/1600 [01:00<00:05, 24.05it/s]         Training loss: 2795.6019, Training accuracy: 0.7031
Macro F1-score: 0.6248
Model performance on Angry speech (in training): 
	Precision: 0.7169, Recall: 0.9625, F1_score: 0.8218
Model performance on Happy speech (in training): 
	Precision: 0.8261, Recall: 0.0475, F1_score: 0.0898
Model performance on Neutral speech (in training): 
	Precision: 0.5804, Recall: 0.9200, F1_score: 0.7118
Model performance on Sad speech (in training): 
	Precision: 0.8695, Recall: 0.8825, F1_score: 0.8759

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 35/100

Training Phase:
Training loss: 2751.9839, Training accuracy: 0.7069
Macro F1-score: 0.6208
Model performance on Angry speech (in training): 
	Precision: 0.7183, Recall: 0.9500, F1_score: 0.8181
Model performance on Happy speech (in training): 
	Precision: 0.7333, Recall: 0.0275, F1_score: 0.0530
Model performance on Neutral speech (in training): 
	Precision: 0.5952, Recall: 0.9375, F1_score: 0.7282
Model performance on Sad speech (in training): 
	Precision: 0.8568, Recall: 0.9125, F1_score: 0.8838

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 36/100

Training Phase:
                                                    Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 243/1600 [00:10<00:55, 24.25it/s]Training:  31%|███       | 489/1600 [00:20<00:45, 24.42it/s]Training:  46%|████▌     | 735/1600 [00:30<00:35, 24.21it/s]Training:  61%|██████    | 975/1600 [00:40<00:25, 24.12it/s]Training:  76%|███████▌  | 1219/1600 [00:50<00:15, 24.20it/s]Training:  91%|█████████▏| 1463/1600 [01:00<00:05, 24.07it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 237/1600 [00:10<00:57, 23.65it/s]Training:  30%|███       | 482/1600 [00:20<00:46, 24.09it/s]Training:  45%|████Training loss: 2781.1957, Training accuracy: 0.7063
Macro F1-score: 0.6243
Model performance on Angry speech (in training): 
	Precision: 0.7148, Recall: 0.9650, F1_score: 0.8213
Model performance on Happy speech (in training): 
	Precision: 0.8889, Recall: 0.0400, F1_score: 0.0766
Model performance on Neutral speech (in training): 
	Precision: 0.5871, Recall: 0.9100, F1_score: 0.7137
Model performance on Sad speech (in training): 
	Precision: 0.8626, Recall: 0.9100, F1_score: 0.8856

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 37/100

Training Phase:
▌     | 726/1600 [00:30<00:36, 24.03it/s]Training:  61%|██████    | 969/1600 [00:40<00:26, 24.10it/s]Training:  76%|███████▌  | 1212/1600 [00:50<00:16, 24.15it/s]Training:  91%|█████████ | 1455/1600 [01:00<00:06, 24.07it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 231/1600 [00:10<00:59, 23.06it/s]Training:  29%|██▉       | 462/1600 [00:20<00:49, 23.01it/s]Training:  43%|████▎     | 695/1600 [00:30<00:39, 23.10it/s]Training:  58%|█████▊    | 928/1600 [00:40<00:28, 23.17it/s]Training:  73%|███████▎  | 1163/1600 [00:50<00:18, 23.29it/s]Training:  73%|███████▎  | 1163/1600 [01:00<00:18, 23.29it/s]Training:  87%|████████▋ | 1396/1600 [01:00<00:08, 23.20it/s]                  Training loss: 2862.1340, Training accuracy: 0.7094
Macro F1-score: 0.6228
Model performance on Angry speech (in training): 
	Precision: 0.7101, Recall: 0.9800, F1_score: 0.8235
Model performance on Happy speech (in training): 
	Precision: 0.8667, Recall: 0.0325, F1_score: 0.0627
Model performance on Neutral speech (in training): 
	Precision: 0.6137, Recall: 0.9175, F1_score: 0.7355
Model performance on Sad speech (in training): 
	Precision: 0.8345, Recall: 0.9075, F1_score: 0.8695

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 38/100

Training Phase:
Training loss: 2794.5378, Training accuracy: 0.7013
Macro F1-score: 0.6176
Model performance on Angry speech (in training): 
	Precision: 0.6973, Recall: 0.9675, F1_score: 0.8105
Model performance on Happy speech (in training): 
	Precision: 0.9333, Recall: 0.0350, F1_score: 0.0675
Model performance on Neutral speech (in training): 
	Precision: 0.5951, Recall: 0.9150, F1_score: 0.7212
Model performance on Sad speech (in training): 
	Precision: 0.8554, Recall: 0.8875, F1_score: 0.8712

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 39/100

Training Phase:
                                           Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 233/1600 [00:10<00:58, 23.24it/s]Training:  29%|██▉       | 469/1600 [00:20<00:48, 23.43it/s]Training:  44%|████▍     | 705/1600 [00:30<00:38, 23.44it/s]Training:  59%|█████▉    | 946/1600 [00:40<00:27, 23.66it/s]Training:  74%|███████▍  | 1190/1600 [00:50<00:17, 23.90it/s]Training:  90%|████████▉ | 1434/1600 [01:00<00:06, 24.01it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 237/1600 [00:10<00:57, 23.67it/s]Training:  30%|██▉       | 474/1600 [00:20<00:48, 23.23it/s]Training:  30%|██▉       | 474/1Training loss: 2776.1903, Training accuracy: 0.7119
Macro F1-score: 0.6312
Model performance on Angry speech (in training): 
	Precision: 0.7201, Recall: 0.9650, F1_score: 0.8248
Model performance on Happy speech (in training): 
	Precision: 0.9048, Recall: 0.0475, F1_score: 0.0903
Model performance on Neutral speech (in training): 
	Precision: 0.5974, Recall: 0.9275, F1_score: 0.7267
Model performance on Sad speech (in training): 
	Precision: 0.8602, Recall: 0.9075, F1_score: 0.8832

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 40/100

Training Phase:
600 [00:30<00:48, 23.23it/s]Training:  44%|████▍     | 703/1600 [00:30<00:39, 22.88it/s]Training:  58%|█████▊    | 936/1600 [00:40<00:28, 23.04it/s]Training:  73%|███████▎  | 1169/1600 [00:50<00:18, 23.12it/s]Training:  88%|████████▊ | 1402/1600 [01:00<00:08, 23.14it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 230/1600 [00:10<00:59, 22.97it/s]Training:  29%|██▉       | 463/1600 [00:20<00:49, 23.10it/s]Training:  43%|████▎     | 695/1600 [00:30<00:39, 23.00it/s]Training:  58%|█████▊    | 924/1600 [00:40<00:29, 22.92it/s]Training:  72%|███████▏  | 1157/1600 [00:50<00:19, 23.05it/s]Training:  87%|████████▋ | 1394/1600 [01:00<00:08, 23.25it/s]                                        Training loss: 2826.3421, Training accuracy: 0.7037
Macro F1-score: 0.6245
Model performance on Angry speech (in training): 
	Precision: 0.7169, Recall: 0.9625, F1_score: 0.8218
Model performance on Happy speech (in training): 
	Precision: 0.9048, Recall: 0.0475, F1_score: 0.0903
Model performance on Neutral speech (in training): 
	Precision: 0.5840, Recall: 0.9125, F1_score: 0.7122
Model performance on Sad speech (in training): 
	Precision: 0.8561, Recall: 0.8925, F1_score: 0.8739

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 41/100

Training Phase:
Training loss: 2812.5442, Training accuracy: 0.7119
Macro F1-score: 0.6329
Model performance on Angry speech (in training): 
	Precision: 0.7014, Recall: 0.9750, F1_score: 0.8159
Model performance on Happy speech (in training): 
	Precision: 0.9167, Recall: 0.0550, F1_score: 0.1038
Model performance on Neutral speech (in training): 
	Precision: 0.6111, Recall: 0.9075, F1_score: 0.7304
Model performance on Sad speech (in training): 
	Precision: 0.8545, Recall: 0.9100, F1_score: 0.8814

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 42/100

Training Phase:
                     Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 239/1600 [00:10<00:57, 23.82it/s]Training:  30%|██▉       | 478/1600 [00:20<00:47, 23.44it/s]Training:  45%|████▍     | 713/1600 [00:30<00:37, 23.45it/s]Training:  59%|█████▉    | 948/1600 [00:40<00:27, 23.30it/s]Training:  74%|███████▍  | 1181/1600 [00:50<00:18, 23.27it/s]Training:  88%|████████▊ | 1414/1600 [01:00<00:08, 23.04it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 232/1600 [00:10<00:59, 23.13it/s]Training:  29%|██▉       | 464/1600 [00:20<00:49, 22.91it/s]Training:  44%|████▎     | 697/1600 [00:30<00:39, Training loss: 2776.2781, Training accuracy: 0.7031
Macro F1-score: 0.6211
Model performance on Angry speech (in training): 
	Precision: 0.7093, Recall: 0.9575, F1_score: 0.8149
Model performance on Happy speech (in training): 
	Precision: 0.9412, Recall: 0.0400, F1_score: 0.0767
Model performance on Neutral speech (in training): 
	Precision: 0.5900, Recall: 0.9175, F1_score: 0.7182
Model performance on Sad speech (in training): 
	Precision: 0.8527, Recall: 0.8975, F1_score: 0.8745

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 43/100

Training Phase:
Training loss: 2785.8368, Training accuracy: 0.7031
Macro F1-score: 0.6243
Model performance on Angry speech (in training): 
	Precision: 0.7281, Recall: 0.9575, F1_score: 0.8272
Model performance on Happy speech (in training): 
	Precision: 0.9524, Recall: 0.0500, F1_score: 0.0950
Model performance on Neutral speech (in training): 
	Precision: 0.5817, Recall: 0.9075, F1_score: 0.7090
Model performance on Sad speech (in training): 
	Precision: 0.8368, Recall: 0.8975, F1_score: 0.8661

Eval Phase: 
23.05it/s]Training:  58%|█████▊    | 930/1600 [00:40<00:28, 23.12it/s]Training:  73%|███████▎  | 1163/1600 [00:50<00:18, 23.12it/s]Training:  87%|████████▋ | 1396/1600 [01:00<00:08, 23.15it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 234/1600 [00:10<00:58, 23.31it/s]Training:  29%|██▉       | 468/1600 [00:20<00:48, 23.32it/s]Training:  44%|████▍     | 702/1600 [00:30<00:38, 23.21it/s]Training:  59%|█████▊    | 937/1600 [00:40<00:28, 23.29it/s]Training:  73%|███████▎  | 1171/1600 [00:50<00:18, 23.22it/s]Training:  88%|████████▊ | 1403/1600 [01:00<00:08, 23.05it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]              Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 44/100

Training Phase:
Training loss: 2826.3327, Training accuracy: 0.7069
Macro F1-score: 0.6237
Model performance on Angry speech (in training): 
	Precision: 0.7034, Recall: 0.9725, F1_score: 0.8164
Model performance on Happy speech (in training): 
	Precision: 0.8889, Recall: 0.0400, F1_score: 0.0766
Model performance on Neutral speech (in training): 
	Precision: 0.6063, Recall: 0.9200, F1_score: 0.7309
Model performance on Sad speech (in training): 
	Precision: 0.8483, Recall: 0.8950, F1_score: 0.8710

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 45/100

Training Phase:
                                     Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 231/1600 [00:10<00:59, 23.08it/s]Training:  29%|██▉       | 464/1600 [00:20<00:49, 23.15it/s]Training:  44%|████▎     | 697/1600 [00:30<00:38, 23.17it/s]Training:  58%|█████▊    | 929/1600 [00:40<00:29, 23.01it/s]Training:  73%|███████▎  | 1161/1600 [00:50<00:19, 23.05it/s]Training:  87%|████████▋ | 1393/1600 [01:00<00:09, 22.95it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 233/1600 [00:10<00:58, 23.23it/s]Training:  29%|██▉       | 466/1600 [00:20<00:49, 22.88it/s]Training:  43%|████▎     | 695/1600 [00:30<00:39, 22.87it/s]Training:  58%|█████▊    | 930/1600 [00:40<00:29, 23.09it/s]TrainTraining loss: 2793.3005, Training accuracy: 0.7125
Macro F1-score: 0.6295
Model performance on Angry speech (in training): 
	Precision: 0.7055, Recall: 0.9700, F1_score: 0.8168
Model performance on Happy speech (in training): 
	Precision: 0.8889, Recall: 0.0400, F1_score: 0.0766
Model performance on Neutral speech (in training): 
	Precision: 0.6033, Recall: 0.9275, F1_score: 0.7310
Model performance on Sad speech (in training): 
	Precision: 0.8753, Recall: 0.9125, F1_score: 0.8935

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 46/100

Training Phase:
Training loss: 2835.5092, Training accuracy: 0.7056
Macro F1-score: 0.6222
Model performance on Angry speech (in training): 
	Precision: 0.6989, Recall: 0.9750, F1_score: 0.8142
Model performance on Happy speech (in training): 
	Precision: 0.8889, Recall: 0.0400, F1_score: 0.0766
Model performance on Neutral speech (in training): 
	Precision: 0.6111, Recall: 0.9075, F1_score: 0.7304
Model performance on Sad speech (in training): 
	Precision: 0.8372, Recall: 0.9000, F1_score: 0.8675

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 47/100

Training Phase:
ing:  73%|███████▎  | 1165/1600 [00:50<00:18, 23.17it/s]Training:  87%|████████▋ | 1399/1600 [01:00<00:08, 23.10it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 231/1600 [00:10<00:59, 23.08it/s]Training:  29%|██▉       | 463/1600 [00:20<00:49, 23.12it/s]Training:  43%|████▎     | 695/1600 [00:30<00:39, 22.91it/s]Training:  58%|█████▊    | 929/1600 [00:40<00:29, 23.08it/s]Training:  73%|███████▎  | 1163/1600 [00:50<00:19, 22.97it/s]Training:  87%|████████▋ | 1396/1600 [01:00<00:08, 23.06it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training loss: 2789.5054, Training accuracy: 0.7106
Macro F1-score: 0.6314
Model performance on Angry speech (in training): 
	Precision: 0.7143, Recall: 0.9625, F1_score: 0.8200
Model performance on Happy speech (in training): 
	Precision: 0.9130, Recall: 0.0525, F1_score: 0.0993
Model performance on Neutral speech (in training): 
	Precision: 0.6007, Recall: 0.9175, F1_score: 0.7260
Model performance on Sad speech (in training): 
	Precision: 0.8525, Recall: 0.9100, F1_score: 0.8803

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 48/100

Training Phase:
Training:  14%|█▍        | 231/1600 [00:10<00:59, 23.00it/s]Training:  29%|██▉       | 466/1600 [00:20<00:48, 23.26it/s]Training:  44%|████▍     | 701/1600 [00:30<00:38, 23.30it/s]Training:  58%|█████▊    | 935/1600 [00:40<00:28, 23.21it/s]Training:  73%|███████▎  | 1166/1600 [00:50<00:18, 23.11it/s]Training:  87%|████████▋ | 1396/1600 [01:00<00:08, 23.03it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 228/1600 [00:10<01:00, 22.75it/s]Training:  29%|██▉       | 462/1600 [00:20<00:49, 23.08it/s]Training:  44%|████▎     | 696/1600 [00:30<00:39, 23.03it/s]Training:  58%|█████▊    | 932/1600 [00:40<00:28, 23.22it/s]Training:  73%|███████▎  | 1170/1600 [00:50<00:18, 23.40it/s]Training:  88%|Training loss: 2707.4674, Training accuracy: 0.7094
Macro F1-score: 0.6283
Model performance on Angry speech (in training): 
	Precision: 0.7452, Recall: 0.9800, F1_score: 0.8467
Model performance on Happy speech (in training): 
	Precision: 0.8500, Recall: 0.0425, F1_score: 0.0810
Model performance on Neutral speech (in training): 
	Precision: 0.5786, Recall: 0.9200, F1_score: 0.7104
Model performance on Sad speech (in training): 
	Precision: 0.8565, Recall: 0.8950, F1_score: 0.8753

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 49/100

Training Phase:
Training loss: 2772.8609, Training accuracy: 0.7069
Macro F1-score: 0.6244
Model performance on Angry speech (in training): 
	Precision: 0.7083, Recall: 0.9650, F1_score: 0.8169
Model performance on Happy speech (in training): 
	Precision: 0.8000, Recall: 0.0400, F1_score: 0.0762
Model performance on Neutral speech (in training): 
	Precision: 0.6010, Recall: 0.9150, F1_score: 0.7255
Model performance on Sad speech (in training): 
	Precision: 0.8521, Recall: 0.9075, F1_score: 0.8789

Eval Phase: 
Validation loss: 389.1427, Validation accuracy: 0.7150
Macro F1-score: 0.6258
Model performance on Angry speech (in validation): 
	Precision: 0.7500, Recall: 0.9600, F1_score: 0.8421
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5750, Recall: 0.9200, F1_score: 0.7077
Model performance on Sad speech (in validation): 
	Precision: 0.8727, Recall: 0.9600, F1_score: 0.9143
Epoch 50/100

Two-stage training complete.
Model best accuracy on validation set: 0.7150

Test Phase: 
███████▊ | 1408/1600 [01:00<00:08, 23.21it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 230/1600 [00:10<00:59, 22.96it/s]Training:  14%|█▍        | 230/1600 [00:20<00:59, 22.96it/s]Training:  28%|██▊       | 445/1600 [00:20<00:54, 21.37it/s]Training:  42%|████▏     | 677/1600 [00:30<00:41, 22.15it/s]Training:  57%|█████▋    | 914/1600 [00:40<00:30, 22.73it/s]Training:  72%|███████▏  | 1151/1600 [00:50<00:19, 22.95it/s]Training:  87%|████████▋ | 1385/1600 [01:00<00:09, 22.97it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]Testing:   1%|          | 2/200 [00:00<00:15, 12.50it/s]Testing:   2%|▎         | 5/200 [00:00<00:10, 18.93it/s]Testing:   4%|▍         | 8/200 [00:00<00:10, 19.08it/s]Testing:   6%|▌         | 11/200 [00:00<00:08, 21.45it/s]Testing:   7%|▋         | 14/200 [00:00<00:09, 20.14it/s]Testing:   8%|▊         | 17/200 [00:00<00:08, 20.60it/s]Testing:  10%|█         | 20/200 [00:00<00:08, 22.18it/s]Testing:  12%|█▏        | 23/200 [00:01<00:08, 21.56it/s]Testing:  14%|█▍        | 28/200 [00:01<00:06, 28.23it/s]Testing:  16%|█▋        | 33/200 [00:01<00:05, 33.30it/s]Testing:  20%|█▉        | 39/200 [00:01<00:04, 39.02it/s]Testing:  23%|██▎       | 46/200 [00:01<00:03, 43.02it/s]Testing:  26%|██▌       | 52/200 [00:01<00:03, 46.48it/s]Testing:  30%|███       | 60/200 [00:01<00:02, 52.79it/s]Testing:  33%|███▎      | 66/200 [00:01<00:02, 52.79it/s]Testing:  36%|███▋      | 73/200 [00:02<00:02, 56.08it/s]Testing:  40%|████      | 80/200 [00:02<00:02, 58.96itTest loss: 329.3772, Test accuracy: 0.7800
Macro F1-score: 0.7164
Model performance on Angry speech (in test): 
	Precision: 0.7812, Recall: 1.0000, F1_score: 0.8772
Model performance on Happy speech (in test): 
	Precision: 1.0000, Recall: 0.1400, F1_score: 0.2456
Model performance on Neutral speech (in test): 
	Precision: 0.6622, Recall: 0.9800, F1_score: 0.7903
Model performance on Sad speech (in test): 
	Precision: 0.9091, Recall: 1.0000, F1_score: 0.9524

======================= This is fold_2 on cn =======================

Load dataset: 
Loading cn train data: fold_2...
Preprocess cn fold_2 data for cn model
Loading de eval data: fold_2...
Preprocess de fold_2 data for cn model
Loading de test data: fold_2...
Preprocess de fold_2 data for cn model
Use cn model to add lora
================== SET ALL PARAMS =====================
modified_wav2vec2.base_model.model.masked_spec_embed: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.0.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.0.layer_norm.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.0.layer_norm.bias: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.1.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.2.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.3.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.4.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.5.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.6.conv.weight: False
modified_wav2vec2.base_model.model.feature_projection.layer_norm.weight: False
modified_wav2vec2.base_model.model.feature_projection.layer_norm.bias: False
modified_wav2vec2.base_model.model.feature_projection.projection.weight: False
modified_wav2vec2.base_model.model.feature_projection.projection.bias: False
modified_wav2vec2.base_model.model.encoder.pos_conv_embed.conv.bias: False
modified_wav2vec2.base_model.model.encoder.pos_conv_embed.conv.weight_g: False
modified_wav2vec2.base_model.model.encoder.pos_conv_embed.conv.weight_v: False
modified_wav2vec2.base_model.model.encoder.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.up.bias: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.up.bias: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.up.bias: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.up.bias: True
normal_classifier.dense1.weight: True
normal_classifier.dense1.bias: True
normal_classifier.dense.weight: True
normal_classifier.dense.bias: True
normal_classifier.out.weight: True
normal_classifier.out.bias: True
Set optimizer and criterion
Epoch 1/100

Training Phase:
/s]Testing:  44%|████▎     | 87/200 [00:02<00:01, 60.82it/s]Testing:  48%|████▊     | 96/200 [00:02<00:01, 68.18it/s]Testing:  53%|█████▎    | 106/200 [00:02<00:01, 70.26it/s]Testing:  57%|█████▋    | 114/200 [00:02<00:01, 61.82it/s]Testing:  60%|██████    | 121/200 [00:02<00:01, 60.82it/s]Testing:  64%|██████▍   | 129/200 [00:02<00:01, 60.20it/s]Testing:  69%|██████▉   | 138/200 [00:03<00:00, 67.25it/s]Testing:  74%|███████▎  | 147/200 [00:03<00:00, 72.08it/s]Testing:  78%|███████▊  | 155/200 [00:03<00:00, 67.16it/s]Testing:  81%|████████  | 162/200 [00:03<00:00, 67.11it/s]Testing:  86%|████████▌ | 172/200 [00:03<00:00, 74.86it/s]Testing:  91%|█████████ | 182/200 [00:03<00:00, 80.81it/s]Testing:  96%|█████████▌| 191/200 [00:03<00:00, 74.89it/s]                                                          TraininTraining loss: 236.4227, Training accuracy: 0.9581
Macro F1-score: 0.9582
Model performance on Angry speech (in training): 
	Precision: 0.9576, Recall: 0.9600, F1_score: 0.9588
Model performance on Happy speech (in training): 
	Precision: 0.9395, Recall: 0.9325, F1_score: 0.9360
Model performance on Neutral speech (in training): 
	Precision: 0.9438, Recall: 0.9650, F1_score: 0.9543
Model performance on Sad speech (in training): 
	Precision: 0.9924, Recall: 0.9750, F1_score: 0.9836

Eval Phase: 
g:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  12%|█▏        | 187/1600 [00:10<01:15, 18.62it/s]Training:  26%|██▌       | 410/1600 [00:20<00:57, 20.76it/s]Training:  42%|████▏     | 665/1600 [00:30<00:40, 22.92it/s]Training:  58%|█████▊    | 933/1600 [00:40<00:27, 24.45it/s]Training:  76%|███████▌  | 1211/1600 [00:50<00:15, 25.64it/s]Training:  94%|█████████▎| 1498/1600 [01:00<00:03, 26.65it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 543.1610, Validation accuracy: 0.4950
Macro F1-score: 0.4155
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.2200, F1_score: 0.3607
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.3089, Recall: 0.7600, F1_score: 0.4393
Model performance on Sad speech (in validation): 
	Precision: 0.7576, Recall: 1.0000, F1_score: 0.8621
New best accuracy for layer 3 on epoch 1: 0.4950. Model saved.
Epoch 2/100

Training Phase:
Training loss: 90.6849, Training accuracy: 0.9825
Macro F1-score: 0.9825
Model performance on Angry speech (in training): 
	Precision: 0.9826, Recall: 0.9875, F1_score: 0.9850
Model performance on Happy speech (in training): 
	Precision: 0.9701, Recall: 0.9750, F1_score: 0.9726
Model performance on Neutral speech (in training): 
	Precision: 0.9824, Recall: 0.9750, F1_score: 0.9787
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  18%|█▊        | 288/1600 [00:10<00:45, 28.74it/s]Training:  36%|███▌      | 579/1600 [00:20<00:35, 28.93it/s]Training:  54%|█████▍    | 870/1600 [00:30<00:25, 28.96it/s]Training:  72%|███████▎  | 1160/1600 [00:40<00:15, 28.84it/s]Training:  91%|█████████ | 1450/1600 [00:50<00:05, 28.87it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 490.2817, Validation accuracy: 0.6600
Macro F1-score: 0.5836
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.8800, F1_score: 0.9362
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.4318, Recall: 0.7600, F1_score: 0.5507
Model performance on Sad speech (in validation): 
	Precision: 0.7353, Recall: 1.0000, F1_score: 0.8475
New best accuracy for layer 3 on epoch 2: 0.6600. Model saved.
Epoch 3/100

Training Phase:
Training loss: 65.1801, Training accuracy: 0.9888
Macro F1-score: 0.9888
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9875, F1_score: 0.9900
Model performance on Happy speech (in training): 
	Precision: 0.9826, Recall: 0.9875, F1_score: 0.9850
Model performance on Neutral speech (in training): 
	Precision: 0.9826, Recall: 0.9875, F1_score: 0.9850
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9925, F1_score: 0.9950

Eval Phase: 
Validation loss: 693.8880, Validation accuracy: 0.3750
Macro F1-score: 0.3001
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.2600, F1_score: 0.4127
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.1967, Recall: 0.2400, F1_score: 0.2162
Model performance on Sad speech (in validation): 
	Precision: 0.4000, Recall: 1.0000, F1_score: 0.5714
Epoch 4/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  18%|█▊        | 285/1600 [00:10<00:46, 28.45it/s]Training:  36%|███▌      | 571/1600 [00:20<00:36, 28.52it/s]Training:  54%|█████▍    | 860/1600 [00:30<00:25, 28.66it/s]Training:  72%|███████▏  | 1149/1600 [00:40<00:15, 28.71it/s]Training:  90%|████████▉ | 1437/1600 [00:50<00:05, 28.67it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  18%|█▊        | 289/1600 [00:10<00:45, 28.87it/s]Training:  36%|███▌      | 578/1600 [00:20<00:35, 28.78it/s]Training:  54%|█████▍    | 866/1600 [00:30<00:25, 28.77it/s]Training:  72%|███████▏  | 1154/1600 [00:40<00:15, 28.69it/s]Training:  90%|█████████ | 1441/1600 [00:50<00:05, 28.67it/s]                       Training loss: 48.0612, Training accuracy: 0.9919
Macro F1-score: 0.9919
Model performance on Angry speech (in training): 
	Precision: 0.9900, Recall: 0.9950, F1_score: 0.9925
Model performance on Happy speech (in training): 
	Precision: 0.9850, Recall: 0.9850, F1_score: 0.9850
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962

Eval Phase: 
                                      Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 706.7160, Validation accuracy: 0.4600
Macro F1-score: 0.3698
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.1400, F1_score: 0.2456
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.2869, Recall: 0.7000, F1_score: 0.4070
Model performance on Sad speech (in validation): 
	Precision: 0.7042, Recall: 1.0000, F1_score: 0.8264
Epoch 5/100

Training Phase:
Training loss: 54.9732, Training accuracy: 0.9869
Macro F1-score: 0.9869
Model performance on Angry speech (in training): 
	Precision: 0.9850, Recall: 0.9875, F1_score: 0.9863
Model performance on Happy speech (in training): 
	Precision: 0.9726, Recall: 0.9750, F1_score: 0.9738
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9925, F1_score: 0.9950

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  18%|█▊        | 289/1600 [00:10<00:45, 28.84it/s]Training:  36%|███▌      | 579/1600 [00:20<00:35, 28.88it/s]Training:  54%|█████▍    | 869/1600 [00:30<00:25, 28.88it/s]Training:  72%|███████▏  | 1158/1600 [00:40<00:15, 28.88it/s]Training:  90%|█████████ | 1447/1600 [00:50<00:05, 28.74it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 632.6317, Validation accuracy: 0.5000
Macro F1-score: 0.4381
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.6400, F1_score: 0.7805
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.2647, Recall: 0.3600, F1_score: 0.3051
Model performance on Sad speech (in validation): 
	Precision: 0.5000, Recall: 1.0000, F1_score: 0.6667
Epoch 6/100

Training Phase:
Training loss: 59.5151, Training accuracy: 0.9875
Macro F1-score: 0.9875
Model performance on Angry speech (in training): 
	Precision: 0.9825, Recall: 0.9850, F1_score: 0.9838
Model performance on Happy speech (in training): 
	Precision: 0.9874, Recall: 0.9825, F1_score: 0.9850
Model performance on Neutral speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900
Model performance on Sad speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913

Eval Phase: 
Validation loss: 584.7833, Validation accuracy: 0.5650
Macro F1-score: 0.5003
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.5200, F1_score: 0.6842
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.3592, Recall: 0.7400, F1_score: 0.4837
Model performance on Sad speech (in validation): 
	Precision: 0.7143, Recall: 1.0000, F1_score: 0.8333
Epoch 7/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  18%|█▊        | 292/1600 [00:10<00:44, 29.14it/s]Training:  36%|███▋      | 584/1600 [00:20<00:35, 28.85it/s]Training:  55%|█████▍    | 875/1600 [00:30<00:25, 28.96it/s]Training:  73%|███████▎  | 1166/1600 [00:40<00:15, 28.87it/s]Training:  91%|█████████ | 1454/1600 [00:50<00:05, 28.73it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  18%|█▊        | 287/1600 [00:10<00:45, 28.65it/s]Training:  36%|███▌      | 578/1600 [00:20<00:35, 28.85it/s]Training:  54%|█████▍    | 868/1600 [00:30<00:25, 28.85it/s]Training:  72%|███████▏  | 1157/1600 [00:40<00:15, 28.69it/s]Training:  90%|█████████ | 1442/1600 [00:50<00:05, 28.59it/s]                       Training loss: 12.4437, Training accuracy: 0.9981
Macro F1-score: 0.9981
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987

Eval Phase: 
Validation loss: 594.6115, Validation accuracy: 0.5500
Macro F1-score: 0.4946
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.7000, F1_score: 0.8235
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0400, F1_score: 0.0769
Model performance on Neutral speech (in validation): 
	Precision: 0.3433, Recall: 0.4600, F1_score: 0.3932
Model performance on Sad speech (in validation): 
	Precision: 0.5208, Recall: 1.0000, F1_score: 0.6849
Epoch 8/100

Training Phase:
Training loss: 37.7197, Training accuracy: 0.9919
Macro F1-score: 0.9919
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9875, F1_score: 0.9900
Model performance on Happy speech (in training): 
	Precision: 0.9875, Recall: 0.9900, F1_score: 0.9888
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950

Eval Phase: 
                                      Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  18%|█▊        | 289/1600 [00:10<00:45, 28.84it/s]Training:  37%|███▋      | 594/1600 [00:20<00:33, 29.80it/s]Training:  56%|█████▌    | 899/1600 [00:30<00:23, 29.84it/s]Training:  76%|███████▌  | 1208/1600 [00:40<00:12, 30.22it/s]Training:  95%|█████████▍| 1517/1600 [00:50<00:02, 30.31it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 585.8837, Validation accuracy: 0.5800
Macro F1-score: 0.5122
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.6600, F1_score: 0.7952
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.3750, Recall: 0.6600, F1_score: 0.4783
Model performance on Sad speech (in validation): 
	Precision: 0.6329, Recall: 1.0000, F1_score: 0.7752
Epoch 9/100

Training Phase:
Training loss: 29.7667, Training accuracy: 0.9938
Macro F1-score: 0.9937
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Happy speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9900, F1_score: 0.9925
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 308/1600 [00:10<00:42, 30.71it/s]Training:  38%|███▊      | 616/1600 [00:20<00:32, 30.37it/s]Training:  38%|███▊      | 616/1600 [00:30<00:32, 30.37it/s]Training:  55%|█████▍    | 874/1600 [00:30<00:25, 27.97it/s]Training:  74%|███████▎  | 1177/1600 [00:40<00:14, 28.86it/s]Training:  92%|█████████▎| 1480/1600 [00:50<00:04, 29.33it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 773.2645, Validation accuracy: 0.5200
Macro F1-score: 0.4420
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.2400, F1_score: 0.3871
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.3281, Recall: 0.8400, F1_score: 0.4719
Model performance on Sad speech (in validation): 
	Precision: 0.8333, Recall: 1.0000, F1_score: 0.9091
Epoch 10/100

Training Phase:
Training loss: 35.9482, Training accuracy: 0.9938
Macro F1-score: 0.9937
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963
Model performance on Happy speech (in training): 
	Precision: 0.9924, Recall: 0.9850, F1_score: 0.9887
Model performance on Neutral speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988

Eval Phase: 
Validation loss: 448.3488, Validation accuracy: 0.5950
Macro F1-score: 0.5410
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.7400, F1_score: 0.8506
Model performance on Happy speech (in validation): 
	Precision: 0.5000, Recall: 0.0400, F1_score: 0.0741
Model performance on Neutral speech (in validation): 
	Precision: 0.3704, Recall: 0.6000, F1_score: 0.4580
Model performance on Sad speech (in validation): 
	Precision: 0.6410, Recall: 1.0000, F1_score: 0.7812
Epoch 11/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 303/1600 [00:10<00:42, 30.21it/s]Training:  38%|███▊      | 606/1600 [00:20<00:33, 30.08it/s]Training:  57%|█████▋    | 906/1600 [00:30<00:23, 29.59it/s]Training:  75%|███████▍  | 1197/1600 [00:40<00:13, 29.35it/s]Training:  93%|█████████▎| 1487/1600 [00:50<00:03, 29.12it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  18%|█▊        | 291/1600 [00:10<00:45, 29.04it/s]Training:  36%|███▋      | 583/1600 [00:20<00:34, 29.08it/s]Training:  55%|█████▍    | 875/1600 [00:30<00:25, 28.82it/s]Training:  73%|███████▎  | 1164/1600 [00:40<00:15, 28.84it/s]Training:  91%|█████████ | 1456/1600 [00:50<00:04, 28.97it/s]                     Training loss: 26.0585, Training accuracy: 0.9956
Macro F1-score: 0.9956
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
                                        Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 661.3636, Validation accuracy: 0.5650
Macro F1-score: 0.5032
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.4600, F1_score: 0.6301
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.3448, Recall: 0.8000, F1_score: 0.4819
Model performance on Sad speech (in validation): 
	Precision: 0.8197, Recall: 1.0000, F1_score: 0.9009
Epoch 12/100

Training Phase:
Training loss: 26.2621, Training accuracy: 0.9956
Macro F1-score: 0.9956
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  18%|█▊        | 287/1600 [00:10<00:45, 28.68it/s]Training:  36%|███▌      | 574/1600 [00:20<00:36, 28.50it/s]Training:  54%|█████▍    | 865/1600 [00:30<00:25, 28.76it/s]Training:  72%|███████▏  | 1156/1600 [00:40<00:15, 28.78it/s]Training:  91%|█████████ | 1452/1600 [00:50<00:05, 29.05it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 802.7636, Validation accuracy: 0.5800
Macro F1-score: 0.5153
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.4200, F1_score: 0.5915
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.3629, Recall: 0.9000, F1_score: 0.5172
Model performance on Sad speech (in validation): 
	Precision: 0.9091, Recall: 1.0000, F1_score: 0.9524
Epoch 13/100

Training Phase:
Training loss: 25.5880, Training accuracy: 0.9956
Macro F1-score: 0.9956
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 307/1600 [00:10<00:42, 30.67it/s]Training:  38%|███▊      | 614/1600 [00:20<00:32, 30.41it/s]Training:  57%|█████▊    | 920/1600 [00:30<00:22, 30.46it/s]Training:  77%|███████▋  | 1226/1600 [00:40<00:12, 29.79it/s]Training:  95%|█████████▍| 1515/1600 [00:50<00:02, 29.40it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 704.1455, Validation accuracy: 0.5250
Macro F1-score: 0.4642
Model performance on Angry speech (in validation): 
	Precision: 0.9706, Recall: 0.6600, F1_score: 0.7857
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.2785, Recall: 0.4400, F1_score: 0.3411
Model performance on Sad speech (in validation): 
	Precision: 0.5747, Recall: 1.0000, F1_score: 0.7299
Epoch 14/100

Training Phase:
Training loss: 11.0714, Training accuracy: 0.9981
Macro F1-score: 0.9981
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  18%|█▊        | 291/1600 [00:10<00:45, 29.03it/s]Training:  36%|███▋      | 582/1600 [00:20<00:35, 28.95it/s]Training:  54%|█████▍    | 871/1600 [00:30<00:25, 28.84it/s]Training:  72%|███████▏  | 1159/1600 [00:40<00:15, 28.81it/s]Training:  90%|█████████ | 1447/1600 [00:50<00:05, 28.69it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 807.4322, Validation accuracy: 0.5000
Macro F1-score: 0.4453
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.4400, F1_score: 0.6111
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.2692, Recall: 0.5600, F1_score: 0.3636
Model performance on Sad speech (in validation): 
	Precision: 0.6757, Recall: 1.0000, F1_score: 0.8065
Epoch 15/100

Training Phase:
Training loss: 11.7722, Training accuracy: 0.9981
Macro F1-score: 0.9981
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  18%|█▊        | 288/1600 [00:10<00:45, 28.76it/s]Training:  36%|███▌      | 576/1600 [00:20<00:35, 28.73it/s]Training:  54%|█████▍    | 864/1600 [00:30<00:25, 28.70it/s]Training:  72%|███████▏  | 1152/1600 [00:40<00:15, 28.72it/s]Training:  90%|█████████ | 1442/1600 [00:50<00:05, 28.82it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 844.5108, Validation accuracy: 0.5000
Macro F1-score: 0.4452
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.6000, F1_score: 0.7500
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.2410, Recall: 0.4000, F1_score: 0.3008
Model performance on Sad speech (in validation): 
	Precision: 0.5747, Recall: 1.0000, F1_score: 0.7299
Epoch 16/100

Training Phase:
Training loss: 13.9804, Training accuracy: 0.9975
Macro F1-score: 0.9975
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9925, F1_score: 0.9950
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9975, F1_score: 0.9950
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  18%|█▊        | 290/1600 [00:10<00:45, 28.94it/s]Training:  36%|███▋      | 580/1600 [00:20<00:35, 28.95it/s]Training:  54%|█████▍    | 870/1600 [00:30<00:25, 28.94it/s]Training:  73%|███████▎  | 1161/1600 [00:40<00:15, 28.97it/s]Training:  91%|█████████ | 1452/1600 [00:50<00:05, 28.79it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 737.2170, Validation accuracy: 0.5750
Macro F1-score: 0.5148
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.6200, F1_score: 0.7654
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.3400, Recall: 0.6800, F1_score: 0.4533
Model performance on Sad speech (in validation): 
	Precision: 0.7246, Recall: 1.0000, F1_score: 0.8403
Epoch 17/100

Training Phase:
Training loss: 14.8839, Training accuracy: 0.9969
Macro F1-score: 0.9969
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  18%|█▊        | 288/1600 [00:10<00:45, 28.78it/s]Training:  36%|███▌      | 579/1600 [00:20<00:35, 28.92it/s]Training:  54%|█████▍    | 870/1600 [00:30<00:25, 28.89it/s]Training:  72%|███████▏  | 1159/1600 [00:40<00:15, 28.78it/s]Training:  90%|█████████ | 1446/1600 [00:50<00:05, 28.69it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 819.1853, Validation accuracy: 0.6250
Macro F1-score: 0.5633
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.6200, F1_score: 0.7654
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.3913, Recall: 0.9000, F1_score: 0.5455
Model performance on Sad speech (in validation): 
	Precision: 0.9074, Recall: 0.9800, F1_score: 0.9423
Epoch 18/100

Training Phase:
Training loss: 23.6591, Training accuracy: 0.9931
Macro F1-score: 0.9931
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937
Model performance on Happy speech (in training): 
	Precision: 0.9876, Recall: 0.9925, F1_score: 0.9900
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  18%|█▊        | 285/1600 [00:10<00:46, 28.50it/s]Training:  36%|███▌      | 572/1600 [00:20<00:35, 28.57it/s]Training:  54%|█████▍    | 860/1600 [00:30<00:25, 28.67it/s]Training:  72%|███████▏  | 1149/1600 [00:40<00:15, 28.74it/s]Training:  90%|█████████ | 1441/1600 [00:50<00:05, 28.89it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 733.7241, Validation accuracy: 0.6050
Macro F1-score: 0.5365
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.8400, F1_score: 0.9130
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.3537, Recall: 0.5800, F1_score: 0.4394
Model performance on Sad speech (in validation): 
	Precision: 0.6579, Recall: 1.0000, F1_score: 0.7937
Epoch 19/100

Training Phase:
Training loss: 21.2099, Training accuracy: 0.9969
Macro F1-score: 0.9969
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 1.0000, F1_score: 0.9975
Model performance on Happy speech (in training): 
	Precision: 0.9975, Recall: 0.9900, F1_score: 0.9937
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988

Eval Phase: 
Validation loss: 716.5515, Validation accuracy: 0.6800
Macro F1-score: 0.6146
Model performance on Angry speech (in validation): 
	Precision: 0.9767, Recall: 0.8400, F1_score: 0.9032
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.4356, Recall: 0.8800, F1_score: 0.5828
Model performance on Sad speech (in validation): 
	Precision: 0.8909, Recall: 0.9800, F1_score: 0.9333
New best accuracy for layer 3 on epoch 19: 0.6800. Model saved.
Epoch 20/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 305/1600 [00:10<00:42, 30.40it/s]Training:  38%|███▊      | 609/1600 [00:20<00:32, 30.34it/s]Training:  57%|█████▋    | 912/1600 [00:30<00:23, 29.55it/s]Training:  75%|███████▍  | 1199/1600 [00:40<00:13, 29.15it/s]Training:  93%|█████████▎| 1490/1600 [00:50<00:03, 29.10it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  18%|█▊        | 285/1600 [00:10<00:46, 28.49it/s]Training:  36%|███▌      | 575/1600 [00:20<00:35, 28.74it/s]Training:  54%|█████▍    | 866/1600 [00:30<00:25, 28.90it/s]Training:  72%|███████▏  | 1157/1600 [00:40<00:15, 28.91it/s]Training:  90%|█████████ | 1447/1600 [00:50<00:05, 28.80it/s]                     Training loss: 5.7159, Training accuracy: 0.9988
Macro F1-score: 0.9988
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Happy speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 700.1979, Validation accuracy: 0.5950
Macro F1-score: 0.5493
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.4000, F1_score: 0.5714
Model performance on Happy speech (in validation): 
	Precision: 0.8000, Recall: 0.0800, F1_score: 0.1455
Model performance on Neutral speech (in validation): 
	Precision: 0.3802, Recall: 0.9200, F1_score: 0.5380
Model performance on Sad speech (in validation): 
	Precision: 0.9074, Recall: 0.9800, F1_score: 0.9423
Validation loss does not decrease for 10 epochs. End training.
Epoch 21/100

Entering 2ND training phase: change training data from cn to DE
Loading de train data: fold_2...
Preprocess de fold_2 data for cn model
Reload model and reset eval loss

Training Phase:
Training loss: 4694.0427, Training accuracy: 0.7000
Macro F1-score: 0.6159
Model performance on Angry speech (in training): 
	Precision: 0.8416, Recall: 0.9300, F1_score: 0.8836
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.0075, F1_score: 0.0149
Model performance on Neutral speech (in training): 
	Precision: 0.5048, Recall: 0.9225, F1_score: 0.6525
Model performance on Sad speech (in training): 
	Precision: 0.8868, Recall: 0.9400, F1_score: 0.9126

Eval Phase: 
Validation loss: 716.5515, Validation accuracy: 0.6800
Macro F1-score: 0.6146
Model performance on Angry speech (in validation): 
	Precision: 0.9767, Recall: 0.8400, F1_score: 0.9032
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.4356, Recall: 0.8800, F1_score: 0.5828
Model performance on Sad speech (in validation): 
	Precision: 0.8909, Recall: 0.9800, F1_score: 0.9333
Epoch 22/100

Training Phase:
                                        Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:   9%|▉         | 142/1600 [00:10<01:42, 14.17it/s]Training:  20%|█▉        | 319/1600 [00:20<01:19, 16.21it/s]Training:  32%|███▏      | 508/1600 [00:30<01:02, 17.40it/s]Training:  44%|████▍     | 707/1600 [00:40<00:48, 18.37it/s]Training:  57%|█████▋    | 911/1600 [00:50<00:36, 19.08it/s]Training:  70%|██████▉   | 1115/1600 [01:00<00:24, 19.40it/s]Training:  83%|████████▎ | 1323/1600 [01:10<00:13, 19.83it/s]Training:  96%|█████████▌| 1535/1600 [01:20<00:03, 20.26it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍       Training loss: 4655.6712, Training accuracy: 0.6925
Macro F1-score: 0.6111
Model performance on Angry speech (in training): 
	Precision: 0.8206, Recall: 0.9150, F1_score: 0.8652
Model performance on Happy speech (in training): 
	Precision: 0.8000, Recall: 0.0100, F1_score: 0.0198
Model performance on Neutral speech (in training): 
	Precision: 0.4986, Recall: 0.9200, F1_score: 0.6467
Model performance on Sad speech (in training): 
	Precision: 0.9002, Recall: 0.9250, F1_score: 0.9125

Eval Phase: 
Validation loss: 716.5515, Validation accuracy: 0.6800
Macro F1-score: 0.6146
Model performance on Angry speech (in validation): 
	Precision: 0.9767, Recall: 0.8400, F1_score: 0.9032
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.4356, Recall: 0.8800, F1_score: 0.5828
Model performance on Sad speech (in validation): 
	Precision: 0.8909, Recall: 0.9800, F1_score: 0.9333
Epoch 23/100

Training Phase:
 | 233/1600 [00:10<00:58, 23.24it/s]Training:  29%|██▉       | 466/1600 [00:20<00:49, 23.00it/s]Training:  44%|████▎     | 698/1600 [00:30<00:39, 23.07it/s]Training:  44%|████▎     | 698/1600 [00:40<00:39, 23.07it/s]Training:  57%|█████▋    | 915/1600 [00:40<00:31, 21.90it/s]Training:  71%|███████▏  | 1142/1600 [00:51<00:20, 22.15it/s]Training:  86%|████████▌ | 1372/1600 [01:01<00:10, 22.43it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 232/1600 [00:10<00:59, 23.12it/s]Training:  29%|██▉       | 464/1600 [00:20<00:49, 22.91it/s]Training:  44%|████▎     | 697/1600 [00:30<00:39, 23.07it/s]Training:  58%|█████▊    | 932/1600 [00:40<00:28, 23.21it/s]Training:  73%|███████▎  | 1167/1600Training loss: 4591.0764, Training accuracy: 0.7075
Macro F1-score: 0.6254
Model performance on Angry speech (in training): 
	Precision: 0.8516, Recall: 0.9325, F1_score: 0.8902
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.0125, F1_score: 0.0247
Model performance on Neutral speech (in training): 
	Precision: 0.5054, Recall: 0.9375, F1_score: 0.6567
Model performance on Sad speech (in training): 
	Precision: 0.9133, Recall: 0.9475, F1_score: 0.9301

Eval Phase: 
Validation loss: 716.5515, Validation accuracy: 0.6800
Macro F1-score: 0.6146
Model performance on Angry speech (in validation): 
	Precision: 0.9767, Recall: 0.8400, F1_score: 0.9032
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.4356, Recall: 0.8800, F1_score: 0.5828
Model performance on Sad speech (in validation): 
	Precision: 0.8909, Recall: 0.9800, F1_score: 0.9333
Epoch 24/100

Training Phase:
Training loss: 4685.2746, Training accuracy: 0.7019
Macro F1-score: 0.6182
Model performance on Angry speech (in training): 
	Precision: 0.8458, Recall: 0.9325, F1_score: 0.8870
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.0075, F1_score: 0.0149
Model performance on Neutral speech (in training): 
	Precision: 0.5014, Recall: 0.9175, F1_score: 0.6484
Model performance on Sad speech (in training): 
	Precision: 0.8962, Recall: 0.9500, F1_score: 0.9223

Eval Phase: 
Validation loss: 716.5515, Validation accuracy: 0.6800
Macro F1-score: 0.6146
Model performance on Angry speech (in validation): 
	Precision: 0.9767, Recall: 0.8400, F1_score: 0.9032
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.4356, Recall: 0.8800, F1_score: 0.5828
Model performance on Sad speech (in validation): 
	Precision: 0.8909, Recall: 0.9800, F1_score: 0.9333
Epoch 25/100

Training Phase:
 [00:50<00:18, 23.15it/s]Training:  88%|████████▊ | 1400/1600 [01:00<00:08, 23.20it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 235/1600 [00:10<00:58, 23.42it/s]Training:  29%|██▉       | 470/1600 [00:20<00:48, 23.20it/s]Training:  44%|████▍     | 701/1600 [00:30<00:38, 23.07it/s]Training:  58%|█████▊    | 934/1600 [00:40<00:28, 23.13it/s]Training:  73%|███████▎  | 1167/1600 [00:50<00:18, 23.04it/s]Training:  87%|████████▋ | 1399/1600 [01:00<00:08, 23.09it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 233/1600 [00:10Training loss: 4634.7775, Training accuracy: 0.7025
Macro F1-score: 0.6183
Model performance on Angry speech (in training): 
	Precision: 0.8311, Recall: 0.9350, F1_score: 0.8800
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.0075, F1_score: 0.0149
Model performance on Neutral speech (in training): 
	Precision: 0.5055, Recall: 0.9225, F1_score: 0.6531
Model performance on Sad speech (in training): 
	Precision: 0.9065, Recall: 0.9450, F1_score: 0.9253

Eval Phase: 
Validation loss: 716.5515, Validation accuracy: 0.6800
Macro F1-score: 0.6146
Model performance on Angry speech (in validation): 
	Precision: 0.9767, Recall: 0.8400, F1_score: 0.9032
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.4356, Recall: 0.8800, F1_score: 0.5828
Model performance on Sad speech (in validation): 
	Precision: 0.8909, Recall: 0.9800, F1_score: 0.9333
Epoch 26/100

Training Phase:
<00:58, 23.20it/s]Training:  29%|██▉       | 466/1600 [00:20<00:49, 22.99it/s]Training:  44%|████▎     | 697/1600 [00:30<00:39, 23.03it/s]Training:  58%|█████▊    | 931/1600 [00:40<00:28, 23.13it/s]Training:  73%|███████▎  | 1165/1600 [00:50<00:18, 23.20it/s]Training:  87%|████████▋ | 1399/1600 [01:00<00:08, 23.13it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 231/1600 [00:10<00:59, 23.06it/s]Training:  29%|██▉       | 462/1600 [00:20<00:49, 22.99it/s]Training:  43%|████▎     | 692/1600 [00:30<00:39, 22.94it/s]Training:  58%|█████▊    | 925/1600 [00:40<00:29, 23.05it/s]Training:  72%|███████▏  | 1159/1600 [00:50<00:19, 23.17it/s]Training:  87%|████████▋ | 1393/1600 [01:00<0Training loss: 4727.2908, Training accuracy: 0.6931
Macro F1-score: 0.6099
Model performance on Angry speech (in training): 
	Precision: 0.8326, Recall: 0.9200, F1_score: 0.8741
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.0075, F1_score: 0.0149
Model performance on Neutral speech (in training): 
	Precision: 0.4986, Recall: 0.9075, F1_score: 0.6436
Model performance on Sad speech (in training): 
	Precision: 0.8782, Recall: 0.9375, F1_score: 0.9069

Eval Phase: 
Validation loss: 716.5515, Validation accuracy: 0.6800
Macro F1-score: 0.6146
Model performance on Angry speech (in validation): 
	Precision: 0.9767, Recall: 0.8400, F1_score: 0.9032
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.4356, Recall: 0.8800, F1_score: 0.5828
Model performance on Sad speech (in validation): 
	Precision: 0.8909, Recall: 0.9800, F1_score: 0.9333
Epoch 27/100

Training Phase:
Training loss: 4661.6692, Training accuracy: 0.7025
Macro F1-score: 0.6180
Model performance on Angry speech (in training): 
	Precision: 0.8371, Recall: 0.9375, F1_score: 0.8844
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.0100, F1_score: 0.0198
Model performance on Neutral speech (in training): 
	Precision: 0.5111, Recall: 0.9200, F1_score: 0.6571
Model performance on Sad speech (in training): 
	Precision: 0.8808, Recall: 0.9425, F1_score: 0.9106

Eval Phase: 
Validation loss: 716.5515, Validation accuracy: 0.6800
Macro F1-score: 0.6146
Model performance on Angry speech (in validation): 
	Precision: 0.9767, Recall: 0.8400, F1_score: 0.9032
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.4356, Recall: 0.8800, F1_score: 0.5828
Model performance on Sad speech (in validation): 
	Precision: 0.8909, Recall: 0.9800, F1_score: 0.9333
Epoch 28/100

Training Phase:
0:08, 23.15it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 231/1600 [00:10<00:59, 23.04it/s]Training:  29%|██▉       | 463/1600 [00:20<00:49, 23.11it/s]Training:  43%|████▎     | 695/1600 [00:30<00:39, 23.04it/s]Training:  58%|█████▊    | 930/1600 [00:40<00:28, 23.19it/s]Training:  73%|███████▎  | 1165/1600 [00:50<00:18, 23.13it/s]Training:  87%|████████▋ | 1396/1600 [01:00<00:08, 23.05it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 232/1600 [00:10<00:59, 23.18it/s]Training:  29%|██▉       | 464/1600 [00:20<00:49, 23.12it/s]TraTraining loss: 4654.6348, Training accuracy: 0.7063
Macro F1-score: 0.6216
Model performance on Angry speech (in training): 
	Precision: 0.8392, Recall: 0.9525, F1_score: 0.8923
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.0100, F1_score: 0.0198
Model performance on Neutral speech (in training): 
	Precision: 0.5131, Recall: 0.9300, F1_score: 0.6613
Model performance on Sad speech (in training): 
	Precision: 0.8945, Recall: 0.9325, F1_score: 0.9131

Eval Phase: 
Validation loss: 716.5515, Validation accuracy: 0.6800
Macro F1-score: 0.6146
Model performance on Angry speech (in validation): 
	Precision: 0.9767, Recall: 0.8400, F1_score: 0.9032
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.4356, Recall: 0.8800, F1_score: 0.5828
Model performance on Sad speech (in validation): 
	Precision: 0.8909, Recall: 0.9800, F1_score: 0.9333
Epoch 29/100

Training Phase:
ining:  44%|████▎     | 696/1600 [00:30<00:39, 23.14it/s]Training:  58%|█████▊    | 928/1600 [00:40<00:29, 22.95it/s]Training:  72%|███████▏  | 1158/1600 [00:50<00:19, 22.96it/s]Training:  87%|████████▋ | 1388/1600 [01:00<00:09, 22.96it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 234/1600 [00:10<00:58, 23.32it/s]Training:  29%|██▉       | 468/1600 [00:20<00:48, 23.14it/s]Training:  44%|████▎     | 699/1600 [00:30<00:39, 23.06it/s]Training:  44%|████▎     | 699/1600 [00:40<00:39, 23.06it/s]Training:  58%|█████▊    | 931/1600 [00:40<00:28, 23.08it/s]Training:  73%|███████▎  | 1163/1600 [00:50<00:18, 23.11it/s]Training:  87%|████████▋ | 1397/1600 [01:00<00:08, 23.19it/s] Training loss: 4639.7629, Training accuracy: 0.7025
Macro F1-score: 0.6181
Model performance on Angry speech (in training): 
	Precision: 0.8439, Recall: 0.9325, F1_score: 0.8860
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.0075, F1_score: 0.0149
Model performance on Neutral speech (in training): 
	Precision: 0.5075, Recall: 0.9300, F1_score: 0.6567
Model performance on Sad speech (in training): 
	Precision: 0.8910, Recall: 0.9400, F1_score: 0.9148

Eval Phase: 
Validation loss: 716.5515, Validation accuracy: 0.6800
Macro F1-score: 0.6146
Model performance on Angry speech (in validation): 
	Precision: 0.9767, Recall: 0.8400, F1_score: 0.9032
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.4356, Recall: 0.8800, F1_score: 0.5828
Model performance on Sad speech (in validation): 
	Precision: 0.8909, Recall: 0.9800, F1_score: 0.9333
Epoch 30/100

Training Phase:
Training loss: 4610.2682, Training accuracy: 0.7131
Macro F1-score: 0.6290
Model performance on Angry speech (in training): 
	Precision: 0.8460, Recall: 0.9475, F1_score: 0.8939
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.0125, F1_score: 0.0247
Model performance on Neutral speech (in training): 
	Precision: 0.5164, Recall: 0.9425, F1_score: 0.6673
Model performance on Sad speech (in training): 
	Precision: 0.9113, Recall: 0.9500, F1_score: 0.9302

Eval Phase: 
Validation loss: 716.5515, Validation accuracy: 0.6800
Macro F1-score: 0.6146
Model performance on Angry speech (in validation): 
	Precision: 0.9767, Recall: 0.8400, F1_score: 0.9032
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.4356, Recall: 0.8800, F1_score: 0.5828
Model performance on Sad speech (in validation): 
	Precision: 0.8909, Recall: 0.9800, F1_score: 0.9333
Epoch 31/100

Training Phase:
                                                            Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 231/1600 [00:10<00:59, 23.09it/s]Training:  29%|██▉       | 462/1600 [00:20<00:49, 22.90it/s]Training:  43%|████▎     | 693/1600 [00:30<00:39, 22.97it/s]Training:  58%|█████▊    | 925/1600 [00:40<00:29, 23.03it/s]Training:  73%|███████▎  | 1162/1600 [00:50<00:18, 23.25it/s]Training:  87%|████████▋ | 1399/1600 [01:00<00:08, 23.20it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 231/1600 [00:10<00:59, 23.02it/s]Training:  14%|█▍        | 231/1600 [00:20<00:59, 23.02it/s]Training:  29%|██Training loss: 4654.0781, Training accuracy: 0.7006
Macro F1-score: 0.6157
Model performance on Angry speech (in training): 
	Precision: 0.8307, Recall: 0.9200, F1_score: 0.8731
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.0050, F1_score: 0.0100
Model performance on Neutral speech (in training): 
	Precision: 0.5068, Recall: 0.9325, F1_score: 0.6567
Model performance on Sad speech (in training): 
	Precision: 0.9021, Recall: 0.9450, F1_score: 0.9231

Eval Phase: 
Validation loss: 716.5515, Validation accuracy: 0.6800
Macro F1-score: 0.6146
Model performance on Angry speech (in validation): 
	Precision: 0.9767, Recall: 0.8400, F1_score: 0.9032
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.4356, Recall: 0.8800, F1_score: 0.5828
Model performance on Sad speech (in validation): 
	Precision: 0.8909, Recall: 0.9800, F1_score: 0.9333
Epoch 32/100

Training Phase:
       | 464/1600 [00:20<00:49, 23.15it/s]Training:  44%|████▎     | 698/1600 [00:30<00:38, 23.22it/s]Training:  58%|█████▊    | 931/1600 [00:40<00:28, 23.21it/s]Training:  73%|███████▎  | 1164/1600 [00:50<00:18, 23.23it/s]Training:  87%|████████▋ | 1397/1600 [01:00<00:08, 23.11it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 232/1600 [00:10<00:59, 23.16it/s]Training:  29%|██▉       | 464/1600 [00:20<00:49, 23.11it/s]Training:  44%|████▎     | 698/1600 [00:30<00:38, 23.23it/s]Training:  58%|█████▊    | 933/1600 [00:40<00:28, 23.29it/s]Training:  73%|███████▎  | 1167/1600 [00:50<00:18, 23.26it/s]Training:  88%|████████▊ | 1400/1600 [01:00<00:08, 23.13it/s]                         Training loss: 4681.2669, Training accuracy: 0.6906
Macro F1-score: 0.6084
Model performance on Angry speech (in training): 
	Precision: 0.8433, Recall: 0.9150, F1_score: 0.8777
Model performance on Happy speech (in training): 
	Precision: 0.6667, Recall: 0.0050, F1_score: 0.0099
Model performance on Neutral speech (in training): 
	Precision: 0.4926, Recall: 0.9200, F1_score: 0.6417
Model performance on Sad speech (in training): 
	Precision: 0.8870, Recall: 0.9225, F1_score: 0.9044

Eval Phase: 
Validation loss: 716.5515, Validation accuracy: 0.6800
Macro F1-score: 0.6146
Model performance on Angry speech (in validation): 
	Precision: 0.9767, Recall: 0.8400, F1_score: 0.9032
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.4356, Recall: 0.8800, F1_score: 0.5828
Model performance on Sad speech (in validation): 
	Precision: 0.8909, Recall: 0.9800, F1_score: 0.9333
Epoch 33/100

Training Phase:
Training loss: 4648.7797, Training accuracy: 0.7050
Macro F1-score: 0.6211
Model performance on Angry speech (in training): 
	Precision: 0.8393, Recall: 0.9400, F1_score: 0.8868
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.0100, F1_score: 0.0198
Model performance on Neutral speech (in training): 
	Precision: 0.5109, Recall: 0.9375, F1_score: 0.6614
Model performance on Sad speech (in training): 
	Precision: 0.9010, Recall: 0.9325, F1_score: 0.9165

Eval Phase: 
Validation loss: 716.5515, Validation accuracy: 0.6800
Macro F1-score: 0.6146
Model performance on Angry speech (in validation): 
	Precision: 0.9767, Recall: 0.8400, F1_score: 0.9032
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.4356, Recall: 0.8800, F1_score: 0.5828
Model performance on Sad speech (in validation): 
	Precision: 0.8909, Recall: 0.9800, F1_score: 0.9333
Epoch 34/100

Training Phase:
                                    Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 232/1600 [00:10<00:58, 23.19it/s]Training:  29%|██▉       | 466/1600 [00:20<00:48, 23.28it/s]Training:  44%|████▍     | 700/1600 [00:30<00:38, 23.27it/s]Training:  58%|█████▊    | 933/1600 [00:40<00:28, 23.26it/s]Training:  73%|███████▎  | 1166/1600 [00:50<00:18, 23.25it/s]Training:  87%|████████▋ | 1399/1600 [01:00<00:08, 23.19it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 236/1600 [00:10<00:57, 23.56it/s]Training:  30%|██▉       | 472/1600 [00:20<00:48, 23.08it/s]Training:  44%|████▍     | 702/1600Training loss: 4654.7374, Training accuracy: 0.6981
Macro F1-score: 0.6138
Model performance on Angry speech (in training): 
	Precision: 0.8200, Recall: 0.9225, F1_score: 0.8682
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.0075, F1_score: 0.0149
Model performance on Neutral speech (in training): 
	Precision: 0.5055, Recall: 0.9150, F1_score: 0.6512
Model performance on Sad speech (in training): 
	Precision: 0.8960, Recall: 0.9475, F1_score: 0.9210

Eval Phase: 
Validation loss: 716.5515, Validation accuracy: 0.6800
Macro F1-score: 0.6146
Model performance on Angry speech (in validation): 
	Precision: 0.9767, Recall: 0.8400, F1_score: 0.9032
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.4356, Recall: 0.8800, F1_score: 0.5828
Model performance on Sad speech (in validation): 
	Precision: 0.8909, Recall: 0.9800, F1_score: 0.9333
Epoch 35/100

Training Phase:
Training loss: 4680.2275, Training accuracy: 0.7006
Macro F1-score: 0.6156
Model performance on Angry speech (in training): 
	Precision: 0.8463, Recall: 0.9225, F1_score: 0.8828
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.0025, F1_score: 0.0050
Model performance on Neutral speech (in training): 
	Precision: 0.5020, Recall: 0.9325, F1_score: 0.6527
Model performance on Sad speech (in training): 
	Precision: 0.9000, Recall: 0.9450, F1_score: 0.9220

Eval Phase: 
 [00:30<00:38, 23.03it/s]Training:  58%|█████▊    | 932/1600 [00:40<00:29, 22.95it/s]Training:  73%|███████▎  | 1165/1600 [00:50<00:18, 23.05it/s]Training:  87%|████████▋ | 1399/1600 [01:00<00:08, 23.15it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 233/1600 [00:10<00:58, 23.22it/s]Training:  29%|██▉       | 466/1600 [00:20<00:49, 23.07it/s]Training:  44%|████▎     | 699/1600 [00:30<00:38, 23.13it/s]Training:  58%|█████▊    | 932/1600 [00:40<00:28, 23.17it/s]Training:  73%|███████▎  | 1165/1600 [00:50<00:18, 23.04it/s]Training:  87%|████████▋ | 1396/1600 [01:00<00:08, 23.06it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]Validation loss: 716.5515, Validation accuracy: 0.6800
Macro F1-score: 0.6146
Model performance on Angry speech (in validation): 
	Precision: 0.9767, Recall: 0.8400, F1_score: 0.9032
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.4356, Recall: 0.8800, F1_score: 0.5828
Model performance on Sad speech (in validation): 
	Precision: 0.8909, Recall: 0.9800, F1_score: 0.9333
Epoch 36/100

Training Phase:
Training loss: 4698.4173, Training accuracy: 0.6975
Macro F1-score: 0.6130
Model performance on Angry speech (in training): 
	Precision: 0.8375, Recall: 0.9275, F1_score: 0.8802
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.0050, F1_score: 0.0100
Model performance on Neutral speech (in training): 
	Precision: 0.5027, Recall: 0.9225, F1_score: 0.6508
Model performance on Sad speech (in training): 
	Precision: 0.8884, Recall: 0.9350, F1_score: 0.9111

Eval Phase: 
Validation loss: 716.5515, Validation accuracy: 0.6800
Macro F1-score: 0.6146
Model performance on Angry speech (in validation): 
	Precision: 0.9767, Recall: 0.8400, F1_score: 0.9032
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.4356, Recall: 0.8800, F1_score: 0.5828
Model performance on Sad speech (in validation): 
	Precision: 0.8909, Recall: 0.9800, F1_score: 0.9333
Epoch 37/100

Training Phase:
                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 235/1600 [00:10<00:58, 23.47it/s]Training:  29%|██▉       | 470/1600 [00:20<00:49, 22.84it/s]Training:  44%|████▍     | 704/1600 [00:30<00:38, 23.07it/s]Training:  59%|█████▊    | 938/1600 [00:40<00:28, 23.15it/s]Training:  73%|███████▎  | 1171/1600 [00:50<00:18, 23.05it/s]Training:  88%|████████▊ | 1400/1600 [01:00<00:08, 23.00it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 230/1600 [00:10<00:59, 22.98it/s]Training:  29%|██▉       | 461/1600 [00:20<00:49, 23.05it/s]Training:  43%|████▎     | 693/1600 [00:30<00:39, 23.10it/s]Training:  58%|█████▊    | 930/1600 [00:40<00:28, 2Training loss: 4608.9287, Training accuracy: 0.7013
Macro F1-score: 0.6190
Model performance on Angry speech (in training): 
	Precision: 0.8513, Recall: 0.9300, F1_score: 0.8889
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.0100, F1_score: 0.0198
Model performance on Neutral speech (in training): 
	Precision: 0.4993, Recall: 0.9225, F1_score: 0.6479
Model performance on Sad speech (in training): 
	Precision: 0.8976, Recall: 0.9425, F1_score: 0.9195

Eval Phase: 
Validation loss: 716.5515, Validation accuracy: 0.6800
Macro F1-score: 0.6146
Model performance on Angry speech (in validation): 
	Precision: 0.9767, Recall: 0.8400, F1_score: 0.9032
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.4356, Recall: 0.8800, F1_score: 0.5828
Model performance on Sad speech (in validation): 
	Precision: 0.8909, Recall: 0.9800, F1_score: 0.9333
Epoch 38/100

Training Phase:
Training loss: 4669.1801, Training accuracy: 0.6937
Macro F1-score: 0.6111
Model performance on Angry speech (in training): 
	Precision: 0.8360, Recall: 0.9175, F1_score: 0.8749
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.0075, F1_score: 0.0149
Model performance on Neutral speech (in training): 
	Precision: 0.4987, Recall: 0.9250, F1_score: 0.6480
Model performance on Sad speech (in training): 
	Precision: 0.8894, Recall: 0.9250, F1_score: 0.9069

Eval Phase: 
Validation loss: 716.5515, Validation accuracy: 0.6800
Macro F1-score: 0.6146
Model performance on Angry speech (in validation): 
	Precision: 0.9767, Recall: 0.8400, F1_score: 0.9032
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.4356, Recall: 0.8800, F1_score: 0.5828
Model performance on Sad speech (in validation): 
	Precision: 0.8909, Recall: 0.9800, F1_score: 0.9333
Epoch 39/100

Training Phase:
3.31it/s]Training:  73%|███████▎  | 1167/1600 [00:50<00:18, 23.06it/s]Training:  87%|████████▋ | 1399/1600 [01:00<00:08, 23.10it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 234/1600 [00:10<00:58, 23.33it/s]Training:  29%|██▉       | 468/1600 [00:20<00:48, 23.12it/s]Training:  44%|████▎     | 698/1600 [00:30<00:39, 23.01it/s]Training:  58%|█████▊    | 930/1600 [00:40<00:29, 23.07it/s]Training:  73%|███████▎  | 1163/1600 [00:50<00:18, 23.12it/s]Training:  87%|████████▋ | 1396/1600 [01:00<00:08, 23.07it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [Training loss: 4621.1578, Training accuracy: 0.7094
Macro F1-score: 0.6236
Model performance on Angry speech (in training): 
	Precision: 0.8438, Recall: 0.9450, F1_score: 0.8915
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.0075, F1_score: 0.0149
Model performance on Neutral speech (in training): 
	Precision: 0.5151, Recall: 0.9375, F1_score: 0.6649
Model performance on Sad speech (in training): 
	Precision: 0.9002, Recall: 0.9475, F1_score: 0.9233

Eval Phase: 
Validation loss: 716.5515, Validation accuracy: 0.6800
Macro F1-score: 0.6146
Model performance on Angry speech (in validation): 
	Precision: 0.9767, Recall: 0.8400, F1_score: 0.9032
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.4356, Recall: 0.8800, F1_score: 0.5828
Model performance on Sad speech (in validation): 
	Precision: 0.8909, Recall: 0.9800, F1_score: 0.9333
Epoch 40/100

Training Phase:
00:00<?, ?it/s]Training:  15%|█▍        | 233/1600 [00:10<00:58, 23.19it/s]Training:  29%|██▉       | 465/1600 [00:20<00:49, 22.93it/s]Training:  43%|████▎     | 695/1600 [00:30<00:39, 22.95it/s]Training:  58%|█████▊    | 929/1600 [00:40<00:29, 23.11it/s]Training:  58%|█████▊    | 929/1600 [00:50<00:29, 23.11it/s]Training:  73%|███████▎  | 1162/1600 [00:50<00:18, 23.15it/s]Training:  87%|████████▋ | 1395/1600 [01:00<00:08, 23.11it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 233/1600 [00:10<00:58, 23.29it/s]Training:  29%|██▉       | 468/1600 [00:20<00:48, 23.39it/s]Training:  29%|██▉       | 468/1600 [00:31<00:48, 23.39it/s]Training:  43%|████▎     | 682/1600 [00:31<00:42, 21.37it/s]Training:  5Training loss: 4633.5514, Training accuracy: 0.7063
Macro F1-score: 0.6218
Model performance on Angry speech (in training): 
	Precision: 0.8352, Recall: 0.9375, F1_score: 0.8834
Model performance on Happy speech (in training): 
	Precision: 0.7500, Recall: 0.0075, F1_score: 0.0149
Model performance on Neutral speech (in training): 
	Precision: 0.5109, Recall: 0.9375, F1_score: 0.6614
Model performance on Sad speech (in training): 
	Precision: 0.9128, Recall: 0.9425, F1_score: 0.9274

Eval Phase: 
Validation loss: 716.5515, Validation accuracy: 0.6800
Macro F1-score: 0.6146
Model performance on Angry speech (in validation): 
	Precision: 0.9767, Recall: 0.8400, F1_score: 0.9032
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.4356, Recall: 0.8800, F1_score: 0.5828
Model performance on Sad speech (in validation): 
	Precision: 0.8909, Recall: 0.9800, F1_score: 0.9333
Epoch 41/100

Training Phase:
Training loss: 4579.1229, Training accuracy: 0.7031
Macro F1-score: 0.6190
Model performance on Angry speech (in training): 
	Precision: 0.8503, Recall: 0.9375, F1_score: 0.8918
Model performance on Happy speech (in training): 
	Precision: 0.7500, Recall: 0.0075, F1_score: 0.0149
Model performance on Neutral speech (in training): 
	Precision: 0.5062, Recall: 0.9250, F1_score: 0.6543
Model performance on Sad speech (in training): 
	Precision: 0.8892, Recall: 0.9425, F1_score: 0.9150

Eval Phase: 
7%|█████▋    | 914/1600 [00:41<00:31, 22.06it/s]Training:  72%|███████▏  | 1146/1600 [00:51<00:20, 22.38it/s]Training:  86%|████████▌ | 1378/1600 [01:01<00:09, 22.64it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 231/1600 [00:10<00:59, 23.09it/s]Training:  29%|██▉       | 464/1600 [00:20<00:48, 23.19it/s]Training:  44%|████▎     | 697/1600 [00:30<00:39, 23.00it/s]Training:  58%|█████▊    | 925/1600 [00:41<00:31, 21.46it/s]Training:  72%|███████▏  | 1149/1600 [00:52<00:20, 21.77it/s]Training:  86%|████████▌ | 1378/1600 [01:02<00:10, 22.12it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                     Validation loss: 716.5515, Validation accuracy: 0.6800
Macro F1-score: 0.6146
Model performance on Angry speech (in validation): 
	Precision: 0.9767, Recall: 0.8400, F1_score: 0.9032
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.4356, Recall: 0.8800, F1_score: 0.5828
Model performance on Sad speech (in validation): 
	Precision: 0.8909, Recall: 0.9800, F1_score: 0.9333
Epoch 42/100

Training Phase:
Training loss: 4590.1013, Training accuracy: 0.7006
Macro F1-score: 0.6153
Model performance on Angry speech (in training): 
	Precision: 0.8545, Recall: 0.9400, F1_score: 0.8952
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.0025, F1_score: 0.0050
Model performance on Neutral speech (in training): 
	Precision: 0.5007, Recall: 0.9200, F1_score: 0.6485
Model performance on Sad speech (in training): 
	Precision: 0.8868, Recall: 0.9400, F1_score: 0.9126

Eval Phase: 
Validation loss: 716.5515, Validation accuracy: 0.6800
Macro F1-score: 0.6146
Model performance on Angry speech (in validation): 
	Precision: 0.9767, Recall: 0.8400, F1_score: 0.9032
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.4356, Recall: 0.8800, F1_score: 0.5828
Model performance on Sad speech (in validation): 
	Precision: 0.8909, Recall: 0.9800, F1_score: 0.9333
Epoch 43/100

Training Phase:
              Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 227/1600 [00:10<01:00, 22.64it/s]Training:  29%|██▉       | 461/1600 [00:20<00:49, 23.04it/s]Training:  43%|████▎     | 695/1600 [00:30<00:39, 23.06it/s]Training:  58%|█████▊    | 926/1600 [00:40<00:29, 23.01it/s]Training:  72%|███████▏  | 1159/1600 [00:50<00:19, 23.11it/s]Training:  87%|████████▋ | 1392/1600 [01:00<00:08, 23.13it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 230/1600 [00:10<00:59, 22.94it/s]Training:  29%|██▉       | 464/1600 [00:20<00:49, 23.15it/s]Training:  44%|████▎     | 697/1600 [00:30<00:39, 23.07it/s]Training:  58%|█████▊    | 929/1600 [00:40<00:29, 23.09it/s]Training:  73%|████Training loss: 4659.3697, Training accuracy: 0.6969
Macro F1-score: 0.6148
Model performance on Angry speech (in training): 
	Precision: 0.8470, Recall: 0.9275, F1_score: 0.8854
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.0100, F1_score: 0.0198
Model performance on Neutral speech (in training): 
	Precision: 0.4966, Recall: 0.9100, F1_score: 0.6425
Model performance on Sad speech (in training): 
	Precision: 0.8847, Recall: 0.9400, F1_score: 0.9115

Eval Phase: 
Validation loss: 716.5515, Validation accuracy: 0.6800
Macro F1-score: 0.6146
Model performance on Angry speech (in validation): 
	Precision: 0.9767, Recall: 0.8400, F1_score: 0.9032
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.4356, Recall: 0.8800, F1_score: 0.5828
Model performance on Sad speech (in validation): 
	Precision: 0.8909, Recall: 0.9800, F1_score: 0.9333
Epoch 44/100

Training Phase:
Training loss: 4713.9953, Training accuracy: 0.6969
Macro F1-score: 0.6138
Model performance on Angry speech (in training): 
	Precision: 0.8356, Recall: 0.9150, F1_score: 0.8735
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.0100, F1_score: 0.0198
Model performance on Neutral speech (in training): 
	Precision: 0.5041, Recall: 0.9200, F1_score: 0.6513
Model performance on Sad speech (in training): 
	Precision: 0.8808, Recall: 0.9425, F1_score: 0.9106

Eval Phase: 
Validation loss: 716.5515, Validation accuracy: 0.6800
Macro F1-score: 0.6146
Model performance on Angry speech (in validation): 
	Precision: 0.9767, Recall: 0.8400, F1_score: 0.9032
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.4356, Recall: 0.8800, F1_score: 0.5828
Model performance on Sad speech (in validation): 
	Precision: 0.8909, Recall: 0.9800, F1_score: 0.9333
Epoch 45/100

Training Phase:
██▎  | 1161/1600 [00:50<00:18, 23.11it/s]Training:  87%|████████▋ | 1393/1600 [01:00<00:08, 23.09it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 229/1600 [00:10<00:59, 22.86it/s]Training:  29%|██▉       | 460/1600 [00:20<00:49, 22.97it/s]Training:  43%|████▎     | 692/1600 [00:30<00:39, 23.07it/s]Training:  58%|█████▊    | 927/1600 [00:40<00:28, 23.22it/s]Training:  73%|███████▎  | 1162/1600 [00:50<00:18, 23.29it/s]Training:  87%|████████▋ | 1397/1600 [01:00<00:08, 23.24it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌ Training loss: 4640.8332, Training accuracy: 0.7094
Macro F1-score: 0.6266
Model performance on Angry speech (in training): 
	Precision: 0.8510, Recall: 0.9425, F1_score: 0.8944
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.0125, F1_score: 0.0247
Model performance on Neutral speech (in training): 
	Precision: 0.5101, Recall: 0.9450, F1_score: 0.6626
Model performance on Sad speech (in training): 
	Precision: 0.9124, Recall: 0.9375, F1_score: 0.9248

Eval Phase: 
Validation loss: 716.5515, Validation accuracy: 0.6800
Macro F1-score: 0.6146
Model performance on Angry speech (in validation): 
	Precision: 0.9767, Recall: 0.8400, F1_score: 0.9032
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.4356, Recall: 0.8800, F1_score: 0.5828
Model performance on Sad speech (in validation): 
	Precision: 0.8909, Recall: 0.9800, F1_score: 0.9333
Epoch 46/100

Training Phase:
       | 241/1600 [00:10<00:56, 24.07it/s]Training:  30%|███       | 483/1600 [00:20<00:46, 24.12it/s]Training:  45%|████▌     | 725/1600 [00:30<00:36, 24.01it/s]Training:  60%|██████    | 968/1600 [00:40<00:26, 24.08it/s]Training:  76%|███████▌  | 1211/1600 [00:50<00:16, 24.11it/s]Training:  91%|█████████ | 1453/1600 [01:00<00:06, 24.12it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 241/1600 [00:10<00:56, 24.07it/s]Training:  30%|███       | 483/1600 [00:20<00:46, 24.13it/s]Training:  45%|████▌     | 726/1600 [00:30<00:36, 24.18it/s]Training:  61%|██████    | 969/1600 [00:40<00:26, 24.22it/s]Training:  76%|███████▌  | 1212/1600 [00:50<00:16, 23.94it/s]Training:  91%|████████Training loss: 4687.0150, Training accuracy: 0.6931
Macro F1-score: 0.6125
Model performance on Angry speech (in training): 
	Precision: 0.8437, Recall: 0.9175, F1_score: 0.8790
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.0100, F1_score: 0.0198
Model performance on Neutral speech (in training): 
	Precision: 0.4920, Recall: 0.9200, F1_score: 0.6411
Model performance on Sad speech (in training): 
	Precision: 0.8959, Recall: 0.9250, F1_score: 0.9102

Eval Phase: 
Validation loss: 716.5515, Validation accuracy: 0.6800
Macro F1-score: 0.6146
Model performance on Angry speech (in validation): 
	Precision: 0.9767, Recall: 0.8400, F1_score: 0.9032
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.4356, Recall: 0.8800, F1_score: 0.5828
Model performance on Sad speech (in validation): 
	Precision: 0.8909, Recall: 0.9800, F1_score: 0.9333
Epoch 47/100

Training Phase:
Training loss: 4674.6844, Training accuracy: 0.7000
Macro F1-score: 0.6167
Model performance on Angry speech (in training): 
	Precision: 0.8277, Recall: 0.9250, F1_score: 0.8737
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.0100, F1_score: 0.0198
Model performance on Neutral speech (in training): 
	Precision: 0.5048, Recall: 0.9175, F1_score: 0.6513
Model performance on Sad speech (in training): 
	Precision: 0.8981, Recall: 0.9475, F1_score: 0.9221

Eval Phase: 
Validation loss: 716.5515, Validation accuracy: 0.6800
Macro F1-score: 0.6146
Model performance on Angry speech (in validation): 
	Precision: 0.9767, Recall: 0.8400, F1_score: 0.9032
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.4356, Recall: 0.8800, F1_score: 0.5828
Model performance on Sad speech (in validation): 
	Precision: 0.8909, Recall: 0.9800, F1_score: 0.9333
Epoch 48/100

Training Phase:
█ | 1455/1600 [01:00<00:06, 24.03it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 231/1600 [00:10<00:59, 23.06it/s]Training:  29%|██▉       | 462/1600 [00:20<00:51, 22.16it/s]Training:  43%|████▎     | 681/1600 [00:30<00:41, 22.02it/s]Training:  56%|█████▋    | 902/1600 [00:40<00:31, 22.02it/s]Training:  70%|███████   | 1123/1600 [00:50<00:21, 22.00it/s]Training:  84%|████████▍ | 1343/1600 [01:00<00:11, 21.98it/s]Training:  98%|█████████▊| 1564/1600 [01:10<00:01, 22.01it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | Training loss: 4669.7931, Training accuracy: 0.7000
Macro F1-score: 0.6167
Model performance on Angry speech (in training): 
	Precision: 0.8539, Recall: 0.9350, F1_score: 0.8926
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.0075, F1_score: 0.0149
Model performance on Neutral speech (in training): 
	Precision: 0.5007, Recall: 0.9250, F1_score: 0.6497
Model performance on Sad speech (in training): 
	Precision: 0.8881, Recall: 0.9325, F1_score: 0.9098

Eval Phase: 
Validation loss: 716.5515, Validation accuracy: 0.6800
Macro F1-score: 0.6146
Model performance on Angry speech (in validation): 
	Precision: 0.9767, Recall: 0.8400, F1_score: 0.9032
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.4356, Recall: 0.8800, F1_score: 0.5828
Model performance on Sad speech (in validation): 
	Precision: 0.8909, Recall: 0.9800, F1_score: 0.9333
Epoch 49/100

Training Phase:
219/1600 [00:10<01:03, 21.85it/s]Training:  27%|██▋       | 438/1600 [00:20<00:53, 21.87it/s]Training:  41%|████      | 657/1600 [00:30<00:43, 21.85it/s]Training:  55%|█████▍    | 877/1600 [00:40<00:33, 21.88it/s]Training:  69%|██████▊   | 1098/1600 [00:50<00:22, 21.93it/s]Training:  82%|████████▏ | 1319/1600 [01:00<00:12, 21.80it/s]Training:  96%|█████████▌| 1539/1600 [01:10<00:02, 21.83it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 217/1600 [00:10<01:03, 21.65it/s]Training:  27%|██▋       | 434/1600 [00:20<00:54, 21.55it/s]Training:  41%|████      | 653/1600 [00:30<00:43, 21.69it/s]Training:  55%|█████▍    | 874/1600 [00:40<00:33, 21.84it/s]Training:  68%|██████▊   | 1095/1600Training loss: 4614.4407, Training accuracy: 0.7019
Macro F1-score: 0.6215
Model performance on Angry speech (in training): 
	Precision: 0.8495, Recall: 0.9175, F1_score: 0.8822
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.0150, F1_score: 0.0296
Model performance on Neutral speech (in training): 
	Precision: 0.5013, Recall: 0.9350, F1_score: 0.6527
Model performance on Sad speech (in training): 
	Precision: 0.9038, Recall: 0.9400, F1_score: 0.9216

Eval Phase: 
Validation loss: 716.5515, Validation accuracy: 0.6800
Macro F1-score: 0.6146
Model performance on Angry speech (in validation): 
	Precision: 0.9767, Recall: 0.8400, F1_score: 0.9032
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.4356, Recall: 0.8800, F1_score: 0.5828
Model performance on Sad speech (in validation): 
	Precision: 0.8909, Recall: 0.9800, F1_score: 0.9333
Epoch 50/100

Two-stage training complete.
Model best accuracy on validation set: 0.6800

Test Phase: 
 [00:50<00:23, 21.93it/s]Training:  82%|████████▏ | 1316/1600 [01:00<00:12, 21.96it/s]Training:  96%|█████████▌| 1538/1600 [01:10<00:02, 22.04it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]Testing:   0%|          | 1/200 [00:00<00:21,  9.06it/s]Testing:   2%|▏         | 4/200 [00:00<00:11, 17.01it/s]Testing:   3%|▎         | 6/200 [00:00<00:11, 17.12it/s]Testing:   5%|▌         | 10/200 [00:00<00:08, 22.02it/s]Testing:   6%|▋         | 13/200 [00:00<00:08, 21.91it/s]Testing:   9%|▉         | 18/200 [00:00<00:06, 28.42it/s]Testing:  10%|█         | 21/200 [00:00<00:06, 27.77it/s]Testing:  12%|█▏        | 24/200 [00:00<00:06, 27.63it/s]Testing:  14%|█▎        | 27/200 [00:01<00:06, 27.37it/s]Testing:  15%|█▌        | 30/200 [00:01<00:06, 24.74it/s]Testing:  16%|█▋        | 33/200 [00:01<00:06, 24.07it/s]Testing:  18%|█▊        | 36/200 [00:01<00:06, 25.49it/s]Testing:  22%|██▏       | 43/200 [00:01<00:04, 35.44it/s]Testing:  24%|██▍       | 48/200 [00:01<00:03, 38.36it/s]Testing:  27%|██▋       | 54/200 [00:01<00:03, 40.02it/s]Testing:  30%|██▉       | 59/200 [00:01<00:03, 42.40it/s]Testing:  32%|███▎      | 65/200 [00:02<00:02, 45.95it/s]Testing:  35%|███▌      | 70/200 [00:02<00:03, 42.40it/s]Testing:  38%|███▊      | 76/200 [00:02<00:02, 46.90it/s]Testing:  40%|████      | 81/200 [00:02<00:02, 47.47it/s]Testing:  43%|████▎     | 86/200 [00:02<00:02, 47.85it/s]Testing:  46%|████▋     | 93/200 [00:02<00:02, 51.81it/s]Testing:  50%|████▉     | 99/200 [00:02<00:02, 50.01it/s]Testing:  54%|█████▍    | 108/200 [00:02<00:01, 60.11it/s]Testing:  57%|█████▊    | 115/200 [00:02<00:01, 61.49it/s]Testing:  62%|██████▏   | 123/200 [00:03<00:01, 66.13it/s]Testing:  66%|██████▌   | 132/200 [00:03<00:00, 71.56it/s]Testing:  70%|███████   | 140/200 [00:03<00:00, 65.00it/s]Testing:  74%|███████▍  | 148/200 [00:03<00:00, 68.91it/s]Testing:  80%|███████▉  | 159/200 [00:03<00:00, 78.26it/s]Testing:  84%|████████▍ | 169/200 [00:03<00:00, 82.90it/s]Testing:  90%|█████████ | 180/200 [00:03<00:00, 87.87it/s]Testing:  94%|█████████▍| 189/200 [00:03<00:00, 87.72it/s]Testing:  99%|█████████▉| 198/200 [00:03<00:00, 87.96it/s]                                                          /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Test loss: 712.0837, Test accuracy: 0.6800
Macro F1-score: 0.6036
Model performance on Angry speech (in test): 
	Precision: 0.9286, Recall: 0.7800, F1_score: 0.8478
Model performance on Happy speech (in test): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in test): 
	Precision: 0.4563, Recall: 0.9400, F1_score: 0.6144
Model performance on Sad speech (in test): 
	Precision: 0.9091, Recall: 1.0000, F1_score: 0.9524

======================= This is fold_3 on cn =======================

Load dataset: 
Loading cn train data: fold_3...
Preprocess cn fold_3 data for cn model
Loading de eval data: fold_3...
Preprocess de fold_3 data for cn model
Loading de test data: fold_3...
Preprocess de fold_3 data for cn model
Use cn model to add lora
================== SET ALL PARAMS =====================
modified_wav2vec2.base_model.model.masked_spec_embed: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.0.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.0.layer_norm.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.0.layer_norm.bias: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.1.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.2.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.3.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.4.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.5.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.6.conv.weight: False
modified_wav2vec2.base_model.model.feature_projection.layer_norm.weight: False
modified_wav2vec2.base_model.model.feature_projection.layer_norm.bias: False
modified_wav2vec2.base_model.model.feature_projection.projection.weight: False
modified_wav2vec2.base_model.model.feature_projection.projection.bias: False
modified_wav2vec2.base_model.model.encoder.pos_conv_embed.conv.bias: False
modified_wav2vec2.base_model.model.encoder.pos_conv_embed.conv.weight_g: False
modified_wav2vec2.base_model.model.encoder.pos_conv_embed.conv.weight_v: False
modified_wav2vec2.base_model.model.encoder.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.up.bias: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.up.bias: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.up.bias: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.up.bias: True
normal_classifier.dense1.weight: True
normal_classifier.dense1.bias: True
normal_classifier.dense.weight: True
normal_classifier.dense.bias: True
normal_classifier.out.weight: True
normal_classifier.out.bias: True
Set optimizer and criterion
Epoch 1/100

Training Phase:
Training loss: 186.5402, Training accuracy: 0.9575
Macro F1-score: 0.9574
Model performance on Angry speech (in training): 
	Precision: 0.9389, Recall: 0.9600, F1_score: 0.9493
Model performance on Happy speech (in training): 
	Precision: 0.9510, Recall: 0.9225, F1_score: 0.9365
Model performance on Neutral speech (in training): 
	Precision: 0.9577, Recall: 0.9625, F1_score: 0.9601
Model performance on Sad speech (in training): 
	Precision: 0.9825, Recall: 0.9850, F1_score: 0.9838

Eval Phase: 
Validation loss: 295.3825, Validation accuracy: 0.5250
Macro F1-score: 0.4604
Model performance on Angry speech (in validation): 
	Precision: 0.9474, Recall: 0.7200, F1_score: 0.8182
Model performance on Happy speech (in validation): 
	Precision: 0.5000, Recall: 0.0200, F1_score: 0.0385
Model performance on Neutral speech (in validation): 
	Precision: 0.3600, Recall: 0.3600, F1_score: 0.3600
Model performance on Sad speech (in validation): 
	Precision: 0.4545, Recall: 1.0000, F1_score: 0.6250
New best accuracy for layer 3 on epoch 1: 0.5250. Model saved.
Epoch 2/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  11%|█         | 169/1600 [00:10<01:24, 16.84it/s]Training:  24%|██▍       | 392/1600 [00:20<01:00, 20.03it/s]Training:  40%|████      | 646/1600 [00:30<00:42, 22.44it/s]Training:  57%|█████▋    | 913/1600 [00:40<00:28, 24.08it/s]Training:  74%|███████▍  | 1188/1600 [00:50<00:16, 25.31it/s]Training:  92%|█████████▏| 1472/1600 [01:00<00:04, 26.34it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 308/1600 [00:10<00:41, 30.79it/s]Training:  38%|███▊      | 616/1600 [00:20<00:32, 30.51it/s]Training:  58%|█████▊    | 925/1600 [00:30<00:22, 30.67it/s]Training:  77%|███████▋  | 1234/1600 [00:40<00:11, 30.56it/s]Training:  96%|███████Training loss: 93.3783, Training accuracy: 0.9825
Macro F1-score: 0.9825
Model performance on Angry speech (in training): 
	Precision: 0.9678, Recall: 0.9775, F1_score: 0.9726
Model performance on Happy speech (in training): 
	Precision: 0.9847, Recall: 0.9650, F1_score: 0.9747
Model performance on Neutral speech (in training): 
	Precision: 0.9851, Recall: 0.9925, F1_score: 0.9888
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938

Eval Phase: 
Validation loss: 293.5607, Validation accuracy: 0.5700
Macro F1-score: 0.5106
Model performance on Angry speech (in validation): 
	Precision: 0.9545, Recall: 0.8400, F1_score: 0.8936
Model performance on Happy speech (in validation): 
	Precision: 0.7500, Recall: 0.0600, F1_score: 0.1111
Model performance on Neutral speech (in validation): 
	Precision: 0.4419, Recall: 0.3800, F1_score: 0.4086
Model performance on Sad speech (in validation): 
	Precision: 0.4587, Recall: 1.0000, F1_score: 0.6289
New best accuracy for layer 3 on epoch 2: 0.5700. Model saved.
Epoch 3/100

Training Phase:
Training loss: 72.7965, Training accuracy: 0.9844
Macro F1-score: 0.9844
Model performance on Angry speech (in training): 
	Precision: 0.9825, Recall: 0.9825, F1_score: 0.9825
Model performance on Happy speech (in training): 
	Precision: 0.9725, Recall: 0.9725, F1_score: 0.9725
Model performance on Neutral speech (in training): 
	Precision: 0.9851, Recall: 0.9900, F1_score: 0.9875
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9925, F1_score: 0.9950

Eval Phase: 
Validation loss: 379.8490, Validation accuracy: 0.5200
Macro F1-score: 0.4723
Model performance on Angry speech (in validation): 
	Precision: 0.9286, Recall: 0.5200, F1_score: 0.6667
Model performance on Happy speech (in validation): 
	Precision: 0.8000, Recall: 0.0800, F1_score: 0.1455
Model performance on Neutral speech (in validation): 
	Precision: 0.3582, Recall: 0.4800, F1_score: 0.4103
Model performance on Sad speech (in validation): 
	Precision: 0.5000, Recall: 1.0000, F1_score: 0.6667
Epoch 4/100

Training Phase:
██▋| 1541/1600 [00:50<00:01, 30.61it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 311/1600 [00:10<00:41, 31.03it/s]Training:  39%|███▉      | 622/1600 [00:20<00:31, 30.71it/s]Training:  58%|█████▊    | 932/1600 [00:30<00:21, 30.81it/s]Training:  78%|███████▊  | 1242/1600 [00:40<00:11, 30.66it/s]Training:  97%|█████████▋| 1549/1600 [00:50<00:01, 30.66it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 308/1600 [00:10<00:41, 30.79it/s]Training:  38%|███▊      | 616/1600 [00:20<00:31, 30.77it/s]Training:  58%|█████▊    | Training loss: 74.1260, Training accuracy: 0.9831
Macro F1-score: 0.9831
Model performance on Angry speech (in training): 
	Precision: 0.9801, Recall: 0.9875, F1_score: 0.9838
Model performance on Happy speech (in training): 
	Precision: 0.9772, Recall: 0.9650, F1_score: 0.9711
Model performance on Neutral speech (in training): 
	Precision: 0.9827, Recall: 0.9925, F1_score: 0.9876
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9875, F1_score: 0.9900

Eval Phase: 
Validation loss: 312.7807, Validation accuracy: 0.6400
Macro F1-score: 0.5632
Model performance on Angry speech (in validation): 
	Precision: 0.9375, Recall: 0.9000, F1_score: 0.9184
Model performance on Happy speech (in validation): 
	Precision: 0.5000, Recall: 0.0200, F1_score: 0.0385
Model performance on Neutral speech (in validation): 
	Precision: 0.5161, Recall: 0.6400, F1_score: 0.5714
Model performance on Sad speech (in validation): 
	Precision: 0.5682, Recall: 1.0000, F1_score: 0.7246
New best accuracy for layer 3 on epoch 4: 0.6400. Model saved.
Epoch 5/100

Training Phase:
Training loss: 45.6550, Training accuracy: 0.9894
Macro F1-score: 0.9894
Model performance on Angry speech (in training): 
	Precision: 0.9826, Recall: 0.9875, F1_score: 0.9850
Model performance on Happy speech (in training): 
	Precision: 0.9899, Recall: 0.9825, F1_score: 0.9862
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9900, F1_score: 0.9937
Model performance on Sad speech (in training): 
	Precision: 0.9876, Recall: 0.9975, F1_score: 0.9925

Eval Phase: 
Validation loss: 250.8428, Validation accuracy: 0.6150
Macro F1-score: 0.5788
Model performance on Angry speech (in validation): 
	Precision: 0.9500, Recall: 0.7600, F1_score: 0.8444
Model performance on Happy speech (in validation): 
	Precision: 0.8889, Recall: 0.1600, F1_score: 0.2712
Model performance on Neutral speech (in validation): 
	Precision: 0.4576, Recall: 0.5400, F1_score: 0.4954
Model performance on Sad speech (in validation): 
	Precision: 0.5435, Recall: 1.0000, F1_score: 0.7042
Epoch 6/100

Training Phase:
924/1600 [00:30<00:21, 30.77it/s]Training:  77%|███████▋  | 1236/1600 [00:40<00:11, 30.92it/s]Training:  97%|█████████▋| 1548/1600 [00:50<00:01, 30.79it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  20%|█▉        | 312/1600 [00:10<00:41, 31.12it/s]Training:  39%|███▉      | 624/1600 [00:20<00:31, 30.91it/s]Training:  58%|█████▊    | 933/1600 [00:30<00:21, 30.89it/s]Training:  78%|███████▊  | 1242/1600 [00:40<00:11, 30.90it/s]Training:  97%|█████████▋| 1551/1600 [00:50<00:01, 30.67it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉    Training loss: 54.8769, Training accuracy: 0.9856
Macro F1-score: 0.9856
Model performance on Angry speech (in training): 
	Precision: 0.9825, Recall: 0.9825, F1_score: 0.9825
Model performance on Happy speech (in training): 
	Precision: 0.9824, Recall: 0.9775, F1_score: 0.9799
Model performance on Neutral speech (in training): 
	Precision: 0.9850, Recall: 0.9875, F1_score: 0.9863
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938

Eval Phase: 
Validation loss: 342.1666, Validation accuracy: 0.6000
Macro F1-score: 0.5506
Model performance on Angry speech (in validation): 
	Precision: 0.9545, Recall: 0.8400, F1_score: 0.8936
Model performance on Happy speech (in validation): 
	Precision: 0.8333, Recall: 0.1000, F1_score: 0.1786
Model performance on Neutral speech (in validation): 
	Precision: 0.5227, Recall: 0.4600, F1_score: 0.4894
Model performance on Sad speech (in validation): 
	Precision: 0.4717, Recall: 1.0000, F1_score: 0.6410
Epoch 7/100

Training Phase:
Training loss: 48.1276, Training accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in training): 
	Precision: 0.9849, Recall: 0.9800, F1_score: 0.9825
Model performance on Happy speech (in training): 
	Precision: 0.9825, Recall: 0.9825, F1_score: 0.9825
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988

Eval Phase: 
    | 310/1600 [00:10<00:41, 30.91it/s]Training:  39%|███▉      | 620/1600 [00:20<00:31, 30.94it/s]Training:  58%|█████▊    | 930/1600 [00:30<00:21, 30.69it/s]Training:  77%|███████▋  | 1234/1600 [00:40<00:12, 30.48it/s]Training:  96%|█████████▋| 1541/1600 [00:50<00:01, 30.54it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 307/1600 [00:10<00:42, 30.63it/s]Training:  38%|███▊      | 614/1600 [00:20<00:32, 30.51it/s]Training:  57%|█████▋    | 919/1600 [00:30<00:22, 30.45it/s]Training:  77%|███████▋  | 1227/1600 [00:40<00:12, 30.55it/s]Training:  96%|█████████▌| 1535/1600 [00:50<00:02, 30.56it/s]                                                             Evaluating:   0%|          | 0/20Validation loss: 271.8819, Validation accuracy: 0.6650
Macro F1-score: 0.6281
Model performance on Angry speech (in validation): 
	Precision: 0.9512, Recall: 0.7800, F1_score: 0.8571
Model performance on Happy speech (in validation): 
	Precision: 0.9000, Recall: 0.1800, F1_score: 0.3000
Model performance on Neutral speech (in validation): 
	Precision: 0.5303, Recall: 0.7000, F1_score: 0.6034
Model performance on Sad speech (in validation): 
	Precision: 0.6024, Recall: 1.0000, F1_score: 0.7519
New best accuracy for layer 3 on epoch 7: 0.6650. Model saved.
Epoch 8/100

Training Phase:
Training loss: 39.8476, Training accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in training): 
	Precision: 0.9875, Recall: 0.9900, F1_score: 0.9888
Model performance on Happy speech (in training): 
	Precision: 0.9875, Recall: 0.9875, F1_score: 0.9875
Model performance on Neutral speech (in training): 
	Precision: 0.9875, Recall: 0.9900, F1_score: 0.9888
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9925, F1_score: 0.9950

Eval Phase: 
Validation loss: 259.7312, Validation accuracy: 0.6700
Macro F1-score: 0.6502
Model performance on Angry speech (in validation): 
	Precision: 0.9200, Recall: 0.9200, F1_score: 0.9200
Model performance on Happy speech (in validation): 
	Precision: 0.9444, Recall: 0.3400, F1_score: 0.5000
Model performance on Neutral speech (in validation): 
	Precision: 0.6774, Recall: 0.4200, F1_score: 0.5185
Model performance on Sad speech (in validation): 
	Precision: 0.4950, Recall: 1.0000, F1_score: 0.6623
New best accuracy for layer 3 on epoch 8: 0.6700. Model saved.
Epoch 9/100

Training Phase:
0 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 308/1600 [00:10<00:42, 30.75it/s]Training:  38%|███▊      | 616/1600 [00:20<00:32, 30.57it/s]Training:  58%|█████▊    | 924/1600 [00:30<00:22, 30.64it/s]Training:  77%|███████▋  | 1232/1600 [00:40<00:12, 30.58it/s]Training:  96%|█████████▌| 1539/1600 [00:50<00:01, 30.62it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 303/1600 [00:10<00:42, 30.29it/s]Training:  38%|███▊      | 609/1600 [00:20<00:32, 30.47it/s]Training:  57%|█████▋    | 917/1600 [00:30<00:22, 30.62it/s]Training:  77%|███████▋  | 1225/1600 [00:40<00:12, 30.67it/s]Training:  96%|█████Training loss: 41.5657, Training accuracy: 0.9900
Macro F1-score: 0.9900
Model performance on Angry speech (in training): 
	Precision: 0.9875, Recall: 0.9875, F1_score: 0.9875
Model performance on Happy speech (in training): 
	Precision: 0.9875, Recall: 0.9900, F1_score: 0.9888
Model performance on Neutral speech (in training): 
	Precision: 0.9900, Recall: 0.9875, F1_score: 0.9887
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950

Eval Phase: 
Validation loss: 432.2823, Validation accuracy: 0.5200
Macro F1-score: 0.4515
Model performance on Angry speech (in validation): 
	Precision: 0.9394, Recall: 0.6200, F1_score: 0.7470
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.4107, Recall: 0.4600, F1_score: 0.4340
Model performance on Sad speech (in validation): 
	Precision: 0.4545, Recall: 1.0000, F1_score: 0.6250
Epoch 10/100

Training Phase:
Training loss: 24.7420, Training accuracy: 0.9938
Macro F1-score: 0.9937
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Happy speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963

Eval Phase: 
Validation loss: 628.2445, Validation accuracy: 0.4800
Macro F1-score: 0.3716
Model performance on Angry speech (in validation): 
	Precision: 0.9167, Recall: 0.8800, F1_score: 0.8980
Model performance on Happy speech (in validation): 
	Precision: 0.6667, Recall: 0.0400, F1_score: 0.0755
Model performance on Neutral speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Sad speech (in validation): 
	Precision: 0.3448, Recall: 1.0000, F1_score: 0.5128
Epoch 11/100

Training Phase:
████▌| 1533/1600 [00:50<00:02, 30.59it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 306/1600 [00:10<00:42, 30.53it/s]Training:  38%|███▊      | 612/1600 [00:20<00:32, 30.52it/s]Training:  57%|█████▋    | 918/1600 [00:30<00:22, 30.54it/s]Training:  76%|███████▋  | 1224/1600 [00:40<00:12, 30.50it/s]Training:  96%|█████████▌| 1530/1600 [00:50<00:02, 30.51it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 308/1600 [00:10<00:42, 30.74it/s]Training:  38%|███▊      | 616/1600 [00:20<00:32, 30.45it/s]Training:  57%|█████▊Training loss: 26.5770, Training accuracy: 0.9969
Macro F1-score: 0.9969
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987

Eval Phase: 
Validation loss: 503.1243, Validation accuracy: 0.4850
Macro F1-score: 0.4339
Model performance on Angry speech (in validation): 
	Precision: 0.9722, Recall: 0.7000, F1_score: 0.8140
Model performance on Happy speech (in validation): 
	Precision: 0.7778, Recall: 0.1400, F1_score: 0.2373
Model performance on Neutral speech (in validation): 
	Precision: 0.2381, Recall: 0.1000, F1_score: 0.1408
Model performance on Sad speech (in validation): 
	Precision: 0.3731, Recall: 1.0000, F1_score: 0.5435
Epoch 12/100

Training Phase:
Training loss: 28.9932, Training accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900
Model performance on Happy speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 447.0828, Validation accuracy: 0.4650
Macro F1-score: 0.4374
Model performance on Angry speech (in validation): 
	Precision: 0.9545, Recall: 0.4200, F1_score: 0.5833
Model performance on Happy speech (in validation): 
	Precision: 0.7000, Recall: 0.2800, F1_score: 0.4000
Model performance on Neutral speech (in validation): 
	Precision: 0.2286, Recall: 0.1600, F1_score: 0.1882
Model performance on Sad speech (in validation): 
	Precision: 0.4065, Recall: 1.0000, F1_score: 0.5780
Epoch 13/100

Training Phase:
    | 920/1600 [00:30<00:22, 30.42it/s]Training:  77%|███████▋  | 1233/1600 [00:40<00:11, 30.73it/s]Training:  97%|█████████▋| 1546/1600 [00:50<00:01, 30.65it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 306/1600 [00:10<00:42, 30.54it/s]Training:  38%|███▊      | 612/1600 [00:20<00:32, 30.54it/s]Training:  57%|█████▋    | 918/1600 [00:30<00:22, 30.47it/s]Training:  77%|███████▋  | 1227/1600 [00:40<00:12, 30.63it/s]Training:  96%|█████████▌| 1536/1600 [00:51<00:02, 28.94it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█Training loss: 33.5651, Training accuracy: 0.9906
Macro F1-score: 0.9906
Model performance on Angry speech (in training): 
	Precision: 0.9875, Recall: 0.9875, F1_score: 0.9875
Model performance on Happy speech (in training): 
	Precision: 0.9875, Recall: 0.9875, F1_score: 0.9875
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938

Eval Phase: 
Validation loss: 257.3760, Validation accuracy: 0.6800
Macro F1-score: 0.6628
Model performance on Angry speech (in validation): 
	Precision: 0.9149, Recall: 0.8600, F1_score: 0.8866
Model performance on Happy speech (in validation): 
	Precision: 0.8889, Recall: 0.3200, F1_score: 0.4706
Model performance on Neutral speech (in validation): 
	Precision: 0.7105, Recall: 0.5400, F1_score: 0.6136
Model performance on Sad speech (in validation): 
	Precision: 0.5155, Recall: 1.0000, F1_score: 0.6803
New best accuracy for layer 3 on epoch 13: 0.6800. Model saved.
Epoch 14/100

Training Phase:
Training loss: 24.8224, Training accuracy: 0.9962
Macro F1-score: 0.9962
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
        | 305/1600 [00:10<00:42, 30.49it/s]Training:  38%|███▊      | 610/1600 [00:20<00:32, 30.39it/s]Training:  57%|█████▋    | 918/1600 [00:30<00:22, 30.55it/s]Training:  77%|███████▋  | 1226/1600 [00:40<00:12, 30.56it/s]Training:  96%|█████████▌| 1533/1600 [00:50<00:02, 30.59it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 308/1600 [00:10<00:42, 30.75it/s]Training:  38%|███▊      | 616/1600 [00:20<00:32, 30.49it/s]Training:  58%|█████▊    | 922/1600 [00:30<00:22, 30.51it/s]Training:  77%|███████▋  | 1229/1600 [00:40<00:12, 30.55it/s]Training:  96%|█████████▌| 1536/1600 [00:50<00:02, 30.52it/s]                                                             Evaluating:   0%|          Validation loss: 397.1355, Validation accuracy: 0.6450
Macro F1-score: 0.5768
Model performance on Angry speech (in validation): 
	Precision: 0.8889, Recall: 0.9600, F1_score: 0.9231
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0600, F1_score: 0.1132
Model performance on Neutral speech (in validation): 
	Precision: 0.6667, Recall: 0.5600, F1_score: 0.6087
Model performance on Sad speech (in validation): 
	Precision: 0.4950, Recall: 1.0000, F1_score: 0.6623
Epoch 15/100

Training Phase:
Training loss: 35.0660, Training accuracy: 0.9912
Macro F1-score: 0.9912
Model performance on Angry speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938
Model performance on Neutral speech (in training): 
	Precision: 0.9875, Recall: 0.9875, F1_score: 0.9875
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937

Eval Phase: 
Validation loss: 236.8615, Validation accuracy: 0.7050
Macro F1-score: 0.6953
Model performance on Angry speech (in validation): 
	Precision: 0.8958, Recall: 0.8600, F1_score: 0.8776
Model performance on Happy speech (in validation): 
	Precision: 0.9167, Recall: 0.4400, F1_score: 0.5946
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.5200, F1_score: 0.6047
Model performance on Sad speech (in validation): 
	Precision: 0.5435, Recall: 1.0000, F1_score: 0.7042
New best accuracy for layer 3 on epoch 15: 0.7050. Model saved.
Epoch 16/100

Training Phase:
| 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 308/1600 [00:10<00:42, 30.73it/s]Training:  38%|███▊      | 616/1600 [00:20<00:32, 30.68it/s]Training:  58%|█████▊    | 923/1600 [00:32<00:24, 27.71it/s]Training:  77%|███████▋  | 1229/1600 [00:42<00:12, 28.77it/s]Training:  96%|█████████▌| 1535/1600 [00:52<00:02, 29.31it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 310/1600 [00:10<00:41, 30.97it/s]Training:  39%|███▉      | 620/1600 [00:20<00:31, 30.92it/s]Training:  58%|█████▊    | 929/1600 [00:30<00:21, 30.80it/s]Training:  77%|███████▋  | 1236/1600 [00:40<00:11, 30.57it/s]Training:  96%|███Training loss: 23.0945, Training accuracy: 0.9975
Macro F1-score: 0.9975
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988

Eval Phase: 
Validation loss: 352.1886, Validation accuracy: 0.5700
Macro F1-score: 0.5431
Model performance on Angry speech (in validation): 
	Precision: 0.9355, Recall: 0.5800, F1_score: 0.7160
Model performance on Happy speech (in validation): 
	Precision: 0.6667, Recall: 0.2000, F1_score: 0.3077
Model performance on Neutral speech (in validation): 
	Precision: 0.4902, Recall: 0.5000, F1_score: 0.4950
Model performance on Sad speech (in validation): 
	Precision: 0.4854, Recall: 1.0000, F1_score: 0.6536
Epoch 17/100

Training Phase:
Training loss: 22.9294, Training accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9900, F1_score: 0.9925
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 1.0000, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Validation loss: 603.5380, Validation accuracy: 0.4050
Macro F1-score: 0.3548
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.3600, F1_score: 0.5294
Model performance on Happy speech (in validation): 
	Precision: 0.5263, Recall: 0.2000, F1_score: 0.2899
Model performance on Neutral speech (in validation): 
	Precision: 0.1765, Recall: 0.0600, F1_score: 0.0896
Model performance on Sad speech (in validation): 
	Precision: 0.3425, Recall: 1.0000, F1_score: 0.5102
Epoch 18/100

Training Phase:
██████▋| 1541/1600 [00:50<00:01, 30.54it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 307/1600 [00:10<00:42, 30.67it/s]Training:  38%|███▊      | 614/1600 [00:20<00:32, 30.66it/s]Training:  58%|█████▊    | 921/1600 [00:30<00:22, 30.63it/s]Training:  77%|███████▋  | 1228/1600 [00:40<00:12, 30.62it/s]Training:  96%|█████████▌| 1538/1600 [00:50<00:02, 30.74it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 306/1600 [00:10<00:42, 30.59it/s]Training:  38%|███▊      | 615/1600 [00:20<00:32, 30.75it/s]Training:  58%|████Training loss: 19.2272, Training accuracy: 0.9962
Macro F1-score: 0.9962
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 371.5148, Validation accuracy: 0.5650
Macro F1-score: 0.5491
Model performance on Angry speech (in validation): 
	Precision: 0.8824, Recall: 0.6000, F1_score: 0.7143
Model performance on Happy speech (in validation): 
	Precision: 0.8182, Recall: 0.3600, F1_score: 0.5000
Model performance on Neutral speech (in validation): 
	Precision: 0.4412, Recall: 0.3000, F1_score: 0.3571
Model performance on Sad speech (in validation): 
	Precision: 0.4545, Recall: 1.0000, F1_score: 0.6250
Epoch 19/100

Training Phase:
Training loss: 27.1776, Training accuracy: 0.9931
Macro F1-score: 0.9931
Model performance on Angry speech (in training): 
	Precision: 0.9875, Recall: 0.9900, F1_score: 0.9888
Model performance on Happy speech (in training): 
	Precision: 0.9875, Recall: 0.9875, F1_score: 0.9875
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987

Eval Phase: 
Validation loss: 654.7665, Validation accuracy: 0.4450
Macro F1-score: 0.3620
Model performance on Angry speech (in validation): 
	Precision: 0.9189, Recall: 0.6800, F1_score: 0.7816
Model performance on Happy speech (in validation): 
	Precision: 0.4167, Recall: 0.1000, F1_score: 0.1613
Model performance on Neutral speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Sad speech (in validation): 
	Precision: 0.3378, Recall: 1.0000, F1_score: 0.5051
Epoch 20/100

Training Phase:
█▊    | 925/1600 [00:30<00:21, 30.81it/s]Training:  77%|███████▋  | 1234/1600 [00:40<00:11, 30.60it/s]Training:  96%|█████████▋| 1542/1600 [00:50<00:01, 30.64it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 309/1600 [00:10<00:41, 30.83it/s]Training:  39%|███▊      | 618/1600 [00:20<00:31, 30.76it/s]Training:  58%|█████▊    | 926/1600 [00:30<00:22, 30.58it/s]Training:  77%|███████▋  | 1234/1600 [00:40<00:11, 30.65it/s]Training:  97%|█████████▋| 1545/1600 [00:50<00:01, 30.81it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19Training loss: 25.1313, Training accuracy: 0.9938
Macro F1-score: 0.9938
Model performance on Angry speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913
Model performance on Happy speech (in training): 
	Precision: 0.9875, Recall: 0.9900, F1_score: 0.9888
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9925, F1_score: 0.9950
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 341.9222, Validation accuracy: 0.6350
Macro F1-score: 0.6130
Model performance on Angry speech (in validation): 
	Precision: 0.9091, Recall: 0.8000, F1_score: 0.8511
Model performance on Happy speech (in validation): 
	Precision: 0.9286, Recall: 0.2600, F1_score: 0.4062
Model performance on Neutral speech (in validation): 
	Precision: 0.6316, Recall: 0.4800, F1_score: 0.5455
Model performance on Sad speech (in validation): 
	Precision: 0.4808, Recall: 1.0000, F1_score: 0.6494
Epoch 21/100

Training Phase:
Training loss: 21.4413, Training accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9925, F1_score: 0.9950
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938

Eval Phase: 
%|█▉        | 305/1600 [00:10<00:42, 30.45it/s]Training:  38%|███▊      | 616/1600 [00:20<00:31, 30.79it/s]Training:  58%|█████▊    | 927/1600 [00:30<00:21, 30.87it/s]Training:  77%|███████▋  | 1237/1600 [00:40<00:11, 30.81it/s]Training:  97%|█████████▋| 1545/1600 [00:50<00:01, 30.75it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 309/1600 [00:10<00:41, 30.88it/s]Training:  39%|███▉      | 620/1600 [00:20<00:31, 30.95it/s]Training:  58%|█████▊    | 931/1600 [00:30<00:21, 30.88it/s]Training:  77%|███████▋  | 1239/1600 [00:40<00:11, 30.61it/s]Training:  97%|█████████▋| 1548/1600 [00:50<00:01, 30.70it/s]                                                             Evaluating:   0%|    Validation loss: 490.6410, Validation accuracy: 0.5700
Macro F1-score: 0.5330
Model performance on Angry speech (in validation): 
	Precision: 0.8864, Recall: 0.7800, F1_score: 0.8298
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1600, F1_score: 0.2759
Model performance on Neutral speech (in validation): 
	Precision: 0.6296, Recall: 0.3400, F1_score: 0.4416
Model performance on Sad speech (in validation): 
	Precision: 0.4132, Recall: 1.0000, F1_score: 0.5848
Epoch 22/100

Training Phase:
Training loss: 22.5930, Training accuracy: 0.9962
Macro F1-score: 0.9962
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987

Eval Phase: 
Validation loss: 458.5669, Validation accuracy: 0.5450
Macro F1-score: 0.5214
Model performance on Angry speech (in validation): 
	Precision: 0.8857, Recall: 0.6200, F1_score: 0.7294
Model performance on Happy speech (in validation): 
	Precision: 0.7917, Recall: 0.3800, F1_score: 0.5135
Model performance on Neutral speech (in validation): 
	Precision: 0.5000, Recall: 0.1800, F1_score: 0.2647
Model performance on Sad speech (in validation): 
	Precision: 0.4065, Recall: 1.0000, F1_score: 0.5780
Epoch 23/100

Training Phase:
      | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 309/1600 [00:10<00:41, 30.85it/s]Training:  39%|███▊      | 618/1600 [00:20<00:31, 30.75it/s]Training:  58%|█████▊    | 927/1600 [00:30<00:21, 30.78it/s]Training:  77%|███████▋  | 1236/1600 [00:40<00:11, 30.65it/s]Training:  96%|█████████▋| 1542/1600 [00:50<00:01, 30.62it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 309/1600 [00:10<00:41, 30.85it/s]Training:  39%|███▊      | 618/1600 [00:20<00:32, 30.65it/s]Training:  58%|█████▊    | 927/1600 [00:30<00:21, 30.73it/s]Training:  77%|███████▋  | 1236/1600 [00:40<00:11, 30.68it/s]Training:  96%|█Training loss: 10.6625, Training accuracy: 0.9994
Macro F1-score: 0.9994
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 337.1295, Validation accuracy: 0.6500
Macro F1-score: 0.6442
Model performance on Angry speech (in validation): 
	Precision: 0.9091, Recall: 0.6000, F1_score: 0.7229
Model performance on Happy speech (in validation): 
	Precision: 0.7568, Recall: 0.5600, F1_score: 0.6437
Model performance on Neutral speech (in validation): 
	Precision: 0.6667, Recall: 0.4400, F1_score: 0.5301
Model performance on Sad speech (in validation): 
	Precision: 0.5155, Recall: 1.0000, F1_score: 0.6803
Epoch 24/100

Training Phase:
Training loss: 23.3182, Training accuracy: 0.9962
Macro F1-score: 0.9962
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Validation loss: 332.2027, Validation accuracy: 0.6850
Macro F1-score: 0.6740
Model performance on Angry speech (in validation): 
	Precision: 0.9130, Recall: 0.8400, F1_score: 0.8750
Model performance on Happy speech (in validation): 
	Precision: 0.9677, Recall: 0.6000, F1_score: 0.7407
Model performance on Neutral speech (in validation): 
	Precision: 0.7143, Recall: 0.3000, F1_score: 0.4225
Model performance on Sad speech (in validation): 
	Precision: 0.4902, Recall: 1.0000, F1_score: 0.6579
Epoch 25/100

Training Phase:
████████▋| 1543/1600 [00:50<00:01, 30.61it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 307/1600 [00:10<00:42, 30.68it/s]Training:  38%|███▊      | 614/1600 [00:20<00:32, 30.62it/s]Training:  58%|█████▊    | 925/1600 [00:30<00:21, 30.80it/s]Training:  77%|███████▋  | 1236/1600 [00:40<00:11, 30.91it/s]Training:  97%|█████████▋| 1547/1600 [00:50<00:01, 30.81it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 310/1600 [00:10<00:41, 30.98it/s]Training:  39%|███▉      | 620/1600 [00:20<00:31, 30.79it/s]Training:  58%|██Training loss: 26.4632, Training accuracy: 0.9938
Macro F1-score: 0.9938
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912
Model performance on Neutral speech (in training): 
	Precision: 0.9900, Recall: 0.9950, F1_score: 0.9925
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987

Eval Phase: 
Validation loss: 729.4056, Validation accuracy: 0.4000
Macro F1-score: 0.3438
Model performance on Angry speech (in validation): 
	Precision: 0.9474, Recall: 0.3600, F1_score: 0.5217
Model performance on Happy speech (in validation): 
	Precision: 0.5556, Recall: 0.2000, F1_score: 0.2941
Model performance on Neutral speech (in validation): 
	Precision: 0.2000, Recall: 0.0400, F1_score: 0.0667
Model performance on Sad speech (in validation): 
	Precision: 0.3268, Recall: 1.0000, F1_score: 0.4926
Validation loss does not decrease for 10 epochs. End training.
Epoch 26/100

Entering 2ND training phase: change training data from cn to DE
Loading de train data: fold_3...
Preprocess de fold_3 data for cn model
Reload model and reset eval loss

Training Phase:
Training loss: 2190.1248, Training accuracy: 0.6619
Macro F1-score: 0.6395
Model performance on Angry speech (in training): 
	Precision: 0.8834, Recall: 0.8900, F1_score: 0.8867
Model performance on Happy speech (in training): 
	Precision: 0.8500, Recall: 0.3400, F1_score: 0.4857
Model performance on Neutral speech (in training): 
	Precision: 0.6292, Recall: 0.4200, F1_score: 0.5037
Model performance on Sad speech (in training): 
	Precision: 0.5182, Recall: 0.9975, F1_score: 0.6821

Eval Phase: 
███▊    | 928/1600 [00:30<00:21, 30.76it/s]Training:  77%|███████▋  | 1236/1600 [00:40<00:11, 30.75it/s]Training:  96%|█████████▋| 1544/1600 [00:50<00:01, 30.64it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:   9%|▉         | 144/1600 [00:10<01:41, 14.40it/s]Training:  21%|██        | 329/1600 [00:20<01:15, 16.77it/s]Training:  33%|███▎      | 521/1600 [00:30<01:00, 17.86it/s]Training:  45%|████▌     | 724/1600 [00:40<00:46, 18.80it/s]Training:  59%|█████▊    | 937/1600 [00:50<00:33, 19.69it/s]Training:  72%|███████▎  | 1160/1600 [01:00<00:21, 20.56it/s]Training:  87%|████████▋ | 1388/1600 [01:10<00:09, 21.28it/s]                                                             Evaluating:   0%|          | 0/Validation loss: 236.8615, Validation accuracy: 0.7050
Macro F1-score: 0.6953
Model performance on Angry speech (in validation): 
	Precision: 0.8958, Recall: 0.8600, F1_score: 0.8776
Model performance on Happy speech (in validation): 
	Precision: 0.9167, Recall: 0.4400, F1_score: 0.5946
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.5200, F1_score: 0.6047
Model performance on Sad speech (in validation): 
	Precision: 0.5435, Recall: 1.0000, F1_score: 0.7042
Epoch 27/100

Training Phase:
Training loss: 2025.1300, Training accuracy: 0.6719
Macro F1-score: 0.6516
Model performance on Angry speech (in training): 
	Precision: 0.9121, Recall: 0.9075, F1_score: 0.9098
Model performance on Happy speech (in training): 
	Precision: 0.8868, Recall: 0.3525, F1_score: 0.5045
Model performance on Neutral speech (in training): 
	Precision: 0.6287, Recall: 0.4275, F1_score: 0.5089
Model performance on Sad speech (in training): 
	Precision: 0.5188, Recall: 1.0000, F1_score: 0.6832

Eval Phase: 
Validation loss: 236.8615, Validation accuracy: 0.7050
Macro F1-score: 0.6953
Model performance on Angry speech (in validation): 
	Precision: 0.8958, Recall: 0.8600, F1_score: 0.8776
Model performance on Happy speech (in validation): 
	Precision: 0.9167, Recall: 0.4400, F1_score: 0.5946
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.5200, F1_score: 0.6047
Model performance on Sad speech (in validation): 
	Precision: 0.5435, Recall: 1.0000, F1_score: 0.7042
Epoch 28/100

Training Phase:
200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 234/1600 [00:10<00:58, 23.31it/s]Training:  30%|███       | 484/1600 [00:20<00:45, 24.30it/s]Training:  46%|████▌     | 734/1600 [00:30<00:36, 23.99it/s]Training:  61%|██████▏   | 981/1600 [00:40<00:25, 24.26it/s]Training:  77%|███████▋  | 1228/1600 [00:50<00:15, 24.18it/s]Training:  92%|█████████▏| 1470/1600 [01:00<00:05, 24.15it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 241/1600 [00:10<00:56, 24.02it/s]Training:  30%|███       | 484/1600 [00:20<00:46, 24.18it/s]Training:  45%|████▌     | 727/1600 [00:30<00:36, 24.24it/s]Training:  61%|██████    | Training loss: 2079.2530, Training accuracy: 0.6619
Macro F1-score: 0.6401
Model performance on Angry speech (in training): 
	Precision: 0.8922, Recall: 0.8900, F1_score: 0.8911
Model performance on Happy speech (in training): 
	Precision: 0.8544, Recall: 0.3375, F1_score: 0.4839
Model performance on Neutral speech (in training): 
	Precision: 0.6085, Recall: 0.4275, F1_score: 0.5022
Model performance on Sad speech (in training): 
	Precision: 0.5210, Recall: 0.9925, F1_score: 0.6833

Eval Phase: 
Validation loss: 236.8615, Validation accuracy: 0.7050
Macro F1-score: 0.6953
Model performance on Angry speech (in validation): 
	Precision: 0.8958, Recall: 0.8600, F1_score: 0.8776
Model performance on Happy speech (in validation): 
	Precision: 0.9167, Recall: 0.4400, F1_score: 0.5946
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.5200, F1_score: 0.6047
Model performance on Sad speech (in validation): 
	Precision: 0.5435, Recall: 1.0000, F1_score: 0.7042
Epoch 29/100

Training Phase:
Training loss: 2094.7149, Training accuracy: 0.6731
Macro F1-score: 0.6524
Model performance on Angry speech (in training): 
	Precision: 0.8958, Recall: 0.9025, F1_score: 0.8991
Model performance on Happy speech (in training): 
	Precision: 0.8688, Recall: 0.3475, F1_score: 0.4964
Model performance on Neutral speech (in training): 
	Precision: 0.6228, Recall: 0.4500, F1_score: 0.5225
Model performance on Sad speech (in training): 
	Precision: 0.5307, Recall: 0.9925, F1_score: 0.6916

Eval Phase: 
Validation loss: 236.8615, Validation accuracy: 0.7050
Macro F1-score: 0.6953
Model performance on Angry speech (in validation): 
	Precision: 0.8958, Recall: 0.8600, F1_score: 0.8776
Model performance on Happy speech (in validation): 
	Precision: 0.9167, Recall: 0.4400, F1_score: 0.5946
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.5200, F1_score: 0.6047
Model performance on Sad speech (in validation): 
	Precision: 0.5435, Recall: 1.0000, F1_score: 0.7042
Epoch 30/100

Training Phase:
972/1600 [00:40<00:25, 24.32it/s]Training:  76%|███████▌  | 1217/1600 [00:50<00:15, 24.23it/s]Training:  91%|█████████ | 1458/1600 [01:00<00:05, 24.15it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 243/1600 [00:10<00:55, 24.29it/s]Training:  30%|███       | 488/1600 [00:20<00:45, 24.39it/s]Training:  46%|████▌     | 733/1600 [00:30<00:36, 24.06it/s]Training:  61%|██████    | 970/1600 [00:40<00:26, 23.55it/s]Training:  75%|███████▍  | 1198/1600 [00:50<00:17, 23.26it/s]Training:  90%|████████▉ | 1433/1600 [01:00<00:07, 23.32it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:  Training loss: 2113.5100, Training accuracy: 0.6706
Macro F1-score: 0.6482
Model performance on Angry speech (in training): 
	Precision: 0.9141, Recall: 0.9050, F1_score: 0.9095
Model performance on Happy speech (in training): 
	Precision: 0.8699, Recall: 0.3175, F1_score: 0.4652
Model performance on Neutral speech (in training): 
	Precision: 0.6187, Recall: 0.4625, F1_score: 0.5293
Model performance on Sad speech (in training): 
	Precision: 0.5257, Recall: 0.9975, F1_score: 0.6885

Eval Phase: 
Validation loss: 236.8615, Validation accuracy: 0.7050
Macro F1-score: 0.6953
Model performance on Angry speech (in validation): 
	Precision: 0.8958, Recall: 0.8600, F1_score: 0.8776
Model performance on Happy speech (in validation): 
	Precision: 0.9167, Recall: 0.4400, F1_score: 0.5946
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.5200, F1_score: 0.6047
Model performance on Sad speech (in validation): 
	Precision: 0.5435, Recall: 1.0000, F1_score: 0.7042
Epoch 31/100

Training Phase:
 0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 238/1600 [00:10<00:57, 23.73it/s]Training:  30%|██▉       | 478/1600 [00:20<00:47, 23.81it/s]Training:  45%|████▌     | 723/1600 [00:30<00:36, 24.11it/s]Training:  60%|██████    | 968/1600 [00:40<00:26, 24.19it/s]Training:  60%|██████    | 968/1600 [00:50<00:26, 24.19it/s]Training:  76%|███████▌  | 1209/1600 [00:50<00:16, 24.12it/s]Training:  91%|█████████ | 1451/1600 [01:00<00:06, 24.11it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 239/1600 [00:10<00:57, 23.84it/s]Training:  30%|███       | 485/1600 [00:20<00:45, 24.28it/s]Training:  46%|████▌     | 731/1600 [00:30<00:35, 24.30it/s]Training:  61%|██████    | 975/1600 [00:40<Training loss: 2073.5910, Training accuracy: 0.6594
Macro F1-score: 0.6382
Model performance on Angry speech (in training): 
	Precision: 0.9128, Recall: 0.8900, F1_score: 0.9013
Model performance on Happy speech (in training): 
	Precision: 0.8679, Recall: 0.3450, F1_score: 0.4937
Model performance on Neutral speech (in training): 
	Precision: 0.5724, Recall: 0.4050, F1_score: 0.4744
Model performance on Sad speech (in training): 
	Precision: 0.5195, Recall: 0.9975, F1_score: 0.6832

Eval Phase: 
Validation loss: 236.8615, Validation accuracy: 0.7050
Macro F1-score: 0.6953
Model performance on Angry speech (in validation): 
	Precision: 0.8958, Recall: 0.8600, F1_score: 0.8776
Model performance on Happy speech (in validation): 
	Precision: 0.9167, Recall: 0.4400, F1_score: 0.5946
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.5200, F1_score: 0.6047
Model performance on Sad speech (in validation): 
	Precision: 0.5435, Recall: 1.0000, F1_score: 0.7042
Epoch 32/100

Training Phase:
Training loss: 2013.8945, Training accuracy: 0.6731
Macro F1-score: 0.6552
Model performance on Angry speech (in training): 
	Precision: 0.9225, Recall: 0.8925, F1_score: 0.9072
Model performance on Happy speech (in training): 
	Precision: 0.8614, Recall: 0.3575, F1_score: 0.5053
Model performance on Neutral speech (in training): 
	Precision: 0.6250, Recall: 0.4500, F1_score: 0.5233
Model performance on Sad speech (in training): 
	Precision: 0.5231, Recall: 0.9925, F1_score: 0.6851

Eval Phase: 
Validation loss: 236.8615, Validation accuracy: 0.7050
Macro F1-score: 0.6953
Model performance on Angry speech (in validation): 
	Precision: 0.8958, Recall: 0.8600, F1_score: 0.8776
Model performance on Happy speech (in validation): 
	Precision: 0.9167, Recall: 0.4400, F1_score: 0.5946
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.5200, F1_score: 0.6047
Model performance on Sad speech (in validation): 
	Precision: 0.5435, Recall: 1.0000, F1_score: 0.7042
Epoch 33/100

Training Phase:
00:25, 24.30it/s]Training:  76%|███████▌  | 1219/1600 [00:50<00:15, 24.03it/s]Training:  91%|█████████▏| 1462/1600 [01:00<00:05, 24.11it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 229/1600 [00:10<01:00, 22.63it/s]Training:  29%|██▉       | 466/1600 [00:20<00:48, 23.23it/s]Training:  44%|████▍     | 710/1600 [00:30<00:37, 23.72it/s]Training:  60%|█████▉    | 954/1600 [00:40<00:27, 23.88it/s]Training:  75%|███████▍  | 1196/1600 [00:50<00:16, 23.93it/s]Training:  90%|█████████ | 1442/1600 [01:00<00:06, 24.13it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          Training loss: 2088.7631, Training accuracy: 0.6706
Macro F1-score: 0.6488
Model performance on Angry speech (in training): 
	Precision: 0.9005, Recall: 0.9050, F1_score: 0.9027
Model performance on Happy speech (in training): 
	Precision: 0.8608, Recall: 0.3400, F1_score: 0.4875
Model performance on Neutral speech (in training): 
	Precision: 0.6197, Recall: 0.4400, F1_score: 0.5146
Model performance on Sad speech (in training): 
	Precision: 0.5278, Recall: 0.9975, F1_score: 0.6903

Eval Phase: 
Validation loss: 236.8615, Validation accuracy: 0.7050
Macro F1-score: 0.6953
Model performance on Angry speech (in validation): 
	Precision: 0.8958, Recall: 0.8600, F1_score: 0.8776
Model performance on Happy speech (in validation): 
	Precision: 0.9167, Recall: 0.4400, F1_score: 0.5946
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.5200, F1_score: 0.6047
Model performance on Sad speech (in validation): 
	Precision: 0.5435, Recall: 1.0000, F1_score: 0.7042
Epoch 34/100

Training Phase:
| 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 231/1600 [00:10<00:59, 23.10it/s]Training:  29%|██▉       | 464/1600 [00:20<00:49, 23.18it/s]Training:  44%|████▎     | 698/1600 [00:30<00:38, 23.24it/s]Training:  58%|█████▊    | 933/1600 [00:40<00:28, 23.28it/s]Training:  73%|███████▎  | 1167/1600 [00:50<00:18, 23.10it/s]Training:  87%|████████▋ | 1399/1600 [01:00<00:08, 23.13it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 233/1600 [00:10<00:58, 23.26it/s]Training:  29%|██▉       | 470/1600 [00:20<00:48, 23.48it/s]Training:  44%|████▍     | 707/1600 [00:30<00:38, 22.99it/s]Training:  59%|█████▉    | 941/1600 [00:40<00:28, 23.11it/s]Training:  73%|███████▎  | 1175/1600 [00:50<00:18, 23Training loss: 2086.4086, Training accuracy: 0.6631
Macro F1-score: 0.6425
Model performance on Angry speech (in training): 
	Precision: 0.9044, Recall: 0.8750, F1_score: 0.8895
Model performance on Happy speech (in training): 
	Precision: 0.8323, Recall: 0.3350, F1_score: 0.4777
Model performance on Neutral speech (in training): 
	Precision: 0.6159, Recall: 0.4450, F1_score: 0.5167
Model performance on Sad speech (in training): 
	Precision: 0.5229, Recall: 0.9975, F1_score: 0.6862

Eval Phase: 
Validation loss: 236.8615, Validation accuracy: 0.7050
Macro F1-score: 0.6953
Model performance on Angry speech (in validation): 
	Precision: 0.8958, Recall: 0.8600, F1_score: 0.8776
Model performance on Happy speech (in validation): 
	Precision: 0.9167, Recall: 0.4400, F1_score: 0.5946
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.5200, F1_score: 0.6047
Model performance on Sad speech (in validation): 
	Precision: 0.5435, Recall: 1.0000, F1_score: 0.7042
Epoch 35/100

Training Phase:
Training loss: 2104.6770, Training accuracy: 0.6719
Macro F1-score: 0.6510
Model performance on Angry speech (in training): 
	Precision: 0.8900, Recall: 0.8900, F1_score: 0.8900
Model performance on Happy speech (in training): 
	Precision: 0.8424, Recall: 0.3475, F1_score: 0.4920
Model performance on Neutral speech (in training): 
	Precision: 0.6169, Recall: 0.4550, F1_score: 0.5237
Model performance on Sad speech (in training): 
	Precision: 0.5378, Recall: 0.9950, F1_score: 0.6982

Eval Phase: 
Validation loss: 236.8615, Validation accuracy: 0.7050
Macro F1-score: 0.6953
Model performance on Angry speech (in validation): 
	Precision: 0.8958, Recall: 0.8600, F1_score: 0.8776
Model performance on Happy speech (in validation): 
	Precision: 0.9167, Recall: 0.4400, F1_score: 0.5946
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.5200, F1_score: 0.6047
Model performance on Sad speech (in validation): 
	Precision: 0.5435, Recall: 1.0000, F1_score: 0.7042
Epoch 36/100

Training Phase:
.07it/s]Training:  89%|████████▉ | 1420/1600 [01:00<00:07, 23.54it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 239/1600 [00:10<00:56, 23.90it/s]Training:  30%|██▉       | 479/1600 [00:20<00:46, 23.93it/s]Training:  45%|████▌     | 725/1600 [00:30<00:36, 24.22it/s]Training:  61%|██████    | 971/1600 [00:40<00:26, 24.13it/s]Training:  76%|███████▌  | 1214/1600 [00:50<00:15, 24.17it/s]Training:  91%|█████████ | 1457/1600 [01:00<00:05, 24.16it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 231/1600 [00:10<00:59, 23.05it/sTraining loss: 2129.2292, Training accuracy: 0.6581
Macro F1-score: 0.6365
Model performance on Angry speech (in training): 
	Precision: 0.8917, Recall: 0.8850, F1_score: 0.8883
Model performance on Happy speech (in training): 
	Precision: 0.8385, Recall: 0.3375, F1_score: 0.4813
Model performance on Neutral speech (in training): 
	Precision: 0.6231, Recall: 0.4175, F1_score: 0.5000
Model performance on Sad speech (in training): 
	Precision: 0.5129, Recall: 0.9925, F1_score: 0.6763

Eval Phase: 
Validation loss: 236.8615, Validation accuracy: 0.7050
Macro F1-score: 0.6953
Model performance on Angry speech (in validation): 
	Precision: 0.8958, Recall: 0.8600, F1_score: 0.8776
Model performance on Happy speech (in validation): 
	Precision: 0.9167, Recall: 0.4400, F1_score: 0.5946
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.5200, F1_score: 0.6047
Model performance on Sad speech (in validation): 
	Precision: 0.5435, Recall: 1.0000, F1_score: 0.7042
Epoch 37/100

Training Phase:
]Training:  29%|██▉       | 468/1600 [00:20<00:48, 23.38it/s]Training:  44%|████▍     | 705/1600 [00:30<00:38, 23.07it/s]Training:  58%|█████▊    | 934/1600 [00:40<00:28, 23.00it/s]Training:  73%|███████▎  | 1166/1600 [00:50<00:18, 23.06it/s]Training:  88%|████████▊ | 1400/1600 [01:00<00:08, 23.14it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 233/1600 [00:10<00:58, 23.25it/s]Training:  29%|██▉       | 466/1600 [00:20<00:48, 23.15it/s]Training:  44%|████▍     | 703/1600 [00:30<00:38, 23.36it/s]Training:  59%|█████▉    | 940/1600 [00:40<00:28, 23.22it/s]Training:  73%|███████▎  | 1170/1600 [00:50<00:18, 23.08it/s]Training:  88%|████████▊ | 1402/1600 [01:00<00:08, 23.11it/s]Training loss: 2014.5446, Training accuracy: 0.6731
Macro F1-score: 0.6550
Model performance on Angry speech (in training): 
	Precision: 0.9195, Recall: 0.8850, F1_score: 0.9019
Model performance on Happy speech (in training): 
	Precision: 0.8614, Recall: 0.3575, F1_score: 0.5053
Model performance on Neutral speech (in training): 
	Precision: 0.6199, Recall: 0.4525, F1_score: 0.5231
Model performance on Sad speech (in training): 
	Precision: 0.5271, Recall: 0.9975, F1_score: 0.6897

Eval Phase: 
Validation loss: 236.8615, Validation accuracy: 0.7050
Macro F1-score: 0.6953
Model performance on Angry speech (in validation): 
	Precision: 0.8958, Recall: 0.8600, F1_score: 0.8776
Model performance on Happy speech (in validation): 
	Precision: 0.9167, Recall: 0.4400, F1_score: 0.5946
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.5200, F1_score: 0.6047
Model performance on Sad speech (in validation): 
	Precision: 0.5435, Recall: 1.0000, F1_score: 0.7042
Epoch 38/100

Training Phase:
Training loss: 2127.0800, Training accuracy: 0.6719
Macro F1-score: 0.6510
Model performance on Angry speech (in training): 
	Precision: 0.8950, Recall: 0.8950, F1_score: 0.8950
Model performance on Happy speech (in training): 
	Precision: 0.8671, Recall: 0.3425, F1_score: 0.4910
Model performance on Neutral speech (in training): 
	Precision: 0.6307, Recall: 0.4525, F1_score: 0.5269
Model performance on Sad speech (in training): 
	Precision: 0.5285, Recall: 0.9975, F1_score: 0.6909

Eval Phase: 
Validation loss: 236.8615, Validation accuracy: 0.7050
Macro F1-score: 0.6953
Model performance on Angry speech (in validation): 
	Precision: 0.8958, Recall: 0.8600, F1_score: 0.8776
Model performance on Happy speech (in validation): 
	Precision: 0.9167, Recall: 0.4400, F1_score: 0.5946
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.5200, F1_score: 0.6047
Model performance on Sad speech (in validation): 
	Precision: 0.5435, Recall: 1.0000, F1_score: 0.7042
Epoch 39/100

Training Phase:
                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 230/1600 [00:10<00:59, 22.98it/s]Training:  29%|██▉       | 460/1600 [00:20<00:49, 22.95it/s]Training:  43%|████▎     | 691/1600 [00:30<00:39, 22.99it/s]Training:  58%|█████▊    | 924/1600 [00:40<00:29, 23.08it/s]Training:  72%|███████▏  | 1157/1600 [00:50<00:19, 23.10it/s]Training:  87%|████████▋ | 1394/1600 [01:00<00:08, 23.28it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 230/1600 [00:10<00:59, 22.89it/s]Training:  29%|██▉       | 464/1600 [00:20<00:49, 23.13it/s]Training:  44%|█Training loss: 2092.9494, Training accuracy: 0.6706
Macro F1-score: 0.6510
Model performance on Angry speech (in training): 
	Precision: 0.9010, Recall: 0.8875, F1_score: 0.8942
Model performance on Happy speech (in training): 
	Precision: 0.8421, Recall: 0.3600, F1_score: 0.5044
Model performance on Neutral speech (in training): 
	Precision: 0.6228, Recall: 0.4375, F1_score: 0.5140
Model performance on Sad speech (in training): 
	Precision: 0.5292, Recall: 0.9975, F1_score: 0.6915

Eval Phase: 
Validation loss: 236.8615, Validation accuracy: 0.7050
Macro F1-score: 0.6953
Model performance on Angry speech (in validation): 
	Precision: 0.8958, Recall: 0.8600, F1_score: 0.8776
Model performance on Happy speech (in validation): 
	Precision: 0.9167, Recall: 0.4400, F1_score: 0.5946
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.5200, F1_score: 0.6047
Model performance on Sad speech (in validation): 
	Precision: 0.5435, Recall: 1.0000, F1_score: 0.7042
Epoch 40/100

Training Phase:
Training loss: 2092.3357, Training accuracy: 0.6719
Macro F1-score: 0.6516
Model performance on Angry speech (in training): 
	Precision: 0.9040, Recall: 0.8950, F1_score: 0.8995
Model performance on Happy speech (in training): 
	Precision: 0.8688, Recall: 0.3475, F1_score: 0.4964
Model performance on Neutral speech (in training): 
	Precision: 0.6290, Recall: 0.4450, F1_score: 0.5212
Model performance on Sad speech (in training): 
	Precision: 0.5256, Recall: 1.0000, F1_score: 0.6891

Eval Phase: 
██▍     | 702/1600 [00:30<00:38, 23.41it/s]Training:  59%|█████▉    | 940/1600 [00:40<00:28, 23.19it/s]Training:  73%|███████▎  | 1169/1600 [00:50<00:18, 23.06it/s]Training:  88%|████████▊ | 1402/1600 [01:00<00:08, 23.11it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 237/1600 [00:10<00:57, 23.60it/s]Training:  30%|██▉       | 473/1600 [00:20<00:48, 23.18it/s]Training:  44%|████▍     | 707/1600 [00:30<00:38, 23.24it/s]Training:  59%|█████▉    | 941/1600 [00:40<00:28, 23.28it/s]Training:  73%|███████▎  | 1175/1600 [00:50<00:18, 23.24it/s]Training:  88%|████████▊ | 1407/1600 [01:00<00:08, 23.08it/s]                                                             Evaluating:   0%|         Validation loss: 236.8615, Validation accuracy: 0.7050
Macro F1-score: 0.6953
Model performance on Angry speech (in validation): 
	Precision: 0.8958, Recall: 0.8600, F1_score: 0.8776
Model performance on Happy speech (in validation): 
	Precision: 0.9167, Recall: 0.4400, F1_score: 0.5946
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.5200, F1_score: 0.6047
Model performance on Sad speech (in validation): 
	Precision: 0.5435, Recall: 1.0000, F1_score: 0.7042
Epoch 41/100

Training Phase:
Training loss: 2107.6774, Training accuracy: 0.6669
Macro F1-score: 0.6453
Model performance on Angry speech (in training): 
	Precision: 0.8778, Recall: 0.8800, F1_score: 0.8789
Model performance on Happy speech (in training): 
	Precision: 0.8471, Recall: 0.3325, F1_score: 0.4776
Model performance on Neutral speech (in training): 
	Precision: 0.6618, Recall: 0.4550, F1_score: 0.5393
Model performance on Sad speech (in training): 
	Precision: 0.5215, Recall: 1.0000, F1_score: 0.6855

Eval Phase: 
Validation loss: 236.8615, Validation accuracy: 0.7050
Macro F1-score: 0.6953
Model performance on Angry speech (in validation): 
	Precision: 0.8958, Recall: 0.8600, F1_score: 0.8776
Model performance on Happy speech (in validation): 
	Precision: 0.9167, Recall: 0.4400, F1_score: 0.5946
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.5200, F1_score: 0.6047
Model performance on Sad speech (in validation): 
	Precision: 0.5435, Recall: 1.0000, F1_score: 0.7042
Epoch 42/100

Training Phase:
 | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 233/1600 [00:10<00:58, 23.29it/s]Training:  29%|██▉       | 466/1600 [00:20<00:49, 22.88it/s]Training:  44%|████▎     | 699/1600 [00:30<00:39, 23.06it/s]Training:  58%|█████▊    | 935/1600 [00:40<00:28, 23.25it/s]Training:  58%|█████▊    | 935/1600 [00:50<00:28, 23.25it/s]Training:  73%|███████▎  | 1170/1600 [00:50<00:18, 23.23it/s]Training:  88%|████████▊ | 1402/1600 [01:00<00:08, 23.11it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 236/1600 [00:10<00:58, 23.48it/s]Training:  30%|██▉       | 472/1600 [00:20<00:48, 23.50it/s]Training:  44%|████▍     |Training loss: 2088.4106, Training accuracy: 0.6700
Macro F1-score: 0.6478
Model performance on Angry speech (in training): 
	Precision: 0.8908, Recall: 0.8975, F1_score: 0.8941
Model performance on Happy speech (in training): 
	Precision: 0.8590, Recall: 0.3350, F1_score: 0.4820
Model performance on Neutral speech (in training): 
	Precision: 0.6228, Recall: 0.4500, F1_score: 0.5225
Model performance on Sad speech (in training): 
	Precision: 0.5306, Recall: 0.9975, F1_score: 0.6927

Eval Phase: 
Validation loss: 236.8615, Validation accuracy: 0.7050
Macro F1-score: 0.6953
Model performance on Angry speech (in validation): 
	Precision: 0.8958, Recall: 0.8600, F1_score: 0.8776
Model performance on Happy speech (in validation): 
	Precision: 0.9167, Recall: 0.4400, F1_score: 0.5946
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.5200, F1_score: 0.6047
Model performance on Sad speech (in validation): 
	Precision: 0.5435, Recall: 1.0000, F1_score: 0.7042
Epoch 43/100

Training Phase:
Training loss: 2035.7510, Training accuracy: 0.6725
Macro F1-score: 0.6549
Model performance on Angry speech (in training): 
	Precision: 0.9191, Recall: 0.8800, F1_score: 0.8991
Model performance on Happy speech (in training): 
	Precision: 0.8538, Recall: 0.3650, F1_score: 0.5114
Model performance on Neutral speech (in training): 
	Precision: 0.6020, Recall: 0.4500, F1_score: 0.5150
Model performance on Sad speech (in training): 
	Precision: 0.5328, Recall: 0.9950, F1_score: 0.6940

Eval Phase: 
 708/1600 [00:30<00:38, 23.18it/s]Training:  59%|█████▊    | 937/1600 [00:40<00:28, 22.99it/s]Training:  73%|███████▎  | 1165/1600 [00:50<00:18, 22.90it/s]Training:  87%|████████▋ | 1396/1600 [01:00<00:08, 22.97it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 230/1600 [00:10<00:59, 22.98it/s]Training:  29%|██▉       | 460/1600 [00:20<00:49, 22.93it/s]Training:  43%|████▎     | 692/1600 [00:30<00:39, 23.01it/s]Training:  58%|█████▊    | 924/1600 [00:40<00:29, 23.07it/s]Training:  72%|███████▏  | 1156/1600 [00:50<00:19, 23.06it/s]Training:  87%|████████▋ | 1391/1600 [01:00<00:09, 23.16it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<Validation loss: 236.8615, Validation accuracy: 0.7050
Macro F1-score: 0.6953
Model performance on Angry speech (in validation): 
	Precision: 0.8958, Recall: 0.8600, F1_score: 0.8776
Model performance on Happy speech (in validation): 
	Precision: 0.9167, Recall: 0.4400, F1_score: 0.5946
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.5200, F1_score: 0.6047
Model performance on Sad speech (in validation): 
	Precision: 0.5435, Recall: 1.0000, F1_score: 0.7042
Epoch 44/100

Training Phase:
Training loss: 2108.1201, Training accuracy: 0.6656
Macro F1-score: 0.6444
Model performance on Angry speech (in training): 
	Precision: 0.8937, Recall: 0.8825, F1_score: 0.8881
Model performance on Happy speech (in training): 
	Precision: 0.8303, Recall: 0.3425, F1_score: 0.4850
Model performance on Neutral speech (in training): 
	Precision: 0.6000, Recall: 0.4425, F1_score: 0.5094
Model performance on Sad speech (in training): 
	Precision: 0.5342, Recall: 0.9950, F1_score: 0.6952

Eval Phase: 
Validation loss: 236.8615, Validation accuracy: 0.7050
Macro F1-score: 0.6953
Model performance on Angry speech (in validation): 
	Precision: 0.8958, Recall: 0.8600, F1_score: 0.8776
Model performance on Happy speech (in validation): 
	Precision: 0.9167, Recall: 0.4400, F1_score: 0.5946
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.5200, F1_score: 0.6047
Model performance on Sad speech (in validation): 
	Precision: 0.5435, Recall: 1.0000, F1_score: 0.7042
Epoch 45/100

Training Phase:
?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 230/1600 [00:10<00:59, 22.99it/s]Training:  29%|██▉       | 466/1600 [00:20<00:48, 23.30it/s]Training:  44%|████▍     | 702/1600 [00:30<00:38, 23.28it/s]Training:  58%|█████▊    | 935/1600 [00:40<00:28, 23.15it/s]Training:  73%|███████▎  | 1168/1600 [00:50<00:18, 23.18it/s]Training:  88%|████████▊ | 1401/1600 [01:00<00:08, 23.10it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 241/1600 [00:10<00:56, 24.07it/s]Training:  30%|███       | 482/1600 [00:20<00:46, 23.89it/s]Training:  45%|████▌     | 726/1600 [00:30<00:36, 24.10it/s]Training:  61%|██████    | 973/1600 [00:40Training loss: 2080.8280, Training accuracy: 0.6669
Macro F1-score: 0.6459
Model performance on Angry speech (in training): 
	Precision: 0.8992, Recall: 0.8925, F1_score: 0.8959
Model performance on Happy speech (in training): 
	Precision: 0.8491, Recall: 0.3375, F1_score: 0.4830
Model performance on Neutral speech (in training): 
	Precision: 0.6367, Recall: 0.4425, F1_score: 0.5221
Model performance on Sad speech (in training): 
	Precision: 0.5196, Recall: 0.9950, F1_score: 0.6827

Eval Phase: 
Validation loss: 236.8615, Validation accuracy: 0.7050
Macro F1-score: 0.6953
Model performance on Angry speech (in validation): 
	Precision: 0.8958, Recall: 0.8600, F1_score: 0.8776
Model performance on Happy speech (in validation): 
	Precision: 0.9167, Recall: 0.4400, F1_score: 0.5946
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.5200, F1_score: 0.6047
Model performance on Sad speech (in validation): 
	Precision: 0.5435, Recall: 1.0000, F1_score: 0.7042
Epoch 46/100

Training Phase:
Training loss: 2094.1061, Training accuracy: 0.6687
Macro F1-score: 0.6499
Model performance on Angry speech (in training): 
	Precision: 0.9126, Recall: 0.8875, F1_score: 0.8999
Model performance on Happy speech (in training): 
	Precision: 0.8529, Recall: 0.3625, F1_score: 0.5088
Model performance on Neutral speech (in training): 
	Precision: 0.6218, Recall: 0.4275, F1_score: 0.5067
Model performance on Sad speech (in training): 
	Precision: 0.5209, Recall: 0.9975, F1_score: 0.6844

Eval Phase: 
<00:25, 24.29it/s]Training:  76%|███████▌  | 1219/1600 [00:50<00:15, 24.10it/s]Training:  91%|█████████▏| 1463/1600 [01:00<00:05, 24.19it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 242/1600 [00:10<00:56, 24.12it/s]Training:  30%|███       | 484/1600 [00:20<00:46, 24.07it/s]Training:  45%|████▌     | 726/1600 [00:30<00:36, 24.09it/s]Training:  60%|██████    | 968/1600 [00:40<00:26, 23.90it/s]Training:  76%|███████▌  | 1216/1600 [00:50<00:15, 24.22it/s]Training:  76%|███████▌  | 1216/1600 [01:00<00:15, 24.22it/s]Training:  91%|█████████▏| 1463/1600 [01:00<00:05, 24.03it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/Validation loss: 236.8615, Validation accuracy: 0.7050
Macro F1-score: 0.6953
Model performance on Angry speech (in validation): 
	Precision: 0.8958, Recall: 0.8600, F1_score: 0.8776
Model performance on Happy speech (in validation): 
	Precision: 0.9167, Recall: 0.4400, F1_score: 0.5946
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.5200, F1_score: 0.6047
Model performance on Sad speech (in validation): 
	Precision: 0.5435, Recall: 1.0000, F1_score: 0.7042
Epoch 47/100

Training Phase:
Training loss: 2097.0833, Training accuracy: 0.6663
Macro F1-score: 0.6478
Model performance on Angry speech (in training): 
	Precision: 0.8990, Recall: 0.8675, F1_score: 0.8830
Model performance on Happy speech (in training): 
	Precision: 0.8439, Recall: 0.3650, F1_score: 0.5096
Model performance on Neutral speech (in training): 
	Precision: 0.6268, Recall: 0.4325, F1_score: 0.5118
Model performance on Sad speech (in training): 
	Precision: 0.5229, Recall: 1.0000, F1_score: 0.6867

Eval Phase: 
Validation loss: 236.8615, Validation accuracy: 0.7050
Macro F1-score: 0.6953
Model performance on Angry speech (in validation): 
	Precision: 0.8958, Recall: 0.8600, F1_score: 0.8776
Model performance on Happy speech (in validation): 
	Precision: 0.9167, Recall: 0.4400, F1_score: 0.5946
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.5200, F1_score: 0.6047
Model performance on Sad speech (in validation): 
	Precision: 0.5435, Recall: 1.0000, F1_score: 0.7042
Epoch 48/100

Training Phase:
s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 238/1600 [00:10<00:57, 23.75it/s]Training:  30%|███       | 483/1600 [00:20<00:46, 24.16it/s]Training:  46%|████▌     | 728/1600 [00:30<00:36, 24.17it/s]Training:  61%|██████    | 976/1600 [00:40<00:25, 24.41it/s]Training:  76%|███████▋  | 1224/1600 [00:50<00:15, 24.32it/s]Training:  92%|█████████▏| 1466/1600 [01:00<00:05, 24.26it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 239/1600 [00:10<00:57, 23.84it/s]Training:  30%|██▉       | 479/1600 [00:20<00:46, 23.92it/s]Training:  45%|████▌     | 721/1600 [00:30<00:36, 24.02it/s]Training:  60%|██████    | 966/1600 [00:40<00:2Training loss: 2093.3546, Training accuracy: 0.6606
Macro F1-score: 0.6390
Model performance on Angry speech (in training): 
	Precision: 0.8950, Recall: 0.8950, F1_score: 0.8950
Model performance on Happy speech (in training): 
	Precision: 0.8528, Recall: 0.3475, F1_score: 0.4938
Model performance on Neutral speech (in training): 
	Precision: 0.6082, Recall: 0.4075, F1_score: 0.4880
Model performance on Sad speech (in training): 
	Precision: 0.5163, Recall: 0.9925, F1_score: 0.6792

Eval Phase: 
Validation loss: 236.8615, Validation accuracy: 0.7050
Macro F1-score: 0.6953
Model performance on Angry speech (in validation): 
	Precision: 0.8958, Recall: 0.8600, F1_score: 0.8776
Model performance on Happy speech (in validation): 
	Precision: 0.9167, Recall: 0.4400, F1_score: 0.5946
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.5200, F1_score: 0.6047
Model performance on Sad speech (in validation): 
	Precision: 0.5435, Recall: 1.0000, F1_score: 0.7042
Epoch 49/100

Training Phase:
Training loss: 2194.7308, Training accuracy: 0.6663
Macro F1-score: 0.6462
Model performance on Angry speech (in training): 
	Precision: 0.9008, Recall: 0.8850, F1_score: 0.8928
Model performance on Happy speech (in training): 
	Precision: 0.8563, Recall: 0.3575, F1_score: 0.5044
Model performance on Neutral speech (in training): 
	Precision: 0.6168, Recall: 0.4225, F1_score: 0.5015
Model performance on Sad speech (in training): 
	Precision: 0.5222, Recall: 1.0000, F1_score: 0.6861

Eval Phase: 
Validation loss: 236.8615, Validation accuracy: 0.7050
Macro F1-score: 0.6953
Model performance on Angry speech (in validation): 
	Precision: 0.8958, Recall: 0.8600, F1_score: 0.8776
Model performance on Happy speech (in validation): 
	Precision: 0.9167, Recall: 0.4400, F1_score: 0.5946
Model performance on Neutral speech (in validation): 
	Precision: 0.7222, Recall: 0.5200, F1_score: 0.6047
Model performance on Sad speech (in validation): 
	Precision: 0.5435, Recall: 1.0000, F1_score: 0.7042
Epoch 50/100

Two-stage training complete.
Model best accuracy on validation set: 0.7050

Test Phase: 
6, 24.19it/s]Training:  76%|███████▌  | 1211/1600 [00:50<00:16, 24.15it/s]Training:  91%|█████████ | 1454/1600 [01:00<00:06, 24.20it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 243/1600 [00:10<00:56, 24.18it/s]Training:  30%|███       | 485/1600 [00:20<00:46, 24.19it/s]Training:  46%|████▌     | 730/1600 [00:30<00:35, 24.30it/s]Training:  61%|██████    | 975/1600 [00:40<00:25, 24.15it/s]Training:  76%|███████▌  | 1216/1600 [00:50<00:15, 24.13it/s]Training:  91%|█████████ | 1458/1600 [01:00<00:05, 24.15it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Testing:   0%|          | 0/200 [00:00<?, ?it/s]Testing:   1%|          | 2/200 [00:00<00:11, 17.08it/s]Testing:   2%|▏         | 4/200 [00:00<00:11, 17.06it/s]Testing:   3%|▎         | 6/200 [00:00<00:10, 17.67it/s]Testing:   4%|▍         | 8/200 [00:00<00:10, 17.73it/s]Testing:   6%|▌         | 11/200 [00:00<00:09, 20.82it/s]Testing:   8%|▊         | 15/200 [00:00<00:07, 24.59it/s]Testing:  10%|█         | 20/200 [00:00<00:05, 30.13it/s]Testing:  14%|█▎        | 27/200 [00:00<00:04, 40.45it/s]Testing:  16%|█▌        | 32/200 [00:01<00:04, 37.62it/s]Testing:  18%|█▊        | 37/200 [00:01<00:04, 35.80it/s]Testing:  21%|██        | 42/200 [00:01<00:04, 37.20it/s]Testing:  24%|██▍       | 48/200 [00:01<00:03, 41.77it/s]Testing:  26%|██▋       | 53/200 [00:01<00:03, 42.77it/s]Testing:  31%|███       | 62/200 [00:01<00:02, 49.25it/s]Testing:  34%|███▍      | 69/200 [00:01<00:02, 53.30it/s]Testing:  40%|███▉      | 79/200 [00:01<00:01, 63.76it/s]Testing:  44%|██Test loss: 297.6189, Test accuracy: 0.6550
Macro F1-score: 0.6328
Model performance on Angry speech (in test): 
	Precision: 0.9388, Recall: 0.9200, F1_score: 0.9293
Model performance on Happy speech (in test): 
	Precision: 0.8947, Recall: 0.3400, F1_score: 0.4928
Model performance on Neutral speech (in test): 
	Precision: 0.6207, Recall: 0.3600, F1_score: 0.4557
Model performance on Sad speech (in test): 
	Precision: 0.4854, Recall: 1.0000, F1_score: 0.6536

======================= This is fold_4 on cn =======================

Load dataset: 
Loading cn train data: fold_4...
Preprocess cn fold_4 data for cn model
Loading de eval data: fold_4...
Preprocess de fold_4 data for cn model
Loading de test data: fold_4...
Preprocess de fold_4 data for cn model
Use cn model to add lora
================== SET ALL PARAMS =====================
modified_wav2vec2.base_model.model.masked_spec_embed: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.0.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.0.layer_norm.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.0.layer_norm.bias: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.1.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.2.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.3.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.4.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.5.conv.weight: False
modified_wav2vec2.base_model.model.feature_extractor.conv_layers.6.conv.weight: False
modified_wav2vec2.base_model.model.feature_projection.layer_norm.weight: False
modified_wav2vec2.base_model.model.feature_projection.layer_norm.bias: False
modified_wav2vec2.base_model.model.feature_projection.projection.weight: False
modified_wav2vec2.base_model.model.feature_projection.projection.bias: False
modified_wav2vec2.base_model.model.encoder.pos_conv_embed.conv.bias: False
modified_wav2vec2.base_model.model.encoder.pos_conv_embed.conv.weight_g: False
modified_wav2vec2.base_model.model.encoder.pos_conv_embed.conv.weight_v: False
modified_wav2vec2.base_model.model.encoder.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.0.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.0.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.0.bottleneck_adaptor.up.bias: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.1.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.1.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.1.bottleneck_adaptor.up.bias: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.2.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.2.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.2.bottleneck_adaptor.up.bias: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.k_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.v_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.q_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.attention.out_proj.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.intermediate_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.base_layer.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.base_layer.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.lora_A.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.feed_forward.output_dense.lora_B.default.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.final_layer_norm.weight: False
modified_wav2vec2.base_model.model.encoder.layers.3.final_layer_norm.bias: False
modified_wav2vec2.base_model.model.encoder.layers.3.weighted_gate.gate: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.down.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.down.bias: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.up.weight: True
modified_wav2vec2.base_model.model.encoder.layers.3.bottleneck_adaptor.up.bias: True
normal_classifier.dense1.weight: True
normal_classifier.dense1.bias: True
normal_classifier.dense.weight: True
normal_classifier.dense.bias: True
normal_classifier.out.weight: True
normal_classifier.out.bias: True
Set optimizer and criterion
Epoch 1/100

Training Phase:
██▍     | 88/200 [00:02<00:01, 68.69it/s]Testing:  48%|████▊     | 95/200 [00:02<00:01, 68.32it/s]Testing:  51%|█████     | 102/200 [00:02<00:01, 62.93it/s]Testing:  55%|█████▍    | 109/200 [00:02<00:01, 64.57it/s]Testing:  58%|█████▊    | 116/200 [00:02<00:01, 60.99it/s]Testing:  62%|██████▎   | 125/200 [00:02<00:01, 67.69it/s]Testing:  68%|██████▊   | 135/200 [00:02<00:00, 76.09it/s]Testing:  72%|███████▏  | 144/200 [00:02<00:00, 79.42it/s]Testing:  77%|███████▋  | 154/200 [00:02<00:00, 83.20it/s]Testing:  82%|████████▏ | 164/200 [00:03<00:00, 87.49it/s]Testing:  87%|████████▋ | 174/200 [00:03<00:00, 88.77it/s]Testing:  92%|█████████▏| 184/200 [00:03<00:00, 91.93it/s]Testing:  97%|█████████▋| 194/200 [00:03<00:00, 93.55it/s]                                                          Training:   0%|          | 0/Training loss: 161.8644, Training accuracy: 0.9594
Macro F1-score: 0.9593
Model performance on Angry speech (in training): 
	Precision: 0.9524, Recall: 0.9500, F1_score: 0.9512
Model performance on Happy speech (in training): 
	Precision: 0.9347, Recall: 0.9300, F1_score: 0.9323
Model performance on Neutral speech (in training): 
	Precision: 0.9651, Recall: 0.9675, F1_score: 0.9663
Model performance on Sad speech (in training): 
	Precision: 0.9851, Recall: 0.9900, F1_score: 0.9875

Eval Phase: 
1600 [00:00<?, ?it/s]Training:  11%|█         | 179/1600 [00:10<01:19, 17.84it/s]Training:  25%|██▍       | 397/1600 [00:20<00:59, 20.15it/s]Training:  41%|████      | 649/1600 [00:30<00:42, 22.45it/s]Training:  57%|█████▋    | 912/1600 [00:40<00:28, 23.96it/s]Training:  74%|███████▍  | 1187/1600 [00:50<00:16, 25.22it/s]Training:  91%|█████████▏| 1462/1600 [01:00<00:05, 25.99it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 527.9328, Validation accuracy: 0.5400
Macro F1-score: 0.4745
Model performance on Angry speech (in validation): 
	Precision: 0.9333, Recall: 0.5600, F1_score: 0.7000
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.3333, Recall: 0.6000, F1_score: 0.4286
Model performance on Sad speech (in validation): 
	Precision: 0.6250, Recall: 1.0000, F1_score: 0.7692
New best accuracy for layer 3 on epoch 1: 0.5400. Model saved.
Epoch 2/100

Training Phase:
Training loss: 93.8474, Training accuracy: 0.9756
Macro F1-score: 0.9756
Model performance on Angry speech (in training): 
	Precision: 0.9607, Recall: 0.9775, F1_score: 0.9690
Model performance on Happy speech (in training): 
	Precision: 0.9671, Recall: 0.9550, F1_score: 0.9610
Model performance on Neutral speech (in training): 
	Precision: 0.9849, Recall: 0.9800, F1_score: 0.9825
Model performance on Sad speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900

Eval Phase: 
Validation loss: 695.9795, Validation accuracy: 0.3750
Macro F1-score: 0.3041
Model performance on Angry speech (in validation): 
	Precision: 1.0000, Recall: 0.3400, F1_score: 0.5075
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.2692, Recall: 0.1400, F1_score: 0.1842
Model performance on Sad speech (in validation): 
	Precision: 0.3205, Recall: 1.0000, F1_score: 0.4854
Epoch 3/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 309/1600 [00:10<00:41, 30.87it/s]Training:  39%|███▊      | 618/1600 [00:20<00:32, 30.65it/s]Training:  58%|█████▊    | 923/1600 [00:30<00:22, 30.51it/s]Training:  77%|███████▋  | 1227/1600 [00:40<00:12, 30.24it/s]Training:  96%|█████████▌| 1532/1600 [00:50<00:02, 30.30it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 303/1600 [00:10<00:42, 30.25it/s]Training:  38%|███▊      | 611/1600 [00:20<00:32, 30.56it/s]Training:  57%|█████▋    | 919/1600 [00:30<00:22, 30.57it/s]Training:  57%|█████▋    | 919/1600 [00:46<00:22, 30.57it/s]Training:  73%|███████▎  | 1165/1600 [00:46<00:19, 22.71it/s]Training:  73%|████Training loss: 51.6277, Training accuracy: 0.9931
Macro F1-score: 0.9931
Model performance on Angry speech (in training): 
	Precision: 0.9876, Recall: 0.9925, F1_score: 0.9900
Model performance on Happy speech (in training): 
	Precision: 0.9875, Recall: 0.9850, F1_score: 0.9862
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987

Eval Phase: 
Validation loss: 476.8595, Validation accuracy: 0.5800
Macro F1-score: 0.5191
Model performance on Angry speech (in validation): 
	Precision: 0.9231, Recall: 0.7200, F1_score: 0.8090
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0400, F1_score: 0.0769
Model performance on Neutral speech (in validation): 
	Precision: 0.3836, Recall: 0.5600, F1_score: 0.4553
Model performance on Sad speech (in validation): 
	Precision: 0.5814, Recall: 1.0000, F1_score: 0.7353
New best accuracy for layer 3 on epoch 3: 0.5800. Model saved.
Epoch 4/100

Training Phase:
Training loss: 42.3160, Training accuracy: 0.9912
Macro F1-score: 0.9912
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912
Model performance on Happy speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900
Model performance on Neutral speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925

Eval Phase: 
Validation loss: 494.0016, Validation accuracy: 0.6300
Macro F1-score: 0.5523
Model performance on Angry speech (in validation): 
	Precision: 0.8148, Recall: 0.8800, F1_score: 0.8462
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.4247, Recall: 0.6200, F1_score: 0.5041
Model performance on Sad speech (in validation): 
	Precision: 0.6944, Recall: 1.0000, F1_score: 0.8197
New best accuracy for layer 3 on epoch 4: 0.6300. Model saved.
Epoch 5/100

Training Phase:
██▎  | 1165/1600 [00:56<00:19, 22.71it/s]Training:  87%|████████▋ | 1389/1600 [00:56<00:09, 22.61it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  17%|█▋        | 267/1600 [00:10<00:50, 26.64it/s]Training:  35%|███▍      | 554/1600 [00:20<00:37, 27.80it/s]Training:  53%|█████▎    | 841/1600 [00:30<00:27, 27.97it/s]Training:  70%|███████   | 1123/1600 [00:41<00:17, 27.10it/s]Training:  88%|████████▊ | 1413/1600 [00:51<00:06, 27.76it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 303/1600 [00:10<00:42, 30.28it/s]Training:  38%|███▊ Training loss: 41.0988, Training accuracy: 0.9912
Macro F1-score: 0.9912
Model performance on Angry speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913
Model performance on Happy speech (in training): 
	Precision: 0.9850, Recall: 0.9825, F1_score: 0.9837
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
     | 609/1600 [00:20<00:32, 30.41it/s]Training:  57%|█████▋    | 916/1600 [00:30<00:22, 30.54it/s]Training:  77%|███████▋  | 1229/1600 [00:40<00:12, 30.80it/s]Training:  96%|█████████▋| 1542/1600 [00:50<00:01, 30.62it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 554.8614, Validation accuracy: 0.5900
Macro F1-score: 0.5112
Model performance on Angry speech (in validation): 
	Precision: 0.8163, Recall: 0.8000, F1_score: 0.8081
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.3836, Recall: 0.5600, F1_score: 0.4553
Model performance on Sad speech (in validation): 
	Precision: 0.6410, Recall: 1.0000, F1_score: 0.7812
Epoch 6/100

Training Phase:
Training loss: 44.5682, Training accuracy: 0.9912
Macro F1-score: 0.9913
Model performance on Angry speech (in training): 
	Precision: 0.9850, Recall: 0.9850, F1_score: 0.9850
Model performance on Happy speech (in training): 
	Precision: 0.9825, Recall: 0.9825, F1_score: 0.9825
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 304/1600 [00:10<00:42, 30.30it/s]Training:  38%|███▊      | 612/1600 [00:20<00:32, 30.57it/s]Training:  57%|█████▊    | 920/1600 [00:30<00:22, 30.58it/s]Training:  77%|███████▋  | 1227/1600 [00:40<00:12, 30.60it/s]Training:  96%|█████████▌| 1534/1600 [00:50<00:02, 30.50it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 484.1814, Validation accuracy: 0.6500
Macro F1-score: 0.5531
Model performance on Angry speech (in validation): 
	Precision: 0.6761, Recall: 0.9600, F1_score: 0.7934
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.5517, Recall: 0.6400, F1_score: 0.5926
Model performance on Sad speech (in validation): 
	Precision: 0.7042, Recall: 1.0000, F1_score: 0.8264
New best accuracy for layer 3 on epoch 6: 0.6500. Model saved.
Epoch 7/100

Training Phase:
Training loss: 39.6235, Training accuracy: 0.9919
Macro F1-score: 0.9919
Model performance on Angry speech (in training): 
	Precision: 0.9851, Recall: 0.9900, F1_score: 0.9875
Model performance on Happy speech (in training): 
	Precision: 0.9900, Recall: 0.9875, F1_score: 0.9887
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9925, F1_score: 0.9950
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963

Eval Phase: 
Validation loss: 597.3946, Validation accuracy: 0.4850
Macro F1-score: 0.4231
Model performance on Angry speech (in validation): 
	Precision: 0.9167, Recall: 0.6600, F1_score: 0.7674
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0400, F1_score: 0.0769
Model performance on Neutral speech (in validation): 
	Precision: 0.3000, Recall: 0.2400, F1_score: 0.2667
Model performance on Sad speech (in validation): 
	Precision: 0.4098, Recall: 1.0000, F1_score: 0.5814
Epoch 8/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 302/1600 [00:10<00:43, 30.16it/s]Training:  38%|███▊      | 607/1600 [00:20<00:32, 30.31it/s]Training:  57%|█████▋    | 916/1600 [00:30<00:22, 30.54it/s]Training:  77%|███████▋  | 1225/1600 [00:40<00:12, 30.63it/s]Training:  96%|█████████▌| 1533/1600 [00:50<00:02, 30.58it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 305/1600 [00:10<00:42, 30.39it/s]Training:  38%|███▊      | 610/1600 [00:20<00:32, 30.42it/s]Training:  57%|█████▋    | 915/1600 [00:30<00:22, 30.32it/s]Training:  76%|███████▋  | 1221/1600 [00:40<00:12, 30.41it/s]Training:  95%|█████████▌| 1527/1600 [00:50<00:02, 30.43it/s]                   Training loss: 23.7616, Training accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9925, F1_score: 0.9925
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 426.1607, Validation accuracy: 0.6050
Macro F1-score: 0.5276
Model performance on Angry speech (in validation): 
	Precision: 0.8000, Recall: 0.9600, F1_score: 0.8727
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0600, F1_score: 0.1132
Model performance on Neutral speech (in validation): 
	Precision: 0.4878, Recall: 0.4000, F1_score: 0.4396
Model performance on Sad speech (in validation): 
	Precision: 0.5208, Recall: 1.0000, F1_score: 0.6849
Epoch 9/100

Training Phase:
Training loss: 26.1117, Training accuracy: 0.9944
Macro F1-score: 0.9944
Model performance on Angry speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9900, F1_score: 0.9912
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988

Eval Phase: 
Validation loss: 472.8933, Validation accuracy: 0.6600
Macro F1-score: 0.5802
Model performance on Angry speech (in validation): 
	Precision: 0.8136, Recall: 0.9600, F1_score: 0.8807
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0400, F1_score: 0.0769
Model performance on Neutral speech (in validation): 
	Precision: 0.4923, Recall: 0.6400, F1_score: 0.5565
Model performance on Sad speech (in validation): 
	Precision: 0.6757, Recall: 1.0000, F1_score: 0.8065
New best accuracy for layer 3 on epoch 9: 0.6600. Model saved.
Epoch 10/100

Training Phase:
                                          Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 308/1600 [00:10<00:42, 30.75it/s]Training:  38%|███▊      | 616/1600 [00:20<00:32, 30.45it/s]Training:  58%|█████▊    | 921/1600 [00:30<00:22, 30.43it/s]Training:  77%|███████▋  | 1226/1600 [00:40<00:12, 30.43it/s]Training:  96%|█████████▌| 1531/1600 [00:50<00:02, 30.42it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 303/1600 [00:10<00:42, 30.24it/s]Training:  38%|███▊      | 606/1600 [00:20<00:32, 30.21it/s]Training:  57%|█████▋    | 914/1600 [00:30<00:22, 30.45it/s]Training:  76%|█████Training loss: 43.5143, Training accuracy: 0.9919
Macro F1-score: 0.9919
Model performance on Angry speech (in training): 
	Precision: 0.9801, Recall: 0.9875, F1_score: 0.9838
Model performance on Happy speech (in training): 
	Precision: 0.9874, Recall: 0.9825, F1_score: 0.9850
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 384.4466, Validation accuracy: 0.6250
Macro F1-score: 0.5702
Model performance on Angry speech (in validation): 
	Precision: 0.8846, Recall: 0.9200, F1_score: 0.9020
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.1200, F1_score: 0.2143
Model performance on Neutral speech (in validation): 
	Precision: 0.4510, Recall: 0.4600, F1_score: 0.4554
Model performance on Sad speech (in validation): 
	Precision: 0.5495, Recall: 1.0000, F1_score: 0.7092
Epoch 11/100

Training Phase:
Training loss: 13.3511, Training accuracy: 0.9981
Macro F1-score: 0.9981
Model performance on Angry speech (in training): 
	Precision: 0.9926, Recall: 1.0000, F1_score: 0.9963
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.9925, F1_score: 0.9962
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Validation loss: 561.0848, Validation accuracy: 0.6500
Macro F1-score: 0.5625
Model performance on Angry speech (in validation): 
	Precision: 0.7869, Recall: 0.9600, F1_score: 0.8649
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0200, F1_score: 0.0392
Model performance on Neutral speech (in validation): 
	Precision: 0.5082, Recall: 0.6200, F1_score: 0.5586
Model performance on Sad speech (in validation): 
	Precision: 0.6494, Recall: 1.0000, F1_score: 0.7874
Epoch 12/100

Training Phase:
█▋  | 1222/1600 [00:40<00:12, 30.38it/s]Training:  96%|█████████▌| 1529/1600 [00:50<00:02, 30.46it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 302/1600 [00:10<00:43, 30.11it/s]Training:  38%|███▊      | 610/1600 [00:20<00:32, 30.46it/s]Training:  57%|█████▋    | 918/1600 [00:30<00:22, 30.57it/s]Training:  77%|███████▋  | 1225/1600 [00:40<00:12, 30.47it/s]Training:  96%|█████████▌| 1530/1600 [00:50<00:02, 30.47it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 307/1600 [00:10<00:42, 30.69it/s]Training:  38%|███Training loss: 35.2219, Training accuracy: 0.9912
Macro F1-score: 0.9912
Model performance on Angry speech (in training): 
	Precision: 0.9900, Recall: 0.9900, F1_score: 0.9900
Model performance on Happy speech (in training): 
	Precision: 0.9850, Recall: 0.9825, F1_score: 0.9837
Model performance on Neutral speech (in training): 
	Precision: 0.9900, Recall: 0.9925, F1_score: 0.9913
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
      | 616/1600 [00:20<00:31, 30.80it/s]Training:  58%|█████▊    | 925/1600 [00:30<00:22, 30.54it/s]Training:  77%|███████▋  | 1230/1600 [00:40<00:12, 30.52it/s]Training:  96%|█████████▌| 1536/1600 [00:50<00:02, 30.54it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 628.4559, Validation accuracy: 0.6700
Macro F1-score: 0.5770
Model performance on Angry speech (in validation): 
	Precision: 0.6667, Recall: 0.9600, F1_score: 0.7869
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.5362, Recall: 0.7400, F1_score: 0.6218
Model performance on Sad speech (in validation): 
	Precision: 0.8305, Recall: 0.9800, F1_score: 0.8991
New best accuracy for layer 3 on epoch 12: 0.6700. Model saved.
Epoch 13/100

Training Phase:
Training loss: 18.1011, Training accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962
Model performance on Happy speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938
Model performance on Neutral speech (in training): 
	Precision: 0.9975, Recall: 0.9950, F1_score: 0.9962
Model performance on Sad speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938

Eval Phase: 
Validation loss: 542.6619, Validation accuracy: 0.5850
Macro F1-score: 0.4999
Model performance on Angry speech (in validation): 
	Precision: 0.7869, Recall: 0.9600, F1_score: 0.8649
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0400, F1_score: 0.0769
Model performance on Neutral speech (in validation): 
	Precision: 0.4857, Recall: 0.3400, F1_score: 0.4000
Model performance on Sad speech (in validation): 
	Precision: 0.4902, Recall: 1.0000, F1_score: 0.6579
Epoch 14/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 303/1600 [00:10<00:42, 30.20it/s]Training:  38%|███▊      | 610/1600 [00:20<00:32, 30.49it/s]Training:  57%|█████▋    | 917/1600 [00:30<00:22, 30.44it/s]Training:  76%|███████▋  | 1221/1600 [00:40<00:12, 30.42it/s]Training:  95%|█████████▌| 1525/1600 [00:50<00:02, 30.40it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 308/1600 [00:10<00:42, 30.75it/s]Training:  38%|███▊      | 616/1600 [00:20<00:32, 30.45it/s]Training:  58%|█████▊    | 925/1600 [00:30<00:22, 30.64it/s]Training:  77%|███████▋  | 1234/1600 [00:40<00:11, 30.53it/s]Training:  96%|█████████▌| 1538/1600 [00:50<00:02, 30.43it/s]                   Training loss: 27.4075, Training accuracy: 0.9950
Macro F1-score: 0.9950
Model performance on Angry speech (in training): 
	Precision: 0.9926, Recall: 1.0000, F1_score: 0.9963
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.9950, F1_score: 0.9975
Model performance on Neutral speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9900, F1_score: 0.9925

Eval Phase: 
Validation loss: 621.7642, Validation accuracy: 0.5900
Macro F1-score: 0.5022
Model performance on Angry speech (in validation): 
	Precision: 0.7273, Recall: 0.9600, F1_score: 0.8276
Model performance on Happy speech (in validation): 
	Precision: 1.0000, Recall: 0.0400, F1_score: 0.0769
Model performance on Neutral speech (in validation): 
	Precision: 0.5294, Recall: 0.3600, F1_score: 0.4286
Model performance on Sad speech (in validation): 
	Precision: 0.5102, Recall: 1.0000, F1_score: 0.6757
Epoch 15/100

Training Phase:
Training loss: 29.0285, Training accuracy: 0.9944
Macro F1-score: 0.9944
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9900, F1_score: 0.9925
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963

Eval Phase: 
                                          Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 306/1600 [00:10<00:42, 30.60it/s]Training:  38%|███▊      | 612/1600 [00:20<00:32, 30.54it/s]Training:  57%|█████▋    | 918/1600 [00:30<00:22, 30.55it/s]Training:  77%|███████▋  | 1226/1600 [00:40<00:12, 30.63it/s]Training:  96%|█████████▌| 1534/1600 [00:50<00:02, 30.52it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 629.9841, Validation accuracy: 0.6050
Macro F1-score: 0.5051
Model performance on Angry speech (in validation): 
	Precision: 0.5714, Recall: 0.9600, F1_score: 0.7164
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.6389, Recall: 0.4600, F1_score: 0.5349
Model performance on Sad speech (in validation): 
	Precision: 0.6250, Recall: 1.0000, F1_score: 0.7692
Epoch 16/100

Training Phase:
Training loss: 11.2784, Training accuracy: 0.9962
Macro F1-score: 0.9963
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9975, F1_score: 0.9950
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9925, F1_score: 0.9937
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987
Model performance on Sad speech (in training): 
	Precision: 0.9975, Recall: 0.9975, F1_score: 0.9975

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 306/1600 [00:10<00:42, 30.49it/s]Training:  38%|███▊      | 611/1600 [00:20<00:32, 30.49it/s]Training:  57%|█████▋    | 917/1600 [00:30<00:22, 30.52it/s]Training:  76%|███████▋  | 1223/1600 [00:40<00:12, 30.50it/s]Training:  96%|█████████▌| 1531/1600 [00:50<00:02, 30.58it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 787.9395, Validation accuracy: 0.5400
Macro F1-score: 0.4318
Model performance on Angry speech (in validation): 
	Precision: 0.6912, Recall: 0.9400, F1_score: 0.7966
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.5000, Recall: 0.2200, F1_score: 0.3056
Model performance on Sad speech (in validation): 
	Precision: 0.4545, Recall: 1.0000, F1_score: 0.6250
Epoch 17/100

Training Phase:
Training loss: 18.8994, Training accuracy: 0.9956
Macro F1-score: 0.9956
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9875, F1_score: 0.9912
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 1.0000, F1_score: 0.9975
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 303/1600 [00:10<00:42, 30.29it/s]Training:  38%|███▊      | 609/1600 [00:20<00:32, 30.47it/s]Training:  57%|█████▋    | 915/1600 [00:30<00:22, 30.41it/s]Training:  76%|███████▋  | 1222/1600 [00:40<00:12, 30.51it/s]Training:  96%|█████████▌| 1529/1600 [00:50<00:02, 30.50it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 893.5774, Validation accuracy: 0.4850
Macro F1-score: 0.3990
Model performance on Angry speech (in validation): 
	Precision: 0.8864, Recall: 0.7800, F1_score: 0.8298
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.4000, Recall: 0.1600, F1_score: 0.2286
Model performance on Sad speech (in validation): 
	Precision: 0.3676, Recall: 1.0000, F1_score: 0.5376
Epoch 18/100

Training Phase:
Training loss: 36.3116, Training accuracy: 0.9938
Macro F1-score: 0.9938
Model performance on Angry speech (in training): 
	Precision: 0.9950, Recall: 0.9875, F1_score: 0.9912
Model performance on Happy speech (in training): 
	Precision: 0.9851, Recall: 0.9900, F1_score: 0.9875
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9975, F1_score: 0.9963
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 304/1600 [00:10<00:42, 30.32it/s]Training:  38%|███▊      | 608/1600 [00:20<00:32, 30.25it/s]Training:  57%|█████▋    | 915/1600 [00:30<00:22, 30.44it/s]Training:  76%|███████▋  | 1222/1600 [00:40<00:12, 30.46it/s]Training:  96%|█████████▌| 1528/1600 [00:50<00:02, 30.49it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 908.6355, Validation accuracy: 0.5350
Macro F1-score: 0.4502
Model performance on Angry speech (in validation): 
	Precision: 0.8039, Recall: 0.8200, F1_score: 0.8119
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.3333, Recall: 0.3200, F1_score: 0.3265
Model performance on Sad speech (in validation): 
	Precision: 0.4950, Recall: 1.0000, F1_score: 0.6623
Epoch 19/100

Training Phase:
Training loss: 17.5423, Training accuracy: 0.9969
Macro F1-score: 0.9969
Model performance on Angry speech (in training): 
	Precision: 0.9925, Recall: 0.9950, F1_score: 0.9938
Model performance on Happy speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Neutral speech (in training): 
	Precision: 1.0000, Recall: 1.0000, F1_score: 1.0000
Model performance on Sad speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 305/1600 [00:10<00:42, 30.45it/s]Training:  38%|███▊      | 611/1600 [00:20<00:32, 30.52it/s]Training:  57%|█████▋    | 918/1600 [00:30<00:22, 30.60it/s]Training:  77%|███████▋  | 1225/1600 [00:40<00:12, 30.50it/s]Training:  96%|█████████▌| 1529/1600 [00:50<00:02, 30.46it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 932.5747, Validation accuracy: 0.5200
Macro F1-score: 0.4413
Model performance on Angry speech (in validation): 
	Precision: 0.9091, Recall: 0.8000, F1_score: 0.8511
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.3333, Recall: 0.2800, F1_score: 0.3043
Model performance on Sad speech (in validation): 
	Precision: 0.4386, Recall: 1.0000, F1_score: 0.6098
Epoch 20/100

Training Phase:
Training loss: 27.6164, Training accuracy: 0.9969
Macro F1-score: 0.9969
Model performance on Angry speech (in training): 
	Precision: 1.0000, Recall: 0.9975, F1_score: 0.9987
Model performance on Happy speech (in training): 
	Precision: 0.9975, Recall: 1.0000, F1_score: 0.9988
Model performance on Neutral speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950
Model performance on Sad speech (in training): 
	Precision: 0.9950, Recall: 0.9950, F1_score: 0.9950

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  19%|█▉        | 304/1600 [00:10<00:42, 30.33it/s]Training:  38%|███▊      | 610/1600 [00:20<00:32, 30.46it/s]Training:  57%|█████▋    | 916/1600 [00:30<00:22, 30.49it/s]Training:  76%|███████▋  | 1224/1600 [00:40<00:12, 30.58it/s]Training:  96%|█████████▌| 1532/1600 [00:50<00:02, 30.56it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 1049.0175, Validation accuracy: 0.4700
Macro F1-score: 0.3491
Model performance on Angry speech (in validation): 
	Precision: 0.8113, Recall: 0.8600, F1_score: 0.8350
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.1429, Recall: 0.0200, F1_score: 0.0351
Model performance on Sad speech (in validation): 
	Precision: 0.3571, Recall: 1.0000, F1_score: 0.5263
Validation loss does not decrease for 10 epochs. End training.
Epoch 21/100

Entering 2ND training phase: change training data from cn to DE
Loading de train data: fold_4...
Preprocess de fold_4 data for cn model
Reload model and reset eval loss

Training Phase:
Training loss: 4737.1927, Training accuracy: 0.6262
Macro F1-score: 0.5385
Model performance on Angry speech (in training): 
	Precision: 0.5244, Recall: 0.9675, F1_score: 0.6801
Model performance on Happy speech (in training): 
	Precision: 0.6000, Recall: 0.0075, F1_score: 0.0148
Model performance on Neutral speech (in training): 
	Precision: 0.6243, Recall: 0.5775, F1_score: 0.6000
Model performance on Sad speech (in training): 
	Precision: 0.7823, Recall: 0.9525, F1_score: 0.8591

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:   9%|▊         | 138/1600 [00:10<01:46, 13.76it/s]Training:  19%|█▉        | 303/1600 [00:20<01:24, 15.36it/s]Training:  30%|███       | 483/1600 [00:30<01:07, 16.55it/s]Training:  42%|████▏     | 679/1600 [00:40<00:51, 17.73it/s]Training:  55%|█████▌    | 880/1600 [00:50<00:38, 18.56it/s]Training:  68%|██████▊   | 1088/1600 [01:00<00:26, 19.31it/s]Training:  81%|████████  | 1296/1600 [01:10<00:15, 19.70it/s]Training:  94%|█████████▍| 1507/1600 [01:20<00:04, 20.12it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 628.4559, Validation accuracy: 0.6700
Macro F1-score: 0.5770
Model performance on Angry speech (in validation): 
	Precision: 0.6667, Recall: 0.9600, F1_score: 0.7869
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.5362, Recall: 0.7400, F1_score: 0.6218
Model performance on Sad speech (in validation): 
	Precision: 0.8305, Recall: 0.9800, F1_score: 0.8991
Epoch 22/100

Training Phase:
Training loss: 4664.2864, Training accuracy: 0.6306
Macro F1-score: 0.5428
Model performance on Angry speech (in training): 
	Precision: 0.5193, Recall: 0.9750, F1_score: 0.6777
Model performance on Happy speech (in training): 
	Precision: 0.7500, Recall: 0.0075, F1_score: 0.0149
Model performance on Neutral speech (in training): 
	Precision: 0.6346, Recall: 0.5775, F1_score: 0.6047
Model performance on Sad speech (in training): 
	Precision: 0.8004, Recall: 0.9625, F1_score: 0.8740

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 231/1600 [00:10<00:59, 23.03it/s]Training:  29%|██▉       | 465/1600 [00:20<00:48, 23.23it/s]Training:  44%|████▎     | 699/1600 [00:30<00:38, 23.24it/s]Training:  58%|█████▊    | 932/1600 [00:40<00:28, 23.12it/s]Training:  73%|███████▎  | 1162/1600 [00:50<00:19, 22.77it/s]Training:  86%|████████▋ | 1384/1600 [01:00<00:09, 22.57it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 628.4559, Validation accuracy: 0.6700
Macro F1-score: 0.5770
Model performance on Angry speech (in validation): 
	Precision: 0.6667, Recall: 0.9600, F1_score: 0.7869
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.5362, Recall: 0.7400, F1_score: 0.6218
Model performance on Sad speech (in validation): 
	Precision: 0.8305, Recall: 0.9800, F1_score: 0.8991
Epoch 23/100

Training Phase:
Training loss: 4706.4319, Training accuracy: 0.6369
Macro F1-score: 0.5486
Model performance on Angry speech (in training): 
	Precision: 0.5328, Recall: 0.9750, F1_score: 0.6890
Model performance on Happy speech (in training): 
	Precision: 0.4286, Recall: 0.0075, F1_score: 0.0147
Model performance on Neutral speech (in training): 
	Precision: 0.6478, Recall: 0.6025, F1_score: 0.6244
Model performance on Sad speech (in training): 
	Precision: 0.7873, Recall: 0.9625, F1_score: 0.8661

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▎        | 217/1600 [00:10<01:03, 21.70it/s]Training:  28%|██▊       | 444/1600 [00:20<00:51, 22.28it/s]Training:  42%|████▏     | 678/1600 [00:30<00:40, 22.74it/s]Training:  57%|█████▋    | 919/1600 [00:40<00:29, 23.27it/s]Training:  72%|███████▎  | 1160/1600 [00:50<00:18, 23.54it/s]Training:  88%|████████▊ | 1406/1600 [01:00<00:08, 23.87it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 628.4559, Validation accuracy: 0.6700
Macro F1-score: 0.5770
Model performance on Angry speech (in validation): 
	Precision: 0.6667, Recall: 0.9600, F1_score: 0.7869
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.5362, Recall: 0.7400, F1_score: 0.6218
Model performance on Sad speech (in validation): 
	Precision: 0.8305, Recall: 0.9800, F1_score: 0.8991
Epoch 24/100

Training Phase:
Training loss: 4755.3710, Training accuracy: 0.6275
Macro F1-score: 0.5389
Model performance on Angry speech (in training): 
	Precision: 0.5160, Recall: 0.9700, F1_score: 0.6736
Model performance on Happy speech (in training): 
	Precision: 0.2500, Recall: 0.0025, F1_score: 0.0050
Model performance on Neutral speech (in training): 
	Precision: 0.6508, Recall: 0.5825, F1_score: 0.6148
Model performance on Sad speech (in training): 
	Precision: 0.7860, Recall: 0.9550, F1_score: 0.8623

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 243/1600 [00:10<00:55, 24.29it/s]Training:  30%|███       | 486/1600 [00:20<00:45, 24.22it/s]Training:  30%|███       | 486/1600 [00:30<00:45, 24.22it/s]Training:  46%|████▌     | 728/1600 [00:30<00:36, 23.91it/s]Training:  61%|██████    | 969/1600 [00:40<00:26, 23.98it/s]Training:  76%|███████▌  | 1213/1600 [00:50<00:16, 24.13it/s]Training:  91%|█████████ | 1459/1600 [01:00<00:05, 24.29it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 628.4559, Validation accuracy: 0.6700
Macro F1-score: 0.5770
Model performance on Angry speech (in validation): 
	Precision: 0.6667, Recall: 0.9600, F1_score: 0.7869
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.5362, Recall: 0.7400, F1_score: 0.6218
Model performance on Sad speech (in validation): 
	Precision: 0.8305, Recall: 0.9800, F1_score: 0.8991
Epoch 25/100

Training Phase:
Training loss: 4679.1933, Training accuracy: 0.6312
Macro F1-score: 0.5411
Model performance on Angry speech (in training): 
	Precision: 0.5209, Recall: 0.9675, F1_score: 0.6772
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.0025, F1_score: 0.0050
Model performance on Neutral speech (in training): 
	Precision: 0.6611, Recall: 0.5900, F1_score: 0.6235
Model performance on Sad speech (in training): 
	Precision: 0.7735, Recall: 0.9650, F1_score: 0.8587

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 243/1600 [00:10<00:55, 24.26it/s]Training:  30%|███       | 486/1600 [00:20<00:45, 24.25it/s]Training:  46%|████▌     | 729/1600 [00:30<00:36, 24.18it/s]Training:  61%|██████    | 975/1600 [00:40<00:25, 24.33it/s]Training:  76%|███████▋  | 1221/1600 [00:50<00:15, 24.33it/s]Training:  92%|█████████▏| 1465/1600 [01:00<00:05, 24.35it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 628.4559, Validation accuracy: 0.6700
Macro F1-score: 0.5770
Model performance on Angry speech (in validation): 
	Precision: 0.6667, Recall: 0.9600, F1_score: 0.7869
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.5362, Recall: 0.7400, F1_score: 0.6218
Model performance on Sad speech (in validation): 
	Precision: 0.8305, Recall: 0.9800, F1_score: 0.8991
Epoch 26/100

Training Phase:
Training loss: 4662.9243, Training accuracy: 0.6356
Macro F1-score: 0.5443
Model performance on Angry speech (in training): 
	Precision: 0.5355, Recall: 0.9800, F1_score: 0.6926
Model performance on Happy speech (in training): 
	Precision: 0.3333, Recall: 0.0025, F1_score: 0.0050
Model performance on Neutral speech (in training): 
	Precision: 0.6556, Recall: 0.5950, F1_score: 0.6239
Model performance on Sad speech (in training): 
	Precision: 0.7689, Recall: 0.9650, F1_score: 0.8559

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 244/1600 [00:10<00:55, 24.32it/s]Training:  30%|███       | 488/1600 [00:20<00:45, 24.36it/s]Training:  46%|████▌     | 732/1600 [00:30<00:35, 24.18it/s]Training:  61%|██████    | 975/1600 [00:40<00:25, 24.20it/s]Training:  76%|███████▌  | 1218/1600 [00:50<00:15, 24.15it/s]Training:  91%|█████████▏| 1461/1600 [01:00<00:05, 24.20it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 628.4559, Validation accuracy: 0.6700
Macro F1-score: 0.5770
Model performance on Angry speech (in validation): 
	Precision: 0.6667, Recall: 0.9600, F1_score: 0.7869
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.5362, Recall: 0.7400, F1_score: 0.6218
Model performance on Sad speech (in validation): 
	Precision: 0.8305, Recall: 0.9800, F1_score: 0.8991
Epoch 27/100

Training Phase:
Training loss: 4745.6647, Training accuracy: 0.6381
Macro F1-score: 0.5515
Model performance on Angry speech (in training): 
	Precision: 0.5220, Recall: 0.9800, F1_score: 0.6811
Model performance on Happy speech (in training): 
	Precision: 0.8000, Recall: 0.0100, F1_score: 0.0198
Model performance on Neutral speech (in training): 
	Precision: 0.6630, Recall: 0.6100, F1_score: 0.6354
Model performance on Sad speech (in training): 
	Precision: 0.8004, Recall: 0.9525, F1_score: 0.8699

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 244/1600 [00:10<00:55, 24.32it/s]Training:  30%|███       | 488/1600 [00:20<00:45, 24.25it/s]Training:  46%|████▌     | 731/1600 [00:30<00:35, 24.15it/s]Training:  61%|██████    | 975/1600 [00:40<00:25, 24.24it/s]Training:  76%|███████▌  | 1219/1600 [00:50<00:15, 24.23it/s]Training:  91%|█████████▏| 1462/1600 [01:00<00:05, 24.19it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 628.4559, Validation accuracy: 0.6700
Macro F1-score: 0.5770
Model performance on Angry speech (in validation): 
	Precision: 0.6667, Recall: 0.9600, F1_score: 0.7869
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.5362, Recall: 0.7400, F1_score: 0.6218
Model performance on Sad speech (in validation): 
	Precision: 0.8305, Recall: 0.9800, F1_score: 0.8991
Epoch 28/100

Training Phase:
Training loss: 4685.2352, Training accuracy: 0.6438
Macro F1-score: 0.5542
Model performance on Angry speech (in training): 
	Precision: 0.5424, Recall: 0.9750, F1_score: 0.6971
Model performance on Happy speech (in training): 
	Precision: 0.7500, Recall: 0.0075, F1_score: 0.0149
Model performance on Neutral speech (in training): 
	Precision: 0.6519, Recall: 0.6275, F1_score: 0.6395
Model performance on Sad speech (in training): 
	Precision: 0.7846, Recall: 0.9650, F1_score: 0.8655

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  16%|█▌        | 248/1600 [00:10<00:54, 24.76it/s]Training:  31%|███       | 496/1600 [00:20<00:45, 24.41it/s]Training:  31%|███       | 496/1600 [00:30<00:45, 24.41it/s]Training:  43%|████▎     | 684/1600 [00:30<00:42, 21.72it/s]Training:  58%|█████▊    | 923/1600 [00:40<00:30, 22.55it/s]Training:  73%|███████▎  | 1164/1600 [00:50<00:18, 23.09it/s]Training:  88%|████████▊ | 1405/1600 [01:00<00:08, 23.40it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 628.4559, Validation accuracy: 0.6700
Macro F1-score: 0.5770
Model performance on Angry speech (in validation): 
	Precision: 0.6667, Recall: 0.9600, F1_score: 0.7869
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.5362, Recall: 0.7400, F1_score: 0.6218
Model performance on Sad speech (in validation): 
	Precision: 0.8305, Recall: 0.9800, F1_score: 0.8991
Epoch 29/100

Training Phase:
Training loss: 4682.5262, Training accuracy: 0.6400
Macro F1-score: 0.5527
Model performance on Angry speech (in training): 
	Precision: 0.5330, Recall: 0.9700, F1_score: 0.6879
Model performance on Happy speech (in training): 
	Precision: 0.5714, Recall: 0.0100, F1_score: 0.0197
Model performance on Neutral speech (in training): 
	Precision: 0.6517, Recall: 0.6175, F1_score: 0.6341
Model performance on Sad speech (in training): 
	Precision: 0.7922, Recall: 0.9625, F1_score: 0.8691

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 241/1600 [00:10<00:56, 24.03it/s]Training:  30%|███       | 483/1600 [00:20<00:46, 24.10it/s]Training:  45%|████▌     | 727/1600 [00:30<00:36, 24.23it/s]Training:  61%|██████    | 971/1600 [00:40<00:26, 24.06it/s]Training:  76%|███████▌  | 1217/1600 [00:50<00:15, 24.23it/s]Training:  91%|█████████▏| 1463/1600 [01:00<00:05, 24.16it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 628.4559, Validation accuracy: 0.6700
Macro F1-score: 0.5770
Model performance on Angry speech (in validation): 
	Precision: 0.6667, Recall: 0.9600, F1_score: 0.7869
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.5362, Recall: 0.7400, F1_score: 0.6218
Model performance on Sad speech (in validation): 
	Precision: 0.8305, Recall: 0.9800, F1_score: 0.8991
Epoch 30/100

Training Phase:
Training loss: 4635.1551, Training accuracy: 0.6350
Macro F1-score: 0.5469
Model performance on Angry speech (in training): 
	Precision: 0.5293, Recall: 0.9725, F1_score: 0.6855
Model performance on Happy speech (in training): 
	Precision: 1.0000, Recall: 0.0075, F1_score: 0.0149
Model performance on Neutral speech (in training): 
	Precision: 0.6421, Recall: 0.6100, F1_score: 0.6256
Model performance on Sad speech (in training): 
	Precision: 0.7884, Recall: 0.9500, F1_score: 0.8617

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 240/1600 [00:10<00:56, 23.98it/s]Training:  30%|███       | 486/1600 [00:20<00:45, 24.32it/s]Training:  30%|███       | 486/1600 [00:30<00:45, 24.32it/s]Training:  46%|████▌     | 729/1600 [00:30<00:36, 24.19it/s]Training:  61%|██████    | 970/1600 [00:40<00:26, 24.15it/s]Training:  76%|███████▌  | 1211/1600 [00:50<00:16, 24.13it/s]Training:  91%|█████████ | 1452/1600 [01:00<00:06, 24.09it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 628.4559, Validation accuracy: 0.6700
Macro F1-score: 0.5770
Model performance on Angry speech (in validation): 
	Precision: 0.6667, Recall: 0.9600, F1_score: 0.7869
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.5362, Recall: 0.7400, F1_score: 0.6218
Model performance on Sad speech (in validation): 
	Precision: 0.8305, Recall: 0.9800, F1_score: 0.8991
Epoch 31/100

Training Phase:
Training loss: 4812.7613, Training accuracy: 0.6312
Macro F1-score: 0.5432
Model performance on Angry speech (in training): 
	Precision: 0.5238, Recall: 0.9625, F1_score: 0.6784
Model performance on Happy speech (in training): 
	Precision: 0.4000, Recall: 0.0050, F1_score: 0.0099
Model performance on Neutral speech (in training): 
	Precision: 0.6576, Recall: 0.6050, F1_score: 0.6302
Model performance on Sad speech (in training): 
	Precision: 0.7744, Recall: 0.9525, F1_score: 0.8543

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 240/1600 [00:10<00:56, 23.97it/s]Training:  30%|███       | 482/1600 [00:20<00:46, 24.09it/s]Training:  45%|████▌     | 724/1600 [00:30<00:36, 24.13it/s]Training:  60%|██████    | 966/1600 [00:40<00:26, 23.96it/s]Training:  76%|███████▌  | 1213/1600 [00:50<00:15, 24.21it/s]Training:  91%|█████████▏| 1460/1600 [01:00<00:05, 24.24it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 628.4559, Validation accuracy: 0.6700
Macro F1-score: 0.5770
Model performance on Angry speech (in validation): 
	Precision: 0.6667, Recall: 0.9600, F1_score: 0.7869
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.5362, Recall: 0.7400, F1_score: 0.6218
Model performance on Sad speech (in validation): 
	Precision: 0.8305, Recall: 0.9800, F1_score: 0.8991
Epoch 32/100

Training Phase:
Training loss: 4735.8763, Training accuracy: 0.6325
Macro F1-score: 0.5443
Model performance on Angry speech (in training): 
	Precision: 0.5295, Recall: 0.9650, F1_score: 0.6838
Model performance on Happy speech (in training): 
	Precision: 0.7500, Recall: 0.0075, F1_score: 0.0149
Model performance on Neutral speech (in training): 
	Precision: 0.6471, Recall: 0.6050, F1_score: 0.6253
Model performance on Sad speech (in training): 
	Precision: 0.7728, Recall: 0.9525, F1_score: 0.8533

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 240/1600 [00:10<00:56, 23.93it/s]Training:  30%|███       | 483/1600 [00:20<00:46, 24.13it/s]Training:  45%|████▌     | 726/1600 [00:30<00:36, 24.06it/s]Training:  61%|██████    | 970/1600 [00:40<00:26, 24.15it/s]Training:  76%|███████▌  | 1213/1600 [00:50<00:16, 24.03it/s]Training:  91%|█████████▏| 1460/1600 [01:00<00:05, 24.22it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 628.4559, Validation accuracy: 0.6700
Macro F1-score: 0.5770
Model performance on Angry speech (in validation): 
	Precision: 0.6667, Recall: 0.9600, F1_score: 0.7869
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.5362, Recall: 0.7400, F1_score: 0.6218
Model performance on Sad speech (in validation): 
	Precision: 0.8305, Recall: 0.9800, F1_score: 0.8991
Epoch 33/100

Training Phase:
Training loss: 4697.2597, Training accuracy: 0.6400
Macro F1-score: 0.5510
Model performance on Angry speech (in training): 
	Precision: 0.5443, Recall: 0.9675, F1_score: 0.6967
Model performance on Happy speech (in training): 
	Precision: 0.5000, Recall: 0.0075, F1_score: 0.0148
Model performance on Neutral speech (in training): 
	Precision: 0.6401, Recall: 0.6225, F1_score: 0.6312
Model performance on Sad speech (in training): 
	Precision: 0.7794, Recall: 0.9625, F1_score: 0.8613

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 236/1600 [00:10<00:57, 23.54it/s]Training:  30%|███       | 480/1600 [00:20<00:46, 24.00it/s]Training:  45%|████▌     | 724/1600 [00:30<00:36, 23.91it/s]Training:  61%|██████    | 970/1600 [00:40<00:26, 24.14it/s]Training:  76%|███████▌  | 1215/1600 [00:50<00:15, 24.24it/s]Training:  91%|█████████▏| 1461/1600 [01:00<00:05, 24.34it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 628.4559, Validation accuracy: 0.6700
Macro F1-score: 0.5770
Model performance on Angry speech (in validation): 
	Precision: 0.6667, Recall: 0.9600, F1_score: 0.7869
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.5362, Recall: 0.7400, F1_score: 0.6218
Model performance on Sad speech (in validation): 
	Precision: 0.8305, Recall: 0.9800, F1_score: 0.8991
Epoch 34/100

Training Phase:
Training loss: 4675.7559, Training accuracy: 0.6362
Macro F1-score: 0.5478
Model performance on Angry speech (in training): 
	Precision: 0.5331, Recall: 0.9650, F1_score: 0.6868
Model performance on Happy speech (in training): 
	Precision: 0.4000, Recall: 0.0050, F1_score: 0.0099
Model performance on Neutral speech (in training): 
	Precision: 0.6408, Recall: 0.6200, F1_score: 0.6302
Model performance on Sad speech (in training): 
	Precision: 0.7893, Recall: 0.9550, F1_score: 0.8643

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 221/1600 [00:10<01:02, 22.04it/s]Training:  28%|██▊       | 442/1600 [00:20<00:52, 21.99it/s]Training:  41%|████▏     | 662/1600 [00:30<00:42, 21.89it/s]Training:  56%|█████▌    | 896/1600 [00:40<00:31, 22.44it/s]Training:  71%|███████   | 1132/1600 [00:50<00:20, 22.83it/s]Training:  86%|████████▌ | 1368/1600 [01:00<00:10, 23.07it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 628.4559, Validation accuracy: 0.6700
Macro F1-score: 0.5770
Model performance on Angry speech (in validation): 
	Precision: 0.6667, Recall: 0.9600, F1_score: 0.7869
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.5362, Recall: 0.7400, F1_score: 0.6218
Model performance on Sad speech (in validation): 
	Precision: 0.8305, Recall: 0.9800, F1_score: 0.8991
Epoch 35/100

Training Phase:
Training loss: 4782.5535, Training accuracy: 0.6338
Macro F1-score: 0.5435
Model performance on Angry speech (in training): 
	Precision: 0.5255, Recall: 0.9800, F1_score: 0.6841
Model performance on Happy speech (in training): 
	Precision: 0.5000, Recall: 0.0025, F1_score: 0.0050
Model performance on Neutral speech (in training): 
	Precision: 0.6438, Recall: 0.5875, F1_score: 0.6144
Model performance on Sad speech (in training): 
	Precision: 0.7926, Recall: 0.9650, F1_score: 0.8703

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 234/1600 [00:10<00:58, 23.31it/s]Training:  29%|██▉       | 468/1600 [00:20<00:48, 23.32it/s]Training:  44%|████▍     | 704/1600 [00:30<00:38, 23.45it/s]Training:  59%|█████▉    | 940/1600 [00:40<00:28, 23.21it/s]Training:  73%|███████▎  | 1173/1600 [00:50<00:18, 23.23it/s]Training:  88%|████████▊ | 1406/1600 [01:00<00:08, 23.09it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 628.4559, Validation accuracy: 0.6700
Macro F1-score: 0.5770
Model performance on Angry speech (in validation): 
	Precision: 0.6667, Recall: 0.9600, F1_score: 0.7869
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.5362, Recall: 0.7400, F1_score: 0.6218
Model performance on Sad speech (in validation): 
	Precision: 0.8305, Recall: 0.9800, F1_score: 0.8991
Epoch 36/100

Training Phase:
Training loss: 4618.7625, Training accuracy: 0.6425
Macro F1-score: 0.5537
Model performance on Angry speech (in training): 
	Precision: 0.5279, Recall: 0.9700, F1_score: 0.6837
Model performance on Happy speech (in training): 
	Precision: 0.5000, Recall: 0.0050, F1_score: 0.0099
Model performance on Neutral speech (in training): 
	Precision: 0.6587, Recall: 0.6225, F1_score: 0.6401
Model performance on Sad speech (in training): 
	Precision: 0.8054, Recall: 0.9725, F1_score: 0.8811

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▍        | 238/1600 [00:10<00:57, 23.70it/s]Training:  30%|██▉       | 475/1600 [00:20<00:48, 23.39it/s]Training:  44%|████▍     | 707/1600 [00:30<00:38, 23.27it/s]Training:  59%|█████▊    | 939/1600 [00:40<00:28, 23.12it/s]Training:  73%|███████▎  | 1173/1600 [00:50<00:18, 23.22it/s]Training:  88%|████████▊ | 1407/1600 [01:00<00:08, 22.92it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 628.4559, Validation accuracy: 0.6700
Macro F1-score: 0.5770
Model performance on Angry speech (in validation): 
	Precision: 0.6667, Recall: 0.9600, F1_score: 0.7869
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.5362, Recall: 0.7400, F1_score: 0.6218
Model performance on Sad speech (in validation): 
	Precision: 0.8305, Recall: 0.9800, F1_score: 0.8991
Epoch 37/100

Training Phase:
Training loss: 4622.5944, Training accuracy: 0.6388
Macro F1-score: 0.5491
Model performance on Angry speech (in training): 
	Precision: 0.5352, Recall: 0.9700, F1_score: 0.6898
Model performance on Happy speech (in training): 
	Precision: 0.5000, Recall: 0.0050, F1_score: 0.0099
Model performance on Neutral speech (in training): 
	Precision: 0.6649, Recall: 0.6200, F1_score: 0.6417
Model performance on Sad speech (in training): 
	Precision: 0.7711, Recall: 0.9600, F1_score: 0.8552

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  14%|█▍        | 223/1600 [00:10<01:01, 22.30it/s]Training:  28%|██▊       | 446/1600 [00:20<00:52, 22.16it/s]Training:  42%|████▏     | 667/1600 [00:30<00:42, 22.12it/s]Training:  56%|█████▌    | 899/1600 [00:40<00:31, 22.53it/s]Training:  71%|███████▏  | 1140/1600 [00:50<00:19, 23.09it/s]Training:  86%|████████▋ | 1384/1600 [01:00<00:09, 23.51it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 628.4559, Validation accuracy: 0.6700
Macro F1-score: 0.5770
Model performance on Angry speech (in validation): 
	Precision: 0.6667, Recall: 0.9600, F1_score: 0.7869
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.5362, Recall: 0.7400, F1_score: 0.6218
Model performance on Sad speech (in validation): 
	Precision: 0.8305, Recall: 0.9800, F1_score: 0.8991
Epoch 38/100

Training Phase:
Training loss: 4776.6481, Training accuracy: 0.6344
Macro F1-score: 0.5454
Model performance on Angry speech (in training): 
	Precision: 0.5223, Recall: 0.9650, F1_score: 0.6778
Model performance on Happy speech (in training): 
	Precision: 0.1667, Recall: 0.0025, F1_score: 0.0049
Model performance on Neutral speech (in training): 
	Precision: 0.6612, Recall: 0.6000, F1_score: 0.6291
Model performance on Sad speech (in training): 
	Precision: 0.7886, Recall: 0.9700, F1_score: 0.8700

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 240/1600 [00:10<00:56, 23.99it/s]Training:  30%|███       | 483/1600 [00:20<00:46, 24.12it/s]Training:  45%|████▌     | 727/1600 [00:30<00:36, 24.22it/s]Training:  61%|██████    | 971/1600 [00:40<00:25, 24.23it/s]Training:  76%|███████▌  | 1214/1600 [00:50<00:15, 24.18it/s]Training:  91%|█████████ | 1456/1600 [01:00<00:05, 24.06it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 628.4559, Validation accuracy: 0.6700
Macro F1-score: 0.5770
Model performance on Angry speech (in validation): 
	Precision: 0.6667, Recall: 0.9600, F1_score: 0.7869
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.5362, Recall: 0.7400, F1_score: 0.6218
Model performance on Sad speech (in validation): 
	Precision: 0.8305, Recall: 0.9800, F1_score: 0.8991
Epoch 39/100

Training Phase:
Training loss: 4734.3848, Training accuracy: 0.6406
Macro F1-score: 0.5525
Model performance on Angry speech (in training): 
	Precision: 0.5372, Recall: 0.9750, F1_score: 0.6927
Model performance on Happy speech (in training): 
	Precision: 0.5714, Recall: 0.0100, F1_score: 0.0197
Model performance on Neutral speech (in training): 
	Precision: 0.6489, Recall: 0.6100, F1_score: 0.6289
Model performance on Sad speech (in training): 
	Precision: 0.7882, Recall: 0.9675, F1_score: 0.8687

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 242/1600 [00:10<00:56, 24.18it/s]Training:  30%|███       | 484/1600 [00:20<00:46, 24.06it/s]Training:  45%|████▌     | 724/1600 [00:30<00:36, 23.95it/s]Training:  60%|██████    | 964/1600 [00:40<00:26, 23.95it/s]Training:  75%|███████▌  | 1206/1600 [00:50<00:16, 24.02it/s]Training:  91%|█████████ | 1451/1600 [01:00<00:06, 24.18it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 628.4559, Validation accuracy: 0.6700
Macro F1-score: 0.5770
Model performance on Angry speech (in validation): 
	Precision: 0.6667, Recall: 0.9600, F1_score: 0.7869
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.5362, Recall: 0.7400, F1_score: 0.6218
Model performance on Sad speech (in validation): 
	Precision: 0.8305, Recall: 0.9800, F1_score: 0.8991
Epoch 40/100

Training Phase:
Training loss: 4732.3828, Training accuracy: 0.6281
Macro F1-score: 0.5382
Model performance on Angry speech (in training): 
	Precision: 0.5208, Recall: 0.9700, F1_score: 0.6777
Model performance on Happy speech (in training): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in training): 
	Precision: 0.6297, Recall: 0.5825, F1_score: 0.6052
Model performance on Sad speech (in training): 
	Precision: 0.7950, Recall: 0.9600, F1_score: 0.8698

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 244/1600 [00:10<00:55, 24.36it/s]Training:  30%|███       | 488/1600 [00:20<00:46, 24.16it/s]Training:  46%|████▌     | 731/1600 [00:30<00:35, 24.20it/s]Training:  61%|██████    | 975/1600 [00:40<00:25, 24.26it/s]Training:  76%|███████▌  | 1219/1600 [00:50<00:15, 24.16it/s]Training:  91%|█████████ | 1459/1600 [01:00<00:05, 23.99it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 628.4559, Validation accuracy: 0.6700
Macro F1-score: 0.5770
Model performance on Angry speech (in validation): 
	Precision: 0.6667, Recall: 0.9600, F1_score: 0.7869
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.5362, Recall: 0.7400, F1_score: 0.6218
Model performance on Sad speech (in validation): 
	Precision: 0.8305, Recall: 0.9800, F1_score: 0.8991
Epoch 41/100

Training Phase:
Training loss: 4684.6885, Training accuracy: 0.6375
Macro F1-score: 0.5505
Model performance on Angry speech (in training): 
	Precision: 0.5228, Recall: 0.9725, F1_score: 0.6801
Model performance on Happy speech (in training): 
	Precision: 0.6667, Recall: 0.0100, F1_score: 0.0197
Model performance on Neutral speech (in training): 
	Precision: 0.6685, Recall: 0.6050, F1_score: 0.6352
Model performance on Sad speech (in training): 
	Precision: 0.7889, Recall: 0.9625, F1_score: 0.8671

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 241/1600 [00:10<00:56, 24.02it/s]Training:  30%|███       | 482/1600 [00:20<00:46, 24.00it/s]Training:  30%|███       | 482/1600 [00:30<00:46, 24.00it/s]Training:  45%|████▌     | 725/1600 [00:30<00:36, 24.10it/s]Training:  61%|██████    | 969/1600 [00:40<00:26, 24.21it/s]Training:  76%|███████▌  | 1213/1600 [00:50<00:16, 24.15it/s]Training:  91%|█████████ | 1455/1600 [01:00<00:06, 24.15it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 628.4559, Validation accuracy: 0.6700
Macro F1-score: 0.5770
Model performance on Angry speech (in validation): 
	Precision: 0.6667, Recall: 0.9600, F1_score: 0.7869
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.5362, Recall: 0.7400, F1_score: 0.6218
Model performance on Sad speech (in validation): 
	Precision: 0.8305, Recall: 0.9800, F1_score: 0.8991
Epoch 42/100

Training Phase:
Training loss: 4707.4340, Training accuracy: 0.6306
Macro F1-score: 0.5411
Model performance on Angry speech (in training): 
	Precision: 0.5140, Recall: 0.9625, F1_score: 0.6701
Model performance on Happy speech (in training): 
	Precision: 0.3333, Recall: 0.0025, F1_score: 0.0050
Model performance on Neutral speech (in training): 
	Precision: 0.6581, Recall: 0.5775, F1_score: 0.6152
Model performance on Sad speech (in training): 
	Precision: 0.7887, Recall: 0.9800, F1_score: 0.8740

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 244/1600 [00:10<00:55, 24.35it/s]Training:  15%|█▌        | 244/1600 [00:20<00:55, 24.35it/s]Training:  30%|███       | 487/1600 [00:20<00:46, 24.08it/s]Training:  46%|████▌     | 730/1600 [00:30<00:36, 24.15it/s]Training:  61%|██████    | 973/1600 [00:40<00:26, 23.99it/s]Training:  76%|███████▌  | 1216/1600 [00:50<00:15, 24.10it/s]Training:  91%|█████████▏| 1462/1600 [01:00<00:05, 24.25it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 628.4559, Validation accuracy: 0.6700
Macro F1-score: 0.5770
Model performance on Angry speech (in validation): 
	Precision: 0.6667, Recall: 0.9600, F1_score: 0.7869
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.5362, Recall: 0.7400, F1_score: 0.6218
Model performance on Sad speech (in validation): 
	Precision: 0.8305, Recall: 0.9800, F1_score: 0.8991
Epoch 43/100

Training Phase:
Training loss: 4692.5102, Training accuracy: 0.6388
Macro F1-score: 0.5523
Model performance on Angry speech (in training): 
	Precision: 0.5306, Recall: 0.9750, F1_score: 0.6872
Model performance on Happy speech (in training): 
	Precision: 0.6250, Recall: 0.0125, F1_score: 0.0245
Model performance on Neutral speech (in training): 
	Precision: 0.6703, Recall: 0.6150, F1_score: 0.6415
Model performance on Sad speech (in training): 
	Precision: 0.7776, Recall: 0.9525, F1_score: 0.8562

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 246/1600 [00:10<00:55, 24.58it/s]Training:  31%|███       | 492/1600 [00:20<00:45, 24.22it/s]Training:  46%|████▌     | 732/1600 [00:30<00:36, 23.98it/s]Training:  61%|██████    | 975/1600 [00:40<00:25, 24.09it/s]Training:  76%|███████▌  | 1218/1600 [00:50<00:15, 24.01it/s]Training:  91%|█████████▏| 1460/1600 [01:00<00:05, 24.04it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 628.4559, Validation accuracy: 0.6700
Macro F1-score: 0.5770
Model performance on Angry speech (in validation): 
	Precision: 0.6667, Recall: 0.9600, F1_score: 0.7869
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.5362, Recall: 0.7400, F1_score: 0.6218
Model performance on Sad speech (in validation): 
	Precision: 0.8305, Recall: 0.9800, F1_score: 0.8991
Epoch 44/100

Training Phase:
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 242/1600 [00:10<00:56, 24.16it/s]Training:  30%|███       | 487/1600 [00:20<00:45, 24.32it/s]Training:  46%|████▌     | 732/1600 [00:30<00:35, 24.33it/s]Training:  61%|██████    | 976/1600 [00:40<00:25, 24.29it/s]Training:  76%|███████▌  | 1219/1600 [00:50<00:15, 24.21it/s]Training:  76%|███████▌  | 1219/1600 [01:04<00:15, 24.21it/s]Training:  90%|████████▉ | 1433/1600 [01:04<00:08, 20.56it/s]Training: 100%|██████████| 1600/1600 [01:14<00:00, 19.39it/s]                                                             /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Training loss: 4730.9229, Training accuracy: 0.6338
Macro F1-score: 0.5420
Model performance on Angry speech (in training): 
	Precision: 0.5212, Recall: 0.9825, F1_score: 0.6811
Model performance on Happy speech (in training): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in training): 
	Precision: 0.6734, Recall: 0.5825, F1_score: 0.6247
Model performance on Sad speech (in training): 
	Precision: 0.7760, Recall: 0.9700, F1_score: 0.8622

Eval Phase: 
Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 628.4559, Validation accuracy: 0.6700
Macro F1-score: 0.5770
Model performance on Angry speech (in validation): 
	Precision: 0.6667, Recall: 0.9600, F1_score: 0.7869
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.5362, Recall: 0.7400, F1_score: 0.6218
Model performance on Sad speech (in validation): 
	Precision: 0.8305, Recall: 0.9800, F1_score: 0.8991
Epoch 45/100

Training Phase:
Training loss: 4717.2463, Training accuracy: 0.6375
Macro F1-score: 0.5489
Model performance on Angry speech (in training): 
	Precision: 0.5206, Recall: 0.9775, F1_score: 0.6794
Model performance on Happy speech (in training): 
	Precision: 0.6667, Recall: 0.0050, F1_score: 0.0099
Model performance on Neutral speech (in training): 
	Precision: 0.6685, Recall: 0.6050, F1_score: 0.6352
Model performance on Sad speech (in training): 
	Precision: 0.7955, Recall: 0.9625, F1_score: 0.8710

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  13%|█▎        | 201/1600 [00:10<01:10, 19.94it/s]Training:  25%|██▌       | 405/1600 [00:20<00:59, 20.18it/s]Training:  39%|███▉      | 620/1600 [00:30<00:47, 20.75it/s]Training:  52%|█████▏    | 835/1600 [00:40<00:36, 20.82it/s]Training:  66%|██████▌   | 1048/1600 [00:50<00:26, 20.98it/s]Training:  79%|███████▉  | 1261/1600 [01:00<00:16, 21.08it/s]Training:  93%|█████████▎| 1485/1600 [01:10<00:05, 21.51it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 628.4559, Validation accuracy: 0.6700
Macro F1-score: 0.5770
Model performance on Angry speech (in validation): 
	Precision: 0.6667, Recall: 0.9600, F1_score: 0.7869
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.5362, Recall: 0.7400, F1_score: 0.6218
Model performance on Sad speech (in validation): 
	Precision: 0.8305, Recall: 0.9800, F1_score: 0.8991
Epoch 46/100

Training Phase:
Training loss: 4664.6479, Training accuracy: 0.6381
Macro F1-score: 0.5478
Model performance on Angry speech (in training): 
	Precision: 0.5343, Recall: 0.9725, F1_score: 0.6897
Model performance on Happy speech (in training): 
	Precision: 0.1667, Recall: 0.0025, F1_score: 0.0049
Model performance on Neutral speech (in training): 
	Precision: 0.6594, Recall: 0.6050, F1_score: 0.6310
Model performance on Sad speech (in training): 
	Precision: 0.7796, Recall: 0.9725, F1_score: 0.8654

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 243/1600 [00:10<00:55, 24.27it/s]Training:  30%|███       | 486/1600 [00:20<00:46, 24.19it/s]Training:  46%|████▌     | 730/1600 [00:30<00:35, 24.24it/s]Training:  61%|██████    | 975/1600 [00:40<00:25, 24.33it/s]Training:  76%|███████▋  | 1221/1600 [00:50<00:15, 24.42it/s]Training:  92%|█████████▏| 1467/1600 [01:00<00:05, 24.26it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 628.4559, Validation accuracy: 0.6700
Macro F1-score: 0.5770
Model performance on Angry speech (in validation): 
	Precision: 0.6667, Recall: 0.9600, F1_score: 0.7869
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.5362, Recall: 0.7400, F1_score: 0.6218
Model performance on Sad speech (in validation): 
	Precision: 0.8305, Recall: 0.9800, F1_score: 0.8991
Epoch 47/100

Training Phase:
Training loss: 4809.1000, Training accuracy: 0.6350
Macro F1-score: 0.5475
Model performance on Angry speech (in training): 
	Precision: 0.5265, Recall: 0.9700, F1_score: 0.6825
Model performance on Happy speech (in training): 
	Precision: 0.5000, Recall: 0.0100, F1_score: 0.0196
Model performance on Neutral speech (in training): 
	Precision: 0.6492, Recall: 0.5875, F1_score: 0.6168
Model performance on Sad speech (in training): 
	Precision: 0.7890, Recall: 0.9725, F1_score: 0.8712

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 241/1600 [00:10<00:56, 24.08it/s]Training:  30%|███       | 482/1600 [00:20<00:46, 23.98it/s]Training:  45%|████▌     | 722/1600 [00:30<00:36, 23.90it/s]Training:  60%|██████    | 963/1600 [00:40<00:26, 23.94it/s]Training:  76%|███████▌  | 1212/1600 [00:50<00:15, 24.28it/s]Training:  91%|█████████▏| 1461/1600 [01:00<00:05, 24.20it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 628.4559, Validation accuracy: 0.6700
Macro F1-score: 0.5770
Model performance on Angry speech (in validation): 
	Precision: 0.6667, Recall: 0.9600, F1_score: 0.7869
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.5362, Recall: 0.7400, F1_score: 0.6218
Model performance on Sad speech (in validation): 
	Precision: 0.8305, Recall: 0.9800, F1_score: 0.8991
Epoch 48/100

Training Phase:
Training loss: 4695.0152, Training accuracy: 0.6369
Macro F1-score: 0.5479
Model performance on Angry speech (in training): 
	Precision: 0.5232, Recall: 0.9600, F1_score: 0.6772
Model performance on Happy speech (in training): 
	Precision: 0.6667, Recall: 0.0050, F1_score: 0.0099
Model performance on Neutral speech (in training): 
	Precision: 0.6585, Recall: 0.6075, F1_score: 0.6320
Model performance on Sad speech (in training): 
	Precision: 0.7895, Recall: 0.9750, F1_score: 0.8725

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 246/1600 [00:10<00:55, 24.51it/s]Training:  31%|███       | 492/1600 [00:20<00:45, 24.25it/s]Training:  46%|████▌     | 733/1600 [00:30<00:35, 24.17it/s]Training:  61%|██████    | 977/1600 [00:40<00:25, 24.23it/s]Training:  76%|███████▋  | 1222/1600 [00:50<00:15, 24.30it/s]Training:  92%|█████████▏| 1467/1600 [01:00<00:05, 24.15it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 628.4559, Validation accuracy: 0.6700
Macro F1-score: 0.5770
Model performance on Angry speech (in validation): 
	Precision: 0.6667, Recall: 0.9600, F1_score: 0.7869
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.5362, Recall: 0.7400, F1_score: 0.6218
Model performance on Sad speech (in validation): 
	Precision: 0.8305, Recall: 0.9800, F1_score: 0.8991
Epoch 49/100

Training Phase:
Training loss: 4772.5934, Training accuracy: 0.6419
Macro F1-score: 0.5530
Model performance on Angry speech (in training): 
	Precision: 0.5285, Recall: 0.9725, F1_score: 0.6849
Model performance on Happy speech (in training): 
	Precision: 0.4000, Recall: 0.0050, F1_score: 0.0099
Model performance on Neutral speech (in training): 
	Precision: 0.6849, Recall: 0.6250, F1_score: 0.6536
Model performance on Sad speech (in training): 
	Precision: 0.7814, Recall: 0.9650, F1_score: 0.8635

Eval Phase: 
Training:   0%|          | 0/1600 [00:00<?, ?it/s]Training:  15%|█▌        | 241/1600 [00:10<00:56, 24.08it/s]Training:  30%|███       | 483/1600 [00:20<00:46, 24.11it/s]Training:  45%|████▌     | 725/1600 [00:30<00:36, 24.14it/s]Training:  60%|██████    | 967/1600 [00:40<00:26, 24.15it/s]Training:  76%|███████▌  | 1209/1600 [00:50<00:16, 24.14it/s]Training:  91%|█████████ | 1457/1600 [01:00<00:05, 24.35it/s]                                                             Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]                                                   /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Validation loss: 628.4559, Validation accuracy: 0.6700
Macro F1-score: 0.5770
Model performance on Angry speech (in validation): 
	Precision: 0.6667, Recall: 0.9600, F1_score: 0.7869
Model performance on Happy speech (in validation): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in validation): 
	Precision: 0.5362, Recall: 0.7400, F1_score: 0.6218
Model performance on Sad speech (in validation): 
	Precision: 0.8305, Recall: 0.9800, F1_score: 0.8991
Epoch 50/100

Two-stage training complete.
Model best accuracy on validation set: 0.6700

Test Phase: 
Testing:   0%|          | 0/200 [00:00<?, ?it/s]Testing:   1%|          | 2/200 [00:00<00:12, 15.34it/s]Testing:   2%|▎         | 5/200 [00:00<00:10, 17.85it/s]Testing:   4%|▎         | 7/200 [00:00<00:10, 18.49it/s]Testing:   6%|▌         | 11/200 [00:00<00:08, 21.82it/s]Testing:   7%|▋         | 14/200 [00:00<00:08, 22.70it/s]Testing:   8%|▊         | 17/200 [00:00<00:08, 21.61it/s]Testing:  10%|█         | 20/200 [00:00<00:08, 22.23it/s]Testing:  12%|█▏        | 24/200 [00:01<00:07, 23.94it/s]Testing:  14%|█▍        | 28/200 [00:01<00:06, 25.95it/s]Testing:  16%|█▋        | 33/200 [00:01<00:06, 27.66it/s]Testing:  20%|█▉        | 39/200 [00:01<00:04, 34.47it/s]Testing:  22%|██▏       | 44/200 [00:01<00:04, 38.27it/s]Testing:  26%|██▌       | 52/200 [00:01<00:03, 48.77it/s]Testing:  29%|██▉       | 58/200 [00:01<00:02, 50.29it/s]Testing:  32%|███▏      | 64/200 [00:01<00:02, 46.79it/s]Testing:  36%|███▌      | 72/200 [00:02<00:02, 55.10it/s]Testing:  40%|████      | 80/200 [00:02<00:01, 61.28it/s]Testing:  44%|████▍     | 89/200 [00:02<00:01, 65.09it/s]Testing:  48%|████▊     | 96/200 [00:02<00:01, 61.86it/s]Testing:  52%|█████▏    | 103/200 [00:02<00:01, 55.94it/s]Testing:  55%|█████▍    | 109/200 [00:02<00:01, 55.94it/s]Testing:  57%|█████▊    | 115/200 [00:02<00:01, 54.64it/s]Testing:  61%|██████    | 122/200 [00:02<00:01, 57.81it/s]Testing:  66%|██████▌   | 131/200 [00:02<00:01, 66.22it/s]Testing:  70%|███████   | 140/200 [00:03<00:00, 70.77it/s]Testing:  75%|███████▌  | 150/200 [00:03<00:00, 77.60it/s]Testing:  79%|███████▉  | 158/200 [00:03<00:00, 75.61it/s]Testing:  84%|████████▎ | 167/200 [00:03<00:00, 78.11it/s]Testing:  88%|████████▊ | 177/200 [00:03<00:00, 83.11it/s]Testing:  93%|█████████▎| 186/200 [00:03<00:00, 81.01it/s]Testing:  98%|█████████▊| 197/200 [00:03<00:00, 87.63it/s]                                                          /work/tc062/tc062/zhan7721/.venv/hgf/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Test loss: 593.2154, Test accuracy: 0.7000
Macro F1-score: 0.5999
Model performance on Angry speech (in test): 
	Precision: 0.6849, Recall: 1.0000, F1_score: 0.8130
Model performance on Happy speech (in test): 
	Precision: 0.0000, Recall: 0.0000, F1_score: 0.0000
Model performance on Neutral speech (in test): 
	Precision: 0.6250, Recall: 0.8000, F1_score: 0.7018
Model performance on Sad speech (in test): 
	Precision: 0.7937, Recall: 1.0000, F1_score: 0.8850

cn, all folds layer accuracy: ['0.6550', '0.7800', '0.6800', '0.6550', '0.7000']
cn, all emo precision: {'Angry': ['0.8400', '0.7812', '0.9286', '0.9388', '0.6849'], 'Happy': ['1.0000', '1.0000', '0.0000', '0.8947', '0.0000'], 'Neutral': ['0.7333', '0.6622', '0.4563', '0.6207', '0.6250'], 'Sad': ['0.4842', '0.9091', '0.9091', '0.4854', '0.7937']}
cn, all emo recall: {'Angry': ['0.8400', '1.0000', '0.7800', '0.9200', '1.0000'], 'Happy': ['0.2000', '0.1400', '0.0000', '0.3400', '0.0000'], 'Neutral': ['0.6600', '0.9800', '0.9400', '0.3600', '0.8000'], 'Sad': ['0.9200', '1.0000', '1.0000', '1.0000', '1.0000']}
cn, all emo f1score: {'Angry': ['0.8400', '0.8772', '0.8478', '0.9293', '0.8130'], 'Happy': ['0.3333', '0.2456', '0.0000', '0.4928', '0.0000'], 'Neutral': ['0.6947', '0.7903', '0.6144', '0.4557', '0.7018'], 'Sad': ['0.6345', '0.9524', '0.9524', '0.6536', '0.8850']}
